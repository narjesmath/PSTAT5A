{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"PSTAT 5A: Sampling Principles and Strategies\"\n",
        "subtitle: \"Lecture 10 - From Samples to Populations: Understanding Uncertainty\"\n",
        "author: \"Narjes Mathlouthi\"\n",
        "date: 07/21/2025\n",
        "format:\n",
        "  revealjs:\n",
        "      logo: /img/logo.png\n",
        "      theme: default\n",
        "      css: new-style.css\n",
        "      slide-number: true\n",
        "      chalkboard: true\n",
        "      preview-links: auto\n",
        "      footer: \"Understanding Data ‚Äì Sampling Principles and Strategies ¬© 2025\"\n",
        "      transition: slide\n",
        "      background-transition: fade\n",
        "      incremental: false\n",
        "      smaller: true\n",
        "jupyter: pstat5a\n",
        "execute:\n",
        "  echo: false\n",
        "  warning: false\n",
        "  message: false\n",
        "---"
      ],
      "id": "690747cf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import norm, t\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Enhanced color palette\n",
        "colors = {\n",
        "    'primary': '#3b82f6',\n",
        "    'secondary': '#f59e0b', \n",
        "    'success': '#10b981',\n",
        "    'danger': '#ef4444',\n",
        "    'info': '#8b5cf6',\n",
        "    'warning': '#f97316',\n",
        "    'light': '#f8fafc',\n",
        "    'dark': '#1f2937',\n",
        "    'accent': '#06b6d4'\n",
        "}\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ],
      "id": "146f0d79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Welcome to Lecture 10 {.center}\n",
        "\n",
        "**From Samples to Populations: Understanding Uncertainty**\n",
        "\n",
        "*\"In statistics, we make educated guesses about the whole by carefully studying a part\"*\n",
        "\n",
        "---\n",
        "\n",
        "## üì¢ Important Announcements\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "### üìù Quiz 2 Details\n",
        "**When:**  \n",
        "- üìÖ **Date:** Friday, July 25  \n",
        "- ‚è∞ **Window:** 7 AM ‚Äì 12 AM  \n",
        "- ‚è≥ **Duration:** 1 hour once started\n",
        "\n",
        "**Where:** üíª Online via Canvas\n",
        "\n",
        "**Covers:** Material from Weeks 3-4\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "### üìö What to Expect\n",
        "- Discrete & continuous distributions\n",
        "- Probability calculations\n",
        "- Expected value & variance\n",
        "- Normal distribution applications\n",
        "- **Note:** Upload photos of written work for calculation problems\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Today's Learning Journey üéØ \n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "### üß† Big Ideas We'll Explore\n",
        "- **Why sampling?** The power and necessity of statistical inference\n",
        "- **Sample behavior** - How sample means form predictable patterns\n",
        "- **Uncertainty quantification** - From point estimates to intervals\n",
        "- **The CLT magic** - Why normal distributions appear everywhere\n",
        "- **Confidence intervals** - Our bridge from samples to populations\n",
        ":::\n",
        "\n",
        "::: {.column}\n",
        "### üõ†Ô∏è Skills You'll Master\n",
        "- Design effective sampling strategies\n",
        "- Calculate and interpret standard errors\n",
        "- Apply the Central Limit Theorem\n",
        "- Construct and interpret confidence intervals\n",
        "- Choose appropriate sample sizes for desired precision\n",
        "- Recognize and avoid sampling bias\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## The Foundation: Why Do We Sample? ü§î\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "### üåç Real-World Constraints\n",
        "\n",
        "**Population vs. Sample Realities:**\n",
        "\n",
        "- **Time**: Surveying 40,000 UCSB students takes months\n",
        "  \n",
        "- **Cost**: Each measurement costs money and resources  \n",
        "  \n",
        "- **Logistics**: Some populations are impossible to reach entirely\n",
        "  \n",
        "- **Feasibility**: Testing every light bulb would destroy the product\n",
        "\n",
        "### üí° The Statistical Solution\n",
        "Use a **representative sample** to make **valid inferences** about the **entire population**\n",
        ":::\n",
        "\n",
        "::: {.column}"
      ],
      "id": "735f343b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 10,
        "fig-height": 6
      },
      "source": [
        "# Create an engaging population vs sample visualization\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=(\"üìä Population: All UCSB Students (40,000)\", \n",
        "                   \"üéØ Our Sample (400 students)\",\n",
        "                   \"üí∞ Cost Analysis\", \"‚è∞ Time Analysis\"),\n",
        "    specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}],\n",
        "           [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
        ")\n",
        "\n",
        "# Population visualization - large cloud of points\n",
        "pop_x = np.random.normal(0, 10, 2000)\n",
        "pop_y = np.random.normal(0, 10, 2000)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=pop_x, y=pop_y,\n",
        "        mode='markers',\n",
        "        marker=dict(size=2, color=colors['primary'], opacity=0.4),\n",
        "        showlegend=False,\n",
        "        name=\"Population\"\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Sample visualization - highlighted subset\n",
        "sample_indices = np.random.choice(2000, 50, replace=False)\n",
        "sample_x = pop_x[sample_indices]\n",
        "sample_y = pop_y[sample_indices]\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=sample_x, y=sample_y,\n",
        "        mode='markers',\n",
        "        marker=dict(size=8, color=colors['danger'], opacity=0.9),\n",
        "        showlegend=False,\n",
        "        name=\"Sample\"\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Cost comparison\n",
        "approaches = ['Full Population', 'Smart Sample']\n",
        "costs = [200000, 2000]  # In dollars\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Bar(\n",
        "        x=approaches, y=costs,\n",
        "        marker_color=[colors['danger'], colors['success']],\n",
        "        showlegend=False,\n",
        "        text=[f'${cost:,}' for cost in costs],\n",
        "        textposition='auto'\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "# Time comparison  \n",
        "times = [180, 7]  # In days\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Bar(\n",
        "        x=approaches, y=times,\n",
        "        marker_color=[colors['danger'], colors['success']],\n",
        "        showlegend=False,\n",
        "        text=[f'{time} days' for time in times],\n",
        "        textposition='auto'\n",
        "    ),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,\n",
        "    showlegend=False\n",
        "    # title_text=\"The Power of Smart Sampling\"\n",
        ")\n",
        "\n",
        "fig.update_yaxes(title_text=\"Cost ($)\", row=2, col=1)\n",
        "fig.update_yaxes(title_text=\"Time (days)\", row=2, col=2)\n",
        "\n",
        "fig.show()"
      ],
      "id": "ca232d7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Study Design: The Foundation of Good Inference"
      ],
      "id": "19a0ce1f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 7
      },
      "source": [
        "# Create comprehensive study design visualization\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=3,\n",
        "    subplot_titles=(\"üîç Observational Study\", \"üß™ Randomized Experiment\", \"üìä Sample vs Population\",\n",
        "                   \"‚ö†Ô∏è Confounding Variables\", \"üé≤ Randomization Effect\", \"üìà Statistical Power\"),\n",
        "    specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"histogram\"}],\n",
        "           [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"scatter\"}]]\n",
        ")\n",
        "\n",
        "# Observational Study - showing correlation but potential confounding\n",
        "obs_x = np.random.normal(0, 1, 100)\n",
        "obs_y = 2*obs_x + np.random.normal(0, 0.5, 100)  # Strong correlation\n",
        "colors_obs = np.where(obs_x > 0, colors['primary'], colors['secondary'])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=obs_x, y=obs_y,\n",
        "        mode='markers',\n",
        "        marker=dict(size=6, color=colors_obs, opacity=0.7),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Randomized Experiment - clear treatment effect\n",
        "np.random.seed(123)\n",
        "control_group = np.random.normal(10, 2, 50)\n",
        "treatment_group = np.random.normal(15, 2, 50)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=['Control']*50,\n",
        "        y=control_group,\n",
        "        mode='markers',\n",
        "        marker=dict(size=6, color=colors['danger'], opacity=0.7),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=['Treatment']*50,\n",
        "        y=treatment_group,\n",
        "        mode='markers',\n",
        "        marker=dict(size=6, color=colors['success'], opacity=0.7),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Sample vs Population distribution\n",
        "population_data = np.random.exponential(2, 1000)\n",
        "sample_data = np.random.choice(population_data, 100)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=population_data,\n",
        "        name=\"Population\",\n",
        "        marker_color=colors['primary'],\n",
        "        opacity=0.6,\n",
        "        nbinsx=50\n",
        "    ),\n",
        "    row=1, col=3\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=sample_data,\n",
        "        name=\"Sample\",\n",
        "        marker_color=colors['danger'],\n",
        "        opacity=0.8,\n",
        "        nbinsx=20\n",
        "    ),\n",
        "    row=1, col=3\n",
        ")\n",
        "\n",
        "# Confounding variables illustration\n",
        "age = np.random.uniform(20, 80, 100)\n",
        "exercise = 5 - 0.05*age + np.random.normal(0, 0.5, 100)  # Exercise decreases with age\n",
        "health = 100 - 0.3*age + 2*exercise + np.random.normal(0, 3, 100)  # Health affected by both\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=exercise, y=health,\n",
        "        mode='markers',\n",
        "        marker=dict(size=6, color=age, colorscale='Viridis', opacity=0.7),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "# Randomization effect demonstration\n",
        "# Without randomization - biased assignment\n",
        "without_rand_x = np.concatenate([np.random.normal(-1, 0.5, 30), np.random.normal(1, 0.5, 30)])\n",
        "without_rand_y = np.concatenate([np.random.normal(45, 5, 30), np.random.normal(75, 5, 30)])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=without_rand_x, y=without_rand_y,\n",
        "        mode='markers',\n",
        "        marker=dict(size=6, color=colors['danger'], opacity=0.7),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# Statistical power illustration\n",
        "effect_sizes = np.array([0, 0.2, 0.5, 0.8, 1.2])\n",
        "power_values = [0.05, 0.17, 0.50, 0.80, 0.95]\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=effect_sizes, y=power_values,\n",
        "        mode='markers+lines',\n",
        "        marker=dict(size=10, color=colors['info']),\n",
        "        line=dict(color=colors['info'], width=3),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=2, col=3\n",
        ")\n",
        "\n",
        "# Update layout and axes\n",
        "fig.update_layout(\n",
        "    height=700,\n",
        "    showlegend=False\n",
        "    # title_text=\"Study Design Fundamentals\"\n",
        ")\n",
        "\n",
        "# Add axis labels\n",
        "fig.update_xaxes(title_text=\"Variable X\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Variable Y\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Group\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Outcome\", row=1, col=2)\n",
        "fig.update_xaxes(title_text=\"Value\", row=1, col=3)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=1, col=3)\n",
        "fig.update_xaxes(title_text=\"Exercise Level\", row=2, col=1)\n",
        "fig.update_yaxes(title_text=\"Health Score\", row=2, col=1)\n",
        "fig.update_xaxes(title_text=\"Group Assignment\", row=2, col=2)\n",
        "fig.update_yaxes(title_text=\"Outcome\", row=2, col=2)\n",
        "fig.update_xaxes(title_text=\"Effect Size\", row=2, col=3)\n",
        "fig.update_yaxes(title_text=\"Statistical Power\", row=2, col=3)\n",
        "\n",
        "fig.show()"
      ],
      "id": "2723b176",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::: {.columns}\n",
        "::: {.column}\n",
        "**üîç Observational Studies:**\n",
        "- Observe what naturally occurs\n",
        "- Good for identifying associations\n",
        "- ‚ö†Ô∏è Cannot establish causation due to confounding\n",
        ":::\n",
        "\n",
        "::: {.column}\n",
        "**üß™ Randomized Experiments:**\n",
        "- Actively assign treatments randomly\n",
        "- Controls for confounding variables\n",
        "- ‚úÖ Can establish causal relationships\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Types of Sampling Methods üéØ\n",
        "\n",
        ":::: {.columns}\n",
        "### üìã Probability Sampling Methods\n",
        "\n",
        "::: {.column width = \"20%\" .left}\n",
        "**1. Simple Random Sampling (SRS)**\n",
        "\n",
        "Every individual has equal chance of selection\n",
        "  \n",
        "*Gold standard for inference*\n",
        "\n",
        "**2. Stratified Sampling**\n",
        "\n",
        "Divide population into **groups (strata)**\n",
        "  \n",
        "Sample *randomly* within each <i>group</i>\n",
        "  \n",
        "Ensures representation of subgroups\n",
        "\n",
        ":::\n",
        "\n",
        ":::{.column width = \"20%\" .right}\n",
        "\n",
        "**3. Cluster Sampling**  \n",
        "\n",
        "Divide into clusters, randomly select clusters\n",
        "  \n",
        "Sample all/some individuals within chosen clusters\n",
        "  \n",
        "Cost-effective for large populations\n",
        "\n",
        "**4. Systematic Sampling**\n",
        "\n",
        "Select every $kth$ individual from ordered list\n",
        "  \n",
        "Simple but can introduce **bias** if pattern exists\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.column width = \"60%\" .right}"
      ],
      "id": "80924815"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 10,
        "fig-height": 8
      },
      "source": [
        "# Visualization of different sampling methods\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=(\"Simple Random Sampling\", \"Stratified Sampling\",\n",
        "                   \"Cluster Sampling\", \"Systematic Sampling\")\n",
        ")\n",
        "\n",
        "# Simple Random Sampling\n",
        "np.random.seed(42)\n",
        "all_x = np.random.uniform(0, 10, 200)\n",
        "all_y = np.random.uniform(0, 10, 200)\n",
        "selected = np.random.choice(200, 30, replace=False)\n",
        "\n",
        "# Plot all points\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=all_x, y=all_y,\n",
        "        mode='markers',\n",
        "        marker=dict(size=4, color=colors['dark'], opacity=0.5),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Plot selected points\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=all_x[selected], y=all_y[selected],\n",
        "        mode='markers',\n",
        "        marker=dict(size=8, color=colors['primary']),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Stratified Sampling\n",
        "strata_colors = [colors['primary'], colors['danger'], colors['success'], colors['info']]\n",
        "for i in range(4):\n",
        "    # Create stratum\n",
        "    # Draw rectangle to show stratum boundary\n",
        "    fig.add_shape(\n",
        "        type=\"rect\",\n",
        "        x0=i * 2.5, y0=0,\n",
        "        x1=(i + 1) * 2.5, y1=10,\n",
        "        line=dict(color=\"LightGray\", dash=\"dot\"),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    stratum_x = np.random.uniform(i*2.5, (i+1)*2.5, 50)\n",
        "    stratum_y = np.random.uniform(0, 10, 50)\n",
        "    \n",
        "    # All points in stratum\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=stratum_x, y=stratum_y,\n",
        "            mode='markers',\n",
        "            marker=dict(size=4, color=colors['dark'], opacity=0.5),\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    # Selected points from stratum\n",
        "    selected_from_stratum = np.random.choice(50, 8, replace=False)\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=stratum_x[selected_from_stratum], \n",
        "            y=stratum_y[selected_from_stratum],\n",
        "            mode='markers',\n",
        "            marker=dict(size=10, color=strata_colors[i]),\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# Cluster Sampling\n",
        "clusters = []\n",
        "for i in range(4):\n",
        "    for j in range(4):\n",
        "        cluster_x = np.random.uniform(i*2.5, i*2.5+2, 15) \n",
        "        cluster_y = np.random.uniform(j*2.5, j*2.5+2, 15)\n",
        "        clusters.append((cluster_x, cluster_y))\n",
        "        # Draw grid rectangles to make cluster boundaries explicit\n",
        "        for gx in range(4):\n",
        "            for gy in range(4):\n",
        "                fig.add_shape(\n",
        "                    type=\"rect\",\n",
        "                    x0=gx * 2.5, y0=gy * 2.5,\n",
        "                    x1=gx * 2.5 + 2, y1=gy * 2.5 + 2,\n",
        "                    line=dict(color=\"LightGray\", dash=\"dot\"),\n",
        "                    row=2, col=1\n",
        "                )\n",
        "\n",
        "# Show all clusters lightly\n",
        "for cluster_x, cluster_y in clusters:\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=cluster_x, y=cluster_y,\n",
        "            mode='markers',\n",
        "            marker=dict(size=4, color=colors['dark'], opacity=0.5),\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# Highlight selected clusters\n",
        "selected_clusters = [0, 5, 10, 15]  # Select 4 clusters\n",
        "for idx in selected_clusters:\n",
        "    cluster_x, cluster_y = clusters[idx]\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=cluster_x, y=cluster_y,\n",
        "            mode='markers',\n",
        "            marker=dict(size=10, color=colors['success']),\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# Systematic Sampling\n",
        "systematic_x = np.linspace(0, 10, 100)\n",
        "systematic_y = 2 + 0.5*systematic_x + np.random.normal(0, 0.5, 100)\n",
        "\n",
        "# All points\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=systematic_x, y=systematic_y,\n",
        "        mode='markers',\n",
        "        marker=dict(size=4, color=colors['dark'], opacity=0.5),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# Every 5th point\n",
        "systematic_selected = systematic_x[::5]\n",
        "systematic_y_selected = systematic_y[::5]\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=systematic_selected, y=systematic_y_selected,\n",
        "        mode='markers',\n",
        "        marker=dict(size=8, color=colors['primary']),\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,\n",
        "    showlegend=False\n",
        "    # title_text=\"Sampling Method Comparison\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "id": "32335d0a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Sampling Bias: What Can Go Wrong? ‚ö†Ô∏è\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "### üö® Common Types of Bias\n",
        "\n",
        "**Selection Bias**\n",
        "- Systematic exclusion of certain groups\n",
        "- Example: Online surveys miss non-internet users\n",
        "\n",
        "**Response Bias**  \n",
        "- Who chooses to respond affects results\n",
        "- Example: Satisfaction surveys - unhappy customers more likely to respond\n",
        "\n",
        "**Nonresponse Bias**\n",
        "- Missing data isn't random\n",
        "- Example: Wealthy people less likely to disclose income\n",
        "\n",
        "**Convenience Sampling**\n",
        "- Sampling whoever is easiest to reach\n",
        "- Example: Surveying only students in your dorm\n",
        ":::\n",
        "\n",
        "::: {.column}"
      ],
      "id": "de4f4c87"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 10,
        "fig-height": 6
      },
      "source": [
        "# Demonstrate sampling bias effects\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=(\"True Population Distribution\", \"Biased Sample (Selection Bias)\",\n",
        "                   \"Response Bias Effect\", \"Convenience Sample Bias\")\n",
        ")\n",
        "\n",
        "# True population - normal distribution\n",
        "true_population = np.random.normal(100, 15, 1000)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=true_population,\n",
        "        name=\"True Population\",\n",
        "        marker_color=colors['success'],\n",
        "        opacity=0.7,\n",
        "        nbinsx=30\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Biased sample - only select from upper portion\n",
        "biased_sample = true_population[true_population > 110]\n",
        "if len(biased_sample) > 100:\n",
        "    biased_sample = np.random.choice(biased_sample, 100, replace=False)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=biased_sample,\n",
        "        name=\"Biased Sample\",\n",
        "        marker_color=colors['danger'],\n",
        "        opacity=0.7,\n",
        "        nbinsx=20\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Response bias - extreme values more likely to respond\n",
        "response_weights = np.abs(true_population - 100) + 0.1  # Extreme values get higher weights\n",
        "response_sample = np.random.choice(true_population, 100, p=response_weights/response_weights.sum())\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=response_sample,\n",
        "        name=\"Response Bias\",\n",
        "        marker_color=colors['warning'],\n",
        "        opacity=0.7,\n",
        "        nbinsx=20\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "# Convenience sample - only from one location/cluster\n",
        "convenience_sample = np.random.normal(85, 8, 100)  # Different mean than population\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=convenience_sample,\n",
        "        name=\"Convenience Sample\",\n",
        "        marker_color=colors['info'],\n",
        "        opacity=0.7,\n",
        "        nbinsx=20\n",
        "    ),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# Add mean lines\n",
        "for i, (data, color) in enumerate([\n",
        "    (true_population, colors['success']),\n",
        "    (biased_sample, colors['danger']),\n",
        "    (response_sample, colors['warning']),\n",
        "    (convenience_sample, colors['info'])\n",
        "]):\n",
        "    row = 1 if i < 2 else 2\n",
        "    col = 1 if i % 2 == 0 else 2\n",
        "    \n",
        "    fig.add_vline(\n",
        "        x=np.mean(data),\n",
        "        line_dash=\"dash\",\n",
        "        line_color=color,\n",
        "        line_width=3,\n",
        "        row=row, col=col\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=500,\n",
        "    showlegend=False\n",
        "    # title_text=\"How Sampling Bias Distorts Results\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "id": "d323ed87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**üí° Key Insight:** Bias can't be fixed by increasing sample size!\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## The Magic of Sample Means: From Chaos to Order \n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "**üé≤ The Setup:** \n",
        "\n",
        "- Take **many** samples from the same population\n",
        "  \n",
        "- Calculate the mean of each sample  \n",
        "  \n",
        "- Plot all these sample means\n",
        "  \n",
        "- **Observe the magic!**\n",
        "\n",
        "**üéØ What We Discover:**\n",
        "\n",
        "- Sample means cluster around the true population mean\n",
        "  \n",
        "- They form a predictable pattern (normal distribution!)\n",
        "  \n",
        "- **Larger samples give more consistent results**\n",
        ":::\n",
        "\n",
        "::: {.column}"
      ],
      "id": "be47777c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 8
      },
      "source": [
        "# Comprehensive sampling distribution demonstration\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=(\"Population Distribution (Skewed)\", \"Individual Sample Distributions\",\n",
        "                   \"Sampling Distribution of Means\", \"Effect of Sample Size\")\n",
        ")\n",
        "\n",
        "# Create a skewed population\n",
        "np.random.seed(42)\n",
        "population = np.concatenate([\n",
        "    np.random.exponential(2, 3000),\n",
        "    np.random.exponential(1, 2000)\n",
        "])\n",
        "population_mean = np.mean(population)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=population,\n",
        "        name=\"Population\",\n",
        "        marker_color=colors['primary'],\n",
        "        opacity=0.7,\n",
        "        nbinsx=50\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Show a few individual samples\n",
        "sample_colors = [colors['danger'], colors['warning'], colors['info']]\n",
        "for i in range(3):\n",
        "    sample = np.random.choice(population, 50)\n",
        "    fig.add_trace(\n",
        "        go.Histogram(\n",
        "            x=sample,\n",
        "            name=f\"Sample {i+1}\",\n",
        "            marker_color=sample_colors[i],\n",
        "            opacity=0.6,\n",
        "            nbinsx=25\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# Generate many sample means\n",
        "sample_sizes = [10, 30, 100]\n",
        "for j, n in enumerate(sample_sizes):\n",
        "    sample_means = []\n",
        "    for i in range(1000):\n",
        "        sample = np.random.choice(population, n)\n",
        "        sample_means.append(np.mean(sample))\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Histogram(\n",
        "            x=sample_means,\n",
        "            name=f\"n={n}\",\n",
        "            marker_color=[colors['danger'], colors['success'], colors['info']][j],\n",
        "            opacity=0.6,\n",
        "            nbinsx=30\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# Effect of sample size on standard error\n",
        "sample_sizes_range = np.array([5, 10, 20, 30, 50, 100, 200])\n",
        "population_std = np.std(population)\n",
        "standard_errors = population_std / np.sqrt(sample_sizes_range)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=sample_sizes_range,\n",
        "        y=standard_errors,\n",
        "        mode='markers+lines',\n",
        "        marker=dict(size=10, color=colors['primary']),\n",
        "        line=dict(color=colors['primary'], width=3),\n",
        "        name='Standard Error'\n",
        "    ),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# Add population mean lines\n",
        "fig.add_vline(x=population_mean, line_dash=\"dash\", line_color=\"black\", \n",
        "              line_width=2, row=1, col=1)\n",
        "fig.add_vline(x=population_mean, line_dash=\"dash\", line_color=\"black\", \n",
        "              line_width=2, row=2, col=1)\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,\n",
        "    showlegend=False\n",
        "    # title_text=\"The Journey from Individual Samples to Sampling Distribution\"\n",
        ")\n",
        "\n",
        "# Update axes\n",
        "fig.update_xaxes(title_text=\"Value\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Value\", row=1, col=2)\n",
        "fig.update_xaxes(title_text=\"Sample Mean\", row=2, col=1)\n",
        "fig.update_xaxes(title_text=\"Sample Size (n)\", row=2, col=2)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=2, col=1)\n",
        "fig.update_yaxes(title_text=\"Standard Error\", row=2, col=2)\n",
        "\n",
        "fig.show()"
      ],
      "id": "ebdf6601",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## The Central Limit Theorem üåü\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column .smaller}\n",
        "### üìê The Statement\n",
        "\n",
        "For a population with mean $\\mu$ and standard deviation $\\sigma$, when sample size $n$ is large enough:\n",
        "\n",
        "$$\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$$\n",
        "\n",
        "Or equivalently:\n",
        "$$Z = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)$$\n",
        "\n",
        "### ‚ú® The Magic Rules\n",
        "- **Rule of Thumb:** $n \\geq 30$ usually works\n",
        "- **Shape doesn't matter:** Works for ANY population distribution  \n",
        "- **Larger $n$ = Better approximation**\n",
        ":::\n",
        "\n",
        "::: {.column}"
      ],
      "id": "1cb77536"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 10
      },
      "source": [
        "# Comprehensive CLT demonstration with different population shapes\n",
        "populations = {\n",
        "    'Uniform': np.random.uniform(0, 10, 5000),\n",
        "    'Exponential': np.random.exponential(2, 5000),\n",
        "    'Bimodal': np.concatenate([np.random.normal(3, 1, 2500), np.random.normal(8, 1, 2500)]),\n",
        "    'Extremely Skewed': np.concatenate([np.random.exponential(0.5, 4000), [20]*1000])\n",
        "}\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=4, cols=4,\n",
        "    subplot_titles=[f'{dist} Population' if i == 0 else f'n={[5, 15, 50][i-1]} Sample Means' \n",
        "                   for dist in populations.keys() for i in range(4)],\n",
        "    horizontal_spacing=0.08,\n",
        "    vertical_spacing=0.06\n",
        ")\n",
        "\n",
        "colors_list = [colors['primary'], colors['danger'], colors['success'], colors['info']]\n",
        "\n",
        "for row, (pop_name, pop_data) in enumerate(populations.items()):\n",
        "    # Population distribution\n",
        "    fig.add_trace(\n",
        "        go.Histogram(\n",
        "            x=pop_data,\n",
        "            name=f\"{pop_name} Population\",\n",
        "            marker_color=colors_list[row],\n",
        "            opacity=0.7,\n",
        "            nbinsx=40\n",
        "        ),\n",
        "        row=row+1, col=1\n",
        "    )\n",
        "    \n",
        "    # Sample means for different sample sizes\n",
        "    sample_sizes = [5, 15, 50]\n",
        "    for col_idx, n in enumerate(sample_sizes):\n",
        "        sample_means = []\n",
        "        for _ in range(1000):\n",
        "            sample = np.random.choice(pop_data, n)\n",
        "            sample_means.append(np.mean(sample))\n",
        "        \n",
        "        fig.add_trace(\n",
        "            go.Histogram(\n",
        "                x=sample_means,\n",
        "                name=f\"{pop_name} n={n}\",\n",
        "                marker_color=colors_list[row],\n",
        "                opacity=0.7,\n",
        "                nbinsx=30\n",
        "            ),\n",
        "            row=row+1, col=col_idx+2\n",
        "        )\n",
        "        \n",
        "        # Add normal overlay for larger samples\n",
        "        if n >= 15:\n",
        "            x_norm = np.linspace(min(sample_means), max(sample_means), 100)\n",
        "            y_norm = stats.norm.pdf(x_norm, np.mean(sample_means), np.std(sample_means))\n",
        "            # Scale to histogram\n",
        "            y_norm = y_norm * len(sample_means) * (max(sample_means) - min(sample_means)) / 30\n",
        "            \n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=x_norm, y=y_norm,\n",
        "                    mode='lines',\n",
        "                    line=dict(color='red', width=3, dash='dash'),\n",
        "                    name='Normal Approximation',\n",
        "                    showlegend=False\n",
        "                ),\n",
        "                row=row+1, col=col_idx+2\n",
        "            )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=800,\n",
        "    showlegend=False\n",
        "    #title_text=\"Central Limit Theorem: The Universal Pattern\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "id": "e59d10f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Standard Error: Measuring Our Uncertainty üìè\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "### üéØ What is Standard Error?\n",
        "\n",
        "**Standard Error (SE)** measures how much sample means vary from sample to sample.\n",
        "\n",
        "$$SE = \\frac{\\sigma}{\\sqrt{n}} \\text{ (when } \\sigma \\text{ is known)}$$\n",
        "\n",
        "$$SE = \\frac{s}{\\sqrt{n}} \\text{ (usual case, } \\sigma \\text{ unknown)}$$\n",
        "\n",
        "### üîç Key Insights\n",
        "- **Smaller SE** = More precise estimates\n",
        "- **SE decreases** as sample size increases\n",
        "- **Rate of decrease:** $SE \\propto 1/\\sqrt{n}$\n",
        "- **4√ó larger sample** = ¬Ω the uncertainty!\n",
        ":::\n",
        "\n",
        "::: {.column}"
      ],
      "id": "2446d826"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 10,
        "fig-height": 8
      },
      "source": [
        "# Interactive demonstration of standard error\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=(\"Effect of Sample Size on SE\", \"Sampling Distributions for Different n\",\n",
        "                   \"Precision vs. Sample Size\", \"Cost-Benefit Analysis\")\n",
        ")\n",
        "\n",
        "# Effect of sample size on SE\n",
        "sample_sizes = np.array([5, 10, 20, 30, 50, 100, 200, 500])\n",
        "sigma = 15  # Population standard deviation\n",
        "standard_errors = sigma / np.sqrt(sample_sizes)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=sample_sizes,\n",
        "        y=standard_errors,\n",
        "        mode='markers+lines',\n",
        "        marker=dict(size=12, color=colors['primary']),\n",
        "        line=dict(color=colors['primary'], width=3),\n",
        "        name='Standard Error'\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Add inverse square root function for comparison\n",
        "theoretical_se = sigma / np.sqrt(sample_sizes)\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=sample_sizes,\n",
        "        y=theoretical_se,\n",
        "        mode='lines',\n",
        "        line=dict(color=colors['danger'], width=2, dash='dash'),\n",
        "        name='Theoretical SE',\n",
        "        showlegend=False\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Sampling distributions for different sample sizes\n",
        "np.random.seed(42)\n",
        "population_mean = 100\n",
        "sample_sizes_demo = [10, 30, 100]\n",
        "colors_demo = [colors['danger'], colors['warning'], colors['success']]\n",
        "\n",
        "for i, n in enumerate(sample_sizes_demo):\n",
        "    sample_means = []\n",
        "    for _ in range(1000):\n",
        "        sample = np.random.normal(population_mean, sigma, n)\n",
        "        sample_means.append(np.mean(sample))\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Histogram(\n",
        "            x=sample_means,\n",
        "            name=f'n={n}, SE={sigma/np.sqrt(n):.2f}',\n",
        "            marker_color=colors_demo[i],\n",
        "            opacity=0.7,\n",
        "            nbinsx=30\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# Precision vs Sample Size (Width of 95% CI)\n",
        "ci_widths = 2 * 1.96 * standard_errors  # 95% CI width\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=sample_sizes,\n",
        "        y=ci_widths,\n",
        "        mode='markers+lines',\n",
        "        marker=dict(size=10, color=colors['info']),\n",
        "        line=dict(color=colors['info'], width=3),\n",
        "        name='95% CI Width'\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "# Cost-benefit analysis\n",
        "costs = sample_sizes * 10  # $10 per participant\n",
        "precision_gained = 1 / standard_errors  # Inverse of SE as precision measure\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=costs,\n",
        "        y=precision_gained,\n",
        "        mode='markers+lines',\n",
        "        marker=dict(size=10, color=colors['secondary']),\n",
        "        line=dict(color=colors['secondary'], width=3),\n",
        "        name='Precision per Dollar'\n",
        "    ),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# Add annotations\n",
        "fig.add_annotation(\n",
        "    x=100, y=5,\n",
        "    text=\"Diminishing returns:<br>Each additional participant<br>helps less and less\",\n",
        "    showarrow=True,\n",
        "    arrowhead=2,\n",
        "    arrowcolor=colors['danger'],\n",
        "    font=dict(size=10),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,\n",
        "    showlegend=False\n",
        "    #title_text=\"Understanding Standard Error\"\n",
        ")\n",
        "\n",
        "# Update axes labels\n",
        "fig.update_xaxes(title_text=\"Sample Size (n)\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Standard Error\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Sample Mean Value\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
        "fig.update_xaxes(title_text=\"Sample Size (n)\", row=2, col=1)\n",
        "fig.update_yaxes(title_text=\"95% CI Width\", row=2, col=1)\n",
        "fig.update_xaxes(title_text=\"Total Cost ($)\", row=2, col=2)\n",
        "fig.update_yaxes(title_text=\"Precision Gained\", row=2, col=2)\n",
        "\n",
        "fig.show()"
      ],
      "id": "bae04fa6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Confidence Intervals: Our Bridge to the Population üåâ\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "### üéØ What Are Confidence Intervals?\n",
        "\n",
        "A **confidence interval** gives us a range of plausible values for the population parameter.\n",
        "\n",
        "**For a population mean:**\n",
        "$$\\bar{x} \\pm z^* \\cdot \\frac{s}{\\sqrt{n}}$$\n",
        "\n",
        "### üî¢ Common Confidence Levels\n",
        "- **90% CI:** $z^* = 1.645$\n",
        "- **95% CI:** $z^* = 1.96$ \n",
        "- **99% CI:** $z^* = 2.576$\n",
        "\n",
        "### üí≠ Correct Interpretation\n",
        "\"We are 95% confident that the true population mean lies between [lower bound] and [upper bound]\"\n",
        ":::\n",
        "\n",
        "::: {.column}"
      ],
      "id": "40c86441"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 8
      },
      "source": [
        "# Comprehensive confidence interval demonstration\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=(\"Multiple 95% CIs from Different Samples\", \"Effect of Confidence Level\",\n",
        "                   \"Effect of Sample Size\", \"CI Interpretation Simulation\")\n",
        ")\n",
        "\n",
        "# Multiple CIs from different samples\n",
        "np.random.seed(42)\n",
        "true_mean = 100\n",
        "population_std = 15\n",
        "n = 30\n",
        "\n",
        "# Generate 20 different samples and their CIs\n",
        "sample_means = []\n",
        "ci_lowers = []\n",
        "ci_uppers = []\n",
        "contains_true = []\n",
        "\n",
        "for i in range(20):\n",
        "    sample = np.random.normal(true_mean, population_std, n)\n",
        "    x_bar = np.mean(sample)\n",
        "    se = population_std / np.sqrt(n)\n",
        "    \n",
        "    ci_lower = x_bar - 1.96 * se\n",
        "    ci_upper = x_bar + 1.96 * se\n",
        "    \n",
        "    sample_means.append(x_bar)\n",
        "    ci_lowers.append(ci_lower)\n",
        "    ci_uppers.append(ci_upper)\n",
        "    contains_true.append(ci_lower <= true_mean <= ci_upper)\n",
        "\n",
        "# Plot CIs\n",
        "for i in range(20):\n",
        "    color = colors['success'] if contains_true[i] else colors['danger']\n",
        "    \n",
        "    # CI line\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=[ci_lowers[i], ci_uppers[i]],\n",
        "            y=[i, i],\n",
        "            mode='lines',\n",
        "            line=dict(color=color, width=3),\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # Sample mean point\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=[sample_means[i]],\n",
        "            y=[i],\n",
        "            mode='markers',\n",
        "            marker=dict(color=color, size=8),\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "# True mean line\n",
        "fig.add_vline(x=true_mean, line_dash=\"solid\", line_color=\"black\", \n",
        "              line_width=3, row=1, col=1)\n",
        "\n",
        "# Effect of confidence level\n",
        "confidence_levels = [0.90, 0.95, 0.99]\n",
        "z_values = [1.645, 1.96, 2.576]\n",
        "colors_conf = [colors['info'], colors['primary'], colors['warning']]\n",
        "\n",
        "sample_mean = 100\n",
        "se = 2.5\n",
        "\n",
        "for i, (conf, z_val, color) in enumerate(zip(confidence_levels, z_values, colors_conf)):\n",
        "    ci_lower = sample_mean - z_val * se\n",
        "    ci_upper = sample_mean + z_val * se\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=[ci_lower, ci_upper],\n",
        "            y=[i, i],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color=color, width=6),\n",
        "            marker=dict(color=color, size=10),\n",
        "            name=f'{int(conf*100)}% CI',\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "# Effect of sample size\n",
        "sample_sizes = [10, 30, 100, 300]\n",
        "colors_size = [colors['danger'], colors['warning'], colors['success'], colors['info']]\n",
        "\n",
        "for i, (n, color) in enumerate(zip(sample_sizes, colors_size)):\n",
        "    se = population_std / np.sqrt(n)\n",
        "    ci_lower = sample_mean - 1.96 * se\n",
        "    ci_upper = sample_mean + 1.96 * se\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=[ci_lower, ci_upper],\n",
        "            y=[i, i],\n",
        "            mode='lines+markers',\n",
        "            line=dict(color=color, width=6),\n",
        "            marker=dict(color=color, size=10),\n",
        "            name=f'n={n}',\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "# CI coverage simulation\n",
        "coverage_rates = []\n",
        "sample_sizes_coverage = range(10, 201, 10)\n",
        "\n",
        "for n in sample_sizes_coverage:\n",
        "    hits = 0\n",
        "    for _ in range(100):  # 100 simulations per sample size\n",
        "        sample = np.random.normal(true_mean, population_std, n)\n",
        "        x_bar = np.mean(sample)\n",
        "        se = population_std / np.sqrt(n)\n",
        "        \n",
        "        ci_lower = x_bar - 1.96 * se\n",
        "        ci_upper = x_bar + 1.96 * se\n",
        "        \n",
        "        if ci_lower <= true_mean <= ci_upper:\n",
        "            hits += 1\n",
        "    \n",
        "    coverage_rates.append(hits / 100)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=list(sample_sizes_coverage),\n",
        "        y=coverage_rates,\n",
        "        mode='markers+lines',\n",
        "        marker=dict(color=colors['primary'], size=8),\n",
        "        line=dict(color=colors['primary'], width=3),\n",
        "        name='Actual Coverage Rate'\n",
        "    ),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# Add 95% reference line\n",
        "fig.add_hline(y=0.95, line_dash=\"dash\", line_color=\"red\", \n",
        "              line_width=2, row=2, col=2)\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,\n",
        "    showlegend=False\n",
        "    #title_text=\"Understanding Confidence Intervals\"\n",
        ")\n",
        "\n",
        "# Update axes\n",
        "fig.update_xaxes(title_text=\"Value\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Sample Number\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Value\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Confidence Level\", row=1, col=2)\n",
        "fig.update_xaxes(title_text=\"Value\", row=2, col=1)\n",
        "fig.update_yaxes(title_text=\"Sample Size\", row=2, col=1)\n",
        "fig.update_xaxes(title_text=\"Sample Size\", row=2, col=2)\n",
        "fig.update_yaxes(title_text=\"Coverage Rate\", row=2, col=2)\n",
        "\n",
        "fig.show()"
      ],
      "id": "2db1cf5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Sample Size Planning: Getting It Right üéØ\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "### üìê The Formula\n",
        "\n",
        "To achieve margin of error $E$ with confidence level $(1-\\alpha)$:\n",
        "\n",
        "$$n = \\left(\\frac{z^*\\sigma}{E}\\right)^2$$\n",
        "\n",
        "### üéØ Key Considerations\n",
        "\n",
        "**Margin of Error Trade-offs:**\n",
        "- Smaller $E$ requires larger $n$\n",
        "- Higher confidence requires larger $n$  \n",
        "- More variable population requires larger $n$\n",
        "\n",
        "**Practical Constraints:**\n",
        "- Budget limitations\n",
        "- Time constraints  \n",
        "- Availability of participants\n",
        ":::\n",
        "\n",
        "::: {.column}"
      ],
      "id": "3d9e87a5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 12,
        "fig-height": 8
      },
      "source": [
        "# Sample size planning visualization\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=(\"Sample Size vs. Margin of Error\", \"Sample Size vs. Confidence Level\",\n",
        "                   \"Cost-Precision Trade-off\", \"Power Analysis\")\n",
        ")\n",
        "\n",
        "# Sample size vs margin of error\n",
        "sigma = 10\n",
        "z_star = 1.96\n",
        "margins_of_error = np.linspace(0.5, 5, 50)\n",
        "sample_sizes_me = (z_star * sigma / margins_of_error) ** 2\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=margins_of_error,\n",
        "        y=sample_sizes_me,\n",
        "        mode='lines+markers',\n",
        "        marker=dict(color=colors['primary'], size=6),\n",
        "        line=dict(color=colors['primary'], width=3),\n",
        "        name='Required Sample Size'\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Sample size vs confidence level\n",
        "confidence_levels = np.linspace(0.80, 0.99, 50)\n",
        "z_values = stats.norm.ppf(1 - (1 - confidence_levels) / 2)\n",
        "margin_of_error = 2\n",
        "sample_sizes_conf = (z_values * sigma / margin_of_error) ** 2\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=confidence_levels * 100,\n",
        "        y=sample_sizes_conf,\n",
        "        mode='lines+markers',\n",
        "        marker=dict(color=colors['success'], size=6),\n",
        "        line=dict(color=colors['success'], width=3),\n",
        "        name='Required Sample Size'\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Cost-precision trade-off\n",
        "cost_per_participant = 50\n",
        "total_costs = sample_sizes_me * cost_per_participant\n",
        "precision = 1 / margins_of_error  # Inverse of margin of error\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=total_costs,\n",
        "        y=precision,\n",
        "        mode='lines+markers',\n",
        "        marker=dict(color=colors['warning'], size=6),\n",
        "        line=dict(color=colors['warning'], width=3),\n",
        "        name='Precision per Dollar'\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "# Power analysis - effect of sample size on power\n",
        "effect_sizes = [0.2, 0.5, 0.8]  # Small, medium, large effect sizes\n",
        "colors_power = [colors['info'], colors['success'], colors['danger']]\n",
        "sample_sizes_power = np.arange(10, 201, 10)\n",
        "\n",
        "for i, effect_size in enumerate(effect_sizes):\n",
        "    power_values = []\n",
        "    for n in sample_sizes_power:\n",
        "        se = sigma / np.sqrt(n)\n",
        "        z_score = effect_size * np.sqrt(n) / sigma\n",
        "        power = 1 - stats.norm.cdf(1.96 - z_score)  # One-tailed test\n",
        "        power_values.append(power)\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=sample_sizes_power,\n",
        "            y=power_values,\n",
        "            mode='lines+markers',\n",
        "            marker=dict(color=colors_power[i], size=4),\n",
        "            line=dict(color=colors_power[i], width=3),\n",
        "            name=f'Effect Size = {effect_size}',\n",
        "            showlegend=False\n",
        "        ),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "# Add power = 0.8 reference line\n",
        "fig.add_hline(y=0.8, line_dash=\"dash\", line_color=\"red\", \n",
        "              line_width=2, row=2, col=2)\n",
        "\n",
        "# Add annotations\n",
        "fig.add_annotation(\n",
        "    x=3, y=400,\n",
        "    text=\"Diminishing returns:<br>Small improvements in<br>precision cost a lot!\",\n",
        "    showarrow=True,\n",
        "    arrowhead=2,\n",
        "    arrowcolor=colors['danger'],\n",
        "    font=dict(size=10),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.add_annotation(\n",
        "    x=15000, y=1.5,\n",
        "    text=\"Sweet spot:<br>Good precision<br>without breaking<br>the budget\",\n",
        "    showarrow=True,\n",
        "    arrowhead=2,\n",
        "    arrowcolor=colors['success'],\n",
        "    font=dict(size=10),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,\n",
        "    showlegend=False,\n",
        "    #title_text=\"Strategic Sample Size Planning\"\n",
        ")\n",
        "\n",
        "# Update axes\n",
        "fig.update_xaxes(title_text=\"Margin of Error\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Required Sample Size\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Confidence Level (%)\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Required Sample Size\", row=1, col=2)\n",
        "fig.update_xaxes(title_text=\"Total Cost ($)\", row=2, col=1)\n",
        "fig.update_yaxes(title_text=\"Precision\", row=2, col=1)\n",
        "fig.update_xaxes(title_text=\"Sample Size\", row=2, col=2)\n",
        "fig.update_yaxes(title_text=\"Statistical Power\", row=2, col=2)\n",
        "\n",
        "fig.show()"
      ],
      "id": "4fa150be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Putting It All Together: A Real Example üìä\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "### üéØ Research Question\n",
        "**\"What is the average height of UCSB students?\"**\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "1. **Population:** All 26,000 UCSB students\n",
        "   \n",
        "2. **Sample:** Random sample of 100 students  \n",
        "   \n",
        "3. **Measurement:** Height in inches\n",
        "   \n",
        "4. **Goal:** 95% confidence interval for population mean\n",
        "\n",
        "**Results:**\n",
        "\n",
        "- Sample mean: $\\bar{x} = 68.2$ inches\n",
        "  \n",
        "- Sample std dev: $s = 4.1$ inches  \n",
        "  \n",
        "- Sample size: $n = 100$\n",
        ":::\n",
        "\n",
        "::: {.column}"
      ],
      "id": "8f2c7435"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 10,
        "fig-height": 6
      },
      "source": [
        "# Real example walkthrough\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulate the \"true\" population\n",
        "true_population_mean = 68.0\n",
        "true_population_std = 4.2\n",
        "population_heights = np.random.normal(true_population_mean, true_population_std, 26000)\n",
        "\n",
        "# Our sample\n",
        "sample_size = 100\n",
        "sample_heights = np.random.choice(population_heights, sample_size)\n",
        "sample_mean = np.mean(sample_heights)\n",
        "sample_std = np.std(sample_heights, ddof=1)\n",
        "\n",
        "# Calculate confidence interval\n",
        "se = sample_std / np.sqrt(sample_size)\n",
        "z_star = 1.96\n",
        "ci_lower = sample_mean - z_star * se\n",
        "ci_upper = sample_mean + z_star * se\n",
        "\n",
        "# Create visualization\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=2,\n",
        "    subplot_titles=(\"Population vs. Sample\", \"95% Confidence Interval\")\n",
        ")\n",
        "\n",
        "# Population histogram\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=population_heights,\n",
        "        name=\"Population (26,000 students)\",\n",
        "        marker_color=colors['primary'],\n",
        "        opacity=0.6,\n",
        "        nbinsx=50\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Sample histogram\n",
        "fig.add_trace(\n",
        "    go.Histogram(\n",
        "        x=sample_heights,\n",
        "        name=\"Our Sample (100 students)\",\n",
        "        marker_color=colors['danger'],\n",
        "        opacity=0.8,\n",
        "        nbinsx=20\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Confidence interval visualization\n",
        "x_range = np.linspace(ci_lower - 1, ci_upper + 1, 1000)\n",
        "y_normal = stats.norm.pdf(x_range, sample_mean, se)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=x_range, y=y_normal,\n",
        "        mode='lines',\n",
        "        line=dict(color=colors['primary'], width=3),\n",
        "        name='Sampling Distribution'\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Shade the confidence interval\n",
        "ci_mask = (x_range >= ci_lower) & (x_range <= ci_upper)\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=np.concatenate([x_range[ci_mask], [ci_upper, ci_lower]]),\n",
        "        y=np.concatenate([y_normal[ci_mask], [0, 0]]),\n",
        "        fill='toself',\n",
        "        fillcolor='rgba(59, 130, 246, 0.3)',\n",
        "        line=dict(color='rgba(0,0,0,0)'),\n",
        "        name='95% Confidence Interval'\n",
        "    ),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Add vertical lines\n",
        "fig.add_vline(x=sample_mean, line_dash=\"solid\", line_color=colors['danger'], \n",
        "              line_width=3, row=1, col=2)\n",
        "fig.add_vline(x=true_population_mean, line_dash=\"dash\", line_color=colors['success'], \n",
        "              line_width=3, row=1, col=2)\n",
        "fig.add_vline(x=ci_lower, line_dash=\"dot\", line_color=colors['warning'], \n",
        "              line_width=2, row=1, col=2)\n",
        "fig.add_vline(x=ci_upper, line_dash=\"dot\", line_color=colors['warning'], \n",
        "              line_width=2, row=1, col=2)\n",
        "\n",
        "# Add annotations\n",
        "annotations = [\n",
        "    dict(x=sample_mean, y=1.05, yref='paper',\n",
        "         text=f\"<b>Sample Mean = {sample_mean:.2f}</b>\",\n",
        "         showarrow=False, xanchor='center'),\n",
        "    dict(x=true_population_mean, y=1.10, yref='paper',\n",
        "         text=f\"<b>True Mean = {true_population_mean:.1f}</b>\",\n",
        "         showarrow=False, xanchor='center'),\n",
        "    dict(x=(ci_lower + ci_upper)/2, y=0.5, yref='paper',\n",
        "         text=f\"<b>95% CI: ({ci_lower:.2f}, {ci_upper:.2f})</b>\",\n",
        "         showarrow=False, xanchor='center', \n",
        "         bgcolor=\"rgba(255,255,255,0.8)\", bordercolor=\"black\")\n",
        "]\n",
        "\n",
        "fig.update_layout(\n",
        "    annotations=annotations,\n",
        "    height=400,\n",
        "    showlegend=False\n",
        "    # title_text=f\"UCSB Student Height Analysis: Sample Mean = {sample_mean:.2f} inches\"\n",
        ")\n",
        "\n",
        "fig.update_xaxes(title_text=\"Height (inches)\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
        "fig.update_xaxes(title_text=\"Height (inches)\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Probability Density\", row=1, col=2)\n",
        "\n",
        "fig.show()"
      ],
      "id": "7b56b0a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**üéØ Interpretation:** We are 95% confident that the true average height of UCSB students is between 67.40 and 69.00 inches.\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Key Takeaways: Your Statistical Toolkit üéØ\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "### üß† Fundamental Concepts\n",
        "\n",
        "**1. Sampling Wisdom**\n",
        "\n",
        "- Representative samples beat large biased samples\n",
        "  \n",
        "- Randomization is your best friend\n",
        "  \n",
        "- **Bias can't be fixed with larger samples**\n",
        "\n",
        "**2. The CLT Magic**  \n",
        "\n",
        "- Sample means are approximately normal ($n ‚â• 30$)\n",
        "  \n",
        "- Works for ANY population distribution\n",
        "  \n",
        "- Enables powerful statistical inference\n",
        "\n",
        "**3. Standard Error**\n",
        "\n",
        "- Measures precision of our estimates\n",
        "  \n",
        "- Decreases with $\\sqrt{n}$, not $n$\n",
        "  \n",
        "- Key ingredient in confidence intervals\n",
        ":::\n",
        "\n",
        "::: {.column}\n",
        "### üõ†Ô∏è Practical Skills\n",
        "\n",
        "**4. Confidence Intervals**\n",
        "\n",
        "- Quantify uncertainty in our estimates\n",
        "  \n",
        "- Correct interpretation is crucial\n",
        "  \n",
        "- Width depends on confidence level and sample size\n",
        "\n",
        "**5. Sample Size Planning**\n",
        "\n",
        "- Balance precision needs with resources\n",
        "  \n",
        "- Consider margin of error requirements\n",
        "  \n",
        "- Account for practical constraints\n",
        "\n",
        "**6. Quality Control**\n",
        "\n",
        "- Always check for potential bias\n",
        "  \n",
        "- Verify assumptions (normality, independence)\n",
        "  \n",
        "- Consider the broader context\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Common Misconceptions to Avoid ‚ö†Ô∏è"
      ],
      "id": "941c1ac3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 14,
        "fig-height": 6
      },
      "source": [
        "# Create misconceptions clarification chart\n",
        "misconceptions = [\n",
        "    (\"‚ùå WRONG\", \"‚úÖ CORRECT\"),\n",
        "    (\"'95% probability the mean\\nis in our specific interval'\", \"'95% of intervals constructed\\nthis way contain the true mean'\"),\n",
        "    (\"'Larger sample always\\nbetter regardless of cost'\", \"'Balance sample size with\\nprecision needs and budget'\"),\n",
        "    (\"'Bias disappears with\\nlarge enough sample'\", \"'Bias requires design fixes,\\nnot just more data'\"),\n",
        "    (\"'Normal population required\\nfor CLT to work'\", \"'CLT works for ANY population\\nshape with n ‚â• 30'\"),\n",
        "    (\"'Confidence interval contains\\nall reasonable values'\", \"'CI contains plausible values\\nfor the population parameter'\")\n",
        "]\n",
        "\n",
        "fig = go.Figure(data=[go.Table(\n",
        "    header=dict(\n",
        "        values=['<b>‚ùå Common Misconception</b>', '<b>‚úÖ Correct Understanding</b>'],\n",
        "        fill_color=[colors['danger'], colors['success']],\n",
        "        font=dict(size=14, color='white'),\n",
        "        align=\"center\",\n",
        "        height=40\n",
        "    ),\n",
        "    cells=dict(\n",
        "        values=[[item[0] for item in misconceptions[1:]], \n",
        "                [item[1] for item in misconceptions[1:]]],\n",
        "        fill_color=[['#ffebee']*5, ['#e8f5e8']*5],\n",
        "        font=dict(size=12),\n",
        "        align=\"center\",\n",
        "        height=60\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig.update_layout(\n",
        "    height=400,\n",
        "    width=900,\n",
        "    title_text=\"Clear Up These Common Misconceptions\",\n",
        "    margin=dict(l=20, r=20, t=60, b=20)\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "id": "70b98785",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Interactive Practice: Test Your Understanding üß™\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "### ü§î Check Questions\n",
        "\n",
        "**1. Sample Size Question:**\n",
        "If we want to halve our margin of error, by what factor should we increase our sample size?\n",
        "\n",
        "**2. CLT Application:**  \n",
        "A population has a right-skewed distribution. What can we say about the distribution of sample means when n = 50?\n",
        "\n",
        "**3. CI Interpretation:**\n",
        "We calculated a 95% CI as (45, 55). What does this mean?\n",
        "\n",
        "**4. Bias Detection:**\n",
        "An online survey about internet usage gets 10,000 responses. What type of bias might be present?\n",
        ":::\n",
        "\n",
        "::: {.column .fragment}\n",
        "### ‚úÖ  Answers\n",
        "\n",
        "**1.** Increase by factor of **4** (since $SE \\propto \\frac{1}{\\sqrt{n}}$)\n",
        "\n",
        "**2.** Sample means will be **approximately normal** regardless of population shape\n",
        "\n",
        "**3.** We're **95% confident** the true population parameter is between 45 and 55\n",
        "\n",
        "**4.** **Selection bias** - excludes people without internet access\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Comprehensive Resources üìö\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "### üìñ Required Reading\n",
        "- **OpenIntro Statistics**\n",
        "  - Section 1.3: Sampling principles and strategies\n",
        "  - Section 3.3: Confidence intervals for a mean\n",
        "  - Section 4.1: Central Limit Theorem\n",
        "\n",
        "### üé• Video Resources\n",
        "- [**Khan Academy:** Central Limit Theorem](https://www.khanacademy.org/math/ap-statistics/sampling-distribution-ap/what-is-sampling-distribution/v/central-limit-theorem)\n",
        "- [**StatQuest:** Confidence Intervals Explained](https://www.youtube.com/watch?v=TqOeMYtOc1w) \n",
        "- [**3Blue1Brown:** Central Limit Theorem Visualization](https://www.3blue1brown.com/lessons/clt)\n",
        "\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.column}\n",
        "\n",
        "### üíª Interactive Tools\n",
        "- [**Seeing Theory:** Probability Visualizations](https://seeing-theory.brown.edu/)\n",
        "- [**Rossman & Chance Applets:** Sampling Distributions](https://www.rossmanchance.com/applets/OneSample53.html?population=model)\n",
        "- [**Central Limit Theorem Simulator**](http://www.ltcconline.net/greenl/java/Statistics/clt/cltsimulation.html)\n",
        "  \n",
        "### ü§ù Getting Help\n",
        "- **Office Hours:** Thursday 11 AM-12 PM (Zoom link on Canvas)\n",
        "- **Email:** nmathlouthi@ucsb.edu\n",
        "\n",
        "### üéØ What's Next?\n",
        "**Next Lecture:** Hypothesis Testing and p-values\n",
        ":::\n",
        "::::\n",
        "\n",
        "---\n",
        "\n",
        "## Questions & Discussion ü§î\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column}\n",
        "### üí≠ Think About This...\n",
        "\n",
        "*\"The goal is not to eliminate uncertainty, but to understand and quantify it intelligently\"*\n",
        "\n",
        "**Key Questions for Reflection:**\n",
        "\n",
        "- How do we balance precision with practicality?\n",
        "  \n",
        "- When might a larger sample actually be worse?\n",
        "  \n",
        "- What makes a \"good\" confidence interval?\n",
        "  \n",
        "- How do we communicate uncertainty to non-statisticians?\n",
        ":::\n",
        "\n",
        "::: {.column}\n",
        "### üéØ Prepare for Next Class\n",
        "\n",
        "**Coming Up:** Hypothesis Testing\n",
        "\n",
        "- What are null and alternative hypotheses?\n",
        "  \n",
        "- How do we make decisions with data?\n",
        "  \n",
        "- What does a p-value really mean?\n",
        "  \n",
        "\n",
        "**Recommended Prep:**\n",
        "\n",
        "- Review today's confidence interval concepts\n",
        "  \n",
        "- Think about yes/no questions you'd test with data\n",
        "  \n",
        "- Consider what \"statistical significance\" means to you\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "# Thank You! üéâ\n",
        "\n",
        "**Remember:** Great statisticians aren't born knowing these concepts, they're developed through practice and curiosity!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```{=html}\n",
        "<a href=\"https://pstat5a.com/schedule.html\" class=\"main-page-btn\">üè† Back to Main Page</a>\n",
        "```\n"
      ],
      "id": "a0f174d1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "pstat5a",
      "language": "python",
      "display_name": "Python (pstat5a)",
      "path": "/Users/narjesmathlouthi/Library/Jupyter/kernels/pstat5a"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}