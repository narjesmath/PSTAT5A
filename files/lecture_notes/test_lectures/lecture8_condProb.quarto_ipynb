{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"PSTAT 5A: Conditional Probabilities\"\n",
        "subtitle: \"Lecture 6\"\n",
        "author: \"Narjes Mathlouthi\"\n",
        "date: today\n",
        "format: \n",
        "  revealjs:\n",
        "    logo: /img/logo.png\n",
        "    theme: default\n",
        "    css: /files/lecture_notes/theme/lecture-styles.css\n",
        "    slide-number: true\n",
        "    chalkboard: true\n",
        "    preview-links: auto\n",
        "    footer: \"Understanding Data - Conditional Probabilities © 2025 Narjes Mathlouthi\"\n",
        "    transition: slide\n",
        "    background-transition: fade\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "## Welcome to Lecture 6 {.center}\n",
        "\n",
        "**Conditional Probabilities**\n",
        "\n",
        "*Understanding probability when information changes the game*\n",
        "\n",
        "---\n",
        "\n",
        "## Today's Learning Objectives\n",
        "\n",
        "By the end of this lecture, you will be able to:\n",
        "\n",
        "- Define and calculate conditional probabilities\n",
        "- Apply the multiplication rule for dependent events\n",
        "- Use tree diagrams to solve multi-stage problems\n",
        "- Apply the law of total probability\n",
        "- Use Bayes' theorem to solve real-world problems\n",
        "- Distinguish between independence and conditional independence\n",
        "- Recognize and avoid common conditional probability fallacies\n",
        "\n",
        "---\n",
        "\n",
        "## Motivation: Why Conditional Probability?\n",
        "\n",
        "In real life, we rarely make decisions with no information\n",
        "\n",
        "**Examples:**\n",
        "- Medical diagnosis with test results\n",
        "- Weather forecast with current conditions  \n",
        "- Investment decisions with market data\n",
        "- Sports betting with team statistics\n",
        "- Insurance premiums based on risk factors\n",
        "\n",
        ":::{.fragment}\n",
        "*Conditional probability helps us update our beliefs when we gain new information*\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## What is Conditional Probability?\n",
        "\n",
        "**Conditional Probability** is the probability of an event occurring, given that another event has already occurred\n",
        "\n",
        "**Notation**: $P(A|B)$ read as \"probability of A given B\"\n",
        "\n",
        ":::{.fragment}\n",
        "**Key insight**: When we know B has occurred, our sample space effectively \"shrinks\" to only outcomes where B is true\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Intuitive Example\n",
        "\n",
        "You roll a fair six-sided die, but before revealing the result, someone tells you \"the number is even\"\n",
        "\n",
        "What's the probability it's a 4?\n",
        "\n",
        ":::{.fragment}\n",
        "**Without information**: $P(\\text{rolling 4}) = \\frac{1}{6}$\n",
        "\n",
        "**With information**: $P(\\text{4 | even}) = ?$\n",
        "\n",
        "Given it's even, possible outcomes: $\\{2, 4, 6\\}$\n",
        "So $P(\\text{4 | even}) = \\frac{1}{3}$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Formal Definition\n",
        "\n",
        "For events A and B where $P(B) > 0$:\n",
        "\n",
        "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
        "\n",
        ":::{.fragment}\n",
        "\n",
        "**Interpretation**: \n",
        "\n",
        "- **Numerator:** Outcomes where both A and B occur\n",
        "  \n",
        "- **Denominator:** All outcomes where B occurs\n",
        "    \n",
        "- **Ratio:** Fraction of B-outcomes where A also occurs\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Understanding the Formula\n",
        "\n",
        "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
        "\n",
        "**Why this formula makes sense:**\n",
        "\n",
        "- We restrict our attention to outcomes where B occurs\n",
        "  \n",
        "- Among those outcomes, what fraction also have A?\n",
        "  \n",
        "- This is exactly $\\frac{P(A \\cap B)}{P(B)}$\n",
        "\n",
        ":::{.fragment}\n",
        "**Rearranging**: $P(A \\cap B) = P(A|B) \\times P(B)$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Practice Problem 1\n",
        "\n",
        "A card is drawn from a standard 52-card deck. Find:\n",
        "\n",
        "a) $P(\\text{King | Face card})$\n",
        "b) $P(\\text{Heart | Red card})$  \n",
        "c) $P(\\text{Ace | Black card})$\n",
        "\n",
        ":::{.fragment}\n",
        "**Solutions:**\n",
        "\n",
        "a) $P(\\text{King | Face}) = \\frac{4}{12} = \\frac{1}{3}$ (4 kings among 12 face cards)\n",
        "\n",
        "b) $P(\\text{Heart | Red}) = \\frac{13}{26} = \\frac{1}{2}$ (13 hearts among 26 red cards)\n",
        "\n",
        "c) $P(\\text{Ace | Black}) = \\frac{2}{26} = \\frac{1}{13}$ (2 black aces among 26 black cards)\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Two-Way Tables\n",
        "\n",
        "Two-way tables are excellent for conditional probability problems\n",
        "\n",
        "**Example**: Survey of 1000 people about coffee preference\n",
        "\n",
        "|          | Coffee | No Coffee | Total |\n",
        "|----------|--------|-----------|-------|\n",
        "| Morning  | 350    | 150       | 500   |\n",
        "| Evening  | 200    | 300       | 500   |\n",
        "| **Total**| 550    | 450       | 1000  |\n",
        "\n",
        "---\n",
        "\n",
        "## Using Two-Way Tables\n",
        "\n",
        "Find: $P(\\text{Coffee | Morning person})$\n",
        "\n",
        "From the table:\n",
        "\n",
        "- Morning people: 500\n",
        "  \n",
        "- Morning people who drink coffee: 350\n",
        "\n",
        ":::{.fragment}\n",
        "$P(\\text{Coffee | Morning}) = \\frac{350}{500} = 0.7$\n",
        "\n",
        "**Compare to**: $P(\\text{Coffee}) = \\frac{550}{1000} = 0.55$\n",
        "\n",
        "Being a morning person increases coffee probability!\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Practice Problem 2\n",
        "\n",
        "Using the coffee table, find:\n",
        "\n",
        "a) $P(\\text{Morning | Coffee drinker})$\n",
        "\n",
        "b) $P(\\text{No Coffee | Evening person})$\n",
        "\n",
        "c) $P(\\text{Evening | No Coffee})$\n",
        "\n",
        ":::{.fragment}\n",
        "**Solutions:**\n",
        "\n",
        "a) $P(\\text{Morning | Coffee}) = \\frac{350}{550} = \\frac{7}{11} \\approx 0.636$\n",
        "\n",
        "b) $P(\\text{No Coffee | Evening}) = \\frac{300}{500} = 0.6$  \n",
        "\n",
        "c) $P(\\text{Evening | No Coffee}) = \\frac{300}{450} = \\frac{2}{3} \\approx 0.667$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Independence Revisited\n",
        "\n",
        "Events A and B are **independent** if knowing that B occurred doesn't change the probability of A\n",
        "\n",
        "$$P(A|B) = P(A)$$\n",
        "\n",
        "**Equivalently:**\n",
        "$$P(A \\cap B) = P(A) \\times P(B)$$\n",
        "\n",
        ":::{.fragment}\n",
        "**Example**: Two coin flips are independent because $P(\\text{H}_2 | \\text{H}_1) = P(\\text{H}_2) = 0.5$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Testing for Independence\n",
        "\n",
        "**Method 1**: Check if $P(A|B) = P(A)$\n",
        "\n",
        "**Method 2**: Check if $P(A \\cap B) = P(A) \\times P(B)$  \n",
        "\n",
        "**Method 3**: Check if $P(B|A) = P(B)$\n",
        "\n",
        ":::{.fragment}\n",
        "**Coffee Example**: Are coffee preference and time preference independent?\n",
        "\n",
        "$P(\\text{Coffee}) = 0.55$\n",
        "\n",
        "$P(\\text{Coffee | Morning}) = 0.7$\n",
        "\n",
        "Since $0.7 \\neq 0.55$, they are **not independent**\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## The Multiplication Rule\n",
        "\n",
        "**General Multiplication Rule**:\n",
        "$$P(A \\cap B) = P(A) \\times P(B|A) = P(B) \\times P(A|B)$$\n",
        "\n",
        "**For Independent Events**:\n",
        "$$P(A \\cap B) = P(A) \\times P(B)$$\n",
        "\n",
        ":::{.fragment}\n",
        "**Extension to Multiple Events**:\n",
        "$$P(A_1 \\cap A_2 \\cap A_3) = P(A_1) \\times P(A_2|A_1) \\times P(A_3|A_1 \\cap A_2)$$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Multiplication Rule Example\n",
        "\n",
        "A jar contains 5 red balls and 3 blue balls. Two balls are drawn **without replacement**. What's the probability both are red?\n",
        "\n",
        ":::{.fragment}\n",
        "Let $R_1$ = first ball is red, $R_2$ = second ball is red\n",
        "\n",
        "$P(R_1 \\cap R_2) = P(R_1) \\times P(R_2|R_1)$\n",
        "\n",
        "$= \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Practice Problem 3\n",
        "\n",
        "A box contains 4 defective and 6 working items. Three items are selected without replacement. Find the probability that:\n",
        "\n",
        "a) All three work\n",
        "b) The first two work and the third is defective\n",
        "c) Exactly two work\n",
        "\n",
        ":::{.fragment}\n",
        "**Solutions:**\n",
        "a) $P(\\text{WWW}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}$\n",
        "\n",
        "b) $P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Practice Problem 3 (continued)\n",
        "\n",
        "c) Exactly two work (three scenarios: WWD, WDW, DWW)\n",
        "\n",
        "$P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{1}{6}$\n",
        "\n",
        "$P(\\text{WDW}) = \\frac{6}{10} \\times \\frac{4}{9} \\times \\frac{5}{8} = \\frac{1}{6}$\n",
        "\n",
        "$P(\\text{DWW}) = \\frac{4}{10} \\times \\frac{6}{9} \\times \\frac{5}{8} = \\frac{1}{6}$\n",
        "\n",
        ":::{.fragment}\n",
        "Total: $\\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{1}{2}$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        ":::{.hidden}\n",
        "## Tree Diagrams\n",
        "\n",
        "Tree diagrams help visualize sequential events and conditional probabilities\n",
        "\n",
        "```\n",
        "                    0.5   Red\n",
        "            0.6 ──┐\n",
        "                    0.5   Blue\n",
        "Ball 1      \n",
        "                    0.4   Red  \n",
        "            0.4 ──┐\n",
        "                    0.6   Blue\n",
        "```\n",
        "\n",
        "*Each branch shows conditional probabilities*\n",
        "\n",
        "---\n",
        "\n",
        "## Tree Diagram Example\n",
        "\n",
        "Medical test scenario:\n",
        "- 2% of population has disease\n",
        "- Test is 95% accurate for sick people  \n",
        "- Test is 90% accurate for healthy people\n",
        "\n",
        "What's the probability of testing positive?\n",
        "\n",
        "---\n",
        "\n",
        "## Tree Diagram Solution\n",
        "\n",
        "```\n",
        "                    0.95   Test +\n",
        "            0.02 ──┐\n",
        "                    0.05   Test -\n",
        "Disease?    \n",
        "                    0.10   Test +\n",
        "            0.98 ──┐\n",
        "                    0.90   Test -\n",
        "```\n",
        "\n",
        ":::{.fragment}\n",
        "$P(\\text{Test+}) = P(\\text{Test+|Disease}) \\times P(\\text{Disease}) + P(\\text{Test+|Healthy}) \\times P(\\text{Healthy})$\n",
        "\n",
        "$= 0.95 \\times 0.02 + 0.10 \\times 0.98 = 0.019 + 0.098 = 0.117$\n",
        ":::\n",
        ":::\n",
        "---\n",
        "\n",
        "## Law of Total Probability\n",
        "\n",
        "If events $B_1, B_2, \\ldots, B_n$ form a **partition** of the sample space (mutually exclusive and exhaustive), then:\n",
        "\n",
        "$$P(A) = \\sum_{i=1}^{n} P(A|B_i) \\times P(B_i)$$\n",
        "\n",
        ":::{.fragment}\n",
        "**Partition means**:\n",
        "\n",
        "- $B_i \\cap B_j = \\emptyset$ for $i \\neq j$ (mutually exclusive)\n",
        "  \n",
        "- $\\bigcup_{i=1}^{n} B_i = S$ (exhaustive)\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Law of Total Probability Example\n",
        "\n",
        "A factory has three machines:\n",
        "- Machine A: 50% of production, 1% defective\n",
        "- Machine B: 30% of production, 2% defective  \n",
        "- Machine C: 20% of production, 3% defective\n",
        "\n",
        "What's the overall defect rate?\n",
        "\n",
        ":::{.fragment}\n",
        "$P(\\text{Defective}) = P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)$\n",
        "\n",
        "$= 0.01 \\times 0.5 + 0.02 \\times 0.3 + 0.03 \\times 0.2$\n",
        "\n",
        "$= 0.005 + 0.006 + 0.006 = 0.017 = 1.7\\%$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Practice Problem 4\n",
        "\n",
        "A student studies for an exam with three possible outcomes based on study time:\n",
        "- Studies hard (40%): 90% chance of passing\n",
        "- Studies moderately (35%): 70% chance of passing  \n",
        "- Doesn't study (25%): 30% chance of passing\n",
        "\n",
        "What's the overall probability of passing?\n",
        "\n",
        ":::{.fragment}\n",
        "$P(\\text{Pass}) = 0.9 \\times 0.4 + 0.7 \\times 0.35 + 0.3 \\times 0.25$\n",
        "\n",
        "$= 0.36 + 0.245 + 0.075 = 0.68$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Bayes' Theorem\n",
        "\n",
        "**The Foundation**: We often want to \"reverse\" conditional probabilities\n",
        "\n",
        "Given: $P(B|A)$, $P(A)$, $P(B)$\n",
        "Want: $P(A|B)$\n",
        "\n",
        "**Bayes' Theorem**:\n",
        "$$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$$\n",
        "\n",
        "---\n",
        "\n",
        "## Bayes' Theorem Components\n",
        "\n",
        "$$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$$\n",
        "\n",
        "- $P(A|B)$: **Posterior probability** (what we want)\n",
        "- $P(B|A)$: **Likelihood** (what we observe)  \n",
        "- $P(A)$: **Prior probability** (initial belief)\n",
        "- $P(B)$: **Evidence** (marginal probability)\n",
        "\n",
        ":::{.fragment}\n",
        "*\"In light of evidence B, how should we update our belief in A?\"*\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Bayes' Theorem with Total Probability\n",
        "\n",
        "When we need to find $P(B)$:\n",
        "\n",
        "$$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B|A) \\times P(A) + P(B|A^c) \\times P(A^c)}$$\n",
        "\n",
        "This is the most common form for applications\n",
        "\n",
        "---\n",
        "\n",
        "## Medical Diagnosis Example\n",
        "\n",
        "Revisiting our medical test:\n",
        "- 2% of population has disease (prior)\n",
        "- Test positive (evidence)  \n",
        "- Test is 95% accurate for sick, 90% accurate for healthy\n",
        "\n",
        "Given a positive test, what's the probability of having the disease?\n",
        "\n",
        "---\n",
        "\n",
        "## Medical Diagnosis Solution\n",
        "\n",
        "Let D = disease, T+ = positive test\n",
        "\n",
        "$$P(D|T+) = \\frac{P(T+|D) \\times P(D)}{P(T+|D) \\times P(D) + P(T+|D^c) \\times P(D^c)}$$\n",
        "\n",
        "$$= \\frac{0.95 \\times 0.02}{0.95 \\times 0.02 + 0.10 \\times 0.98}$$\n",
        "\n",
        "$$= \\frac{0.019}{0.019 + 0.098} = \\frac{0.019}{0.117} \\approx 0.162$$\n",
        "\n",
        ":::{.fragment}\n",
        "**Surprising**: Only 16.2% chance of disease despite positive test!\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Why the Low Probability?\n",
        "\n",
        "**Base Rate Fallacy**: When disease is rare (2%), most positive tests are false positives\n",
        "\n",
        "**Intuition**: Out of 10,000 people:\n",
        "- 200 have disease → 190 test positive  \n",
        "- 9,800 healthy → 980 test positive\n",
        "- Total positive tests: 1,170\n",
        "- True positives: 190\n",
        "\n",
        "$P(\\text{Disease | Positive}) = \\frac{190}{1,170} \\approx 0.162$ ✓\n",
        "\n",
        "---\n",
        "\n",
        "## Practice Problem 5\n",
        "\n",
        "Email spam filter:\n",
        "- 60% of emails are spam\n",
        "- Filter catches 95% of spam\n",
        "- Filter incorrectly flags 8% of legitimate emails\n",
        "\n",
        "If an email is flagged as spam, what's the probability it's actually spam?\n",
        "\n",
        ":::{.fragment}\n",
        "$P(\\text{Spam | Flagged}) = \\frac{0.95 \\times 0.6}{0.95 \\times 0.6 + 0.08 \\times 0.4}$\n",
        "\n",
        "$= \\frac{0.57}{0.57 + 0.032} = \\frac{0.57}{0.602} \\approx 0.947$\n",
        "\n",
        "The filter is quite reliable!\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Multiple Events and Bayes'\n",
        "\n",
        "**Extended Bayes' Theorem**: If $A_1, A_2, \\ldots, A_n$ partition the sample space:\n",
        "\n",
        "$$P(A_i|B) = \\frac{P(B|A_i) \\times P(A_i)}{\\sum_{j=1}^{n} P(B|A_j) \\times P(A_j)}$$\n",
        "\n",
        "This allows us to update probabilities for multiple hypotheses\n",
        "\n",
        "---\n",
        "\n",
        "## Three Machine Example Revisited\n",
        "\n",
        "A defective item is found. Which machine most likely produced it?\n",
        "\n",
        "From before:\n",
        "- Machine A: 50% production, 1% defective  \n",
        "- Machine B: 30% production, 2% defective\n",
        "- Machine C: 20% production, 3% defective\n",
        "- Overall defect rate: 1.7%\n",
        "\n",
        "---\n",
        "\n",
        "## Three Machine Solution\n",
        "\n",
        "$$P(A|\\text{Defective}) = \\frac{0.01 \\times 0.5}{0.017} = \\frac{0.005}{0.017} \\approx 0.294$$\n",
        "\n",
        "$$P(B|\\text{Defective}) = \\frac{0.02 \\times 0.3}{0.017} = \\frac{0.006}{0.017} \\approx 0.353$$\n",
        "\n",
        "$$P(C|\\text{Defective}) = \\frac{0.03 \\times 0.2}{0.017} = \\frac{0.006}{0.017} \\approx 0.353$$\n",
        "\n",
        ":::{.fragment}\n",
        "Machine B or C are most likely sources of the defective item\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Practice Problem 6\n",
        "\n",
        "Three boxes contain colored balls:\n",
        "- Box 1: 3 red, 2 blue (chosen 40% of time)\n",
        "- Box 2: 2 red, 3 blue (chosen 35% of time)  \n",
        "- Box 3: 1 red, 4 blue (chosen 25% of time)\n",
        "\n",
        "A red ball is drawn. Which box was it most likely from?\n",
        "\n",
        ":::{.fragment}\n",
        "$P(\\text{Red}) = \\frac{3}{5} \\times 0.4 + \\frac{2}{5} \\times 0.35 + \\frac{1}{5} \\times 0.25 = 0.24 + 0.14 + 0.05 = 0.43$\n",
        "\n",
        "$P(\\text{Box 1 | Red}) = \\frac{0.6 \\times 0.4}{0.43} \\approx 0.558$\n",
        "$P(\\text{Box 2 | Red}) = \\frac{0.4 \\times 0.35}{0.43} \\approx 0.326$  \n",
        "$P(\\text{Box 3 | Red}) = \\frac{0.2 \\times 0.25}{0.43} \\approx 0.116$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Conditional Independence\n",
        "\n",
        "Events A and B are **conditionally independent** given C if:\n",
        "\n",
        "$$P(A \\cap B | C) = P(A|C) \\times P(B|C)$$\n",
        "\n",
        "**Important**: Conditional independence doesn't imply independence!\n",
        "\n",
        ":::{.fragment}\n",
        "**Example**: Weather in two cities may be independent normally, but conditionally dependent given a major weather system\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Simpson's Paradox\n",
        "\n",
        "**Simpson's Paradox**: A trend in subgroups can reverse when groups are combined\n",
        "\n",
        "**Classic Example**: University admissions by gender\n",
        "\n",
        "|         | Men    | Women  |\n",
        "|---------|--------|--------|\n",
        "| Dept A  | 62% (825/1327) | 82% (108/131) |\n",
        "| Dept B  | 63% (560/893)  | 68% (25/37)   |\n",
        "| **Overall** | **44% (1385/2220)** | **30% (133/168)** |\n",
        "\n",
        "Women have higher rates in each department but lower overall!\n",
        "\n",
        "---\n",
        "\n",
        "## Common Fallacies\n",
        "\n",
        "**1. Confusion of the Inverse**\n",
        "- Confusing $P(A|B)$ with $P(B|A)$\n",
        "- \"If it rains, the ground is wet\" ≠ \"If the ground is wet, it rained\"\n",
        "\n",
        "**2. Base Rate Neglect**  \n",
        "- Ignoring prior probabilities\n",
        "- Medical test example\n",
        "\n",
        "**3. Prosecutor's Fallacy**\n",
        "- $P(\\text{Evidence | Innocent}) \\neq P(\\text{Innocent | Evidence})$\n",
        "\n",
        "---\n",
        "\n",
        "## Prosecutor's Fallacy Example\n",
        "\n",
        "DNA evidence matches defendant with probability 1 in a million for random person\n",
        "\n",
        "**Wrong reasoning**: \"Probability of innocence is 1 in a million\"\n",
        "\n",
        "**Correct reasoning**: Need to consider:\n",
        "- How many people could have committed the crime?\n",
        "- What's the prior probability of guilt?\n",
        "- Possibility of lab error, planted evidence, etc.\n",
        "\n",
        "---\n",
        "\n",
        "## Practice Problem 7\n",
        "\n",
        "Quality control: 5% of items are defective. A test detects 96% of defective items but has a 4% false positive rate.\n",
        "\n",
        "a) What's the probability an item testing positive is actually defective?\n",
        "b) What's the probability an item testing negative is actually good?\n",
        "\n",
        ":::{.fragment}\n",
        "a) $P(\\text{Defective | Positive}) = \\frac{0.96 \\times 0.05}{0.96 \\times 0.05 + 0.04 \\times 0.95} = \\frac{0.048}{0.086} \\approx 0.558$\n",
        "\n",
        "b) $P(\\text{Good | Negative}) = \\frac{0.96 \\times 0.95}{0.96 \\times 0.95 + 0.04 \\times 0.05} = \\frac{0.912}{0.914} \\approx 0.998$\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Real-World Applications\n",
        "\n",
        "**Medical Screening**:\n",
        "- Mammograms, COVID tests\n",
        "- Balancing sensitivity vs specificity\n",
        "\n",
        "**Machine Learning**:\n",
        "- Naive Bayes classifiers\n",
        "- Spam detection, recommendation systems\n",
        "\n",
        "**Finance**:\n",
        "- Credit scoring\n",
        "- Fraud detection\n",
        "\n",
        "**Legal System**:\n",
        "- DNA evidence interpretation\n",
        "- Probability of guilt/innocence\n",
        "\n",
        "---\n",
        "\n",
        "## Technology and Tools\n",
        "\n",
        "**Calculators**: \n",
        "- Basic probability calculations\n",
        "- Watch for rounding errors\n",
        "\n",
        "**Software**:\n",
        "- R: conditional probability tables\n",
        "- Python: pandas for two-way tables\n",
        "- Excel: pivot tables for conditional analysis\n",
        "\n",
        "**Visualization**:\n",
        "- Tree diagrams  \n",
        "- Contingency tables\n",
        "- Bayes networks\n",
        "\n",
        "---\n",
        "\n",
        "## Diagnostic Thinking\n",
        "\n",
        "**Questions to ask**:\n",
        "1. What information am I conditioning on?\n",
        "2. How does this information change the probability?\n",
        "3. What's the base rate or prior probability?\n",
        "4. Am I confusing $P(A|B)$ with $P(B|A)$?\n",
        "5. Are the events independent?\n",
        "\n",
        "---\n",
        "\n",
        "## Problem-Solving Strategy\n",
        "\n",
        "1. **Identify the type**: Direct conditional, Bayes', or law of total probability?\n",
        "2. **Define events clearly**: Use precise notation\n",
        "3. **Organize information**: Two-way tables or tree diagrams\n",
        "4. **Check for independence**: Does additional info matter?\n",
        "5. **Apply appropriate formula**: Don't forget denominators!\n",
        "6. **Verify answer**: Does it make intuitive sense?\n",
        "\n",
        "---\n",
        "\n",
        "## Practice Problem 8\n",
        "\n",
        "A survey shows:\n",
        "- 70% of people like pizza\n",
        "- 60% of people like movies  \n",
        "- 40% like both pizza and movies\n",
        "\n",
        "a) Are liking pizza and movies independent?\n",
        "b) What's $P(\\text{Pizza | Movies})$?\n",
        "c) What's $P(\\text{Movies | Pizza})$?\n",
        "\n",
        "---\n",
        "\n",
        "## Practice Problem 8 Solutions\n",
        "\n",
        "a) Check independence: $P(\\text{Pizza}) \\times P(\\text{Movies}) = 0.7 \\times 0.6 = 0.42 \\neq 0.4$\n",
        "   Not independent!\n",
        "\n",
        "b) $P(\\text{Pizza | Movies}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Movies})} = \\frac{0.4}{0.6} = \\frac{2}{3}$\n",
        "\n",
        "c) $P(\\text{Movies | Pizza}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Pizza})} = \\frac{0.4}{0.7} = \\frac{4}{7}$\n",
        "\n",
        "---\n",
        "\n",
        "## Advanced Topics Preview\n",
        "\n",
        "**Markov Chains**: \n",
        "- Sequences where future depends only on present\n",
        "- $P(X_{n+1} | X_n, X_{n-1}, \\ldots, X_1) = P(X_{n+1} | X_n)$\n",
        "\n",
        "**Bayesian Statistics**:\n",
        "- Using Bayes' theorem for statistical inference\n",
        "- Updating beliefs with data\n",
        "\n",
        "**Information Theory**:\n",
        "- Conditional entropy\n",
        "- Mutual information\n",
        "\n",
        "---\n",
        "\n",
        "## Historical Context\n",
        "\n",
        "**Thomas Bayes** (1701-1761):\n",
        "- Presbyterian minister and mathematician\n",
        "- Bayes' theorem published posthumously\n",
        "\n",
        "**Pierre-Simon Laplace** (1749-1827):\n",
        "- Developed and popularized Bayesian methods\n",
        "- \"Probability is nothing but common sense reduced to calculation\"\n",
        "\n",
        "**Modern Applications**: AI, machine learning, medical diagnosis, finance\n",
        "\n",
        "---\n",
        "\n",
        "## Common Student Questions\n",
        "\n",
        "**Q**: \"How do I know when to use Bayes' theorem?\"\n",
        "**A**: When you want to \"reverse\" a conditional probability\n",
        "\n",
        "**Q**: \"Why are medical test problems so counterintuitive?\"  \n",
        "**A**: Base rates matter more than we intuitively expect\n",
        "\n",
        "**Q**: \"What's the difference between independence and conditional independence?\"\n",
        "**A**: Independence means no relationship; conditional independence means no relationship given specific information\n",
        "\n",
        "---\n",
        "\n",
        "## Key Formulas Summary\n",
        "\n",
        "- **Conditional Probability**: $P(A|B) = \\frac{P(A \\cap B)}{P(B)}$\n",
        "- **Multiplication Rule**: $P(A \\cap B) = P(A) \\times P(B|A)$\n",
        "- **Law of Total Probability**: $P(A) = \\sum P(A|B_i) \\times P(B_i)$\n",
        "- **Bayes' Theorem**: $P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$\n",
        "- **Independence**: $P(A|B) = P(A)$\n",
        "\n",
        "---\n",
        "\n",
        "## Looking Ahead\n",
        "\n",
        "**Next lecture**: Discrete Random Variables\n",
        "- Random variables as functions\n",
        "- Probability mass functions\n",
        "- Expected value and variance\n",
        "- Common discrete distributions (binomial, geometric, Poisson)\n",
        "\n",
        "**Connection**: Conditional probability is essential for understanding dependence in random variables\n",
        "\n",
        "---\n",
        "\n",
        "## Study Tips\n",
        "\n",
        "1. **Practice with real scenarios**: Medical tests, quality control\n",
        "2. **Draw diagrams**: Tree diagrams and two-way tables\n",
        "3. **Check your intuition**: Do answers make sense?\n",
        "4. **Master the basics**: Conditional probability formula\n",
        "5. **Watch for fallacies**: Don't confuse $P(A|B)$ and $P(B|A)$\n",
        "\n",
        "---\n",
        "\n",
        "## Final Thoughts\n",
        "\n",
        "Conditional probability is everywhere:\n",
        "- Updates beliefs with new information\n",
        "- Foundation of Bayesian thinking\n",
        "- Critical for proper statistical reasoning\n",
        "- Essential for machine learning and AI\n",
        "\n",
        ":::{.fragment}\n",
        "**Key insight**: Information changes probability - embrace this uncertainty!\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Questions? {.center}\n",
        "\n",
        "**Office Hours**: [Your office hours]\n",
        "**Email**: [Your email]  \n",
        "**Next Class**: Discrete Random Variables\n",
        "\n",
        "*Remember: Homework due [date]*\n",
        "\n",
        "---\n",
        "\n",
        "## Bonus: Monty Hall Problem\n",
        "\n",
        "Three doors: one has a car, two have goats\n",
        "1. You choose a door\n",
        "2. Host opens a door with a goat\n",
        "3. Do you switch?\n",
        "\n",
        ":::{.fragment}\n",
        "**Answer**: Yes! Switch!\n",
        "- $P(\\text{Car behind your door}) = \\frac{1}{3}$\n",
        "- $P(\\text{Car behind other remaining door}) = \\frac{2}{3}$\n",
        "\n",
        "*Conditional probability in action!*\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Bonus: Birthday Paradox Connection\n",
        "\n",
        "In a room of 23 people, probability of shared birthday ≈ 50%\n",
        "\n",
        "**Conditional approach**: What's $P(\\text{no match | first $k$ people have different birthdays})$?\n",
        "\n",
        "This helps build intuition for why the probability grows so quickly!\n",
        "\n",
        "*Surprising results often involve conditional probability!*"
      ],
      "id": "ce70933b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/narjesmathlouthi/Desktop/PSTAT5A/web/PSTAT5A/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}