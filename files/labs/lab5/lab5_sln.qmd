---
title: "Lab 5 Solutions: Continuous Random Variables & Confidence Intervals"
subtitle: "PSTAT 5A - Summer Session A 2025"
author: "Complete Solutions Guide"
format: 
  html:
    toc: true
    toc-depth: 3
    number-sections: false
    code-fold: false
    theme: cosmo
  pdf:
    toc: true
    number-sections: false
date: today
jupyter: python3
execute: 
  eval: true
  warning: false
  message: false
---

# Getting Started - Setup Code

```{python}
#| warning: false
#| message: false


# Install any missing packages (will skip those already installed)
#!%pip install --quiet numpy matplotlib scipy pandas statsmodels

# Load our tools (libraries)
import numpy as np # numerical computing (arrays, random numbers, etc.)
import matplotlib.pyplot as plt # plotting library for static 2D graphs and visualizations
from scipy import stats #  statistical functions (distributions, tests, etc.)
import pandas as pd # data structures (DataFrame) and data analysis tools
import statsmodels  # statistical modeling (regression, time series, ANOVA, etc.)

# Make our graphs look nice
#!%matplotlib inline     # embed Matplotlib plots directly in the notebook
plt.style.use('seaborn-v0_8-whitegrid')  # Apply a clean whitegrid style from Seaborn

# Set random seed for reproducible results
np.random.seed(42)    # fix the random seed so results can be reproduced exactly

print("✅ All tools loaded successfully!") 
```

# Task 1 Solution: Your First Normal Distribution

Human heights follow a normal distribution with mean = 68 inches and standard deviation = 4 inches.

```{python}
# Heights distribution - SOLUTION
mean_height = 68  # SOLUTION: 68
std_height = 4    # SOLUTION: 4

heights = stats.norm(loc=mean_height, scale=std_height)

print(f"Mean height: {heights.mean()} inches")
print(f"Standard deviation: {heights.std()} inches")
```

```{python}
# Calculate probabilities - SOLUTION

# a) What's the probability someone is taller than 72 inches (6 feet)?
prob_tall = 1 - heights.cdf(72)  # SOLUTION: 72
print(f"P(height > 72 inches) = {prob_tall:.4f}")

# b) What's the probability someone is between 64 and 72 inches?
prob_between = heights.cdf(72) - heights.cdf(64)  # SOLUTION: 72, 64
print(f"P(64 < height < 72) = {prob_between:.4f}")

# c) What height is at the 90th percentile? (90% of people are shorter)
height_90th = heights.ppf(0.90)  # SOLUTION: 0.90
print(f"90th percentile height: {height_90th:.2f} inches")
```

```{python}
# Visualization - SOLUTION
x = np.linspace(50, 86, 1000)
y = heights.pdf(x)

plt.figure(figsize=(10, 6))
plt.plot(x, y, 'b-', linewidth=2)
plt.fill_between(x, y, alpha=0.3, color='lightgreen')
plt.title('Human Heights Distribution')
plt.xlabel('Height (inches)')
plt.ylabel('Density')
plt.axvline(mean_height, color='red', linestyle='--', linewidth=2, 
           label=f'Mean = {mean_height} inches')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

# Task 2 Solution: Bus Waiting Times

The time between buses follows an exponential distribution with an average of 15 minutes between buses.

```{python}
# Bus waiting times - SOLUTION
average_wait = 15  # SOLUTION: 15 minutes
rate = 1 / average_wait
bus_times = stats.expon(scale=average_wait)  # SOLUTION: average_wait

# Questions:
# a) What's the probability you wait less than 10 minutes?
prob_short = bus_times.cdf(10)  # SOLUTION: 10
print(f"P(wait < 10 min) = {prob_short:.4f}")

# b) What's the probability you wait more than 30 minutes?
prob_long = 1 - bus_times.cdf(30)  # SOLUTION: 30
print(f"P(wait > 30 min) = {prob_long:.4f}")

# c) What's the median waiting time? (50th percentile)
median_wait = bus_times.ppf(0.5)  # SOLUTION: 0.5
print(f"Median wait time: {median_wait:.2f} minutes")
```

# Task 3 Solution: Explore the CLT

Let's verify the Central Limit Theorem with a uniform distribution!

```{python}
# Population: Uniform distribution from 0 to 100 - SOLUTION
population = stats.uniform(loc=0, scale=100)

print("Population (Uniform 0 to 100):")
print(f"Population mean: {population.mean()}")
print(f"Population std: {population.std():.2f}")

# Take 500 samples of size 25 each - SOLUTION
sample_size = 25   # SOLUTION: 25
n_samples = 500    # SOLUTION: 500

sample_means = []
for i in range(n_samples):
    sample = population.rvs(sample_size)  # SOLUTION: sample_size
    sample_means.append(np.mean(sample))

# Check the CLT prediction
predicted_mean = population.mean()
predicted_std = population.std() / np.sqrt(sample_size)

print(f"\nCLT Predictions:")
print(f"Sample means should have mean ≈ {predicted_mean:.2f}")
print(f"Sample means should have std ≈ {predicted_std:.2f}")

print(f"\nActual Results:")
print(f"Sample means actually have mean = {np.mean(sample_means):.2f}")
print(f"Sample means actually have std = {np.std(sample_means):.2f}")

# Make a histogram
plt.figure(figsize=(10, 6))
plt.hist(sample_means, bins=30, density=True, alpha=0.7, color='purple', edgecolor='black')
plt.title('Distribution of Sample Means from Uniform Population')
plt.xlabel('Sample Mean')
plt.ylabel('Density')
plt.axvline(np.mean(sample_means), color='red', linestyle='--', linewidth=2, 
           label=f'Actual mean = {np.mean(sample_means):.2f}')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

# Task 4 Solution: Your Own Confidence Interval

Creating a 90% confidence interval for homework time data.

```{python}
# Homework time data (in hours per week) - SOLUTION
np.random.seed(456)
homework_data = np.random.normal(15, 5, 40)  # 40 students, roughly normal

print("Homework Survey Results:")
print(f"Sample size: {len(homework_data)}")
print(f"Sample mean: {np.mean(homework_data):.2f} hours/week")
print(f"Sample std dev: {np.std(homework_data, ddof=1):.2f} hours/week")

# Create a 90% confidence interval - SOLUTION
# Step 1: Calculate the needed values
sample_mean = np.mean(homework_data)
sample_std = np.std(homework_data, ddof=1)
n = len(homework_data)

# Step 2: Find the critical value for 90% confidence
confidence = 0.90
alpha = 1 - confidence
z_star = stats.norm.ppf(1 - alpha/2)
print(f"Critical value for 90% confidence: {z_star:.3f}")

# Step 3: Calculate standard error and margin of error
standard_error = sample_std / np.sqrt(n)
margin_of_error = z_star * standard_error

print(f"Standard error: {standard_error:.3f}")
print(f"Margin of error: {margin_of_error:.3f}")

# Step 4: Build the confidence interval
ci_lower = sample_mean - margin_of_error
ci_upper = sample_mean + margin_of_error

print(f"\n90% Confidence Interval for average homework time:")
print(f"[{ci_lower:.2f}, {ci_upper:.2f}] hours per week")

# Step 5: Interpret your result
print(f"\nInterpretation:")
print(f"We are 90% confident that the true average homework time")
print(f"for all students is between {ci_lower:.2f} and {ci_upper:.2f} hours per week.")
```

**Comparison Questions:**

1. **How would a 95% confidence interval compare to your 90% interval?**
   - A 95% CI would be **wider** than the 90% CI because we need more "room" to be more confident.

2. **What if you had surveyed 100 students instead of 40?**
   - The CI would be **narrower** because larger sample sizes give more precise estimates.

```{python}
# Demonstrate the comparisons
print("Comparison of different confidence levels:")
print("=" * 45)

# 90% vs 95% confidence intervals
for conf_level in [0.90, 0.95]:
    alpha = 1 - conf_level
    z_crit = stats.norm.ppf(1 - alpha/2)
    margin = z_crit * standard_error
    lower = sample_mean - margin
    upper = sample_mean + margin
    width = upper - lower
    print(f"{conf_level*100:2.0f}% CI: [{lower:.2f}, {upper:.2f}], width = {width:.2f}")

print("\nComparison of different sample sizes (95% CI):")
print("=" * 45)

# Different sample sizes (simulated)
for sample_size_comp in [40, 100]:
    se_comp = sample_std / np.sqrt(sample_size_comp)
    margin_comp = 1.96 * se_comp  # 95% CI
    lower_comp = sample_mean - margin_comp
    upper_comp = sample_mean + margin_comp
    width_comp = upper_comp - lower_comp
    print(f"n={sample_size_comp:3d}: [{lower_comp:.2f}, {upper_comp:.2f}], width = {width_comp:.2f}")
```

# Task 5 Solution: Which Distribution Should I Use?

Match each scenario with the best distribution:

```{python}
# SOLUTION
print("SOLUTIONS:")
print("A. Time between arrivals: 3 (Exponential)")      
print("B. Heights: 1 (Normal)")                    
print("C. Die roll: 4 (Discrete uniform)")                   
print("D. Temperature: 1 (Normal)")                
print("E. Coin flip: 5 (Bernoulli)")                  

print("\nReasoning:")
print("A. Exponential - Time between events follows exponential distribution")
print("B. Normal - Heights of people are naturally normally distributed")  
print("C. Discrete uniform - All 6 outcomes (1,2,3,4,5,6) equally likely")
print("D. Normal - Temperature measurements tend to be normally distributed")
print("E. Bernoulli - Two outcomes (heads/tails) with fixed probability")
```

<!-- # Additional Examples and Practice

## Working with Different Normal Distributions

```{python}
# Create and compare different normal distributions
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Different means, same std dev
x = np.linspace(-10, 20, 1000)
for i, mean in enumerate([0, 5, 10]):
    y = stats.norm(mean, 2).pdf(x)
    axes[0,0].plot(x, y, label=f'μ={mean}, σ=2')
axes[0,0].set_title('Different Means, Same Standard Deviation')
axes[0,0].legend()
axes[0,0].grid(True, alpha=0.3)

# Same mean, different std devs  
x = np.linspace(-15, 15, 1000)
for i, std in enumerate([1, 2, 4]):
    y = stats.norm(0, std).pdf(x)
    axes[0,1].plot(x, y, label=f'μ=0, σ={std}')
axes[0,1].set_title('Same Mean, Different Standard Deviations')
axes[0,1].legend()
axes[0,1].grid(True, alpha=0.3)

# Probability calculations example
normal_dist = stats.norm(100, 15)  # IQ scores: mean=100, std=15
x = np.linspace(40, 160, 1000)
y = normal_dist.pdf(x)

axes[1,0].plot(x, y, 'b-', linewidth=2)
axes[1,0].fill_between(x, y, alpha=0.3)

# Highlight specific regions
x_high = x[x >= 130]
y_high = normal_dist.pdf(x_high)
axes[1,0].fill_between(x_high, y_high, alpha=0.7, color='red', 
                      label=f'P(IQ ≥ 130) = {1-normal_dist.cdf(130):.3f}')
axes[1,0].set_title('IQ Scores Distribution')
axes[1,0].legend()
axes[1,0].grid(True, alpha=0.3)

# Z-score example
raw_scores = [85, 100, 115, 130]
z_scores = [(score - 100) / 15 for score in raw_scores]

axes[1,1].scatter(raw_scores, z_scores, s=100, c='red')
for i, (raw, z) in enumerate(zip(raw_scores, z_scores)):
    axes[1,1].annotate(f'({raw}, {z:.1f})', (raw, z), xytext=(5, 5), 
                      textcoords='offset points')
axes[1,1].set_xlabel('Raw Score')
axes[1,1].set_ylabel('Z-Score')
axes[1,1].set_title('Raw Scores vs Z-Scores')
axes[1,1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

print("Z-Score Transformations:")
for raw, z in zip(raw_scores, z_scores):
    print(f"Raw score {raw} → Z-score {z:.2f}")
```

## Confidence Interval Simulation

```{python}
# Simulate many confidence intervals to verify coverage probability
def simulate_confidence_intervals(true_mean, true_std, sample_size, confidence_level, n_simulations=100):
    """
    Simulate many confidence intervals and check coverage rate
    """
    alpha = 1 - confidence_level
    z_critical = stats.norm.ppf(1 - alpha/2)
    
    coverage_count = 0
    intervals = []
    
    for i in range(n_simulations):
        # Generate a sample
        sample = np.random.normal(true_mean, true_std, sample_size)
        sample_mean = np.mean(sample)
        sample_std = np.std(sample, ddof=1)
        
        # Calculate confidence interval
        se = sample_std / np.sqrt(sample_size)
        margin = z_critical * se
        ci_lower = sample_mean - margin
        ci_upper = sample_mean + margin
        
        # Check if interval captures true mean
        captures = ci_lower <= true_mean <= ci_upper
        if captures:
            coverage_count += 1
            
        intervals.append((ci_lower, ci_upper, captures))
    
    coverage_rate = coverage_count / n_simulations
    return intervals, coverage_rate

# Run simulation
true_mean, true_std = 50, 10
sample_size = 30
confidence_level = 0.95
n_sims = 100

intervals, coverage_rate = simulate_confidence_intervals(
    true_mean, true_std, sample_size, confidence_level, n_sims
)

print(f"Simulation Results:")
print(f"True population mean: {true_mean}")
print(f"Sample size: {sample_size}")
print(f"Confidence level: {confidence_level*100}%")
print(f"Number of simulations: {n_sims}")
print(f"Coverage rate: {coverage_rate*100:.1f}%")
print(f"Expected coverage rate: {confidence_level*100}%")

# Plot first 20 intervals
plt.figure(figsize=(12, 8))
plt.axvline(true_mean, color='red', linewidth=3, label=f'True Mean = {true_mean}')

for i in range(min(20, len(intervals))):
    lower, upper, captures = intervals[i]
    color = 'green' if captures else 'red'
    alpha = 0.6 if captures else 1.0
    
    plt.plot([lower, upper], [i, i], color=color, linewidth=2, alpha=alpha)
    plt.plot((lower + upper)/2, i, 'o', color=color, markersize=4)

plt.xlabel('Value')
plt.ylabel('Simulation Number')
plt.title(f'First 20 Confidence Intervals\n{confidence_level*100}% Confidence Level')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
``` -->


## 🎯 Lab 5 Complete Solutions Summary


- ✅ **Task 1**: Normal distribution calculations with human heights
- ✅ **Task 2**: Exponential distribution for bus waiting times  
- ✅ **Task 3**: Central Limit Theorem verification with uniform distribution
- ✅ **Task 4**: 90% confidence interval construction for homework data
- ✅ **Task 5**: Distribution matching exercise with reasoning



**Key Takeaways:**

1. Continuous distributions use PDFs and calculate probabilities as areas
   
2. Normal distribution is fundamental and appears everywhere via CLT
   
3. Confidence intervals provide ranges of plausible values for parameters
   
4. Sample size affects precision; confidence level affects interval width
   
5. Python's `scipy.stats` provides powerful tools for distribution analysis

