[
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#important-announcements",
    "href": "files/lecture_notes/lecture12/lecture12.html#important-announcements",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "ğŸ“¢ Important Announcements",
    "text": "ğŸ“¢ Important Announcements\n\n\nğŸ“ Quiz 2 Details\nWhen:\n- ğŸ“… Date: Friday, July 25\n- â° Window: 7 AM â€“ 12 AM\n- â³ Duration: 1 hour once started\nWhere: ğŸ’» Online via Canvas\nCovers: Material from Weeks 3-4\n\nğŸ“š What to Expect\n\nDiscrete & continuous distributions\nProbability calculations\nExpected value & variance\nNormal distribution applications\nNote: Upload photos of written work for calculation problems"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#todays-roadmap",
    "href": "files/lecture_notes/lecture12/lecture12.html#todays-roadmap",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "ğŸ“¢ Todayâ€™s Roadmap",
    "text": "ğŸ“¢ Todayâ€™s Roadmap\n\n\nğŸ¯ Learning Objectives\n\nKnow the difference between \\(z\\) and \\(t\\) distributions\nUnderstand when to use each distribution\nLearn to find critical values from tables and plots\nPractice calculating confidence intervals step-by-step\nInterpret results correctly in context\n\n\nğŸ“‹ What Weâ€™ll Cover\n\nReview: Confidence interval basics\nThe t-Distribution: When and why we use it\nCritical Regions: Finding the right values\nPractical Examples: z and t calculations\nCommon Mistakes: What to avoid\nReal Applications: Making it meaningful"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#quick-review-confidence-interval-basics",
    "href": "files/lecture_notes/lecture12/lecture12.html#quick-review-confidence-interval-basics",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "Quick Review: Confidence Interval Basics ğŸ”„",
    "text": "Quick Review: Confidence Interval Basics ğŸ”„\n\n\nğŸ¯ The Big Idea\nA confidence interval (CI) takes a single sample statistic and turns it into a range that is likely to contain an unknown population parameter; most often the mean \\(\\mu\\).\nCI template\n\\[\n\\underbrace{\\text{Point estimate}}_{\\color{blue}{(e.g., \\bar{x})}}\n\\;\\pm\\;\n\\underbrace{\\text{(critical value) $\\times$ (standard error)}}_{\\color{red}{\\text{Margin of Error (ME)}}}\n\\]\nFor the mean\n\n\n\n\n\n\n\n\nSituation\nFormula\nDistribution\n\n\n\n\nÏƒ known (rare)\n\\(\\displaystyle \\bar{x} \\;\\pm\\; z^{*}\\,\\frac{\\sigma}{\\sqrt{n}}\\)\nz-distribution\n\n\nÏƒ unknown (typical)\n\\(\\displaystyle \\bar{x} \\;\\pm\\; t^{*}\\,\\frac{s}{\\sqrt{n}}\\)\nt-distribution (\\(df = n-1\\))\n\n\n\nKey points\n\nWe never know the true mean \\(\\mu\\) in practice, thatâ€™s exactly what the CI estimates.\n\nUse the population SD Ïƒ only when it is genuinely known (e.g., industrial process with longâ€‘term QC).\n\nOtherwise substitute the sample SD s and switch to the tâ€‘distribution, which is wider to reflect that extra uncertainty.\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nKey Formula: \\(\\bar{x} \\pm z^* \\cdot \\frac{s}{\\sqrt{n}}\\) (when using z-distribution)"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#step-by-step-example-1-using-z-distribution",
    "href": "files/lecture_notes/lecture12/lecture12.html#step-by-step-example-1-using-z-distribution",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "Step-by-Step Example 1: Using z-Distribution ğŸ“",
    "text": "Step-by-Step Example 1: Using z-Distribution ğŸ“\n\n\nğŸ¯ Problem Setup\nResearch Question: What is the average SAT score of students at UCSB?\nGiven Information:\n\nSample size: \\(n = 50\\) students\nSample mean: \\(\\bar{x} = 1180\\)\nPopulation standard deviation: \\(\\sigma = 120\\) (known from past data)\nConfidence level: \\(95\\%\\)\n\nQuestion: Construct a \\(95\\%\\) confidence interval for the population mean SAT score.\n\n\nShow Solution\n\n\nStep 1: Check conditions\n\n\\(\\sigma\\) is known âœ“\nUse z-distribution âœ“\n\nStep 2: Find critical value\n\nFor \\(95\\%\\) CI: \\(\\alpha = 0.05, \\frac{\\alpha}{2} = 0.025\\)\n\\(z^* = 1.96\\) (from z-table)\n\nStep 3: Calculate SE\n\\[SE = \\frac{\\sigma}{\\sqrt{n}} = \\frac{120}{\\sqrt{50}} = \\frac{120}{7.071} = 16.97\\]\nStep 4: Calculate Margin of Error\n\\[ME = z^* \\times SE = 1.96 \\times 16.97 = 33.26\\]\nStep 5: Construct CI\n\\[CI = \\bar{x} \\pm ME = 1180 \\pm 33.26 = (1146.7, 1213.3)\\]\nFinal Answer: We are 95% confident that the true average SAT score is between 1146.7 and 1213.3."
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#step-by-step-example-2-using-t-distribution",
    "href": "files/lecture_notes/lecture12/lecture12.html#step-by-step-example-2-using-t-distribution",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "Step-by-Step Example 2: Using t-Distribution ğŸ“",
    "text": "Step-by-Step Example 2: Using t-Distribution ğŸ“\n\n\nğŸ¯ Problem Setup\nResearch Question: What is the average daily coffee consumption at our office?\nGiven Information:\n- Sample size: n = 16 employees\n- Sample mean: \\(\\bar{x} = 2.8\\) cups\n- Sample standard deviation: s = 0.9 (\\(\\sigma\\) unknown)\n- Confidence level: 90%\nQuestion: Construct a 90% confidence interval for the population mean daily coffee consumption.\n\n\nShow Solution\n\n\nStep 1: Check conditions - \\(\\sigma\\) is unknown âœ“ - n &lt; 30 âœ“ - Use t-distribution âœ“\nStep 2: Calculate degrees of freedom - df = n - 1 = 16 - 1 = 15\nStep 3: Find critical value - For 90% CI: \\(\\alpha = 0.10, \\alpha/2 = 0.05\\) - t* = 1.753 (from t-table, df = 15)\nStep 4: Calculate SE\n\\[SE = \\frac{s}{\\sqrt{n}} = \\frac{0.9}{\\sqrt{16}} = \\frac{0.9}{4} = 0.225\\]\nStep 5: Calculate Margin of Error\n\\[ME = t^* \\times SE = 1.753 \\times 0.225 = 0.394\\]\nStep 6: Construct CI\n\\[CI = \\bar{x} \\pm ME = 2.8 \\pm 0.394 = (2.406, 3.194)\\]\nFinal Answer: We are 90% confident that the true average daily coffee consumption is between 2.406 and 3.194 cups."
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#practice-problem-test-your-skills",
    "href": "files/lecture_notes/lecture12/lecture12.html#practice-problem-test-your-skills",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "Practice Problem: Test Your Skills! ğŸ§ ",
    "text": "Practice Problem: Test Your Skills! ğŸ§ \n\n\nğŸ¯ Your Turn!\nProblem: A researcher wants to estimate the average time students spend studying per day.\nGiven:\n\nSample size: \\(n = 25\\) students\n\nSample mean: \\(\\bar{x} = 3.2\\) hours\nSample standard deviation: \\(s = 1.1\\) hours\nConfidence level: \\(95\\%\\)\n\nQuestions:\n\nShould you use \\(z\\) or \\(t\\)-distribution? Why?\nWhat are the degrees of freedom?\nWhat is the critical value?\nCalculate the 95% confidence interval\nInterpret your result in context\n\n\n\nShow Solution\n\n\nStep 1: Distribution Choice Use t-distribution because: - Ïƒ is unknown (only sample standard deviation s is given) - n = 25 &lt; 30\nStep 2: Degrees of Freedom df = n - 1 = 25 - 1 = 24\nStep 3: Critical Value For 95% CI with df = 24: t* = 2.064\nStep 4: Calculate CI\nStandard Error: \\(SE = \\frac{s}{\\sqrt{n}} = \\frac{1.1}{\\sqrt{25}} = \\frac{1.1}{5} = 0.220\\)\nMargin of Error: \\(ME = t^* \\times SE = 2.064 \\times 0.220 = 0.454\\)\nConfidence Interval: \\(CI = \\bar{x} \\pm ME = 3.2 \\pm 0.454 = (2.746, 3.654)\\)\nStep 5: Interpretation We are 95% confident that the true average study time for students is between 2.746 and 3.654 hours per day.\n\n\n\n\n\n                            \n                                            \n\n\nğŸ¤” Think About Itâ€¦\n\nWhy is the t-distribution appropriate here?\nHow would the interval change if n = 100?\nWhat if we wanted 99% confidence instead?"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#summary-key-takeaways",
    "href": "files/lecture_notes/lecture12/lecture12.html#summary-key-takeaways",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "Summary: Key Takeaways ğŸ¯",
    "text": "Summary: Key Takeaways ğŸ¯\n\n\nğŸ§  Core Concepts\n1. Distribution Choice - Ïƒ known â†’ z-distribution - Ïƒ unknown + n â‰¥ 30 â†’ z-distribution\n- Ïƒ unknown + n &lt; 30 â†’ t-distribution\n2. t-Distribution Properties - Heavier tails than z - Depends on degrees of freedom (df = n-1) - Approaches z as df increases\n3. Critical Regions - Î±/2 in each tail for two-sided CI - Critical values from tables or software - Larger confidence â†’ larger critical values\n\nğŸ› ï¸ Practical Skills\n4. Calculation Steps 1. Check conditions (Ïƒ known?, sample size?) 2. Choose distribution (z or t) 3. Find critical value 4. Calculate standard error 5. Compute margin of error\n6. Construct interval 7. Interpret in context\n5. Interpretation - â€œWe are C% confidentâ€¦â€ - Focus on the process, not individual interval - Consider practical significance\n6. Common Pitfalls to Avoid - Wrong distribution choice - Incorrect degrees of freedom - Using Î± instead of Î±/2 - Misinterpreting the interval"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#important-announcements",
    "href": "files/lecture_notes/lecture11/lecture11.html#important-announcements",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "ğŸ“¢ Important Announcements",
    "text": "ğŸ“¢ Important Announcements\n\n\nğŸ“ Quiz 2 Details\nWhen:\n- ğŸ“… Date: Friday, July 25\n- â° Window: 7 AM â€“ 12 AM\n- â³ Duration: 1 hour once started\nWhere: ğŸ’» Online via Canvas\nCovers: Material from Weeks 3-4\n\nğŸ“š What to Expect\n\nDiscrete & continuous distributions\nProbability calculations\nExpected value & variance\nNormal distribution applications\nNote: Upload photos of written work for calculation problems"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#what-well-learn-today",
    "href": "files/lecture_notes/lecture11/lecture11.html#what-well-learn-today",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "What Weâ€™ll Learn Today ğŸ¯",
    "text": "What Weâ€™ll Learn Today ğŸ¯\n\n\nBig Ideas:\n\nHow sample means behave (theyâ€™re surprisingly predictable!)\nWhy we use intervals instead of single numbers\nHow confident we can be in our estimates\nPlanning studies for the right precision\n\n\nSkills Youâ€™ll Gain:\n\nBuild confidence intervals step-by-step\nInterpret what confidence really means\nChoose appropriate sample sizes\nAvoid common mistakes in interpretation"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#from-observation-experimentation-why-design-matters",
    "href": "files/lecture_notes/lecture11/lecture11.html#from-observation-experimentation-why-design-matters",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "From Observation â¡ï¸ Experimentation: Why DesignÂ Matters",
    "text": "From Observation â¡ï¸ Experimentation: Why DesignÂ Matters\n\nObservational Study: Passively record what already happens â€” good for spotting patterns, but hidden confounders can fool us.\nControlled Experiment: Actively assign treatments; randomization balances the lurking variables so we can talk about cause.\nRandomizationÂ & Replication: Twin shields that protect us from bias and oneâ€‘off flukes.\nProbability Framework: Sample space, events, and probabilities let us quantify uncertainty."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#the-big-picture-from-sample-to-population",
    "href": "files/lecture_notes/lecture11/lecture11.html#the-big-picture-from-sample-to-population",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "The Big Picture: From Sample to Population",
    "text": "The Big Picture: From Sample to Population\n\n\nThink of this like trying to understand a huge library by reading just a few books\n\n\n                            \n                                            \n\n\n\nKey Terms Made Simple:\n\nPopulation (\\(\\mu\\)): Everyone we care about (like all students at UCSB)\nSample (\\(\\bar x\\)): The people we actually measured (like 100 students we surveyed)\nParameter: The true answer we want (population mean)\nStatistic: Our best guess (sample mean)"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#why-point-estimates-arent-enough",
    "href": "files/lecture_notes/lecture11/lecture11.html#why-point-estimates-arent-enough",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Why Point Estimates Arenâ€™t Enough",
    "text": "Why Point Estimates Arenâ€™t Enough\n\n\nImagine asking: â€œWhatâ€™s the average height of UCSB students?â€\n\n\n                            \n                                            \n\n\n\nThe Problem: Each sample gives a slightly different answer!\n\nThe Solution: Use confidence intervals to show the range of reasonable values."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#sampling-distributions",
    "href": "files/lecture_notes/lecture11/lecture11.html#sampling-distributions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\n\n\nThink of sampling distributions like â€œWhat if we repeated our study 1000 times?â€\n\n\n                            \n                                            \n\n\n\nKey Insights:\n\nPopulation can be any shape (skewed, normal, weird)\nOne sample might not look like the population\nSample means vary from sample to sample\nMany sample means form a beautiful normal distribution!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#the-central-limit-theorem-clt",
    "href": "files/lecture_notes/lecture11/lecture11.html#the-central-limit-theorem-clt",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "The Central Limit Theorem (CLT) ğŸ¯",
    "text": "The Central Limit Theorem (CLT) ğŸ¯\n\n\n\n\n                            \n                                            \nCentral Limit Theorem: Larger Samples â†’ More Normal!\n\n\n\nThe Magic Rule: No matter what shape your population is, sample means will be approximately normal!\nThe Rule of Thumb: With n â‰¥ 30, sample means will be approximately normal, regardless of population shape!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#standard-error",
    "href": "files/lecture_notes/lecture11/lecture11.html#standard-error",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Standard Error",
    "text": "Standard Error\n\n\nWhat it measures\n\nStandard deviationÂ (\\(\\sigma\\) or \\(s\\)): spread of individual data points\n\nStandard errorÂ (SE): spread of sample means\n\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}}\n\\qquad(\\text{if } \\sigma \\text{ is known})\n\\]\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\qquad(\\text{usual case, } \\sigma \\text{ unknown})\n\\]\nKey facts\n\nSE shrinks at rateÂ \\(1/\\sqrt{n}\\)Â â€” every 4Ã— more observations â‡’ Â½ the SE\n\nSmaller SE â‡’ narrower confidence intervals and more powerful tests\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nImportant\n\n\nDoubling your sample size doesnâ€™t halve the error - you need 4 times the sample for half the error!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-the-intuitive-idea",
    "href": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-the-intuitive-idea",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals: The Intuitive Idea",
    "text": "Confidence Intervals: The Intuitive Idea\n\n\nImagine youâ€™re trying to guess someoneâ€™s height just by looking at their shadowâ€¦\n\n\n                            \n                                            \n\n\n\nSimple Interpretation: â€œWeâ€™re \\(95\\\\%\\) confident the true average height is between \\(64.3\\) and \\(70.1\\)Â inches.â€"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#what-exactly-is-a-confidence-interval",
    "href": "files/lecture_notes/lecture11/lecture11.html#what-exactly-is-a-confidence-interval",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "What Exactly Is a Confidence Interval? ğŸ¤“",
    "text": "What Exactly Is a Confidence Interval? ğŸ¤“\n\n\n\nA confidence interval (CI) is point estimateÂ \\(\\pm\\) margin of error\n\\[\n  \\text{CI} = \\text{statistic} \\;\\pm\\; \\bigl(\\text{critical value}\\bigr)\\times\\bigl(\\text{SE}\\bigr)\n\\]\nThe â€œcritical valueâ€ comes from a probability model (e.g., \\(z^{\\star}\\) or \\(t^{\\star}\\)).\nThe standard error (SE) captures sampling variation.\n\nFrequentist meaning\n\nIf we repeated the study infinitely many times and built a \\(95â€¯\\%\\) CI each time, about \\(95â€¯\\%\\) of those intervals would cover the true parameter.\n\n(For any one computed interval the parameter is fixed, the process has a \\(95â€¯\\%\\) success rate, not the individual interval.)\n\n\n\n\n\n\n\n\nWhat controls the width?\n\n\n\nVariability in the data: larger \\(\\sigma\\) or \\(s\\) â‡’ wider CI\nSample size \\(n\\): width shrinks at rate \\(1/\\sqrt{n}\\)\nConfidence level: 99â€¯% CIs are wider than 90â€¯% CIs\n\n\n\n\n\n\n\n\n\n\nCommon pitfalls\n\n\n\nSaying â€œthere is a \\(95â€¯\\%\\) probabilityÂ that \\(\\mu\\) lies in this intervalâ€ (wrong)\nInterpreting the CI as covering \\(95â€¯\\%\\) of future observations (it does not)\nIgnoring conditions (normality or CLT) before using the formulae"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#building-confidence-intervals-step-by-step",
    "href": "files/lecture_notes/lecture11/lecture11.html#building-confidence-intervals-step-by-step",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Building Confidence Intervals Step-by-Step",
    "text": "Building Confidence Intervals Step-by-Step\n\n\nFor Population Means (Most Common Case)\nWhen we DONâ€™T know the population standard deviation (\\(\\sigma\\)):\n\n\n                            \n                                            \n\n\n\nThe Formula: \\(\\bar{x} \\pm t^* \\cdot \\frac{s}{\\sqrt{n}}\\)\nBreaking it down:\n\n\\(\\bar{x}\\) = our sample average (the center of our guess)\n\\(t^*\\) = critical value (how many standard errors to go out)\n\\(\\frac{s}{\\sqrt{n}}\\) = standard error (our uncertainty measure)"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#the-t-distribution-when-sigma-is-unknown",
    "href": "files/lecture_notes/lecture11/lecture11.html#the-t-distribution-when-sigma-is-unknown",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "The t-Distribution: When \\(\\sigma\\) is Unknown",
    "text": "The t-Distribution: When \\(\\sigma\\) is Unknown\n\n\nWhy not use the normal distribution? Because when we estimate \\(\\sigma\\) with \\(s\\), we add extra uncertainty!\n\n\n                            \n                                            \n\n\n\nKey Points:\n\nSmall samples (\\(n &lt; 30\\)): Use t-distribution\nLarge samples (\\(n â‰¥ 30\\)): \\(t\\) â‰ˆ normal\nDegrees of freedom (df)= \\(n - 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-for-proportions",
    "href": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-for-proportions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals for Proportions",
    "text": "Confidence Intervals for Proportions\n\n\nFor Yes/No questions like: â€œWhat percentage of students prefer online classes?â€\n\n\n                            \n                                            \n\n\n\nThe Formula: \\(\\hat{p} \\pm z^* \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\)\nResults: Sample: 60% prefer online (120/200)\n95% CI: (53.2%, 66.8%) - Weâ€™re 95% confident the true percentage is in this range."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#what-does-95-confident-really-mean",
    "href": "files/lecture_notes/lecture11/lecture11.html#what-does-95-confident-really-mean",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "What Does â€œ95% Confidentâ€ Really Mean? ğŸ¤”",
    "text": "What Does â€œ95% Confidentâ€ Really Mean? ğŸ¤”\n\n\nThe Biggest Misconception: â€œThereâ€™s a 95% chance the true mean is in our intervalâ€\nActually: â€œIf we repeated this study 100 times, about 95 of our intervals would contain the true meanâ€\n\n\n                            \n                                            \n\n\n\nRemember: The interval either contains the true value or it doesnâ€™t - thereâ€™s no probability involved for a single interval!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#sample-size-planning-getting-the-precision-you-want",
    "href": "files/lecture_notes/lecture11/lecture11.html#sample-size-planning-getting-the-precision-you-want",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Sample Size Planning: Getting the Precision You Want",
    "text": "Sample Size Planning: Getting the Precision You Want\n\n\nThe Question: â€œHow many people do we need to survey?â€\n\n\n                            \n                                            \n\n\n\nKey Formula for Means: \\(n = \\left(\\frac{z^* \\sigma}{ME}\\right)^2\\)\nTrade-offs:\n\nWant smaller margin of error? Need bigger sample\nWant higher confidence? Need bigger sample\nWant to save money? Accept wider intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#real-example-student-sleep-study",
    "href": "files/lecture_notes/lecture11/lecture11.html#real-example-student-sleep-study",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Real Example: Student Sleep Study ğŸ˜´",
    "text": "Real Example: Student Sleep Study ğŸ˜´\n\n\nResearch Question: How many hours do UCSB students sleep per night?\n\n\n                            \n                                            \n\n\n\nBottom Line: Weâ€™re 95% confident that UCSB students sleep between 6.73 and 7.47 hours per night on average."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/lecture11/lecture11.html#common-mistakes-to-avoid",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Common Mistakes to Avoid âš ï¸",
    "text": "Common Mistakes to Avoid âš ï¸\n\n\nâŒ Wrong Interpretations\nâ€œ95% of students sleep in this rangeâ€ - NO! This is about the population mean, not individual students\nâ€œThereâ€™s a 95% chance Î¼ is in our intervalâ€ - NO! \\(\\mu\\) is fixed; our interval varies\nâ€œWe can be 95% certainâ€ - NO! Use â€œconfidentâ€ not â€œcertainâ€\n\nâœ… Correct Approach\nâ€œWe are 95% confident the population mean is in this intervalâ€\nKey Reminders:\n\nCheck conditions before using formulas\nUse t-distribution when \\(\\sigma\\) is unknown\nLarger samples give narrower intervals\nHigher confidence gives wider intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#problem-1-coffee-shop-revenue",
    "href": "files/lecture_notes/lecture11/lecture11.html#problem-1-coffee-shop-revenue",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Problem 1: Coffee Shop Revenue",
    "text": "Problem 1: Coffee Shop Revenue\nA coffee shop owner samples 36 days and finds average daily revenue of $850 with standard deviation $120.\nYour turn: Calculate a 90% confidence interval for the true average daily revenue.\n\n\nShow Solution\n\n\nGiven (from the prompt)\n\\(n = 36,\\; \\bar{x} = \\$850,\\; s = \\$120,\\; \\text{confidence level} = 90\\%\\)\n\nStepÂ 1Â â€“ Conditions\n\n\\(n \\ge 30\\) â‡’ a \\(t\\)â€‘interval is justified by the Central Limit Theorem.\n\nAssume daily revenues are independent.\n\nStepÂ 2Â â€“ Critical value\n\\(\\alpha = 1-0.90 = 0.10 \\;\\Rightarrow\\; \\alpha/2 = 0.05\\)\nDegrees of freedom: \\(df = n-1 = 35\\)\n\\(\\displaystyle t^{\\star}_{0.90,\\,35} \\approx 1.690\\)\nStepÂ 3Â â€“ Standard error\n\\[SE = \\frac{s}{\\sqrt{n}}\n        = \\frac{120}{\\sqrt{36}}\n        = \\frac{120}{6}\n        = \\$20\\]\nStepÂ 4Â â€“ Margin of error\n\\[ME = t^{\\star}\\; SE\n       = 1.690 \\times \\$20\n       = \\$33.8\\]\nStepÂ 5Â â€“ Confidence interval\n\\[\\bar{x} \\pm ME\n     = 850 \\pm 33.8\n     \\;\\Longrightarrow\\;\n     (\\$816.2,\\; \\$883.8)\\]\nInterpretation â€“ We are 90â€¯% confident that the true mean daily revenue lies between $816.20 and $883.80."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#problem-2-student-survey",
    "href": "files/lecture_notes/lecture11/lecture11.html#problem-2-student-survey",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Problem 2: Student Survey",
    "text": "Problem 2: Student Survey\nIn a survey of 400 students, 280 say they would recommend their major to a friend.\nYour turn:\n\nCalculate the sample proportion\nBuild a \\(95\\%\\) confidence interval\nCheck if conditions are met\n\n\n\nShow Solution\n\n\nGiven (from the survey)\n\\(n = 400,\\; x = 280\\) â€œyesâ€ responses\n\nStepÂ 1Â â€“ Sample proportion\n\\[\\hat{p} = \\frac{x}{n} = \\frac{280}{400} = 0.70\\]\nStepÂ 2Â â€“ Conditions for a \\(z\\)â€‘interval\n\\(n\\hat{p} = 400(0.70)=280 \\ge 10\\)\n\\(n(1-\\hat{p}) = 400(0.30)=120 \\ge 10\\)\nBoth counts â‰¥â€¯10, so the normal approximation is appropriate.\nStepÂ 3Â â€“ Standard error\n\\[SE = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n        = \\sqrt{\\frac{0.70(0.30)}{400}}\n        = \\sqrt{0.000525}\n        \\approx 0.0229\\]\nStepÂ 4Â â€“ Critical value & margin of error\nFor 95â€¯% confidence, \\(z^{\\star} = 1.96\\)\n\\[ME = z^{\\star}\\; SE\n       = 1.96 \\times 0.0229\n       \\approx 0.045\\]\nStepÂ 5Â â€“ Confidence interval\n\\[\\hat{p} \\pm ME\n     = 0.70 \\pm 0.045\n     \\;\\Longrightarrow\\;\n     (0.655,\\; 0.745)\\]\nInterpretation â€“ We are 95â€¯% confident that between 65.5â€¯% and 74.5â€¯% of all students would recommend their major to a friend."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#looking-ahead-hypothesis-testing",
    "href": "files/lecture_notes/lecture11/lecture11.html#looking-ahead-hypothesis-testing",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Looking Ahead: Hypothesis Testing ğŸ”®",
    "text": "Looking Ahead: Hypothesis Testing ğŸ”®\n\n\nNext week weâ€™ll learn:\n\nHow to test specific claims about populations\nWhen to reject or fail to reject hypotheses\nThe connection between confidence intervals and hypothesis tests"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#key-takeaways",
    "href": "files/lecture_notes/lecture11/lecture11.html#key-takeaways",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Key Takeaways ğŸ¯",
    "text": "Key Takeaways ğŸ¯\n\n\nBig Ideas:\n\nSamples vary - confidence intervals capture this uncertainty\nLarger samples give more precise estimates\nHigher confidence means wider intervals\nThe CLT makes normal-based inference possible\n\n\nPractical Skills:\n\nBuild CIs for means and proportions\nInterpret confidence correctly\nPlan sample sizes for desired precision\nAvoid common interpretation mistakes"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#comprehensive-resources",
    "href": "files/lecture_notes/lecture11/lecture11.html#comprehensive-resources",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Comprehensive Resources ğŸ“š",
    "text": "Comprehensive Resources ğŸ“š\n\n\nğŸ“– Required Reading\n\nOpenIntro Statistics\n\nSection 1.3: Sampling principles and strategies\nSection 3.3: Confidence intervals for a mean\nSection 4.1: Central Limit Theorem\nSection 7.1.1 The distribution of \\(\\bar x\\)\nSection7.1.2 Evaluating the two conditions required for modeling \\(\\bar x\\)\nSection 7.1.3 Introducing the \\(t\\)-distribution\n\n\nğŸ¥ Video Resources\n\nKhan Academy: Central Limit Theorem\nStatQuest: Confidence Intervals Explained\n3Blue1Brown: Central Limit Theorem Visualization\n\n\nğŸ’» Interactive Tools\n\nSeeing Theory: Probability Visualizations\nRossman & Chance Applets: Sampling Distributions\nCentral Limit Theorem Simulator"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#questions",
    "href": "files/lecture_notes/lecture11/lecture11.html#questions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Questions? ğŸ¤”",
    "text": "Questions? ğŸ¤”\n\n\nOffice Hours: Thursday 11AM (link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nâ€œThe goal is not to eliminate uncertainty, but to understand and work with itâ€\n\n\n\n\nğŸ  Back to Main Page"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#section",
    "href": "files/lecture_notes/lecture12/lecture12.html#section",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "",
    "text": "ğŸ  Back to Main Page"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#quick-announcements",
    "href": "files/lecture_notes/lecture13/lecture13.html#quick-announcements",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "ğŸ“¢ Quick Announcements",
    "text": "ğŸ“¢ Quick Announcements\n\n\nğŸ“ Quiz 2 Reminder\nWhen:\n- ğŸ“… Date: Friday, July 25\n- â° Window: 7 AM â€“ 12 AM\n- â³ Duration: 1 hour once started\nWhere: ğŸ’» Online via Canvas\n\nğŸ“š Todayâ€™s Focus\n\nFoundation: Logic of hypothesis testing\nPractice: Real examples with Python\nSkills: Making statistical decisions\nApplications: From medicine to marketing"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#learning-journey-today",
    "href": "files/lecture_notes/lecture13/lecture13.html#learning-journey-today",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Learning Journey Today ğŸ¯",
    "text": "Learning Journey Today ğŸ¯\n\n\nğŸ§  Conceptual Goals\n\nUnderstand the logic of hypothesis testing\nMaster the language of statistical decisions\nRecognize different types of errors and their consequences\nConnect to confidence intervals from last lecture\n\n\nğŸ› ï¸ Practical Skills\n\nFormulate hypotheses from research questions\nCalculate and interpret p-values correctly\nPerform hypothesis tests in Python\nMake informed decisions using statistical evidence\nCommunicate results effectively"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#what-is-hypothesis-testing",
    "href": "files/lecture_notes/lecture13/lecture13.html#what-is-hypothesis-testing",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "What is Hypothesis Testing? ğŸ¤”",
    "text": "What is Hypothesis Testing? ğŸ¤”\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nHypothesis testing helps us answer: â€œIs what we observed in our sample strong enough evidence to conclude something about the population?â€"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#the-courtroom-analogy",
    "href": "files/lecture_notes/lecture13/lecture13.html#the-courtroom-analogy",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "The Courtroom Analogy âš–ï¸",
    "text": "The Courtroom Analogy âš–ï¸\n\n\n                            \n                                            \n\n\nKey Insight: Just like in court, we never â€œproveâ€ innocence or â€œacceptâ€ the null hypothesis. We only determine if thereâ€™s sufficient evidence to reject it!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#the-six-steps-of-hypothesis-testing",
    "href": "files/lecture_notes/lecture13/lecture13.html#the-six-steps-of-hypothesis-testing",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "The Six Steps of Hypothesis Testing ğŸ“‹",
    "text": "The Six Steps of Hypothesis Testing ğŸ“‹"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#types-of-alternative-hypotheses",
    "href": "files/lecture_notes/lecture13/lecture13.html#types-of-alternative-hypotheses",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Types of Alternative Hypotheses ğŸ¯",
    "text": "Types of Alternative Hypotheses ğŸ¯"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#understanding-p-values",
    "href": "files/lecture_notes/lecture13/lecture13.html#understanding-p-values",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Understanding P-values ğŸ“Š",
    "text": "Understanding P-values ğŸ“Š\nKey Message: P-value tells us â€œHow surprised should we be by this data if Hâ‚€ were true?â€"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#types-of-errors-the-trade-off",
    "href": "files/lecture_notes/lecture13/lecture13.html#types-of-errors-the-trade-off",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Types of Errors: The Trade-off ğŸ²",
    "text": "Types of Errors: The Trade-off ğŸ²\n\n\n                            \n                                            \n\n\nBottom Line: Thereâ€™s always a trade-off between Type I and Type II errors. Choose Î± based on which error is more costly in your context!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#statistical-power-detecting-true-effects",
    "href": "files/lecture_notes/lecture13/lecture13.html#statistical-power-detecting-true-effects",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Statistical Power: Detecting True Effects ğŸ’ª",
    "text": "Statistical Power: Detecting True Effects ğŸ’ª\n\n\n                            \n                                            \n\n\nKey Insight: Higher power means youâ€™re more likely to detect a true effect when it exists. Aim for power â‰¥ 0.80!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#example-1-one-sample-t-test",
    "href": "files/lecture_notes/lecture13/lecture13.html#example-1-one-sample-t-test",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Example 1: One-Sample t-test ğŸ“Š",
    "text": "Example 1: One-Sample t-test ğŸ“Š\nProblem Setup\nResearch Question: A new study technique claims to improve test scores. The current average is 75. We test 25 students using the new method.\n\n\nğŸ“Š Sample Data Summary:\n========================================\nSample size (n): 25\nSample mean (xÌ„): 77.19\nSample std (s): 7.65\nCurrent average (Î¼â‚€): 75\n\n\nComplete Hypothesis Test\n\n\n                            \n                                            \n\n\n\nğŸ¯ DETAILED RESULTS:\n==================================================\nTest Statistic: t = 1.432\nP-value: 0.0825\nCritical Value: 1.711\nEffect Size (Cohen's d): 0.286\n\nâŒ DECISION: Fail to reject Hâ‚€\nğŸ“Š CONCLUSION: There is insufficient evidence (p = 0.0825) that the new study method improves test scores.\nğŸ’¡ PRACTICAL IMPACT: The observed difference could reasonably be due to chance.\n\n\nUsing Pythonâ€™s Built-in Functions\n\n\nğŸ PYTHON IMPLEMENTATION:\n========================================\nMethod 1: scipy.stats.ttest_1samp\nt-statistic: 1.432\np-value (two-tailed): 0.1650\np-value (one-tailed): 0.0825\n\nMethod 2: Manual with 95% Confidence Interval\n95% CI: (74.03, 80.35)\nInterpretation: We're 95% confident the true mean is between 74.0 and 80.4\n\nEffect Size (Cohen's d): 0.286\nEffect size interpretation: small effect"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#example-2-two-sample-t-test",
    "href": "files/lecture_notes/lecture13/lecture13.html#example-2-two-sample-t-test",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Example 2: Two-Sample t-test ğŸ“Š",
    "text": "Example 2: Two-Sample t-test ğŸ“Š\nProblem Setup\nResearch Question: Compare effectiveness of two teaching methods\n\n\nğŸ“Š TWO-GROUP COMPARISON:\n========================================\nMethod A (Traditional):\n  n = 30, mean = 75.45, std = 11.87\n\nMethod B (New):\n  n = 28, mean = 82.72, std = 14.82\n\nDifference in means: 7.27 points"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#statistical-vs-practical-significance",
    "href": "files/lecture_notes/lecture13/lecture13.html#statistical-vs-practical-significance",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Statistical vs Practical Significance ğŸ¤”",
    "text": "Statistical vs Practical Significance ğŸ¤”\n\n\n                            \n                                            \n\n\nğŸ”‘ KEY LESSON: Statistical Significance â‰  Practical Importance\n============================================================\nLeft: Tiny effect (0.02) but significant due to large sample\nRight: Large effect (8.7) but significant with small sample\n\nğŸ’¡ Always consider BOTH statistical significance AND effect size!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#best-practices-summary",
    "href": "files/lecture_notes/lecture13/lecture13.html#best-practices-summary",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Best Practices Summary ğŸ“‹",
    "text": "Best Practices Summary ğŸ“‹"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#python-code-templates",
    "href": "files/lecture_notes/lecture13/lecture13.html#python-code-templates",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Python Code Templates ğŸ’»",
    "text": "Python Code Templates ğŸ’»\n\n# =============================================================================\n# COMPLETE HYPOTHESIS TESTING TOOLKIT\n# =============================================================================\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# -----------------------------------------------------------------------------\n# Template 1: One-Sample t-test\n# -----------------------------------------------------------------------------\ndef one_sample_ttest(data, null_value, alpha=0.05, alternative='two-sided'):\n    \"\"\"\n    Perform one-sample t-test with complete analysis\n    \n    Parameters:\n    -----------\n    data : array-like\n        Sample data\n    null_value : float\n        Hypothesized population mean\n    alpha : float\n        Significance level (default 0.05)\n    alternative : str\n        'two-sided', 'greater', or 'less'\n    \"\"\"\n    \n    # Calculate statistics\n    n = len(data)\n    x_bar = np.mean(data)\n    s = np.std(data, ddof=1)\n    se = s / np.sqrt(n)\n    \n    # Test statistic\n    t_stat = (x_bar - null_value) / se\n    df = n - 1\n    \n    # P-value calculation\n    if alternative == 'two-sided':\n        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    elif alternative == 'greater':\n        p_value = 1 - stats.t.cdf(t_stat, df)\n    elif alternative == 'less':\n        p_value = stats.t.cdf(t_stat, df)\n    \n    # Effect size (Cohen's d)\n    cohens_d = (x_bar - null_value) / s\n    \n    # Confidence interval\n    t_crit = stats.t.ppf(1 - alpha/2, df)\n    ci_lower = x_bar - t_crit * se\n    ci_upper = x_bar + t_crit * se\n    \n    # Results\n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'confidence_interval': (ci_lower, ci_upper),\n        'reject_null': p_value &lt;= alpha,\n        'sample_mean': x_bar,\n        'sample_std': s,\n        'sample_size': n\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 2: Two-Sample t-test\n# -----------------------------------------------------------------------------\ndef two_sample_ttest(group1, group2, alpha=0.05, equal_var=True):\n    \"\"\"\n    Perform two-sample t-test with complete analysis\n    \"\"\"\n    \n    # Calculate statistics\n    n1, n2 = len(group1), len(group2)\n    mean1, mean2 = np.mean(group1), np.mean(group2)\n    s1, s2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n    \n    if equal_var:\n        # Pooled variance\n        pooled_var = ((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2)\n        se = np.sqrt(pooled_var * (1/n1 + 1/n2))\n        df = n1 + n2 - 2\n    else:\n        # Welch's t-test\n        se = np.sqrt(s1**2/n1 + s2**2/n2)\n        df = (s1**2/n1 + s2**2/n2)**2 / ((s1**2/n1)**2/(n1-1) + (s2**2/n2)**2/(n2-1))\n    \n    # Test statistic\n    t_stat = (mean1 - mean2) / se\n    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    \n    # Effect size (Cohen's d)\n    if equal_var:\n        pooled_std = np.sqrt(pooled_var)\n    else:\n        pooled_std = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2))\n    \n    cohens_d = (mean1 - mean2) / pooled_std\n    \n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'reject_null': p_value &lt;= alpha,\n        'group1_stats': {'mean': mean1, 'std': s1, 'n': n1},\n        'group2_stats': {'mean': mean2, 'std': s2, 'n': n2}\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 3: Power Analysis\n# -----------------------------------------------------------------------------\ndef power_analysis(effect_size, alpha=0.05, power=0.8):\n    \"\"\"\n    Calculate required sample size for desired power\n    \"\"\"\n    from scipy.stats import norm\n    \n    z_alpha = norm.ppf(1 - alpha/2)\n    z_beta = norm.ppf(power)\n    \n    n = ((z_alpha + z_beta) / effect_size) ** 2\n    \n    return int(np.ceil(n))\n\n# -----------------------------------------------------------------------------\n# Example Usage\n# -----------------------------------------------------------------------------\n\n# Generate sample data\nnp.random.seed(42)\nsample_data = np.random.normal(105, 15, 25)\n\n# Perform one-sample t-test\nresults = one_sample_ttest(sample_data, null_value=100, alternative='greater')\n\nprint(\"One-Sample t-test Results:\")\nprint(f\"Test statistic: {results['test_statistic']:.3f}\")\nprint(f\"P-value: {results['p_value']:.4f}\")\nprint(f\"Effect size (d): {results['effect_size']:.3f}\")\nprint(f\"95% CI: ({results['confidence_interval'][0]:.2f}, {results['confidence_interval'][1]:.2f})\")\nprint(f\"Reject null: {results['reject_null']}\")\n\n# Power analysis\nrequired_n = power_analysis(effect_size=0.5, power=0.8)\nprint(f\"\\nRequired sample size for d=0.5, power=0.8: {required_n}\")"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#summary-key-takeaways",
    "href": "files/lecture_notes/lecture13/lecture13.html#summary-key-takeaways",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Summary: Key Takeaways ğŸ¯",
    "text": "Summary: Key Takeaways ğŸ¯\n\n\nğŸ§  Core Concepts\n\nHypothesis testing provides a framework for making decisions under uncertainty\nP-values quantify how surprising our data would be if Hâ‚€ were true\nStatistical significance â‰  practical importance - always consider effect size\nType I and II errors represent different kinds of mistakes with different costs\nPower is the ability to detect true effects when they exist\n\n\nğŸ› ï¸ Practical Skills\n\nPlan before you analyze - specify hypotheses and Î± level in advance\nCheck assumptions and use appropriate tests\nReport effect sizes and confidence intervals, not just p-values\nConsider practical significance alongside statistical significance\nBe honest about limitations and acknowledge uncertainty"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "href": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Todayâ€™s Agenda",
    "text": "Todayâ€™s Agenda\n\nIntroduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\nWhy it matters before any modeling\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset theyâ€™ve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "href": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Learning Objectives (LOs)",
    "text": "Learning Objectives (LOs)\nBy the end of this lecture you should be able to:\n\nDefine descriptive statistics and explain its importance in data analysis (SectionÂ 1)\nDistinguish between different types of data and measurement scales (SectionÂ 2)\nCalculate and interpret measures of central tendency (mean, median, mode)(SectionÂ 3)\nUnderstand when to use each measure of central tendency\nApply Python to compute descriptive statistics(SectionÂ 9)\nInterpret basic descriptive statistics in real-world contexts(SectionÂ 10)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Statistics",
    "text": "Statistics\nFacts are stubborn, but statistics are more pliable.\nMark Twain\n\nStatistics refers to the mathematics and techniques with which we understand data. 1\n\n\n(source)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What are Descriptive Statistics?",
    "text": "What are Descriptive Statistics?\nDescriptive statistics are numerical and graphical methods used to summarize, organize, and describe data in a meaningful way.\n\nPurpose of Descriptive Statistics\n\nSummarize large datasets into manageable information\nIdentify patterns and trends in data\nCommunicate findings clearly to others\nPrepare data for further analysis\nMake initial assessments about data quality"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs.Â Inferential Statistics",
    "text": "Descriptive vs.Â Inferential Statistics\n\n\n\n\n\n\n\nDescriptive Statistics\nInferential Statistics\n\n\n\n\nDescribes what the data shows\nMakes predictions about populations\n\n\nSummarizes sample data\nUses sample data to make generalizations\n\n\nNo conclusions beyond the data\nDraws conclusions beyond the immediate data\n\n\nExamples: mean, median, graphs\nExamples: hypothesis testing, confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs.Â Inferential Statistics",
    "text": "Descriptive vs.Â Inferential Statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "href": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Why Data Types Matter",
    "text": "Why Data Types Matter\nUnderstanding data types is crucial because:\n\nDifferent statistics are appropriate for different data types\nStatistical methods depend on the level of measurement\nMisapplying statistics can lead to incorrect conclusions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Data",
    "text": "Types of Data\ngraph TD\n    A[Variable Types]\n    A --&gt; B[Categorical]\n    A --&gt; C[Numerical]\n    B --&gt; B1[\"Nominal&lt;br/&gt;e.g., gender, major\"]\n    B --&gt; B2[\"Ordinal&lt;br/&gt;e.g., rating, education level\"]\n    C --&gt; C1[\"Discrete&lt;br/&gt;e.g., count (# of students)\"]\n    C --&gt; C2[\"Continuous&lt;br/&gt;e.g., measurements like height, weight\"]\n    \n    classDef root fill:#e1f5fe,stroke:#01579b,stroke-width:3px\n    classDef categorical fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef numerical fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px\n    classDef nominal fill:#fce4ec,stroke:#880e4f,stroke-width:2px\n    classDef ordinal fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef discrete fill:#e0f2f1,stroke:#00695c,stroke-width:2px\n    classDef continuous fill:#f1f8e9,stroke:#33691e,stroke-width:2px\n    \n    class A root\n    class B categorical\n    class C numerical\n    class B1 nominal\n    class B2 ordinal\n    class C1 discrete\n    class C2 continuous\n\nPrompt: Which summary stat would you pick for â€œmajorâ€? For â€œgpaâ€?"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Categorical Data (Qualitative)",
    "text": "Categorical Data (Qualitative)\n\n\nNominal Data\n\nCategories with no natural order\nExamples: gender, color, brand names, marital status\nAppropriate statistics: mode, frequency counts, proportions\n\n\nOrdinal Data\n\nCategories with a natural order or ranking\nExamples: education level, satisfaction ratings, letter grades\nAppropriate statistics: mode, median, percentiles"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Numerical Data (Quantitative)",
    "text": "Numerical Data (Quantitative)\n\nDiscrete Data\n\nCountable values, often integers\nExamples: number of children, cars sold, defective items\nCan take on finite or countably infinite values\n\n\n\nContinuous Data\n\nCan take any value within a range\nExamples: height, weight, temperature, time\nMeasured rather than counted"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "href": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Measurement Scales Summary",
    "text": "Measurement Scales Summary\n\n\n\n\n\n\n\n\n\n\nScale\nType\nProperties\nExamples\nAppropriate Statistics\n\n\n\n\nNominal\nCategorical\nCategories only\nGender, Color\nMode, Frequency\n\n\nOrdinal\nCategorical\nOrder matters\nRankings, Grades\nMode, Median\n\n\nInterval\nNumerical\nEqual intervals, no true zero\nTemperature (Â°C)\nMean, Median, Mode\n\n\nRatio\nNumerical\nEqual intervals, true zero\nHeight, Weight, Income\nAll statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What is Central Tendency?",
    "text": "What is Central Tendency?\nCentral tendency describes the center or typical value of a dataset.\nIt answers the question: â€œWhat is a representative value for this data?â€"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition and Formula",
    "text": "Definition and Formula\n\nğŸ¯ Definition: The mean is the sum of all values divided by the number of values.\n\n\nFormula\n\nFor a sample: \\(\\bar{x} = \\frac{\\sum x}{n}\\)\nFor a population: \\(\\mu = \\frac{\\sum x}{N}\\)\n\nWhere:\n\n\\(\\bar{x}\\) (x-bar) = sample mean\n\\(\\mu\\) (mu) = population mean\n\\(\\sum x\\) = sum of all values\n\\(n\\) = sample size, \\(N\\) = population size"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example Calculation",
    "text": "Example Calculation\nStudent test scores: 85, 90, 78, 92, 88\n\nMean = \\(\\frac{85 + 90 + 78 + 92 + 88}{5} = \\frac{433}{5} = 86.6\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mean",
    "text": "Properties of the Mean\n\nUses all data points - every value affects the mean\nSensitive to outliers - extreme values can distort the mean\nUnique - there is only one mean for a dataset\nCan be calculated for interval and ratio data\nBalancing point - sum of deviations from mean equals zero"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mean",
    "text": "When to Use the Mean\nâœ… Use the mean when:\n\nData is approximately symmetric\nNo extreme outliers present\nWorking with interval or ratio data\nNeed to use the value in further calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "href": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Advantages and Disadvantages",
    "text": "Advantages and Disadvantages\n\n\nAdvantages\n\nUses all information in the dataset\nAlgebraically defined and mathematically tractable\nWidely understood and accepted\n\n\nDisadvantages\n\nAffected by outliers and skewed distributions\nMay not represent a typical value in skewed data\nCannot be used with nominal or ordinal data"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\n\nğŸ¯ Definition: The median is the middle value when data is arranged in ascending or descending order."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "href": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Calculation Steps",
    "text": "Calculation Steps\n\nArrange data in ascending order\nFind the middle position:\n\nIf n is odd: position = \\(\\frac{n + 1}{2}\\)\nIf n is even: average of positions \\(\\frac{n}{2}\\) and \\(\\frac{n}{2} + 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#examples",
    "href": "files/lecture_notes/lecture2/lecture2.html#examples",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Examples",
    "text": "Examples\n\nOdd number of values:\n\nData: 12, 15, 18, 20, 25\nWhat is the median here ?\nMedian = 18 (middle value)\n\n\n\nEven number of values:\n\nData: 10, 15, 20, 25, 30, 35\nWhat is the median here ?\nMedian = \\(\\frac{20 + 25}{2} = 22.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Median",
    "text": "Properties of the Median\n\nNot affected by outliers - resistant measure\nRepresents the 50th percentile\nMay not be an actual data value (when n is even)\nAppropriate for ordinal, interval, and ratio data\nDivides data into two equal halves"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Median",
    "text": "When to Use the Median\nâœ… Use the median when:\n\nData is skewed (not symmetric)\nOutliers are present\nWorking with ordinal data\nWant a robust measure of central tendency\nData represents income, housing prices, or similar distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "href": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Median vs Mean with Outliers",
    "text": "Median vs Mean with Outliers\nConsider household incomes: $30,000, $32,000, $35,000, $38,000, $2,000,000\n\n\nMean = $427,000 (not representative of typical household)\nMedian = $35,000 (better represents typical household)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\n\nğŸ¯ Definition: The mode is the value that appears most frequently in a dataset.\n\n%%{init: {'flowchart': {'nodeSpacing': 100, 'rankSpacing': 100}, 'width': 600, 'height': 400}}%%\ngraph TD\n    A[\"Mode Types\"]\n    A --&gt; B[\"Unimodal&lt;br/&gt;One peak\"]\n    A --&gt; C[\"Bimodal&lt;br/&gt;Two peaks\"]\n    A --&gt; D[\"Multimodal&lt;br/&gt;Multiple peaks\"]\n    A --&gt; E[\"No Mode&lt;br/&gt;No repeated values\"]\n    \n    classDef main fill:#e1f5fe,stroke:#01579b,stroke-width:3px,font-size:16px\n    classDef types fill:#f5f5f5,stroke:#424242,stroke-width:2px,font-size:14px\n    \n    class A main\n    class B,C,D,E types"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Distributions by Mode",
    "text": "Types of Distributions by Mode\n\nUnimodal: One mode\nBimodal: Two modes\n\nMultimodal: More than two modes\nNo mode: All values appear with equal frequency"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 1:",
    "text": "Example 1:\nData: 2, 3, 3, 4, 5, 5, 5, 6, 7\n\nAnalysis:\n\nCount each value: 2(1), 3(2), 4(1), 5(3), 6(1), 7(1)\nMost frequent value: 5 appears 3 times\nMode = 5\nType: Unimodal (one mode)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 2:",
    "text": "Example 2:\nData: 1, 2, 2, 3, 4, 4, 5\n\nAnalysis:\n\nCount each value: 1(1), 2(2), 3(1), 4(2), 5(1)\nMost frequent values: 2 and 4 both appear twice\nModes = 2 and 4\nType: Bimodal (two modes)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 3:",
    "text": "Example 3:\nData: 1, 2, 3, 4, 5\n\nAnalysis:\n\nCount each value: 1(1), 2(1), 3(1), 4(1), 5(1)\nAll values appear exactly once\nNo mode (no value repeats)\nType: No mode"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "href": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mode for Different Data Types",
    "text": "Mode for Different Data Types\nCategorical Data:\nFavorite colors: Red, Blue, Blue, Green, Blue, Red, Blue Mode = Blue\nContinuous Data:\nOften requires grouping into intervals or bins Example: Heights grouped into ranges"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mode",
    "text": "Properties of the Mode\n\nCan be used with any type of data (nominal, ordinal, interval, ratio)\nNot affected by outliers\nMay not exist or may not be unique\nRepresents the most common value\nEasy to identify in frequency distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mode",
    "text": "When to Use the Mode\nâœ… Use the mode when:\n\nWorking with categorical (nominal) data\nWant to identify the most popular or common choice\nData has clear peaks in frequency\nQuality control applications (most common defect type)\nBusiness applications (best-selling product, most common customer complaint)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Comparing Measures of Central Tendency",
    "text": "Comparing Measures of Central Tendency\n\n\n\n\n\n\n\n\n\n\nMeasure\nBest for Data Type\nStrengths\nWeaknesses\nAffected by Outliers?\n\n\n\n\nMean\nInterval, Ratio\nUses all data, mathematically tractable\nSensitive to outliers\nYes\n\n\nMedian\nOrdinal, Interval, Ratio\nRobust to outliers, represents middle\nIgnores extreme values\nNo\n\n\nMode\nAll types\nWorks with categorical, identifies most common\nMay not exist/be unique\nNo"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "href": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Shape of Distribution Effects",
    "text": "Shape of Distribution Effects\n\nSymmetric distribution: Mean â‰ˆ Median â‰ˆ Mode\nRight-skewed (positively skewed): Mean &gt; Median &gt; Mode\n\nLeft-skewed (negatively skewed): Mode &gt; Median &gt; Mean"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "href": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Central Measures",
    "text": "Central Measures\n\n\n\nMean CalculationMedian CalculationMode Calculation\n\n\n\n# Import numpy library for numeric operations\nimport numpy as np \n\n# Import pandas library for data structures\nimport pandas as pd\n\n# Define sample data as a list of test scores\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\n\n# Compute the arithmetic mean using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np:.2f}\")\n\n# Convert the data list into a pandas DataFrame\ndf = pd.DataFrame({'scores': data})\n\n# Compute the arithmetic mean using Pandas\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd:.2f}\")\n\n# Manually sum all scores and divide by count\nmanual_mean = sum(data) / len(data)\nprint(f\"Mean (Manual): {manual_mean:.2f}\")\n\nMean (NumPy): 87.10\nMean (Pandas): 87.10\nMean (Manual): 87.10\n\n\n\n\n\n# Compute the median value using NumPy\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np:.2f}\")\n\n# Compute the median value using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd:.2f}\")\n\n# Sort the data list in ascending order\nsorted_data = sorted(data)\n\n# Determine the number of elements\nn = len(sorted_data)\n\n# If even count, average the two middle elements; else take middle element\nif n % 2 == 0:\n    manual_median = (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2\nelse:\n    manual_median = sorted_data[n//2]\n\nprint(f\"Median (Manual): {manual_median:.2f}\")\n\nMedian (NumPy): 87.50\nMedian (Pandas): 87.50\nMedian (Manual): 87.50\n\n\n\n\n\n# Import SciPy stats module to compute mode\nfrom scipy import stats\n\n# Use SciPy to find the most common value and its count\nmode_result = stats.mode(data, keepdims=True)\nprint(f\"Mode (SciPy): {mode_result.mode[0]}, Count: {mode_result.count[0]}\")\n\n# Use Pandas to get mode(s) from the DataFrame\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\n# Import Counter for manual frequency counting\nfrom collections import Counter\n\n# Count occurrences of each score\ncounter = Counter(data)\n\n# Find the highest frequency\nmax_count = max(counter.values())\n\n# Identify all values that appear with that frequency\nmodes = [k for k, v in counter.items() if v == max_count]\n\nprint(f\"Mode (Manual): {modes}, Count: {max_count}\")\n\nMode (SciPy): 85, Count: 2\nMode (Pandas): [85]\nMode (Manual): [85], Count: 2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "href": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mean, Mode and Median Visualization",
    "text": "Mean, Mode and Median Visualization\n\nCodeVisualization\n\n\n\n# import libraries\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n# define your data and compute statistics here\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\nmean_np   = np.mean(data)\nmedian_np = np.median(data)\n# for mode, use Counter\ncounter   = Counter(data)\nmax_count = max(counter.values())\nmodes     = [k for k,v in counter.items() if v==max_count]\nmode_val  = modes[0]\n\n\n\n\n\n\n\n\nDistribution of Test Scores with Central Tendency Measures"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Business Applications",
    "text": "Business Applications\n\nCustomer Satisfaction: Mean rating shows overall satisfaction, median shows typical experience\nSales Data: Mode identifies best-selling products, median shows typical sale amount\n\nEmployee Performance: Mean for overall team performance, median for typical employee"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Educational Applications",
    "text": "Educational Applications\n\nTest Scores: Mean for class average, median for typical student performance\nGrade Distribution: Mode shows most common grade\nAttendance: Mean for overall attendance rate"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Healthcare Applications",
    "text": "Healthcare Applications\n\nPatient Wait Times: Median often preferred due to skewed distributions\nTreatment Outcomes: Mean for overall effectiveness, mode for most common result\nVital Signs: All three measures provide different insights"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "href": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Interpretation Guidelines",
    "text": "Interpretation Guidelines\n\nAlways consider the context of your data\nReport multiple measures when appropriate\n\nBe aware of data distribution shape\nConsider the presence of outliers\nChoose the most appropriate measure for your specific question"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "href": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Remember These Points",
    "text": "Remember These Points\n\nData type determines which statistics are appropriate\nMean uses all data but is sensitive to outliers\nMedian is robust and represents the middle value\nMode identifies the most common value and works with all data types\nContext matters when choosing and interpreting measures\nPython provides powerful tools for calculating descriptive statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "href": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Next Lecture Preview",
    "text": "Next Lecture Preview\nDescriptive Statistics Part II will cover:\n\nMeasures of variability (range, variance, standard deviation)\nMeasures of position (percentiles, quartiles, z-scores)\nShape of distributions (skewness and kurtosis)\nAdvanced Python visualization techniques"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "href": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Try These Problems",
    "text": "Try These Problems\n\nCalculate mean, median, and mode for: 12, 15, 18, 12, 20, 25, 12, 30\nA dataset has mean = 50 and median = 45. What does this tell you about the distribution?\nWhy might median be preferred over mean for reporting household income?\nCreate a Python function to identify the most appropriate measure of central tendency for a given dataset."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#learning-objectives",
    "href": "files/lecture_notes/lecture3/lecture3.html#learning-objectives",
    "title": "Descriptive Statistics Part II",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture, you will be able to:\n\nCalculate and interpret measures of variability (range, variance, standard deviation)\nUnderstand and compute measures of position (percentiles, quartiles, z-scores)\nAssess distribution shape using skewness and kurtosis\nCreate and interpret histograms with appropriate bin widths\nConstruct and analyze boxplots for data exploration\nIdentify trends, patterns, and outliers in data visualizations\nApply Python for comprehensive descriptive analysis and visualization"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#lecture-outline",
    "href": "files/lecture_notes/lecture3/lecture3.html#lecture-outline",
    "title": "Descriptive Statistics Part II",
    "section": "Lecture Outline",
    "text": "Lecture Outline\n\n\nPart I: Measures of Variability (25 min)\n\nRange, Variance, Standard Deviation\nCoefficient of Variation\nPython Implementation\n\nPart II: Measures of Position (20 min)\n\nPercentiles and Quartiles\nZ-scores and Standardization\n\n\n\nPart III: Distribution Shape (10 min)\n\nSkewness and Kurtosis\n\nPart IV: Data Visualization (20 min)\n\nHistograms and Bin Width Selection\nBoxplots and Interpretation\n\nPart V: Identifying Patterns (5 min)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-is-variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-is-variability",
    "title": "Descriptive Statistics Part II",
    "section": "What is Variability?",
    "text": "What is Variability?\n\nğŸ¯ Definition: Variability (or dispersion) measures how spread out or scattered the data points are around the center.\n\nWhy Variability Matters\n\nTwo datasets can have the same mean but very different spreads\nVariability indicates consistency and predictability\nEssential for risk assessment and quality control\nHelps determine confidence in our central tendency measures"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#range",
    "href": "files/lecture_notes/lecture3/lecture3.html#range",
    "title": "Descriptive Statistics Part II",
    "section": "Range",
    "text": "Range\n\nRange = Maximum value - Minimum value\n\nExample\nData: 12, 15, 18, 22, 25, 30, 35\n\nRange = 35 - 12 = 23"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#when-to-use-range",
    "href": "files/lecture_notes/lecture3/lecture3.html#when-to-use-range",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Range",
    "text": "When to Use Range\nâœ… Use range when:\n\nNeed a quick, simple measure of spread\nWorking with small datasets\nCommunicating to non-technical audiences\n\nâŒ Avoid range when:\n\nOutliers are present\nNeed detailed information about variability\nWorking with large datasets"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#variance-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#variance-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Variance Definition",
    "text": "Variance Definition\n\nğŸ¯ Definition: Variance measures the average squared deviation from the mean."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#recall",
    "href": "files/lecture_notes/lecture3/lecture3.html#recall",
    "title": "Descriptive Statistics Part II",
    "section": "Recall",
    "text": "Recall"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#side-by-side-comparison",
    "href": "files/lecture_notes/lecture3/lecture3.html#side-by-side-comparison",
    "title": "Descriptive Statistics Part II",
    "section": "Side-by-Side Comparison",
    "text": "Side-by-Side Comparison\n\n\n\nPopulation Variance\n\n\n\\[\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\]\n\n\\(\\sigma^2\\) = population variance\n\\(x_i\\) = value of \\(i^{th}\\) element\n\\(\\mu\\) = population mean\n\\(N\\) = population size\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\]\n\n\\(s^2\\) = sample variance\n\\(x_i\\) = value of \\(i^{th}\\) element\n\\(\\bar{x}\\) = sample mean\n\\(n\\) = sample size"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#key-differences",
    "href": "files/lecture_notes/lecture3/lecture3.html#key-differences",
    "title": "Descriptive Statistics Part II",
    "section": "Key Differences",
    "text": "Key Differences\n\nKey Difference: Sample variance uses \\((n-1)\\) instead of \\(N\\) in the denominator\n\nWhy \\((n-1)\\)?\n\nWhen we use sample mean \\(\\bar{x}\\) to estimate population mean \\(\\mu\\)\nWe lose one degree of freedom\nCalled Besselâ€™s correction\nMakes sample variance an unbiased estimator"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#when-to-use-each-formula",
    "href": "files/lecture_notes/lecture3/lecture3.html#when-to-use-each-formula",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Each Formula",
    "text": "When to Use Each Formula\n\nPopulation Variance (\\(\\sigma^2\\))\n\nYou have data for the entire population\nYou know the true population mean \\(\\mu\\)\nExample: Test scores for all students in a small class\n\n\n\nSample Variance (\\(s^2\\))\n\nYou have data from a sample only\nWant to estimate population variance\nExample: Survey responses from 100 people out of 10,000"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#understanding-degrees-of-freedom",
    "href": "files/lecture_notes/lecture3/lecture3.html#understanding-degrees-of-freedom",
    "title": "Descriptive Statistics Part II",
    "section": "Understanding Degrees of Freedom",
    "text": "Understanding Degrees of Freedom\n\n\nğŸ“Š Population Case\nAll observations are independent\n\nWe know the true population mean \\(\\mu\\)\nEach of the \\(N\\) observations provides independent information\nNo constraints on the data\n\n\n\\[\\text{Degrees of Freedom} = N\\]\n\n\n\nğŸ“ˆ Sample Case\nConstraint introduced by sample mean\n\nWe must estimate \\(\\mu\\) using \\(\\bar{x}\\)\nOnce we know \\(\\bar{x}\\) and \\((n-1)\\) observations, the last one is determined\nWe â€œloseâ€ one degree of freedom\n\n\n\\[\\text{Degrees of Freedom} = n-1\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#section",
    "href": "files/lecture_notes/lecture3/lecture3.html#section",
    "title": "Descriptive Statistics Part II",
    "section": "",
    "text": "Sample Mean Constraint\n\\[\\bar{x} = \\frac{x_1 + x_2 + \\cdots + x_n}{n}\\]\nRearranging: \\[x_n = n\\bar{x} - (x_1 + x_2 + \\cdots + x_{n-1})\\]\nOnce we know \\(\\bar{x}\\) and the first \\((n-1)\\) values, \\(x_n\\) is completely determined!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#example-calculation",
    "href": "files/lecture_notes/lecture3/lecture3.html#example-calculation",
    "title": "Descriptive Statistics Part II",
    "section": "Example Calculation",
    "text": "Example Calculation\nData: 3, 7, 2, 8, 5\nIf this is the entire population:\n\n\\(\\mu = \\frac{3+7+2+8+5}{5} = 5\\)\n\\(\\sigma^2 = \\frac{(3-5)^2+(7-5)^2+(2-5)^2+(8-5)^2+(5-5)^2}{5} = \\frac{22}{5} = 4.4\\)\n\nIf this is a sample:\n\n\\(\\bar{x} = 5\\) (same calculation)\n\\(s^2 = \\frac{22}{5-1} = \\frac{22}{4} = 5.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#variance-properties",
    "href": "files/lecture_notes/lecture3/lecture3.html#variance-properties",
    "title": "Descriptive Statistics Part II",
    "section": "Variance Properties",
    "text": "Variance Properties\nVariance measures:\n\nAverage squared deviation from the mean\nAlways non-negative: \\(\\sigma^2 \\geq 0\\), \\(s^2 \\geq 0\\)\nUnits: (original units)Â²\n\nStandard Deviation:\n\n\\(\\sigma = \\sqrt{\\sigma^2}\\) (population)\n\\(s = \\sqrt{s^2}\\) (sample)\nSame units as original data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#bias-and-unbiasedness",
    "href": "files/lecture_notes/lecture3/lecture3.html#bias-and-unbiasedness",
    "title": "Descriptive Statistics Part II",
    "section": "Bias and Unbiasedness",
    "text": "Bias and Unbiasedness\nPopulation variance:\n\nTrue parameter value\nNo estimation involved\n\nSample variance with \\((n-1)\\):\n\n\\(E[s^2] = \\sigma^2\\) (unbiased)\nOn average, equals population variance\n\nSample variance with \\(n\\):\n\n\\(E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n}\\right] = \\frac{n-1}{n}\\sigma^2\\) (biased)\nSystematically underestimates population variance"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#implementation",
    "href": "files/lecture_notes/lecture3/lecture3.html#implementation",
    "title": "Descriptive Statistics Part II",
    "section": "Implementation",
    "text": "Implementation\nCalculators:\n\nMost use \\((n-1)\\) by default for sample standard deviation\nCheck your calculatorâ€™s documentation\n\nSoftware:\n\nR: var() uses \\((n-1)\\), sd() uses \\((n-1)\\)\nExcel: VAR.S() uses \\((n-1)\\), VAR.P() uses \\(n\\)\nPython: np.var(ddof=1) uses \\((n-1)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practice-problem",
    "href": "files/lecture_notes/lecture3/lecture3.html#practice-problem",
    "title": "Descriptive Statistics Part II",
    "section": "Practice Problem",
    "text": "Practice Problem\nDataset: Number of hours studied by 6 students: 2, 4, 3, 5, 6, 4\nCalculate both:\n\nPopulation variance (assuming this is the entire population)\nSample variance (assuming this is a sample)\n\n\nSolution:\n\nMean: \\(\\bar{x} = \\frac{24}{6} = 4\\)\nPopulation variance: \\(\\sigma^2 = \\frac{10}{6} = 1.67\\)\nSample variance: \\(s^2 = \\frac{10}{5} = 2.0\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#summary",
    "href": "files/lecture_notes/lecture3/lecture3.html#summary",
    "title": "Descriptive Statistics Part II",
    "section": "Summary",
    "text": "Summary\n\nKey Takeaways\n\nPopulation variance uses \\(N\\) (entire population)\nSample variance uses \\((n-1)\\) (Besselâ€™s correction)\nSample variance is unbiased estimator of population variance\nDifference matters more for small samples\nAlways check which formula your software uses!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#example-1",
    "href": "files/lecture_notes/lecture3/lecture3.html#example-1",
    "title": "Descriptive Statistics Part II",
    "section": "Example",
    "text": "Example\n\n\nğŸ“Š Complete Population Data (Test Scores)\nWe have test scores from 100 students arranged in a grid:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nM\nN\nO\nP\nQ\nR\nS\nT\n\n\n\n\n1\n24\n96\n30\n69\n85\n60\n55\n18\n30\n66\n64\n99\n92\n95\n84\n55\n72\n38\n86\n32\n\n\n2\n53\n81\n30\n89\n42\n94\n31\n26\n53\n78\n38\n60\n93\n90\n82\n85\n89\n54\n30\n58\n\n\n3\n62\n67\n75\n47\n99\n25\n32\n63\n49\n45\n30\n97\n57\n32\n37\n62\n33\n16\n11\n41\n\n\n4\n95\n74\n28\n73\n82\n97\n65\n88\n56\n95\n85\n44\n70\n65\n34\n85\n58\n15\n64\n84\n\n\n5\n76\n46\n83\n56\n98\n16\n76\n77\n35\n19\n97\n42\n90\n79\n73\n28\n82\n92\n90\n22\n\n\n\n\n\n\nğŸ¯ Random Sample Selection\nWe randomly select 5 scores from different positions in our population:\nOur Sample: 82, 95, 83, 60, 92"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#final-calculations",
    "href": "files/lecture_notes/lecture3/lecture3.html#final-calculations",
    "title": "Descriptive Statistics Part II",
    "section": "Final Calculations",
    "text": "Final Calculations\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum(x_i - \\bar{x})^2}{n-1}\\] \\[s^2 = \\frac{753.2}{5-1} = \\frac{753.2}{4} = 188.3\\]\n\n\n\n\nSample Standard Deviation\n\n\n\\[s = \\sqrt{s^2}\\] \\[s = \\sqrt{188.3} = 13.72\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#properties-of-standard-deviation",
    "href": "files/lecture_notes/lecture3/lecture3.html#properties-of-standard-deviation",
    "title": "Descriptive Statistics Part II",
    "section": "Properties of Standard Deviation",
    "text": "Properties of Standard Deviation\n\nSame units as the original data\nAlways non-negative\nZero only when all values are identical\nLarger values indicate more variability\nApproximately 68% of data within 1 SD of mean (for normal distributions)\nApproximately 95% of data within 2 SD of mean"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#empirical-rule-68-95-99.7-rule",
    "href": "files/lecture_notes/lecture3/lecture3.html#empirical-rule-68-95-99.7-rule",
    "title": "Descriptive Statistics Part II",
    "section": "Empirical Rule (68-95-99.7 Rule)",
    "text": "Empirical Rule (68-95-99.7 Rule)\nFor approximately normal distributions:\n\n68% of data falls within 1 standard deviation of the mean\n95% of data falls within 2 standard deviations of the mean\n99.7% of data falls within 3 standard deviations of the mean\n\nThis rule helps us understand what constitutes â€œtypicalâ€ vs â€œunusualâ€ values."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#definition-and-purpose",
    "href": "files/lecture_notes/lecture3/lecture3.html#definition-and-purpose",
    "title": "Descriptive Statistics Part II",
    "section": "Definition and Purpose",
    "text": "Definition and Purpose\n\nğŸ¯ Definition: Coefficient of Variation (CV) = \\(\\frac{\\text{Standard Deviation}}{\\text{Mean}} \\times 100\\%\\)\n\n\nWhy Use CV?\n\nCompares variability across different units or scales\nRelative measure of variability\nUseful when means differ substantially"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-implementation---variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-implementation---variability",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Variability",
    "text": "Python Implementation - Variability\n\nCodeVisualization\n\n\n\nimport numpy as np\nimport pandas as pd\n\n# Sample data\ndata = [10, 12, 14, 16, 18, 22, 25]\n\n# Calculate measures of variability\nrange_val = np.max(data) - np.min(data)\nvariance_sample = np.var(data, ddof=1)  # Sample variance\nstd_sample = np.std(data, ddof=1)       # Sample standard deviation\ncv = (std_sample / np.mean(data)) * 100\n\nprint(f\"Range: {range_val}\")\nprint(f\"Variance: {variance_sample:.2f}\")\nprint(f\"Standard Deviation: {std_sample:.2f}\")\nprint(f\"Coefficient of Variation: {cv:.1f}%\")\n\nRange: 15\nVariance: 28.90\nStandard Deviation: 5.38\nCoefficient of Variation: 32.2%"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-are-measures-of-position",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-are-measures-of-position",
    "title": "Descriptive Statistics Part II",
    "section": "What are Measures of Position?",
    "text": "What are Measures of Position?\n\n\nMeasures of position tell us where a particular value stands relative to the rest of the data.\nThey answer questions like:\n\nâ€œWhat percentage of students scored below 85?â€\nâ€œIs this value typical or unusual?â€\nâ€œHow does this observation compare to others?â€"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#percentiles-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#percentiles-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Percentiles Definition",
    "text": "Percentiles Definition\nThe k-th percentile is the value below which k% of the data falls.\nExamples:\n\n50th percentile = Median (50% of data below this value)\n90th percentile = 90% of data falls below this value\n25th percentile = 25% of data falls below this value"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#quartiles",
    "href": "files/lecture_notes/lecture3/lecture3.html#quartiles",
    "title": "Descriptive Statistics Part II",
    "section": "Quartiles",
    "text": "Quartiles\nQuartiles divide the data into four equal parts:\n\nQ1 (First Quartile) = 25th percentile\nQ2 (Second Quartile) = 50th percentile = Median\nQ3 (Third Quartile) = 75th percentile"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#interquartile-range-iqr",
    "href": "files/lecture_notes/lecture3/lecture3.html#interquartile-range-iqr",
    "title": "Descriptive Statistics Part II",
    "section": "Interquartile Range (IQR)",
    "text": "Interquartile Range (IQR)\nIQR = Q3 - Q1\n\n\n\n\nProperties of IQR:\n\nContains the middle 50% of the data\nResistant to outliers\nUsed in boxplot construction\nUseful for outlier detection"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#z-score-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#z-score-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Z-score Definition",
    "text": "Z-score Definition\n\n\n\nğŸ¯ Definition\nZ-score tells us how many standard deviations a value is from the mean.\n\n\n\\[z = \\frac{x - \\mu}{\\sigma} \\text{ or } z = \\frac{x - \\bar{x}}{s}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#z-score-example",
    "href": "files/lecture_notes/lecture3/lecture3.html#z-score-example",
    "title": "Descriptive Statistics Part II",
    "section": "Z-score Example",
    "text": "Z-score Example\nStudentâ€™s test score: 85 Class mean: 78, Class standard deviation: 6\n\n\\[z = \\frac{85 - 78}{6} = \\frac{7}{6} = 1.17\\]\n\nInterpretation: This student scored 1.17 standard deviations above the class average."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#benefits-of-standardization",
    "href": "files/lecture_notes/lecture3/lecture3.html#benefits-of-standardization",
    "title": "Descriptive Statistics Part II",
    "section": "Benefits of Standardization",
    "text": "Benefits of Standardization\n\nCompare across different scales (test scores vs income)\nIdentify outliers systematically\n\nCombine different variables meaningfully\nPrepare data for certain statistical methods"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#skewness",
    "href": "files/lecture_notes/lecture3/lecture3.html#skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Skewness",
    "text": "Skewness\nSkewness measures the asymmetry of a distribution.\nTypes of Skewness:\n\n\n\n\nSymmetric (Skewness â‰ˆ 0): Mean â‰ˆ Median â‰ˆ Mode\nRight-skewed (Positive skewness): Mean &gt; Median, long tail to the right\nLeft-skewed (Negative skewness): Mean &lt; Median, long tail to the left"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#examples-of-skewness",
    "href": "files/lecture_notes/lecture3/lecture3.html#examples-of-skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Examples of Skewness",
    "text": "Examples of Skewness\nRight-skewed (Income data):\n\nMost people earn moderate amounts\nFew people earn very high amounts\nMean &gt; Median\n\nLeft-skewed (Test scores with ceiling effect):\n\nMost students score high\nFew students score very low\nMean &lt; Median"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#kurtosis",
    "href": "files/lecture_notes/lecture3/lecture3.html#kurtosis",
    "title": "Descriptive Statistics Part II",
    "section": "Kurtosis",
    "text": "Kurtosis\nKurtosis measures the â€œtailednessâ€ of a distribution. It measures the degree of peaked Ness or flatness of a distribution compared to the normal distribution.\nTypes:\n\nMesokurtic (Normal-like): Kurtosis â‰ˆ 3\nLeptokurtic (Heavy tails): Kurtosis &gt; 3, more peaked\nPlatykurtic (Light tails): Kurtosis &lt; 3, flatter\n\nExcess Kurtosis = Kurtosis - 3 (makes normal distributions have excess kurtosis of 0)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-implementation---position-shape",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-implementation---position-shape",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Position & Shape",
    "text": "Python Implementation - Position & Shape\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndata = [12, 15, 18, 22, 25, 28, 30, 35, 40, 45]\n\n# Percentiles and quartiles\nq1 = np.percentile(data, 25)\nmedian = np.percentile(data, 50)\nq3 = np.percentile(data, 75)\niqr = q3 - q1\n\n# Z-scores\nz_scores = stats.zscore(data)\n\n# Shape measures\nskewness = stats.skew(data)\nkurt = stats.kurtosis(data)\n\nprint(f\"Q1: {q1}, Median: {median}, Q3: {q3}\")\nprint(f\"IQR: {iqr}\")\nprint(f\"Skewness: {skewness:.3f}\")\nprint(f\"Kurtosis: {kurt:.3f}\")\n\nQ1: 19.0, Median: 26.5, Q3: 33.75\nIQR: 14.75\nSkewness: 0.243\nKurtosis: -1.023"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-is-a-histogram",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-is-a-histogram",
    "title": "Descriptive Statistics Part II",
    "section": "What is a Histogram?",
    "text": "What is a Histogram?\nA histogram displays the distribution of a continuous variable by dividing data into bins and showing the frequency of observations in each bin.\nKey Components:\n\nX-axis: Variable values (continuous)\nY-axis: Frequency or density\nBins: Intervals that group the data\nBars: Height represents frequency in each bin"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#choosing-bin-width-critical-decision",
    "href": "files/lecture_notes/lecture3/lecture3.html#choosing-bin-width-critical-decision",
    "title": "Descriptive Statistics Part II",
    "section": "Choosing Bin Width: Critical Decision",
    "text": "Choosing Bin Width: Critical Decision\nBin width dramatically affects histogram interpretation!\nToo Few Bins (Wide bins):\n\nOversmoothing - lose important details\nMay hide multimodality\nDistribution appears simpler than it is\n\nToo Many Bins (Narrow bins):\n\nUndersmoothing - too much noise\nMay create artificial gaps\nHard to see overall pattern"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#bin-width-guidelines",
    "href": "files/lecture_notes/lecture3/lecture3.html#bin-width-guidelines",
    "title": "Descriptive Statistics Part II",
    "section": "Bin Width Guidelines",
    "text": "Bin Width Guidelines\nRule of Thumb Methods:\n\nSquare Root Rule: Number of bins â‰ˆ \\(\\sqrt{n}\\)\nSturgesâ€™ Rule: Number of bins = \\(1 + \\log_2(n)\\)\nScottâ€™s Rule: Bin width = \\(\\frac{3.5 \\times \\text{SD}}{n^{1/3}}\\)\nFreedman-Diaconis Rule: Bin width = \\(\\frac{2 \\times \\text{IQR}}{n^{1/3}}\\)\n\nBest practice: Try multiple bin widths and choose based on the story your data tells!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-histogram-examples",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-histogram-examples",
    "title": "Descriptive Statistics Part II",
    "section": "Python Histogram Examples",
    "text": "Python Histogram Examples\n\nCodeVisualization\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate sample data\nnp.random.seed(42)\ndata = np.random.normal(100, 15, 1000)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#interpreting-histograms",
    "href": "files/lecture_notes/lecture3/lecture3.html#interpreting-histograms",
    "title": "Descriptive Statistics Part II",
    "section": "Interpreting Histograms",
    "text": "Interpreting Histograms\nWhat to Look For:\n\nShape: Normal, skewed, uniform, bimodal?\nCenter: Where is the â€œtypicalâ€ value?\nSpread: How variable is the data?\nOutliers: Any unusual values?\nGaps: Are there missing values in certain ranges?\nMultiple peaks: Suggests multiple subgroups"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#anatomy-of-a-boxplot",
    "href": "files/lecture_notes/lecture3/lecture3.html#anatomy-of-a-boxplot",
    "title": "Descriptive Statistics Part II",
    "section": "Anatomy of a Boxplot",
    "text": "Anatomy of a Boxplot"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#boxplot-components-explained",
    "href": "files/lecture_notes/lecture3/lecture3.html#boxplot-components-explained",
    "title": "Descriptive Statistics Part II",
    "section": "Boxplot Components Explained",
    "text": "Boxplot Components Explained\nThe Box:\n\nLeft edge: Q1 (25th percentile)\nMiddle line: Median (Q2, 50th percentile)\n\nRight edge: Q3 (75th percentile)\nBox width: IQR (contains middle 50% of data)\n\nThe Whiskers:\n\nExtend to: Most extreme values within 1.5 Ã— IQR from box edges\nLower whisker: Minimum value within Q1 - 1.5Ã—IQR\nUpper whisker: Maximum value within Q3 + 1.5Ã—IQR"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-boxplots-tell-us",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-boxplots-tell-us",
    "title": "Descriptive Statistics Part II",
    "section": "What Boxplots Tell Us",
    "text": "What Boxplots Tell Us\nDistribution Shape:\n\nSymmetric: Median in center of box, whiskers equal length\nRight-skewed: Median closer to Q1, longer upper whisker\nLeft-skewed: Median closer to Q3, longer lower whisker\n\nVariability:\n\nWide box: High variability in middle 50%\nLong whiskers: High overall variability\nMany outliers: Extreme variability"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#comparing-groups-with-boxplots",
    "href": "files/lecture_notes/lecture3/lecture3.html#comparing-groups-with-boxplots",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Groups with Boxplots",
    "text": "Comparing Groups with Boxplots"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#advanced-boxplot-interpretations",
    "href": "files/lecture_notes/lecture3/lecture3.html#advanced-boxplot-interpretations",
    "title": "Descriptive Statistics Part II",
    "section": "Advanced Boxplot Interpretations",
    "text": "Advanced Boxplot Interpretations"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#comparing-boxplots",
    "href": "files/lecture_notes/lecture3/lecture3.html#comparing-boxplots",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Boxplots:",
    "text": "Comparing Boxplots:\n\nMedian differences: Which group has higher typical values?\nIQR differences: Which group is more consistent?\nOutlier patterns: Which group has more extreme values?\nOverlap: Do the groups have similar ranges?"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#business-applications",
    "href": "files/lecture_notes/lecture3/lecture3.html#business-applications",
    "title": "Descriptive Statistics Part II",
    "section": "Business Applications:",
    "text": "Business Applications:\n\nQuality control: Compare product batches\nPerformance analysis: Compare team/department performance\n\nCustomer segmentation: Compare customer groups"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#common-patterns-in-data",
    "href": "files/lecture_notes/lecture3/lecture3.html#common-patterns-in-data",
    "title": "Descriptive Statistics Part II",
    "section": "Common Patterns in Data",
    "text": "Common Patterns in Data\nDistribution Patterns:\n\nNormal/Bell-shaped: Symmetric, single peak\nUniform: All values equally likely\nBimodal: Two distinct peaks (suggests subgroups)\nMultimodal: Multiple peaks\nU-shaped: High values at extremes, low in middle\n\nOutlier Patterns:\n\nIndividual outliers: Data entry errors, measurement errors\nClustered outliers: Distinct subpopulation\nSystematic outliers: May indicate process changes"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#red-flags-in-data-visualization",
    "href": "files/lecture_notes/lecture3/lecture3.html#red-flags-in-data-visualization",
    "title": "Descriptive Statistics Part II",
    "section": "Red Flags in Data Visualization",
    "text": "Red Flags in Data Visualization\nWarning Signs:\n\nGaps in histograms: Missing data or measurement limitations\nHeaping: Values cluster at round numbers (10, 50, 100)\nTruncation: Data cut off at certain values\nDigit preference: People prefer certain ending digits\nMultiple modes: Hidden subgroups in your data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#essential-concepts-to-remember",
    "href": "files/lecture_notes/lecture3/lecture3.html#essential-concepts-to-remember",
    "title": "Descriptive Statistics Part II",
    "section": "Essential Concepts to Remember",
    "text": "Essential Concepts to Remember\nVariability:\n\nStandard deviation is preferred over range for most analyses\nCV allows comparison across different scales\nIQR is resistant to outliers\n\nPosition:\n\nPercentiles and quartiles provide relative position\nZ-scores standardize across different distributions\nFive-number summary gives complete overview"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practical-guidelines",
    "href": "files/lecture_notes/lecture3/lecture3.html#practical-guidelines",
    "title": "Descriptive Statistics Part II",
    "section": "Practical Guidelines",
    "text": "Practical Guidelines\n\nAlways visualize before calculating statistics\nUse multiple measures - no single statistic tells the whole story\nConsider the context - what makes sense for your data?\nCheck for outliers - they can drastically affect your analysis\nCompare distributions using standardized measures when appropriate"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#try-these-exercises",
    "href": "files/lecture_notes/lecture3/lecture3.html#try-these-exercises",
    "title": "Descriptive Statistics Part II",
    "section": "Try These Exercises",
    "text": "Try These Exercises\n\nCalculate the five-number summary for: 12, 15, 18, 22, 25, 28, 30, 35, 40, 45\nCreate histograms with 5, 15, and 50 bins for the same dataset. What patterns do you observe?\nInterpret this scenario: Dataset A has mean=50, SD=5. Dataset B has mean=100, SD=10. Which is more variable?\nA student scores 85 on a test where the class mean is 78 and SD is 6. Calculate and interpret the z-score.\nDesign a boxplot comparison for three different customer segments in your business."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#additional-resources",
    "href": "files/lecture_notes/lecture3/lecture3.html#additional-resources",
    "title": "Descriptive Statistics Part II",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nMatplotlib Gallery: Histogram and Boxplot Examples\nExplore examples of histograms, boxplots, and other visualizations using Matplotlib.\nSeaborn Documentation: Statistical Visualizations\nFind examples and documentation for statistical visualizations, including distribution plots, categorical plots, and regression plots.\nNumPy Statistical Functions Reference\nOfficial reference for NumPyâ€™s statistical functions such as mean, median, variance, and standard deviation.\nSciPy Statistical Functions Reference\nComprehensive documentation for statistical functions in scipy.stats, including probability distributions, hypothesis tests, and descriptive statistics.\nRecommended reading: Continue reading Chapter 2 in course textbook"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sec-objectives",
    "href": "files/lecture_notes/lecture4/lecture4.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Todayâ€™s Learning Objectives",
    "text": "Todayâ€™s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sec-prob",
    "href": "files/lecture_notes/lecture4/lecture4.html#sec-prob",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is Probability?",
    "text": "What is Probability?\n\nğŸ¯ Definition\nProbability is a measure of the likelihood that an event will occur"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-range",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-range",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Range",
    "text": "Probability Range\n\n\n\nRanges from 0 to 1 (or 0% to 100%)\n0: Event will never occur (impossible)\n1: Event will certainly occur (certain)\n0.5: Event has equal chance of occurring or not"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#three-ways-to-express-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#three-ways-to-express-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Three Ways to Express Probability",
    "text": "Three Ways to Express Probability\n\nFraction: \\(\\frac{1}{2}\\), \\(\\frac{3}{4}\\), \\(\\frac{2}{6}\\)\nDecimal: 0.5, 0.75, 0.33\nPercentage: 50%, 75%, 33%"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#example",
    "href": "files/lecture_notes/lecture4/lecture4.html#example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example",
    "text": "Example\nWhen we roll a die, there are six possible outcomes:\n1, 2, 3, 4, 5, 6.\nThe probability of any of them turning up is 1/6 or 16%."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#why-study-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#why-study-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Why Study Probability?",
    "text": "Why Study Probability?\nProbability helps us:\n\nMake decisions under uncertainty\nUnderstand random processes\nAnalyze data and draw conclusions\nModel real-world phenomena\nAssess risk and likelihood\n\n\n\nApplications: Weather forecasting, medical diagnosis, finance, quality control, gaming, insurance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#random-experiments",
    "href": "files/lecture_notes/lecture4/lecture4.html#random-experiments",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Random Experiments",
    "text": "Random Experiments\nA random experiment is a process that:\n\nCan be repeated under similar conditions\nHas multiple possible outcomes\nThe outcome cannot be predicted with certainty\n\n\n\nExamples\n\nğŸª™ Flipping a coin\nğŸ² Rolling a die\nğŸƒ Drawing a card from a deck\nğŸ’¡ Measuring the lifetime of a light bulb"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sample-space",
    "href": "files/lecture_notes/lecture4/lecture4.html#sample-space",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space",
    "text": "Sample Space\n\nğŸ¯ Definition The sample space (denoted \\(S\\) or \\(\\Omega\\)) is the set of all possible outcomes of a random experiment"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sample-space-examples",
    "href": "files/lecture_notes/lecture4/lecture4.html#sample-space-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space Examples",
    "text": "Sample Space Examples\n\nCoin flip: \\(S = \\{H, T\\}\\)\nTwo coin flips: \\(S = \\{HH, HT, TH, TT\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#types-of-sample-spaces",
    "href": "files/lecture_notes/lecture4/lecture4.html#types-of-sample-spaces",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Types of Sample Spaces",
    "text": "Types of Sample Spaces\n\n\nFinite Sample Space\n\nLimited number of outcomes\n\nExample: Rolling a die\n\n\n\n\n\n\n\n\n\n\n\nInfinite Sample Space\n\nUnlimited outcomes (countable or uncountable)\n\nExample: Measuring exact height of students"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#events",
    "href": "files/lecture_notes/lecture4/lecture4.html#events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Events",
    "text": "Events\n\nğŸ¯ Definition An event is a subset of the sample space\n\nSimple event: Contains exactly one outcome (Ex: \\(A = \\{3\\}\\) (rolling a 3))\nCompound event: Contains multiple outcomes (Ex: \\(B = \\{2, 4, 6\\}\\) (rolling an even number))"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#event-notation",
    "href": "files/lecture_notes/lecture4/lecture4.html#event-notation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Event Notation",
    "text": "Event Notation\nFor a die roll with \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (rolling an odd number)\n\\(B = \\{4, 5, 6\\}\\) (rolling 4 or higher)\n\\(C = \\{6\\}\\) (rolling a six)\n\n\n\nWe can describe events in words or using set notation"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#set-operations-overview",
    "href": "files/lecture_notes/lecture4/lecture4.html#set-operations-overview",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Set Operations Overview",
    "text": "Set Operations Overview\n\n\n\n\nğŸ¯ Definition:\n\nSet: Collection of distinct objects\nUnion: A OR B occurs\n\nIntersection: A AND B occurs\nComplement: A does NOT occur\nSample Space: All possible outcomes"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#what-is-a-set",
    "href": "files/lecture_notes/lecture4/lecture4.html#what-is-a-set",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is a Set?",
    "text": "What is a Set?\n\n\n\n\nğŸ¯ Definition: A collection of things that share common characteristics. They can be elements, members, objects or similar terms.\nExamples:\n\nSet of even numbers:\n\n{2, 4, 6, 8, â€¦}\n\nSet of vowels: {a, e, i, o, u}"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#union-a-b",
    "href": "files/lecture_notes/lecture4/lecture4.html#union-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Union: A âˆª B",
    "text": "Union: A âˆª B\n\n\n\n\nğŸ¯ Definition: Contains all set elements, including intersections.\nIn Probability: The event that A OR B occurs (or both).\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#intersection-a-b",
    "href": "files/lecture_notes/lecture4/lecture4.html#intersection-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Intersection: A âˆ© B",
    "text": "Intersection: A âˆ© B\n\n\n\n\nğŸ¯ Definition: Area where two or more sets overlap.\nIn Probability: The event that A AND B occurs.\nProperties:\n\nAlways smaller than or equal to individual sets\nCan be empty (disjoint sets)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#absolute-complement-ac",
    "href": "files/lecture_notes/lecture4/lecture4.html#absolute-complement-ac",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Absolute Complement: \\(A^c\\)",
    "text": "Absolute Complement: \\(A^c\\)\n\n\n\nğŸ¯ Definition: All elements that do not belong to the set.\nIn Probability: The event that A does NOT occur.\n\n\\(P(A^c) = 1 - P(A)\\)\n\n\nKey Property:\n\\(A \\cup A^c = S\\) (Sample Space)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#summary-table",
    "href": "files/lecture_notes/lecture4/lecture4.html#summary-table",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Summary Table",
    "text": "Summary Table\n\n\n\n\n\n\n\n\n\nOperation\nSymbol\nMeaning\nProbability\n\n\n\n\nUnion\n\\(A \\cup B\\)\nOccurs if \\(A\\) or \\(B\\)\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\nIntersection\n\\(A \\cap B\\)\nOccurs if \\(A\\) and \\(B\\)\n\\(P(A \\cap B)\\)\n\n\nComplement\n\\(A^c\\)\nOccurs if \\(A\\) does not occur\n\\(P(A^c) = 1 - P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-commutative",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-commutative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Commutative",
    "text": "Probability Axioms: Commutative\n\nCommutative\n\\(A \\cup B = B \\cup A\\)\n\\(A \\cap B = B \\cap A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-associative",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-associative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Associative",
    "text": "Probability Axioms: Associative\n\nAssociative\n\\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\)\n\\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-distributive",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-distributive",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Distributive",
    "text": "Probability Axioms: Distributive\n\nDistributive\n\\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\n\\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-de-morgans-laws",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-de-morgans-laws",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: De Morganâ€™s Laws",
    "text": "Probability Axioms: De Morganâ€™s Laws\n\nDe Morganâ€™s Laws\n\\((A \\cup B)^c = A^c \\cap B^c\\)\n\\((A \\cap B)^c = A^c \\cup B^c\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-examples",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Examples",
    "text": "Practice Examples\n\nExample 1: In a class of students:\n\nSet A = Students who like Math\nSet B = Students who like Science\n\nQ: What does A âˆª B represent?\n\n\n\nSolution. Students who like Math OR Science (or both)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#example-set-operations",
    "href": "files/lecture_notes/lecture4/lecture4.html#example-set-operations",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example: Set Operations",
    "text": "Example: Set Operations\n\n\nFor die roll \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (odd numbers)\n\\(B = \\{4, 5, 6\\}\\) (4 or higher)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind:\n\n\\(A \\cup B\\)\n\\(A \\cap B\\)\n\\(A^c\\)\n\n\n\n\n\nSolution. \n\n\\(A \\cup B = \\{1, 3, 4, 5, 6\\}\\)\n\\(A \\cap B = \\{5\\}\\)\n\\(A^c = \\{2, 4, 6\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-events",
    "href": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive Events",
    "text": "Mutually Exclusive Events\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive (or disjoint) if they cannot occur simultaneously\n\\[A \\cap B = \\emptyset\\]\n\n\n\n\n\n\n\n\n\n\n\n\nWhen rolling a die\n\n\\(A = \\{1, 3, 5\\}\\) (odd)\n\\(B = \\{2, 4, 6\\}\\) (even)\n\n\\(A\\) and \\(B\\) are mutually exclusive"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-classical-definition-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-classical-definition-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Classical Definition of Probability",
    "text": "The Classical Definition of Probability\n\nğŸ¯ Definition: For equally likely outcomes:\n\\[P(A) = \\frac{\\text{Number of outcomes in } A}{\\text{Total number of outcomes in } S}\\]\n\n\nProbability of rolling an even number on a fair die\n\n\n\\[P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#properties-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#properties-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Properties of Probability",
    "text": "Properties of Probability\n\nNon-negativity: \\(P(A) \\geq 0\\) for any event \\(A\\)\nNormalization: \\(P(S) = 1\\)\nAdditivity: If \\(A\\) and \\(B\\) are mutually exclusive, then\n\n\n\\[P(A \\cup B) = P(A) + P(B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-complement-rule",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-complement-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Complement Rule",
    "text": "The Complement Rule\n\n\\[P(A) + P(A^c) = 1\\]\n\\[P(A^c) = 1 - P(A)\\]\n\n\n\nIf the probability of rain is 0.3, whatâ€™s the probability of no rain?\n\n\n\n\nSolution. \\[P(\\text{no rain}) = 1 - P(\\text{rain}) = 1 - 0.3 = 0.7\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#questions",
    "href": "files/lecture_notes/lecture4/lecture4.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursdayâ€™s 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Conditional Probabilities & Independence"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#resources",
    "href": "files/lecture_notes/lecture4/lecture4.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms\nProbability Animations"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#sec-objectives",
    "href": "files/lecture_notes/lecture5/lecture5.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Todayâ€™s Learning Objectives",
    "text": "Todayâ€™s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-1",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\n\n\n\nA standard deck has 52 cards. What is the probability of drawing:\n\nA heart \\(\\heartsuit\\)?\nA face card (Jack, Queen, King)?\nThe ace of spades \\(\\spadesuit\\)?\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{heart}) = \\frac{13}{52} = \\frac{1}{4}\\)\n\\(P(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\\)\n\\(P(\\text{ace of spades}) = \\frac{1}{52}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#the-addition-rule",
    "href": "files/lecture_notes/lecture5/lecture5.html#the-addition-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Addition Rule",
    "text": "The Addition Rule\nFor any two events \\(A\\) and \\(B\\):\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\n\nWhy subtract \\(P(A \\cap B)\\)?\n\n\n\nSolution. We donâ€™t want to double-count outcomes that are in both events"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#addition-rule-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#addition-rule-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Addition Rule Example",
    "text": "Addition Rule Example\n\n\n\n\nDrawing from a standard deck:\n\n\\(A\\): Drawing a heart \\(\\heartsuit\\) (\\(P(A) = \\frac{13}{52}\\))\n\\(B\\): Drawing a face card (\\(P(B) = \\frac{12}{52}\\))\nWhatâ€™s \\(P(A \\cup B)\\) (heart OR face card)?"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\n\n\n\nğŸ¯Conditional probability is the probability of event \\(A\\) given that event \\(B\\) has occurred\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nprovided \\(P(B) &gt; 0\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-interpretation",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-interpretation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Interpretation",
    "text": "Conditional Probability Interpretation\n\\(P(A|B)\\) means:\n\nWe know event  \\(B\\) has occurred \nWhatâ€™s the probability that \\(A\\) also occurred?\nWe â€œrestrictâ€ our sample space to only outcomes in \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Example",
    "text": "Conditional Probability Example\n\n\n\nDrawing a card from a standard deck:\n\n\\(A\\): Card is a heart \\(\\heartsuit\\)\n\\(B\\): Card is red\nQ: Find \\(P(A|B)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution. \\(P(A \\cap B) = P(\\text{heart}) = \\frac{13}{52}\\)\n\\(P(B) = P(\\text{red}) = \\frac{26}{52}\\)\n\\(P(A|B) = \\frac{13/52}{26/52} = \\frac{13}{26} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#independence",
    "href": "files/lecture_notes/lecture5/lecture5.html#independence",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\nğŸ¯ Definition Events \\(A\\) and \\(B\\) are independent if:\n\\[P(A|B) = P(A)\\]\nor equivalently:\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\n\n\nKnowing that \\(B\\) occurred doesnâ€™t change the probability of \\(A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#independence-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#independence-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence Example",
    "text": "Independence Example\n\nTwo coin flips:\n\n\\(A\\): First flip is heads\n\\(B\\): Second flip is heads\n\nQ: Are \\(A\\) and \\(B\\) independent?\n\n\n\nSolution. \\(P(A) = \\frac{1}{2}\\), \\(P(B) = \\frac{1}{2}\\)\n\\(P(A \\cap B) = P(\\text{HH}) = \\frac{1}{4}\\)\n\\(P(A) \\times P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\)\nYes, they are independent!"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent",
    "href": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.Â Independent",
    "text": "Mutually Exclusive vs.Â Independent\n\nMutually Exclusive (left): the circles A and B do not overlap, so \\(P(A\\cap B)=0\\).\nIndependent (right): the circles overlap, and weâ€™ve sized the intersection so that \\(P(A\\cap B)=P(A)\\,P(B)\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.Â Independent Example",
    "text": "Mutually Exclusive vs.Â Independent Example\n\n\n\nDraw a single card from a 52-card deck:\n\nLet A={â€œdraw an Aceâ€}, so P(A)=4/52.\nLet B={â€œdraw a Kingâ€}, so P(B)=4/52.\n\nQ: What is \\(P(A\\cap B)\\) ?\n\n\n\n\n\nSolution. Theyâ€™re disjoint (you canâ€™t draw an Ace and a King), so \\(P(A\\cap B) = 0\\).\nBut \\(P(A)\\,P(B) = \\frac{4}{52}\\times\\frac{4}{52} = \\frac{16}{2704} \\neq 0\\).\nHence, \\(P(A\\cap B)\\neq P(A)P(B)\\), so theyâ€™re not independent."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#multiplication-rule",
    "href": "files/lecture_notes/lecture5/lecture5.html#multiplication-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Multiplication Rule",
    "text": "Multiplication Rule\nGeneral case: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nIndependent events: \\(P(A \\cap B) = P(A) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#tree-diagrams",
    "href": "files/lecture_notes/lecture5/lecture5.html#tree-diagrams",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\n\nğŸ¯ Definition Tree diagrams help visualize sequential events and calculate probabilities."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#tree-diagram-examples",
    "href": "files/lecture_notes/lecture5/lecture5.html#tree-diagram-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagram Examples",
    "text": "Tree Diagram Examples"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-2",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-2",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\n\n\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement.\n\nWhatâ€™s the probability both balls are red?\nWhatâ€™s the probability the first is red and second is blue?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{both red}) = \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)\n\\(P(\\text{red then blue}) = \\frac{5}{8} \\times \\frac{3}{7} = \\frac{15}{56}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability",
    "href": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nğŸ¯ Definition\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space, then:\n\\[P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \\cdots + P(A|B_n)P(B_n)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\n\nA factory has two machines:\n\nMachine 1: Produces 60% of items, 5% defective\nMachine 2: Produces 40% of items, 3% defective\n\nQ: Whatâ€™s the overall probability an item is defective?\n\n\n\nSolution. \\(P(\\text{defective}) = P(D|M_1)P(M_1) + P(D|M_2)P(M_2)\\)\n\\(= 0.05 \\times 0.6 + 0.03 \\times 0.4 = 0.03 + 0.012 = 0.042\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayesâ€™ Theorem",
    "text": "Bayesâ€™ Theorem\n\nğŸ¯ Definition \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\nThis allows us to â€œreverseâ€ conditional probabilities\nNamed after Thomas Bayes (1701-1761)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-components",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-components",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayesâ€™ Theorem Components",
    "text": "Bayesâ€™ Theorem Components\n\n\\(A,B\\): Events\n\\(P(A|B)\\): Posterior probability - what we want to find\n\\(P(B|A)\\): Likelihood - given \\(A\\), probability of observing \\(B\\)\n\\(P(A)\\): Prior probability - initial probability of \\(A\\)\n\\(P(B)\\): Marginal probability - total probability of \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayesâ€™ Theorem Example",
    "text": "Bayesâ€™ Theorem Example\n\n\n\nMedical test for a disease: 1\n\nDisease affects 1% of population\nTest is 95% accurate for sick people\nTest is 90% accurate for healthy people\n\nQ:If someone tests positive, whatâ€™s the probability they have the disease?\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n\\(P(\\neg D \\,\\wedge\\, \\text{Negative})\n\\;=\\;P(\\neg D)\\times P(\\text{Negative}\\mid \\neg D)\n\\;=\\;0.99\\times0.90\n\\;=\\;0.891\\;(89.1\\%)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayesâ€™ Theorem Solution",
    "text": "Bayesâ€™ Theorem Solution\nLet:\n\n\\(D\\): Person has disease\n\\(T^+\\): Test is positive\n\nGiven:\n\n\\(P(D) = 0.01\\)\n\\(P(T^+|D) = 0.95\\)\n\\(P(T^-|D^c) = 0.90\\), so \\(P(T^+|D^c) = 0.10\\)\n\n\n\nSolution. \\(P(T^+) = P(T^+|D)P(D) + P(T^+|D^c)P(D^c)\\)\n\\(= 0.95 \\times 0.01 + 0.10 \\times 0.99 = 0.1085\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution-cont.",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution-cont.",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayesâ€™ Theorem Solution (cont.)",
    "text": "Bayesâ€™ Theorem Solution (cont.)\n\\[P(D|T^+) = \\frac{P(T^+|D) \\times P(D)}{P(T^+)} = \\frac{0.95 \\times 0.01}{0.1085} \\approx 0.088\\]\n\n\n\nSurprising result: Even with a positive test, thereâ€™s only an 8.8% chance of having the disease!\nThis is due to the low base rate of the disease"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nConfusing \\(P(A|B)\\) with \\(P(B|A)\\)\n\n\nProsecutorâ€™s fallacy is a specific error in interpreting conditional probabilities. Confusing\n\\(P(\\text{Evidence}\\mid\\text{Innocent})\n\\quad\\text{with}\\quad\nP(\\text{Innocent}\\mid\\text{Evidence})\\).\nEx: OJ Simpson Case 1\n\nthe DNA evidence in the O. J. Simpson trial are a classic example of the prosecutorâ€™s fallacy. Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was â€œone in 170 million,â€ then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes-1",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nAssuming independence when events are dependent\nIgnoring base rates (as in the medical test example)\n\n\nBase rate fallacy is when you ignore or underweight the prior probability \\(P(H)\\) of a hypothesis, focusing only on the new evidence \\(E\\).\n\n\nDouble counting in union calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-3",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-3",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nTwo fair dice are rolled. Find:\n\n\\(P(\\text{sum} = 7)\\)\n\\(P(\\text{sum} = 7 | \\text{first die shows 3})\\)\nAre these events independent?\n\n\n\n\nSolution. \n\n6 ways out of 36: \\(P(\\text{sum} = 7) = \\frac{6}{36} = \\frac{1}{6}\\)\nGiven first die is 3, need second die to be 4: \\(P(\\text{sum} = 7 | \\text{first} = 3) = \\frac{1}{6}\\)\nYes, theyâ€™re independent since \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#real-world-applications",
    "href": "files/lecture_notes/lecture5/lecture5.html#real-world-applications",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Diagnosis: Using Bayesâ€™ theorem for test interpretation\nQuality Control: Probability of defective items\nFinance: Risk assessment and portfolio theory\nSports: Probability of wins, fantasy sports\nInsurance: Calculating premiums based on risk"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture5/lecture5.html#key-formulas-summary",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\nBasic probability: \\(P(A) = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\\)\nComplement: \\(P(A^c) = 1 - P(A)\\)\nAddition: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nConditional: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nIndependence: \\(P(A \\cap B) = P(A) \\times P(B)\\)\nBayesâ€™: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture5/lecture5.html#problem-solving-strategy",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\nIdentify the sample space and events\nDetermine if events are independent or mutually exclusive\nChoose the appropriate rule or formula\nCalculate step by step\nCheck if your answer makes sense"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-questions",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Questions",
    "text": "Common Questions\n\nQ1.: â€œWhy isnâ€™t \\(P(A \\cup B) = P(A) + P(B)\\) always?â€\nA: Weâ€™d double-count outcomes in both events\nQ2.: â€œHow do I know if events are independent?â€\nA: Check if \\(P(A|B) = P(A)\\) or if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nQ3.: â€œWhen do I use Bayesâ€™ theorem?â€\nA: When you want to â€œreverseâ€ a conditional probability\n\n\nQ3 note (Bayes Example)\n\nForward: I know my test picks up disease 95% of the time â‡’ \\(P(+\\mid D)=0.95\\).\nReverse: I want the chance I really have the disease when the test is positive â‡’ \\(P(D\\mid +)\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#looking-ahead",
    "href": "files/lecture_notes/lecture5/lecture5.html#looking-ahead",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture:\n\nCounting\nRandom Variables and Probability Distributions\nDiscrete vs.Â continuous random variables\nExpected value and variance"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#final-thoughts",
    "href": "files/lecture_notes/lecture5/lecture5.html#final-thoughts",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Final Thoughts",
    "text": "Final Thoughts\n\nProbability is the foundation of statistics:\n\nHelps us quantify uncertainty\nProvides tools for making decisions with incomplete information\nEssential for understanding statistical inference\n\n\n\nPractice: The key to mastering probability is working through many problems!"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#questions",
    "href": "files/lecture_notes/lecture5/lecture5.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursdayâ€™s 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Conditional Probability & Bayes Theorem"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#resources",
    "href": "files/lecture_notes/lecture5/lecture5.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms\nInteractive Set Theory & Conditional Probability"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#welcome-to-lecture-7",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#welcome-to-lecture-7",
    "title": "PSTAT 5A: Counting",
    "section": "Welcome to Lecture 7",
    "text": "Welcome to Lecture 7\nThe art and science of systematic enumeration"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#learning-objectives",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#learning-objectives",
    "title": "PSTAT 5A: Counting",
    "section": "Todayâ€™s Learning Objectives",
    "text": "Todayâ€™s Learning Objectives\n\n\n\n\n\n\n\nLearning Objectives\n\n\nBy the end of this lecture, you will be able to:\n\nApply the fundamental counting principles (SectionÂ 0.4)\nCalculate permutations with and without repetition (SectionÂ 0.8, SectionÂ 0.11, SectionÂ 0.15)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#why-study-counting",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#why-study-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Why Study Counting?",
    "text": "Why Study Counting?\n\n\n\n\n\nCounting helps us:\n\nCalculate probabilities for complex events\n\nSolve optimization problems\n\nUnderstand combinations in genetics, computer science\n\nAnalyze algorithms and data structures\n\nMake decisions involving arrangements and selections\n\n\n\nReal-world applications of counting include:\n\nCryptography: Password strength and encryption key space\nGenetics: DNA sequence analysis and gene combinations\n\nTournament brackets: March Madness and sports competitions\nLottery odds: Probability calculations for games of chance\nPassword security: Character combinations and brute force protection"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-fundamental-counting",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-fundamental-counting",
    "title": "PSTAT 5A: Counting",
    "section": "The Fundamental Counting Principle",
    "text": "The Fundamental Counting Principle\n\n\n\n\n\n\n\n\n\nMultiplication Rule\n\n\nIf a procedure consists of \\(k\\) separate tasks where:\n\nTask 1 can be performed in \\(n_1\\) ways\nTask 2 can be performed in \\(n_2\\) ways\nâ€¦\nTask \\(k\\) can be performed in \\(n_k\\) ways\n\nThen, the entire procedure can be performed in \\(n_1 \\times n_2 \\times \\cdots \\times n_k\\) ways\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {'flowchart': {'nodeSpacing': 20, 'rankSpacing': 50}}}%%\nflowchart TD\n    Start([ğŸŸ¢ Start]) --&gt; T1[ğŸ“‹ Task 1&lt;br/&gt;nâ‚ ways]\n    T1 --&gt; C1[Choice 1]\n    T1 --&gt; C2[Choice 2]\n    T1 --&gt; Cn1[Choice nâ‚]\n    \n    C1 --&gt; T2[ğŸ“‹ Task 2&lt;br/&gt;nâ‚‚ ways]\n    C2 --&gt; T2\n    Cn1 --&gt; T2\n    \n    T2 --&gt; C21[Choice 1]\n    T2 --&gt; C22[Choice 2]\n    T2 --&gt; C2n[Choice nâ‚‚]\n    \n    C21 --&gt; Total[ğŸ¯ Total ways&lt;br/&gt;nâ‚ Ã— nâ‚‚ Ã— ... Ã— nâ‚–]\n    C22 --&gt; Total\n    C2n --&gt; Total\n    \n    classDef start fill:#d4edda,stroke:#155724,stroke-width:3px\n    classDef task fill:#d1ecf1,stroke:#0c5460,stroke-width:2px\n    classDef choice fill:#fff3cd,stroke:#856404,stroke-width:1px\n    classDef total fill:#f8d7da,stroke:#721c24,stroke-width:3px\n    \n    class Start start\n    class T1,T2 task\n    class C1,C2,Cn1,C21,C22,C2n choice\n    class Total total"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#simple-counting-example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#simple-counting-example",
    "title": "PSTAT 5A: Counting",
    "section": "Simple Counting Example",
    "text": "Simple Counting Example\n\n\n\nFormat: ABC-123\n\\[\n\\underbrace{A \\; B \\; \\_ \\; \\ - \\_ \\; \\_ \\; \\_}_{positions}\n\\]\n\nFirst position: 26 letters\nSecond position: 26 letters\nThird position: 26 letters\nFourth position: 10 digits\nFifth position: 10 digits\nSixth position: 10 digits\n\n\n\n\n\nSolution. Total possibilities: \\(26 \\times 26 \\times 26 \\times 10 \\times 10 \\times 10 = 26^3 \\times 10^3 = 17,576,000\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#restaurant-menu-example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#restaurant-menu-example",
    "title": "PSTAT 5A: Counting",
    "section": "Restaurant Menu Example",
    "text": "Restaurant Menu Example\n\nA restaurant offers:\nğŸ¤ Appetizers: 4\nğŸ² Main Courses: 6\nğŸ° Desserts: 3\nHow many different three-course meals are possible?\n\n\nSolution. \\(4 \\times 6 \\times 3 = 72\\) different meals"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#practice-1",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#practice-1",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\nA password must contain:\n\nExactly 8 characters\nEach character is either a letter (26 possibilities) or digit (10 possibilities)\n\nHow many possible passwords are there?\n\n\n\n\n\n\n\nSolution. Each position has \\(26 + 10 = 36\\) choices.\nTotal: \\(36^8 = 2,821,109,907,456\\) passwords"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Permutations?",
    "text": "What Are Permutations?\n\n\n\n\n\n\n\n\n\nPermutation\n\n\nAn arrangement of objects where order matters\n\n\n\n\n\n\n\n\n\n\n\nOrder Matters\n\n\n\nRace finish positions (1st, 2nd, 3rd)\nSeating arrangements\nPasswords\nDNA sequences\n\n\n\n\n\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nAll permutations of ABC:\n1. ABC\n2. ACB\n3. BAC\n4. BCA\n5. CAB\n6. CBA"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-of-n-distinct-objects",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-of-n-distinct-objects",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(n\\) Distinct Objects",
    "text": "Permutations of \\(n\\) Distinct Objects\n\n\n\n\n\n\n\n\n\nKey Formula\n\n\nThe number of ways to arrange \\(n\\) distinct objects is:\n\\[n! = n \\times (n-1) \\times (n-2) \\times \\cdots \\times 2 \\times 1\\]\n\n\n\n\n\n\n\n\n\n\n\nSeating Process:\n1st position: 5 choices (Alice, Bob, Carol, David, Eve)\n2nd position: 4 choices (whoever is left)\n3rd position: 3 choices (whoever is left)\n4th position: 2 choices (whoever is left)\n5th position: 1 choice (last person)\nHow many ways can 5 people sit in a row?\n\n\nSolution. \\(5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#factorial-values",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#factorial-values",
    "title": "PSTAT 5A: Counting",
    "section": "Factorial Values",
    "text": "Factorial Values\n\n\n\n\n\n\\(n\\)\n\\(n!\\)\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n2\n2\n\n\n3\n6\n\n\n4\n24\n\n\n5\n120\n\n\n10\n3,628,800\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\n\nNote\n\n\n\\(0! = 1\\) by definition"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-r-from-n",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-r-from-n",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(r\\) Objects from \\(n\\)",
    "text": "Permutations of \\(r\\) Objects from \\(n\\)\n\n\n\n\n\n\n\n\n\nKey Formula\n\n\n\\(P(n,r)\\) or \\(_nP_r\\): Number of ways to arrange \\(r\\) objects selected from \\(n\\) distinct objects\n\\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\\[\nP_{k,n} =\n\\frac{n!}{(n-k)!}\n=\n\\]\n\\[\n= \\frac{\n  n(n-1)\\cdots(n-k+1)\\,\n  \\overbrace{(n-k)(n-k-1)\\cdots3\\cdot2\\cdot1}^{(n-k)!}\n}{\n  (n-k)!\n}\n\\]\n\\[\n= \\underbrace{\nn (n-1) (n-2) \\cdots (n-k+1)\n}_{k \\text{ terms}}\n\\]\nFill in \\(k\\) slots with no repetitions\n\\[\n\\underbrace{n \\; (n-1) \\; \\_ \\; \\_ \\; \\cdots}_{k}\n\\]\nNote that if we allowed repetitions we would get \\(n^k\\) \\[\n\\underbrace{n \\; n \\; n \\; \\cdots \\; n}_{k}\n\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#example",
    "title": "PSTAT 5A: Counting",
    "section": "Example",
    "text": "Example\n\nHow many ways can we select and arrange 3 people from a group of 8 for president, vice-president, and secretary? \n\n\nSolution. \\(P(8,3) = \\frac{8!}{(8-3)!} = \\frac{8!}{5!} = 8 \\times 7 \\times 6 = 336\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#understanding-pnr",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#understanding-pnr",
    "title": "PSTAT 5A: Counting",
    "section": "Understanding \\(P(n,r)\\)",
    "text": "Understanding \\(P(n,r)\\)\nWhy is \\(P(n,r) = \\frac{n!}{(n-r)!}\\)?\n\nFirst position: \\(n\\) choices\nSecond position: \\((n-1)\\) choices\n\nThird position: \\((n-2)\\) choices\nâ€¦\n\\(r\\)-th position: \\((n-r+1)\\) choices\n\n\nTotal: \\(n \\times (n-1) \\times (n-2) \\times \\cdots \\times (n-r+1) = \\frac{n!}{(n-r)!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#practice-2",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#practice-2",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\nA baseball team has 15 players. How many ways can the coach:\n\nArrange all 15 players in a line?\nChoose and arrange 9 players for the starting lineup (batting order matters)?\n\n\n\n\nSolution. \n\n\\(15! = 1,307,674,368,000\\)\n\\(P(15,9) = \\frac{15!}{6!} = 1,816,214,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-repetition",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-repetition",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition",
    "text": "Permutations with Repetition\n\n\n\n\n\n\n\nPermutations with Repetition\n\n\nWhen some objects are identical, we have fewer distinct arrangements\nIf we have \\(n\\) objects where:\n\n\\(n_1\\) are of type 1\n\\(n_2\\) are of type 2\nâ€¦\n\\(n_k\\) are of type \\(k\\)\n\nNumber of distinct arrangements: \\(\\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-with-repetition-example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-with-repetition-example",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition Example",
    "text": "Permutations with Repetition Example\n\n\n\nHow many distinct arrangements are there of the letters in â€œSTATISTICSâ€? \n\n\n\n\n\n\n\nTip\n\n\nS-T-A-T-I-S-T-I-C-S\n\nTotal letters: 10\nS appears 3 times\nT appears 3 times\nA appears 1 time\nI appears 2 times\nC appears 1 time\n\n\n\n\n\n\nSolution. \\(\\frac{10!}{3! \\times 3! \\times 1! \\times 2! \\times 1!} = \\frac{3,628,800}{6 \\times 6 \\times 1 \\times 2 \\times 1} = \\frac{3,628,800}{72} = 50,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#learning-summary",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#learning-summary",
    "title": "PSTAT 5A: Counting",
    "section": "Learning Objectives Summary",
    "text": "Learning Objectives Summary\n\n\n\n\n\n\n\nWhat Weâ€™ve Covered\n\n\nIn this lecture, weâ€™ve addressed all the learning objectives:\n\nâœ… Apply the fundamental counting principles: Covered in SectionÂ 0.4\nâœ… Calculate permutations with and without repetition: Covered in SectionÂ 0.8, SectionÂ 0.11, and SectionÂ 0.15"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#questions",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#questions",
    "title": "PSTAT 5A: Counting",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursdayâ€™s 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Counting continued"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-8",
    "href": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-8",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Welcome to Lecture 8",
    "text": "Welcome to Lecture 8\nDiscrete Random Variables\nFrom outcomes to numbers: quantifying randomness"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Todayâ€™s Learning Objectives",
    "text": "Todayâ€™s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine random variables and distinguish discrete from continuous\nWork with probability mass functions (PMFs) and cumulative distribution functions (CDFs)\nCalculate expected values and variances for discrete random variables\nApply properties of expectation and variance\nWork with common discrete distributions (Bernoulli, Binomial, Geometric, Poisson)\nSolve real-world problems using discrete random variables\nUse python to compute probabilities and parameters"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "href": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "What is a Random Variable?",
    "text": "What is a Random Variable?\n\nDefinition: A random variable is a function that assigns a numerical value to each outcome of a random experiment.\nNotation: Usually denoted by capital letters \\(X\\), \\(Y\\), \\(Z\\)\nKey insight: Random variables transform outcomes into numbers, making statistical analysis possible\n\n\n\nTreena - Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#die-roll-example-mapping-outcomes-to-numbers",
    "href": "files/lecture_notes/lecture7/lecture7.html#die-roll-example-mapping-outcomes-to-numbers",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Die Roll Example: Mapping Outcomes to Numbers",
    "text": "Die Roll Example: Mapping Outcomes to Numbers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n\n\n\nRandom Variable X maps each die face to its numerical value."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Why Use Random Variables?",
    "text": "Why Use Random Variables?\n\n\nRandom variables allow us to:\n\nQuantify outcomes numerically\nCalculate means, variances, and other statistics\nModel real-world phenomena\nMake predictions and decisions\nCompare different random processes\n\nExamples: Height, test scores, number of defects, wait times, stock prices\n\n\n\nTreena - Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Types of Random Variables",
    "text": "Types of Random Variables\n\n\nToday we focus on discrete random variables - notice there are gaps between possible values!\n\n\n\nDiscrete vs.Â Continuous: Demystifying the type of Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "href": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Probability Mass Function (PMF)",
    "text": "Probability Mass Function (PMF)\n\n\nDefinition: The Probability Mass Function (PMF) of a discrete random variable \\(X\\) is:\n\n\n\\[P(X = x) = \\text{probability that } X \\text{ takes the value } x\\]\n\n\nProperties of PMF:\n\n\n\n\\(P(X = x) \\geq 0\\) for all \\(x\\)\n\n\n\\(\\sum_{\\text{all } x} P(X = x) = 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "href": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "PMF Example: Two Coin Flips",
    "text": "PMF Example: Two Coin Flips\n\nTwo Coin Flips - Number of Heads\nLet \\(X\\) = number of heads in two coin flips\nSample Space: \\(\\{HH, HT, TH, TT\\}\\)\n\n\n\nH T H T\n\n\nCurrent outcome: H T H T\n\nClick coins to flip them!\n\nTable summarizes by number of heads, not the exact sequence.\n\n\n\n\n\n\\(x\\) (heads)\n\n\nOutcomes\n\n\n\\(P(X = x)\\)\n\n\nEmpirical\n\n\n\n\n\n\n0\n\n\nTT\n\n\n0.25\n\n\n0\n\n\n\n\n1\n\n\nHT, TH\n\n\n0.50\n\n\n0\n\n\n\n\n2\n\n\nHH\n\n\n0.25\n\n\n0\n\n\n\n\n\nEmpirical probability updates as you flip!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "href": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\n\n\n\nThe cumulative distribution function of a random variable \\(X\\) is:\n\\[F(x) = P(X \\leq x)\\]\nProperties of CDF: 1. \\(F(x)\\) is non-decreasing 2. \\(\\lim_{x \\to -\\infty} F(x) = 0\\) 3. \\(\\lim_{x \\to \\infty} F(x) = 1\\) 4. \\(F(x)\\) is right-continuous"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#expected-value-and-variance",
    "href": "files/lecture_notes/lecture7/lecture7.html#expected-value-and-variance",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value and Variance",
    "text": "Expected Value and Variance\nThe expected value of a discrete random variable \\(X\\) is:\n\\[E[X] = \\mu = \\sum_{\\text{all } x} x \\cdot P(X = x)\\]\nThe variance of a random variable \\(X\\) measures spread around the mean:\n\\[\\text{Var}(X) = \\sigma^2 = E[(X - \\mu)^2] = E[X^2] - (E[X])^2\\]\n\nExpected value represents the long-run average if we repeat the experiment many times."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#law-of-large-numbers-demo",
    "href": "files/lecture_notes/lecture7/lecture7.html#law-of-large-numbers-demo",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Law of Large Numbers Demo",
    "text": "Law of Large Numbers Demo\n\nLaw of Large Numbers Demo\n\n\nRun Simulation\n\n 100 trials 500 trials 1000 trials 5000 trials \n\n\n\n\n\nWatch how the sample mean converges to the expected value! {.smaller}"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#common-discrete-distributions",
    "href": "files/lecture_notes/lecture7/lecture7.html#common-discrete-distributions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Common Discrete Distributions",
    "text": "Common Discrete Distributions\n\nBernoulli\nSingle trial, two outcomes\nParameters: \\(p\\) (success probability)\nPMF: \\(P(X = 1) = p\\), \\(P(X = 0) = 1-p\\)\nMean: \\(p\\)\nVariance: \\(p(1-p)\\)\n\n\nBinomial\n\\(n\\) independent Bernoulli trials\nParameters: \\(n\\) (trials), \\(p\\) (success prob.)\nPMF: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\)\nMean: \\(np\\)\nVariance: \\(np(1-p)\\)\n\n\nGeometric\nTrials until first success\nParameters: \\(p\\) (success probability)\nPMF: \\(P(X = k) = (1-p)^{k-1} p\\)\nMean: \\(1/p\\)\nVariance: \\((1-p)/p^2\\)\n\n\nPoisson\nEvents in fixed interval\nParameters: \\(\\lambda\\) (average rate)\nPMF: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\)\nMean: \\(\\lambda\\)\nVariance: \\(\\lambda\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#interactive-distribution-explorer",
    "href": "files/lecture_notes/lecture7/lecture7.html#interactive-distribution-explorer",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Interactive Distribution Explorer",
    "text": "Interactive Distribution Explorer\n\nDistribution Visualizer\n\n Binomial Geometric Poisson  Parameter 1:  Parameter 2:"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\nA box contains 3 red balls and 2 blue balls. Two balls are drawn without replacement. Let \\(X\\) = number of red balls drawn. Find the PMF of \\(X\\).\n\nShow Solution\n\n\nSolution. \\(X\\) can take values 0, 1, or 2.\n\\(P(X = 0) = \\frac{\\binom{3}{0}\\binom{2}{2}}{\\binom{5}{2}} = \\frac{1 \\times 1}{10} = \\frac{1}{10}\\)\n\\(P(X = 1) = \\frac{\\binom{3}{1}\\binom{2}{1}}{\\binom{5}{2}} = \\frac{3 \\times 2}{10} = \\frac{6}{10}\\)\n\\(P(X = 2) = \\frac{\\binom{3}{2}\\binom{2}{0}}{\\binom{5}{2}} = \\frac{3 \\times 1}{10} = \\frac{3}{10}\\)\nCheck: \\(\\frac{1}{10} + \\frac{6}{10} + \\frac{3}{10} = 1\\) âœ“"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2-expected-value",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2-expected-value",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 2: Expected Value",
    "text": "Practice Problem 2: Expected Value\n\nUsing the red balls example from Problem 1, find \\(E[X]\\) and \\(\\text{Var}(X)\\).\n\nShow Solution\n\n\nSolution. Expected Value: \\[E[X] = 0 \\times \\frac{1}{10} + 1 \\times \\frac{6}{10} + 2 \\times \\frac{3}{10} = 0 + \\frac{6}{10} + \\frac{6}{10} = 1.2\\]\nVariance: \\[E[X^2] = 0^2 \\times \\frac{1}{10} + 1^2 \\times \\frac{6}{10} + 2^2 \\times \\frac{3}{10} = 0 + \\frac{6}{10} + \\frac{12}{10} = 1.8\\]\n\\[\\text{Var}(X) = E[X^2] - (E[X])^2 = 1.8 - (1.2)^2 = 1.8 - 1.44 = 0.36\\]\nStandard Deviation: \\(\\sigma = \\sqrt{0.36} = 0.6\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nA student takes a 10-question multiple choice quiz with 4 options per question. If the student guesses randomly, whatâ€™s the probability of getting exactly 3 correct?\n\nShow Solution\n\n\nSolution. This is a binomial distribution with \\(n = 10\\), \\(p = 1/4 = 0.25\\)\n\\[P(X = 3) = \\binom{10}{3} \\times (0.25)^3 \\times (0.75)^7\\]\n\\[P(X = 3) = 120 \\times 0.015625 \\times 0.1335 \\approx 0.2503\\]\nSo thereâ€™s about a 25% chance of getting exactly 3 correct by guessing."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "href": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Properties of Expected Value",
    "text": "Properties of Expected Value\n\n\n\nLinearity of Expectation\n\n\\(E[c] = c\\) (constant)\n\\(E[cX] = c \\cdot E[X]\\) (scaling)\n\\(E[X + Y] = E[X] + E[Y]\\) (additivity)\n\\(E[aX + bY + c] = aE[X] + bE[Y] + c\\)\n\n\nVariance Properties\n\n\\(\\text{Var}(aX + b) = a^2 \\text{Var}(X)\\)\n\\(\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y)\\) (if \\(X\\) and \\(Y\\) are independent)\n\n\nImportant: Property 3 holds even if \\(X\\) and \\(Y\\) are dependent!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#key-takeaways",
    "href": "files/lecture_notes/lecture7/lecture7.html#key-takeaways",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\n\n\nMain Concepts\n\nRandom variables transform outcomes into numbers for mathematical analysis\nPMF gives probabilities for specific values; CDF gives cumulative probabilities\nExpected value is the long-run average; variance measures spread\n\n\nDistribution Selection\nChoose distributions based on the underlying process:\n\nBernoulli for single trials\nBinomial for fixed trials\nGeometric for waiting times\nPoisson for rates\n\nKey Principle\n\nLaw of Large Numbers connects theoretical expectations with observed averages"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "href": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\nNext Lecture: Continuous Random Variables\nTopics weâ€™ll cover:\n\nProbability density functions (PDFs)\nNormal distribution\nExponential distribution\nCentral Limit Theorem applications\n\n\nConnection: Discrete distributions often approximate continuous ones, and vice versa"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#questions",
    "href": "files/lecture_notes/lecture7/lecture7.html#questions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: 11AM on Thursday (link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Continuous Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#resources",
    "href": "files/lecture_notes/lecture7/lecture7.html#resources",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Resources",
    "text": "Resources\n\n\n\n Read OpenIntro Statistics Chapter 3 section 3.4\n\n\n Random Variable - Treena Courses\n\n\n Random Variables and Probability Functions\n\n\n Random Variables - Distribution and Expectation\n\n\n Khan Academy - Unit9: Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#welcome-to-lecture-9",
    "href": "files/lecture_notes/lecture8/lecture8.html#welcome-to-lecture-9",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Welcome to Lecture 9",
    "text": "Welcome to Lecture 9\nContinuous Random Variables\nFrom discrete jumps to smooth curves: modeling the continuous world"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture8/lecture8.html#todays-learning-objectives",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Todayâ€™s Learning Objectives",
    "text": "Todayâ€™s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDistinguish between discrete and continuous random variables (SectionÂ 3)\nUnderstand probability density functions (PDFs) and their interpretation (SectionÂ 4)\nWork with cumulative distribution functions (CDFs) for continuous variables\nCalculate probabilities using areas under curves\nCompute expected values and variances for continuous distributions\nWork with common continuous distributions (Uniform, Normal, Exponential)\nApply the Central Limit Theorem\nUse python to work with continuous distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#sec-dis-cont-vars",
    "href": "files/lecture_notes/lecture8/lecture8.html#sec-dis-cont-vars",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Review: Discrete vs Continuous",
    "text": "Review: Discrete vs Continuous\n\n\n\n\nDiscrete Random Variables\n\n\n\nCountable values (can list them)\n\n\nGaps between possible values\n\n\nUses Probability Mass Function (PMF)\n\n\n\\(P(X = x)\\) makes sense\n\n\n\nExamples: Dice rolls, number of emails, quiz scores\n\n\n\n\n\n\n\n\n\nContinuous Random Variables\n\n\n\nUncountable values (infinite possibilities)\n\n\nNo gaps - any value in an interval\n\n\nUses Probability Density Function (PDF)\n\n\n\\(P(X = x) = 0\\) for any specific value!\n\n\n\nExamples: Height, weight, time, temperature"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#sec-pdf",
    "href": "files/lecture_notes/lecture8/lecture8.html#sec-pdf",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Why P(X = x) = 0 for Continuous Variables?",
    "text": "Why P(X = x) = 0 for Continuous Variables?\n\n\nFor continuous random variables, the probability of any exact value is zero!\nThink about it: Whatâ€™s the probability someone is exactly 5.7324681â€¦ feet tall?\n\n\n\n\nInstead, we ask:\n\nP(5.7 â‰¤ X â‰¤ 5.8)?\nP(X â‰¤ 6.0)?\nP(X &gt; 5.5)?\n\nKey insight: We calculate probabilities for intervals, not exact points.\n\n\n\n\n\nClick to see why P(X = exact value) = 0"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#probability-density-function-pdf",
    "href": "files/lecture_notes/lecture8/lecture8.html#probability-density-function-pdf",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Probability Density Function (PDF)",
    "text": "Probability Density Function (PDF)\n\n\n\n\n ğŸ¯ Definition: The Probability Density Function (PDF) of a continuous random variable \\(X\\) is a function \\(f(x)\\) such that:\n\n\n\\[P(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx\\]\n\n\n\n\n\nProperties of PDF:\n\n\n\n\\(f(x) \\geq 0\\) for all \\(x\\)\n\n\n\\(\\int_{-\\infty}^{\\infty} f(x) \\, dx = 1\\)\n\n\n\\(f(x)\\) is NOT a probability - itâ€™s a density!\n\n\n\nKey Insight:\n\n\nThe area under the PDF curve between \\(a\\) and \\(b\\) gives the probability that \\(X\\) falls in that interval."
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#cumulative-distribution-function-cdf",
    "href": "files/lecture_notes/lecture8/lecture8.html#cumulative-distribution-function-cdf",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\n\n\n\nFor continuous random variables, the CDF is:\n\\[F(x) = P(X \\leq x) = \\int_{-\\infty}^x f(t) \\, dt\\]\nKey relationship: \\[f(x) = \\frac{d}{dx}F(x)\\]\nThe PDF is the derivative of the CDF!\n\n\n\n\n\nClick anywhere to see F(x) = P(X â‰¤ x) for that point"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#expected-value-and-variance",
    "href": "files/lecture_notes/lecture8/lecture8.html#expected-value-and-variance",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Expected Value and Variance",
    "text": "Expected Value and Variance\n\n\nExpected Value: \\[E[X] = \\mu = \\int_{-\\infty}^{\\infty} x \\cdot f(x) \\, dx\\]\nVariance:\n\\[\\text{Var}(X) = \\sigma^2 = \\int_{-\\infty}^{\\infty} (x - \\mu)^2 f(x) \\, dx = E[X^2] - (E[X])^2\\]\nWhere:\n\\[E[X^2] = \\int_{-\\infty}^{\\infty} x^2 \\cdot f(x) \\, dx\\]\n\n\n\n\n\n\n\nImportant\n\n\nNotice: Integrals replace sums when moving from discrete to continuous!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#common-continuous-distributions",
    "href": "files/lecture_notes/lecture8/lecture8.html#common-continuous-distributions",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Common Continuous Distributions",
    "text": "Common Continuous Distributions\n\nUniform Distribution\nAll values equally likely in an interval\nParameters: \\(a\\) (min), \\(b\\) (max)\nPDF: \\(f(x) = \\frac{1}{b-a}\\) for \\(a \\leq x \\leq b\\)\nMean: \\(\\frac{a+b}{2}\\)\nVariance: \\(\\frac{(b-a)^2}{12}\\)\nUse: Random numbers, waiting times\n\n\nNormal Distribution\nBell-shaped, symmetric\nParameters: \\(\\mu\\) (mean), \\(\\sigma^2\\) (variance)\nPDF: \\(f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\)\nMean: \\(\\mu\\)\nVariance: \\(\\sigma^2\\)\nUse: Heights, test scores, errors\n\n\nExponential Distribution\nModels waiting times\nParameters: \\(\\lambda\\) (rate)\nPDF: \\(f(x) = \\lambda e^{-\\lambda x}\\) for \\(x \\geq 0\\)\nMean: \\(\\frac{1}{\\lambda}\\)\nVariance: \\(\\frac{1}{\\lambda^2}\\)\nUse: Time between events, lifetimes"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#the-normal-distribution",
    "href": "files/lecture_notes/lecture8/lecture8.html#the-normal-distribution",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "The Normal Distribution",
    "text": "The Normal Distribution\n\n\n\nWhy Normal is Special\n\nCentral Limit Theorem: Sample means approach normal\n68-95-99.7 Rule:\n\n68% within \\(1 \\sigma\\) of \\(\\mu\\)\n95% within \\(2 \\sigma\\) of \\(\\mu\\)\n\n99.7% within \\(3 \\sigma\\) of \\(\\mu\\)\n\nStandard Normal: \\(\\mu = 0\\) , \\(\\sigma = 1\\)\n\nZ-Score Transformation\n\\[Z = \\frac{X - \\mu}{\\sigma}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-1-uniform-distribution",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-1-uniform-distribution",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Practice Problem 1: Uniform Distribution",
    "text": "Practice Problem 1: Uniform Distribution\n\nA bus arrives uniformly between 10:00 AM and 10:20 AM. Let \\(X\\) = arrival time in minutes after 10:00 AM.\n(a) What is the PDF of \\(X\\)?\n(b) Whatâ€™s the probability the bus arrives between 10:05 and 10:12?\n(c) Whatâ€™s the expected arrival time?\n\nShow Solution\n\n\nSolution. (a) \\(X \\sim \\text{Uniform}(0, 20)\\) \\[f(x) = \\frac{1}{20-0} = \\frac{1}{20} \\text{ for } 0 \\leq x \\leq 20\\]\n(b) \\(P(5 \\leq X \\leq 12) = \\int_5^{12} \\frac{1}{20} dx = \\frac{1}{20} \\times (12-5) = \\frac{7}{20} = 0.35\\)\n(c) \\(E[X] = \\frac{a+b}{2} = \\frac{0+20}{2} = 10\\) minutes after 10:00 AM"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-2-normal-distribution",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-2-normal-distribution",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Practice Problem 2: Normal Distribution",
    "text": "Practice Problem 2: Normal Distribution\n\nHeights of adult women are normally distributed with Î¼ = 64 inches and Ïƒ = 2.5 inches.\n(a) Whatâ€™s the probability a woman is taller than 67 inches?\n(b) What height represents the 90th percentile?\n(c) Whatâ€™s the probability a woman is between 62 and 66 inches tall?\n\nShow Solution\n\n\nSolution. (a) \\(P(X &gt; 67) = P\\left(Z &gt; \\frac{67-64}{2.5}\\right) = P(Z &gt; 1.2) = 1 - 0.8849 = 0.1151\\)\n(b) For 90th percentile: \\(P(X \\leq x) = 0.90\\)\n\\(z_{0.90} = 1.28\\), so \\(x = 64 + 1.28(2.5) = 67.2\\) inches\n(c) \\(P(62 \\leq X \\leq 66) = P\\left(\\frac{62-64}{2.5} \\leq Z \\leq \\frac{66-64}{2.5}\\right)\\)\n\\(= P(-0.8 \\leq Z \\leq 0.8) = 0.7881 - 0.2119 = 0.5762\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-3-exponential-distribution",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-3-exponential-distribution",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Practice Problem 3: Exponential Distribution",
    "text": "Practice Problem 3: Exponential Distribution\n\nThe time between customer arrivals at a store follows an exponential distribution with an average of 5 minutes between arrivals.\n(a) What is the PDF?\n(b) Whatâ€™s the probability the next customer arrives within 3 minutes?\n(c) Whatâ€™s the probability no customer arrives in the next 10 minutes?\n\nShow Solution\n\n\nSolution. (a) Average = 5 minutes = \\(\\frac{1}{\\lambda}\\), so \\(\\lambda = 0.2\\)\n\\[f(x) = 0.2e^{-0.2x} \\text{ for } x \\geq 0\\]\n(b) \\(P(X \\leq 3) = \\int_0^3 0.2e^{-0.2x} dx = 1 - e^{-0.2 \\times 3} = 1 - e^{-0.6} = 0.4512\\)\n(c) \\(P(X &gt; 10) = e^{-0.2 \\times 10} = e^{-2} = 0.1353\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#central-limit-theorem",
    "href": "files/lecture_notes/lecture8/lecture8.html#central-limit-theorem",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nInteractive CLT Demo: Sample Means Approach Normal\n\n Uniform Population Exponential Population Bimodal Population  Sample Size:  Run Simulation\n\n\n\n\n\n\nPopulation Distribution\n\n\n\n\n\n\nSample Means Distribution\n\n\n\n\nCLT in Action: Run simulation to see the magic!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#transformations-of-random-variables",
    "href": "files/lecture_notes/lecture8/lecture8.html#transformations-of-random-variables",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Transformations of Random Variables",
    "text": "Transformations of Random Variables\n\n\nLinear Transformations\nIf \\(Y = aX + b\\), then:\n\n\\(E[Y] = aE[X] + b\\)\n\\(\\text{Var}(Y) = a^2\\text{Var}(X)\\)\nIf \\(X \\sim N(\\mu, \\sigma^2)\\), then \\(Y \\sim N(a\\mu + b, a^2\\sigma^2)\\)\n\n\nStandardization\n\\[Z = \\frac{X - \\mu}{\\sigma} \\sim N(0, 1)\\]\n\nImportant: Normal distributions are closed under linear transformations!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#comparing-discrete-and-continuous",
    "href": "files/lecture_notes/lecture8/lecture8.html#comparing-discrete-and-continuous",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Comparing Discrete and Continuous",
    "text": "Comparing Discrete and Continuous\n\n\n\n\n\n\n\n\n\nProperty\nDiscrete\nContinuous\n\n\n\n\nProbability Function\nPMF: \\(P(X = x)\\)\nPDF: \\(f(x)\\)\n\n\nExact Value Probability\n\\(P(X = x) &gt; 0\\) possible\n\\(P(X = x) = 0\\) always\n\n\nInterval Probability\n\\(\\sum P(X = x_i)\\)\n\\(\\int_a^b f(x) dx\\)\n\n\nExpected Value\n\\(\\sum x \\cdot P(X = x)\\)\n\\(\\int x \\cdot f(x) dx\\)\n\n\nVariance\n\\(\\sum (x-\\mu)^2 P(X = x)\\)\n\\(\\int (x-\\mu)^2 f(x) dx\\)\n\n\nCDF\n\\(\\sum_{x_i \\leq x} P(X = x_i)\\)\n\\(\\int_{-\\infty}^x f(t) dt\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#properties-of-continuous-distributions",
    "href": "files/lecture_notes/lecture8/lecture8.html#properties-of-continuous-distributions",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Properties of Continuous Distributions",
    "text": "Properties of Continuous Distributions\n\n\n\nKey Properties\n\nMemoryless Property (Exponential only):\n\\(P(X &gt; s+t | X &gt; s) = P(X &gt; t)\\)\nSymmetry (Normal):\n\\(P(X \\leq \\mu - a) = P(X \\geq \\mu + a)\\)\nScaling Invariance (Normal):\nLinear combinations of normals are normal\n\n\nUseful Relationships\n\nCDF to PDF: \\(f(x) = F'(x)\\)\nPDF to CDF: \\(F(x) = \\int_{-\\infty}^x f(t) dt\\)\nComplementary CDF: \\(P(X &gt; x) = 1 - F(x)\\)\n\n\nRemember: Area under PDF = 1, but PDF values can exceed 1!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#key-takeaways",
    "href": "files/lecture_notes/lecture8/lecture8.html#key-takeaways",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\n\n\nMain Concepts\n\nContinuous variables require PDFs, not PMFs\nProbabilities are areas under curves, not function values\nIntegration replaces summation for continuous distributions\nNormal distribution is central due to CLT\n\n\nDistribution Selection\nChoose distributions based on the data characteristics:\n\nUniform for equally likely intervals\nNormal for symmetric, bell-shaped data\n\nExponential for waiting times/lifetimes\nUse CLT when working with sample means\n\nKey Principle\n\nCentral Limit Theorem makes normal distributions ubiquitous in statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#looking-ahead",
    "href": "files/lecture_notes/lecture8/lecture8.html#looking-ahead",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\nNext Lecture: Statistical Inference\nTopics weâ€™ll cover:\n\nSampling distributions\nConfidence intervals\nHypothesis testing\np-values and significance\n\n\nConnection: Continuous distributions (especially normal) form the foundation for statistical inference"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#questions",
    "href": "files/lecture_notes/lecture8/lecture8.html#questions",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: 11AM on Thursday (link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Statistical Inference and Hypothesis Testing"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#resources",
    "href": "files/lecture_notes/lecture8/lecture8.html#resources",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Resources",
    "text": "Resources\n\n\n\n Read OpenIntro Statistics Chapter 4 sections 4.1-4.3\n\n\n Khan Academy - Continuous Random Variables\n\n\n Seeing Theory - Probability Distributions\n\n\n Central Limit Theorem - Wikipedia\n\n\n Introduction to Probability - Continuous Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#back-to-main-page",
    "href": "files/lecture_notes/lecture8/lecture8.html#back-to-main-page",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Back to Main Page",
    "text": "Back to Main Page\nğŸ  Back to Main Page"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture9/lecture9.html#todays-learning-objectives",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Todayâ€™s Learning Objectives",
    "text": "Todayâ€™s Learning Objectives\nBy the end of this session, you will be able to:\n\nDefine what a random variable is\nDistinguish between different types of random variables\nIdentify examples of random variables in your field of study\nConnect probability concepts to real-world applications"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#what-is-a-random-variable",
    "href": "files/lecture_notes/lecture9/lecture9.html#what-is-a-random-variable",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "What is a Random Variable?",
    "text": "What is a Random Variable?\n\nA random variable (r.v.) is a function that assigns numerical values to the outcomes of a random experiment\nNotation: Usually denoted by capital letters (X, Y, Z)\nItâ€™s a bridge between the sample space and real numbers\nThink of it as a â€œruleâ€ that translates outcomes into numbers\n\n\nKey Point: Itâ€™s not actually â€œrandomâ€, itâ€™s a deterministic function applied to random outcomes!"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#real-world-connection",
    "href": "files/lecture_notes/lecture9/lecture9.html#real-world-connection",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Real-World Connection",
    "text": "Real-World Connection"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#activity-your-research-field",
    "href": "files/lecture_notes/lecture9/lecture9.html#activity-your-research-field",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Activity: Your Research Field",
    "text": "Activity: Your Research Field\n\n\n\n\n\n\n\n\nThink About Your Major/Research Area\n\n\nTake 2 minutes to brainstorm:\n\nWhat random phenomena occur in your field?\nHow might you assign numbers to these outcomes?\nWhat questions could you answer with this data?\n\n\n\n\n\n\n\n\n\n\n\n\nExamples by Field\n\n\n\nPsychology: Reaction times, survey responses\nBiology: Species counts, gene expression levels\nEconomics: Stock prices, unemployment rates\nEngineering: System failures, signal strength"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#discrete-random-variables",
    "href": "files/lecture_notes/lecture9/lecture9.html#discrete-random-variables",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Discrete Random Variables",
    "text": "Discrete Random Variables\n\nDefinition: Takes on countable values (finite or countably infinite)\nExamples:\n\nNumber of emails received per day\nNumber of defective products in a batch\nStudent enrollment in courses\nNumber of research papers published per year\n\n\n\nNote: If X is discrete, then X can take values \\(x_1, x_2, x_3, \\cdot\\) where we can list all possible values."
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#continuous-random-variables",
    "href": "files/lecture_notes/lecture9/lecture9.html#continuous-random-variables",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Continuous Random Variables",
    "text": "Continuous Random Variables\n\nDefinition: Takes on uncountably infinite values (any value in an interval)\nExamples:\n\nHeight of students\nTime until equipment failure\nTemperature measurements\nGPA (technically discrete, but often treated as continuous)\n\n\n\nNote: If \\(X\\) is continuous, then \\(X\\) can take any value in an interval \\([a,b]\\) or \\((-\\infty, \\infty)\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#sampling-and-random-variables",
    "href": "files/lecture_notes/lecture9/lecture9.html#sampling-and-random-variables",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Sampling and Random Variables",
    "text": "Sampling and Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#central-limit-theorem-connection",
    "href": "files/lecture_notes/lecture9/lecture9.html#central-limit-theorem-connection",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Central Limit Theorem Connection",
    "text": "Central Limit Theorem Connection\n\nWhen we repeatedly sample from a population, the sample mean becomes a random variable\nFormula: \\(\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i\\)\nEach time we sample, we get a different \\(\\bar{X}\\)\nThe distribution of \\(\\bar{X}\\) has special properties!"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#central-limit-theorem-connection-1",
    "href": "files/lecture_notes/lecture9/lecture9.html#central-limit-theorem-connection-1",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Central Limit Theorem Connection",
    "text": "Central Limit Theorem Connection\n\n\nThese properties are :\n\nCenter (Unbiased): \\(E[\\bar{X}] = \\mu\\).\nSpread Shrinks with \\(n\\): \\(\\mathrm{Var}(\\bar{X}) = \\sigma^2/n\\); \\(\\mathrm{SE}(\\bar{X}) = \\sigma/\\sqrt{n}\\) (estimate with \\(s/\\sqrt{n}\\)).\nShape:\n\nIf the population is Normal, then \\(\\bar{X} \\sim \\text{Normal}(\\mu, \\sigma^2/n)\\) exactly.\n\nOtherwise, CLT: for large \\(n\\), \\(\\bar{X}\\) is approximately Normal even when the data arenâ€™t.\n\n\n\n\nConsistency / Law of Large Numbers: \\(\\bar{X} \\xrightarrow{P} \\mu\\) as \\(n \\to \\infty\\) (estimates get closer to the truth with more data).\n(If sampling w/out replacement, pop size \\(N\\)): Apply finite population correction (FPC):\n\\(\\mathrm{SE}(\\bar{X}) = \\dfrac{\\sigma}{\\sqrt{n}}\\sqrt{\\dfrac{N-n}{N-1}}\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#common-discrete-distributions",
    "href": "files/lecture_notes/lecture9/lecture9.html#common-discrete-distributions",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Common Discrete Distributions",
    "text": "Common Discrete Distributions\nBinomial Distribution - Characteristics\n\n\n\n\nFixed number of trials (n)\nEach trial has two outcomes\nConstant probability of success\nTrials are independent\n\nExample: Number of successful research grants out of 10 applications"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#poisson-distribution---characteristics",
    "href": "files/lecture_notes/lecture9/lecture9.html#poisson-distribution---characteristics",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Poisson Distribution - Characteristics",
    "text": "Poisson Distribution - Characteristics\n\n\n\nModels rare events\nEvents occur independently\nConstant average rate\nUseful for counts over time/space\n\nExample: Number of emails received per hour, number of mutations in DNA sequences"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#common-continuous-distributions",
    "href": "files/lecture_notes/lecture9/lecture9.html#common-continuous-distributions",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Common Continuous Distributions",
    "text": "Common Continuous Distributions\nNormal Distribution - Characteristics\n\n\n\nBell-shaped curve\nSymmetric around mean\nParameters: \\(\\mu\\) (mean), \\(\\sigma\\) (standard deviation)\nMany natural phenomena follow this pattern\n\nExample: Heights, test scores, measurement errors"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#exponential-distribution---characteristics",
    "href": "files/lecture_notes/lecture9/lecture9.html#exponential-distribution---characteristics",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Exponential Distribution - Characteristics",
    "text": "Exponential Distribution - Characteristics\n\n\n\nModels waiting times\nMemoryless property\nParameter: \\(\\lambda\\) (rate)\nRight-skewed\n\nExample: Time between arrivals, equipment lifespan, time to next earthquake"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#interactive-activity-choose-your-distribution",
    "href": "files/lecture_notes/lecture9/lecture9.html#interactive-activity-choose-your-distribution",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Interactive Activity: Choose Your Distribution",
    "text": "Interactive Activity: Choose Your Distribution\n\n\n\n\n\n\nGroup Discussion (5 minutes)\n\n\nFor each scenario, identify: 1. Is the random variable discrete or continuous? 2. What distribution might it follow? 3. What are the parameters?\nScenarios: - Number of students attending office hours per week - Time spent studying for an exam - Number of typos in a research paper - Body temperature of patients in a hospital"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#application-research-design",
    "href": "files/lecture_notes/lecture9/lecture9.html#application-research-design",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Application: Research Design",
    "text": "Application: Research Design\nConsider your research question:\n\nIdentify your random variable(s)\n\nWhat are you measuring?\nWhat values can it take?\n\nChoose appropriate distribution\n\nBased on the nature of your data\nConsider the underlying process\n\nPlan your analysis\n\nHow will you collect data?\nWhat statistical tests are appropriate?"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#probability-mass-vs.-density-functions",
    "href": "files/lecture_notes/lecture9/lecture9.html#probability-mass-vs.-density-functions",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Probability Mass vs.Â Density Functions",
    "text": "Probability Mass vs.Â Density Functions\n\n\nDiscrete: Probability Mass Function (PMF)\n\n\\(P(X = x)\\) for specific values\nSums to 1 over all possible values\nCan find exact probabilities\n\nExample: \\(P(X = 3) = 0.2\\)\n\nContinuous: Probability Density Function (PDF)\n\n\\(f(x)\\) represents density\nArea under curve = 1\n\\(P(X = x) = 0\\) for any specific value\nFind probabilities over intervals\n\nExample: \\(P(a &lt; X &lt; b) =  \\int_{a}^{b} f(x)dx\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#comparing-distributions-side-by-side",
    "href": "files/lecture_notes/lecture9/lecture9.html#comparing-distributions-side-by-side",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Comparing Distributions Side-by-Side",
    "text": "Comparing Distributions Side-by-Side"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#confidence-intervals-for-means",
    "href": "files/lecture_notes/lecture9/lecture9.html#confidence-intervals-for-means",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Confidence Intervals for Means",
    "text": "Confidence Intervals for Means\n\nProblem: We have one sample mean, but want to estimate the population mean\nSolution: Use the sampling distribution to create a confidence interval\nKey Insight: If we know how \\(\\bar{X}\\) varies, we can make probabilistic statements about Î¼\n\n\n95% Confidence Interval Formula: \\(\\bar{x} \\pm 1.96 \\times \\frac{\\sigma}{\\sqrt{n}}\\)\nInterpretation: â€œWe are 95% confident that the true population mean lies within this intervalâ€"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#visualizing-confidence-intervals",
    "href": "files/lecture_notes/lecture9/lecture9.html#visualizing-confidence-intervals",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Visualizing Confidence Intervals",
    "text": "Visualizing Confidence Intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#confidence-interval-interpretation",
    "href": "files/lecture_notes/lecture9/lecture9.html#confidence-interval-interpretation",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Confidence Interval Interpretation",
    "text": "Confidence Interval Interpretation\n\n\n\n\n\n\nCommon Misconceptions\n\n\nâŒ WRONG: â€œThereâ€™s a 95% probability that Î¼ is in this specific intervalâ€\nâœ… CORRECT: â€œIf we repeated this process many times, 95% of the intervals we construct would contain the true Î¼â€\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe interval is random, not the population parameter\nBefore collecting data: 95% chance our method will work\nAfter collecting data: The interval either contains Î¼ or it doesnâ€™t\nConfidence level = Long-run success rate of the method"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#factors-affecting-confidence-interval-width",
    "href": "files/lecture_notes/lecture9/lecture9.html#factors-affecting-confidence-interval-width",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Factors Affecting Confidence Interval Width",
    "text": "Factors Affecting Confidence Interval Width"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#key-takeaways",
    "href": "files/lecture_notes/lecture9/lecture9.html#key-takeaways",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nRandom variables translate random outcomes into numbers\nDiscrete variables have countable values; continuous variables have uncountable values\nDistributions describe the probability patterns of random variables\nChoosing the right distribution depends on understanding your dataâ€™s nature\nReal applications exist in every field - think about your research!"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#next-steps",
    "href": "files/lecture_notes/lecture9/lecture9.html#next-steps",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Next Steps",
    "text": "Next Steps\n\n\n\n\n\n\nFor Your Research/Interests\n\n\n\nIdentify random variables in your field\nThink about appropriate distributions\nConsider data collection methods\nPlan statistical analyses\nConnect theory to practice"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#questions-and-discussion",
    "href": "files/lecture_notes/lecture9/lecture9.html#questions-and-discussion",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Questions and Discussion",
    "text": "Questions and Discussion\n\nShare with the class:\n\nWhat random variables are important in your field of study/major?\nWhich distributions might be most relevant?\nWhat challenges do you anticipate in data collection?\n\n\n\nThank you for your participation!"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#appendix-python-code-examples",
    "href": "files/lecture_notes/lecture9/lecture9.html#appendix-python-code-examples",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Appendix: Python Code Examples",
    "text": "Appendix: Python Code Examples\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport seaborn as sns\n\n# Generate random samples from different distributions\n\n# Binomial\nbinom_data = np.random.binomial(n=10, p=0.3, size=100)\n\n# Poisson  \npoisson_data = np.random.poisson(lam=3, size=100)\n\n# Normal\nnormal_data = np.random.normal(loc=0, scale=1, size=100)\n\n# Exponential\nexp_data = np.random.exponential(scale=1/1.5, size=100)\n\n# Create histograms\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\naxes[0,0].hist(binom_data, bins=11, alpha=0.7, color='steelblue')\naxes[0,0].set_title('Binomial Sample')\n\naxes[0,1].hist(poisson_data, bins=15, alpha=0.7, color='coral')\naxes[0,1].set_title('Poisson Sample')\n\naxes[1,0].hist(normal_data, bins=20, alpha=0.7, color='lightblue')\naxes[1,0].set_title('Normal Sample')\n\naxes[1,1].hist(exp_data, bins=20, alpha=0.7, color='lightgreen')\naxes[1,1].set_title('Exponential Sample')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#additional-resources",
    "href": "files/lecture_notes/lecture9/lecture9.html#additional-resources",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n# Useful Python libraries for statistics and probability\nimport numpy as np           # Numerical computing\nimport scipy.stats as stats  # Statistical functions\nimport matplotlib.pyplot as plt  # Plotting\nimport seaborn as sns        # Statistical visualization\nimport pandas as pd          # Data manipulation\n\n# Quick reference for common distributions:\n# stats.binom.pmf(k, n, p)     # Binomial PMF\n# stats.poisson.pmf(k, lam)    # Poisson PMF  \n# stats.norm.pdf(x, mu, sigma) # Normal PDF\n# stats.expon.pdf(x, scale)    # Exponential PDF\n\n# Generate random samples:\n# np.random.binomial(n, p, size)\n# np.random.poisson(lam, size)\n# np.random.normal(mu, sigma, size)\n# np.random.exponential(scale, size)"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#important-announcements",
    "href": "files/lecture_notes/lecture10/lecture10.html#important-announcements",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "ğŸ“¢ Important Announcements",
    "text": "ğŸ“¢ Important Announcements\n\n\nğŸ“ Quiz 2 Details\nWhen:\n- ğŸ“… Date: Friday, July 25\n- â° Window: 7 AM â€“ 12 AM\n- â³ Duration: 1 hour once started\nWhere: ğŸ’» Online via Canvas\nCovers: Material from Weeks 3-4\n\nğŸ“š What to Expect\n\nDiscrete & continuous distributions\nProbability calculations\nExpected value & variance\nNormal distribution applications\nNote: Upload photos of written work for calculation problems"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#todays-learning-journey",
    "href": "files/lecture_notes/lecture10/lecture10.html#todays-learning-journey",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Todayâ€™s Learning Journey ğŸ¯",
    "text": "Todayâ€™s Learning Journey ğŸ¯\n\n\nğŸ§  Big Ideas Weâ€™ll Explore\n\nWhy sampling? The power and necessity of statistical inference\nSample behavior - How sample means form predictable patterns\nUncertainty quantification - From point estimates to intervals\nThe CLT magic - Why normal distributions appear everywhere\nConfidence intervals - Our bridge from samples to populations\n\n\nğŸ› ï¸ Skills Youâ€™ll Master\n\nDesign effective sampling strategies\nCalculate and interpret standard errors\nApply the Central Limit Theorem\nConstruct and interpret confidence intervals\nChoose appropriate sample sizes for desired precision\nRecognize and avoid sampling bias"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#the-foundation-why-do-we-sample",
    "href": "files/lecture_notes/lecture10/lecture10.html#the-foundation-why-do-we-sample",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "The Foundation: Why Do We Sample? ğŸ¤”",
    "text": "The Foundation: Why Do We Sample? ğŸ¤”\n\n\nğŸŒ Real-World Constraints\nPopulation vs.Â Sample Realities:\n\nTime: Surveying 40,000 UCSB students takes months\nCost: Each measurement costs money and resources\nLogistics: Some populations are impossible to reach entirely\nFeasibility: Testing every light bulb would destroy the product\n\nğŸ’¡ The Statistical Solution\nUse a representative sample to make valid inferences about the entire population"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#study-design-the-foundation-of-good-inference",
    "href": "files/lecture_notes/lecture10/lecture10.html#study-design-the-foundation-of-good-inference",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Study Design: The Foundation of Good Inference",
    "text": "Study Design: The Foundation of Good Inference\n\n\n                            \n                                            \n\n\n\n\nğŸ” Observational Studies: - Observe what naturally occurs - Good for identifying associations - âš ï¸ Cannot establish causation due to confounding\n\nğŸ§ª Randomized Experiments: - Actively assign treatments randomly - Controls for confounding variables - âœ… Can establish causal relationships"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#types-of-sampling-methods",
    "href": "files/lecture_notes/lecture10/lecture10.html#types-of-sampling-methods",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Types of Sampling Methods ğŸ¯",
    "text": "Types of Sampling Methods ğŸ¯\n\nğŸ“‹ Probability Sampling Methods\n\n1. Simple Random Sampling (SRS)\nEvery individual has equal chance of selection\nGold standard for inference\n2. Stratified Sampling\nDivide population into groups (strata)\nSample randomly within each group\nEnsures representation of subgroups\n\n3. Cluster Sampling\nDivide into clusters, randomly select clusters\nSample all/some individuals within chosen clusters\nCost-effective for large populations\n4. Systematic Sampling\nSelect every \\(kth\\) individual from ordered list\nSimple but can introduce bias if pattern exists"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#sampling-bias-what-can-go-wrong",
    "href": "files/lecture_notes/lecture10/lecture10.html#sampling-bias-what-can-go-wrong",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Sampling Bias: What Can Go Wrong? âš ï¸",
    "text": "Sampling Bias: What Can Go Wrong? âš ï¸\n\n\nğŸš¨ Common Types of Bias\nSelection Bias - Systematic exclusion of certain groups - Example: Online surveys miss non-internet users\nResponse Bias\n- Who chooses to respond affects results - Example: Satisfaction surveys - unhappy customers more likely to respond\nNonresponse Bias - Missing data isnâ€™t random - Example: Wealthy people less likely to disclose income\nConvenience Sampling - Sampling whoever is easiest to reach - Example: Surveying only students in your dorm\n\n\n\n                            \n                                            \n\n\nğŸ’¡ Key Insight: Bias canâ€™t be fixed by increasing sample size!"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#the-magic-of-sample-means-from-chaos-to-order",
    "href": "files/lecture_notes/lecture10/lecture10.html#the-magic-of-sample-means-from-chaos-to-order",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "The Magic of Sample Means: From Chaos to Order",
    "text": "The Magic of Sample Means: From Chaos to Order\n\n\nğŸ² The Setup:\n\nTake many samples from the same population\nCalculate the mean of each sample\nPlot all these sample means\nObserve the magic!\n\nğŸ¯ What We Discover:\n\nSample means cluster around the true population mean\nThey form a predictable pattern (normal distribution!)\nLarger samples give more consistent results"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#the-central-limit-theorem",
    "href": "files/lecture_notes/lecture10/lecture10.html#the-central-limit-theorem",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "The Central Limit Theorem ğŸŒŸ",
    "text": "The Central Limit Theorem ğŸŒŸ\n\n\nğŸ“ The Statement\nFor a population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), when sample size \\(n\\) is large enough:\n\\[\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\]\nOr equivalently: \\[Z = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)\\]\nâœ¨ The Magic Rules\n\nRule of Thumb: \\(n \\geq 30\\) usually works\nShape doesnâ€™t matter: Works for ANY population distribution\n\nLarger \\(n\\) = Better approximation"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#standard-error-measuring-our-uncertainty",
    "href": "files/lecture_notes/lecture10/lecture10.html#standard-error-measuring-our-uncertainty",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Standard Error: Measuring Our Uncertainty ğŸ“",
    "text": "Standard Error: Measuring Our Uncertainty ğŸ“\n\n\nğŸ¯ What is Standard Error?\nStandard Error (SE) measures how much sample means vary from sample to sample.\n\\[SE = \\frac{\\sigma}{\\sqrt{n}} \\text{ (when } \\sigma \\text{ is known)}\\]\n\\[SE = \\frac{s}{\\sqrt{n}} \\text{ (usual case, } \\sigma \\text{ unknown)}\\]\nğŸ” Key Insights\n\nSmaller SE = More precise estimates\nSE decreases as sample size increases\nRate of decrease: \\(SE \\propto 1/\\sqrt{n}\\)\n4Ã— larger sample = Â½ the uncertainty!"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#confidence-intervals-our-bridge-to-the-population",
    "href": "files/lecture_notes/lecture10/lecture10.html#confidence-intervals-our-bridge-to-the-population",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Confidence Intervals: Our Bridge to the Population ğŸŒ‰",
    "text": "Confidence Intervals: Our Bridge to the Population ğŸŒ‰\n\n\nğŸ¯ What Are Confidence Intervals?\nA confidence interval gives us a range of plausible values for the population parameter.\nFor a population mean: \\[\\bar{x} \\pm z^* \\cdot \\frac{s}{\\sqrt{n}}\\]\nğŸ”¢ Common Confidence Levels\n\n90% CI: \\(z^* = 1.645\\)\n95% CI: \\(z^* = 1.96\\)\n99% CI: \\(z^* = 2.576\\)\n\nğŸ’­ Correct Interpretation\nâ€œWe are 95% confident that the true population mean lies between [lower bound] and [upper bound]â€"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#sample-size-planning-getting-it-right",
    "href": "files/lecture_notes/lecture10/lecture10.html#sample-size-planning-getting-it-right",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Sample Size Planning: Getting It Right ğŸ¯",
    "text": "Sample Size Planning: Getting It Right ğŸ¯\n\n\nğŸ“ The Formula\nTo achieve margin of error \\(E\\) with confidence level \\((1-\\alpha)\\):\n\\[n = \\left(\\frac{z^*\\sigma}{E}\\right)^2\\]\nğŸ¯ Key Considerations\nMargin of Error Trade-offs: - Smaller \\(E\\) requires larger \\(n\\) - Higher confidence requires larger \\(n\\)\n- More variable population requires larger \\(n\\)\nPractical Constraints: - Budget limitations - Time constraints\n- Availability of participants"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#putting-it-all-together-a-real-example",
    "href": "files/lecture_notes/lecture10/lecture10.html#putting-it-all-together-a-real-example",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Putting It All Together: A Real Example ğŸ“Š",
    "text": "Putting It All Together: A Real Example ğŸ“Š\n\n\nğŸ¯ Research Question\nâ€œWhat is the average height of UCSB students?â€\nOur Approach:\n\nPopulation: All 26,000 UCSB students\nSample: Random sample of 100 students\nMeasurement: Height in inches\nGoal: 95% confidence interval for population mean\n\nResults:\n\nSample mean: \\(\\bar{x} = 68.2\\) inches\nSample std dev: \\(s = 4.1\\) inches\nSample size: \\(n = 100\\)\n\n\n\n\n                            \n                                            \n\n\nğŸ¯ Interpretation: We are 95% confident that the true average height of UCSB students is between 67.40 and 69.00 inches."
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#key-takeaways-your-statistical-toolkit",
    "href": "files/lecture_notes/lecture10/lecture10.html#key-takeaways-your-statistical-toolkit",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Key Takeaways: Your Statistical Toolkit ğŸ¯",
    "text": "Key Takeaways: Your Statistical Toolkit ğŸ¯\n\n\nğŸ§  Fundamental Concepts\n1. Sampling Wisdom\n\nRepresentative samples beat large biased samples\nRandomization is your best friend\nBias canâ€™t be fixed with larger samples\n\n2. The CLT Magic\n\nSample means are approximately normal (\\(n â‰¥ 30\\))\nWorks for ANY population distribution\nEnables powerful statistical inference\n\n3. Standard Error\n\nMeasures precision of our estimates\nDecreases with \\(\\sqrt{n}\\), not \\(n\\)\nKey ingredient in confidence intervals\n\n\nğŸ› ï¸ Practical Skills\n4. Confidence Intervals\n\nQuantify uncertainty in our estimates\nCorrect interpretation is crucial\nWidth depends on confidence level and sample size\n\n5. Sample Size Planning\n\nBalance precision needs with resources\nConsider margin of error requirements\nAccount for practical constraints\n\n6. Quality Control\n\nAlways check for potential bias\nVerify assumptions (normality, independence)\nConsider the broader context"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#common-misconceptions-to-avoid",
    "href": "files/lecture_notes/lecture10/lecture10.html#common-misconceptions-to-avoid",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Common Misconceptions to Avoid âš ï¸",
    "text": "Common Misconceptions to Avoid âš ï¸"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#interactive-practice-test-your-understanding",
    "href": "files/lecture_notes/lecture10/lecture10.html#interactive-practice-test-your-understanding",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Interactive Practice: Test Your Understanding ğŸ§ª",
    "text": "Interactive Practice: Test Your Understanding ğŸ§ª\n\n\nğŸ¤” Check Questions\n1. Sample Size Question: If we want to halve our margin of error, by what factor should we increase our sample size?\n2. CLT Application:\nA population has a right-skewed distribution. What can we say about the distribution of sample means when n = 50?\n3. CI Interpretation: We calculated a 95% CI as (45, 55). What does this mean?\n4. Bias Detection: An online survey about internet usage gets 10,000 responses. What type of bias might be present?\n\nâœ… Answers\n1. Increase by factor of 4 (since \\(SE \\propto \\frac{1}{\\sqrt{n}}\\))\n2. Sample means will be approximately normal regardless of population shape\n3. Weâ€™re 95% confident the true population parameter is between 45 and 55\n4. Selection bias - excludes people without internet access"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#comprehensive-resources",
    "href": "files/lecture_notes/lecture10/lecture10.html#comprehensive-resources",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Comprehensive Resources ğŸ“š",
    "text": "Comprehensive Resources ğŸ“š\n\n\nğŸ“– Required Reading\n\nOpenIntro Statistics\n\nSection 1.3: Sampling principles and strategies\nSection 3.3: Confidence intervals for a mean\nSection 4.1: Central Limit Theorem\n\n\nğŸ¥ Video Resources\n\nKhan Academy: Central Limit Theorem\nStatQuest: Confidence Intervals Explained\n3Blue1Brown: Central Limit Theorem Visualization\n\n\nğŸ’» Interactive Tools\n\nSeeing Theory: Probability Visualizations\nRossman & Chance Applets: Sampling Distributions\nCentral Limit Theorem Simulator\n\nğŸ¤ Getting Help\n\nOffice Hours: Thursday 11 AM-12 PM (Zoom link on Canvas)\nEmail: nmathlouthi@ucsb.edu\n\nğŸ¯ Whatâ€™s Next?\nNext Lecture: Hypothesis Testing and p-values"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#questions-discussion",
    "href": "files/lecture_notes/lecture10/lecture10.html#questions-discussion",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Questions & Discussion ğŸ¤”",
    "text": "Questions & Discussion ğŸ¤”\n\n\nğŸ’­ Think About Thisâ€¦\nâ€œThe goal is not to eliminate uncertainty, but to understand and quantify it intelligentlyâ€\nKey Questions for Reflection:\n\nHow do we balance precision with practicality?\nWhen might a larger sample actually be worse?\nWhat makes a â€œgoodâ€ confidence interval?\nHow do we communicate uncertainty to non-statisticians?\n\n\nğŸ¯ Prepare for Next Class\nComing Up: Hypothesis Testing\n\nWhat are null and alternative hypotheses?\nHow do we make decisions with data?\nWhat does a p-value really mean?\n\nRecommended Prep:\n\nReview todayâ€™s confidence interval concepts\nThink about yes/no questions youâ€™d test with data\nConsider what â€œstatistical significanceâ€ means to you"
  }
]