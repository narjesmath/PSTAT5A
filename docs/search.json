[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Class Schedule",
    "section": "",
    "text": "‚ö†Ô∏è\n\nImportant: This schedule is subject to change. Please check back regularly for updates and announcements.\n\n\n\n\n\n\nLabs & Worksheets\n\n\n\n\n\nQuizzes & Exams\n\n\n\n\n\nLecture Materials\n\n\n\n\n\n\n\nAnonymous Feedback Survey\n\n\n\n\n\nWeek 1: Introduction & Descriptive Statistics\n\n\n\n\n1\n\n\n6/23\n\n\nIntroduction\n\n\nLab 1\nlab1 Solutions\n\n\nWorksheet 1\n\n\n\n\n\n\n\n6/24\n\n\nNo class (lecture canceled)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n6/25\n\n\nDescriptive Statistics I\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n6/26\n\n\nDescriptive Statistics II\nLinear Transformations (Worksheet 1 Q3)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 2: Probability Foundations\n\n\n\n\n2\n\n\n6/30\n\n\nDescriptive Statistics II (Continued)\n\n\nLab2\nLab2 Notebook\nlab2 Solutions\n\n\nWorksheet 2\nWorksheet 2 Solutions\n\n\n\n\n\n\n\n7/01\n\n\nIntro to Probability\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/02\n\n\nIntro to Probability (Continued)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/03\n\n\nConditional Probability, Independence, & Bayes Theorem\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 3: Conditional Probability, Counting & Random Variables\n\n\n\n\n3\n\n\n7/07\n\n\nConditional Probability & Bayes Theorem\n\n\nLab3\nLab3 Solutions\n\n\nWorksheet 3\nWorksheet 3 Solutions\n\n\n\n\n\n\n\n7/08\n\n\nIntro to Counting & Permutations\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/09\n\n\nIntro to Counting & Combinations\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/10\n\n\nDiscrete Random Variables\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/11\n\n\nQuiz 1 (Weeks 1‚Äì2)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 4: Random Variables & Distributions - Confidence Intervals\n\n\n\n\n4\n\n\n7/14\n\n\nContinuous Random Variables & Distributions\n\n\nLab 4\nlab 4 Solutions\n\n\nWorksheet 4\nWorksheet 4 Solutions\n\n\n\n\n\n\n\n7/15\n\n\nContinuous Random Variables & Distributions Continued\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/16\n\n\nContinuous Random Variables & Distributions Wrap Up & Exercises\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/17\n\n\nRandom Variables, Sampling & Intro to Confidence Intervals\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 5: Inference & Statistical Modeling\n\n\n\n\n5\n\n\n7/21\n\n\nSampling Principles and Strategies\n\n\nLab 5\nLab5 Solutions\n\n\nWorksheet 5\nWorksheet 5 Solutions\n\n\n\n\n\n\n\n7/22\n\n\nConfidence Intervals (Means & Proportions)\n\nZ-table, t-table\n\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/23\n\n\nIntro to Hypothesis Testing\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/24\n\n\nHypothesis Testing Continued\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/25\n\n\nQuiz 2 (Weeks 3‚Äì4)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 6: Regression & Course Wrap-Up\n\n\n\n\n6\n\n\n7/28\n\n\nRegression Analysis\n\n\nLab 6\n\n\nWorksheet 6\n\n\n\n\n\n\n\n7/29\n\n\nRegression Diagnostics, Sampling\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/30\n\n\nWrap-Up\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/31\n\n\nQuiz 3 (Weeks 5‚Äì6)\n\n\n‚Äî\n\n\n‚Äî"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html",
    "href": "files/lecture_notes/lecture13/lecture13.html",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Making Decisions with Data: From Questions to Statistical Evidence\n‚ÄúThe goal is not to eliminate uncertainty, but to make informed decisions despite it‚Äù\n\n\n\n\n\n\n\nWhen:\n- üìÖ Date: Friday, July 25\n- ‚è∞ Window: 7 AM ‚Äì 12 AM\n- ‚è≥ Duration: 1 hour once started\nWhere: üíª Online via Canvas\n\n\n\n\n\nFoundation: Logic of hypothesis testing\nPractice: Real examples with Python\nSkills: Making statistical decisions\nApplications: From medicine to marketing\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstand the logic of hypothesis testing\nMaster the language of statistical decisions\nRecognize different types of errors and their consequences\nConnect to confidence intervals from last lecture\n\n\n\n\n\n\nFormulate hypotheses from research questions\nCalculate and interpret p-values correctly\nPerform hypothesis tests in Python\nMake informed decisions using statistical evidence\nCommunicate results effectively\n\n\n\n\n\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nHypothesis testing helps us answer: ‚ÄúIs what we observed in our sample strong enough evidence to conclude something about the population?‚Äù\n\n\n\n\n\n\n                            \n                                            \n\n\nKey Insight: Just like in court, we never ‚Äúprove‚Äù innocence or ‚Äúaccept‚Äù the null hypothesis. We only determine if there‚Äôs sufficient evidence to reject it!\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\nKey Message: P-value tells us ‚ÄúHow surprised should we be by this data if H‚ÇÄ were true?‚Äù\n\n\n\n\n\n\n                            \n                                            \n\n\nBottom Line: There‚Äôs always a trade-off between Type I and Type II errors. Choose Œ± based on which error is more costly in your context!\n\n\n\n\n\n\n                            \n                                            \n\n\nKey Insight: Higher power means you‚Äôre more likely to detect a true effect when it exists. Aim for power ‚â• 0.80!\n\n\n\n\n\n\nResearch Question: A new study technique claims to improve test scores. The current average is 75. We test 25 students using the new method.\n\n\nüìä Sample Data Summary:\n========================================\nSample size (n): 25\nSample mean (xÃÑ): 77.19\nSample std (s): 7.65\nCurrent average (Œº‚ÇÄ): 75\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\nüéØ DETAILED RESULTS:\n==================================================\nTest Statistic: t = 1.432\nP-value: 0.0825\nCritical Value: 1.711\nEffect Size (Cohen's d): 0.286\n\n‚ùå DECISION: Fail to reject H‚ÇÄ\nüìä CONCLUSION: There is insufficient evidence (p = 0.0825) that the new study method improves test scores.\nüí° PRACTICAL IMPACT: The observed difference could reasonably be due to chance.\n\n\n\n\n\n\n\nüêç PYTHON IMPLEMENTATION:\n========================================\nMethod 1: scipy.stats.ttest_1samp\nt-statistic: 1.432\np-value (two-tailed): 0.1650\np-value (one-tailed): 0.0825\n\nMethod 2: Manual with 95% Confidence Interval\n95% CI: (74.03, 80.35)\nInterpretation: We're 95% confident the true mean is between 74.0 and 80.4\n\nEffect Size (Cohen's d): 0.286\nEffect size interpretation: small effect\n\n\n\n\n\n\n\n\n\nResearch Question: Compare effectiveness of two teaching methods\n\n\nüìä TWO-GROUP COMPARISON:\n========================================\nMethod A (Traditional):\n  n = 30, mean = 75.45, std = 11.87\n\nMethod B (New):\n  n = 28, mean = 82.72, std = 14.82\n\nDifference in means: 7.27 points\n\n\n\n\n\n\n\n\n                            \n                                            \n\n\nüîë KEY LESSON: Statistical Significance ‚â† Practical Importance\n============================================================\nLeft: Tiny effect (0.02) but significant due to large sample\nRight: Large effect (8.7) but significant with small sample\n\nüí° Always consider BOTH statistical significance AND effect size!\n\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n# =============================================================================\n# COMPLETE HYPOTHESIS TESTING TOOLKIT\n# =============================================================================\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# -----------------------------------------------------------------------------\n# Template 1: One-Sample t-test\n# -----------------------------------------------------------------------------\ndef one_sample_ttest(data, null_value, alpha=0.05, alternative='two-sided'):\n    \"\"\"\n    Perform one-sample t-test with complete analysis\n    \n    Parameters:\n    -----------\n    data : array-like\n        Sample data\n    null_value : float\n        Hypothesized population mean\n    alpha : float\n        Significance level (default 0.05)\n    alternative : str\n        'two-sided', 'greater', or 'less'\n    \"\"\"\n    \n    # Calculate statistics\n    n = len(data)\n    x_bar = np.mean(data)\n    s = np.std(data, ddof=1)\n    se = s / np.sqrt(n)\n    \n    # Test statistic\n    t_stat = (x_bar - null_value) / se\n    df = n - 1\n    \n    # P-value calculation\n    if alternative == 'two-sided':\n        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    elif alternative == 'greater':\n        p_value = 1 - stats.t.cdf(t_stat, df)\n    elif alternative == 'less':\n        p_value = stats.t.cdf(t_stat, df)\n    \n    # Effect size (Cohen's d)\n    cohens_d = (x_bar - null_value) / s\n    \n    # Confidence interval\n    t_crit = stats.t.ppf(1 - alpha/2, df)\n    ci_lower = x_bar - t_crit * se\n    ci_upper = x_bar + t_crit * se\n    \n    # Results\n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'confidence_interval': (ci_lower, ci_upper),\n        'reject_null': p_value &lt;= alpha,\n        'sample_mean': x_bar,\n        'sample_std': s,\n        'sample_size': n\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 2: Two-Sample t-test\n# -----------------------------------------------------------------------------\ndef two_sample_ttest(group1, group2, alpha=0.05, equal_var=True):\n    \"\"\"\n    Perform two-sample t-test with complete analysis\n    \"\"\"\n    \n    # Calculate statistics\n    n1, n2 = len(group1), len(group2)\n    mean1, mean2 = np.mean(group1), np.mean(group2)\n    s1, s2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n    \n    if equal_var:\n        # Pooled variance\n        pooled_var = ((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2)\n        se = np.sqrt(pooled_var * (1/n1 + 1/n2))\n        df = n1 + n2 - 2\n    else:\n        # Welch's t-test\n        se = np.sqrt(s1**2/n1 + s2**2/n2)\n        df = (s1**2/n1 + s2**2/n2)**2 / ((s1**2/n1)**2/(n1-1) + (s2**2/n2)**2/(n2-1))\n    \n    # Test statistic\n    t_stat = (mean1 - mean2) / se\n    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    \n    # Effect size (Cohen's d)\n    if equal_var:\n        pooled_std = np.sqrt(pooled_var)\n    else:\n        pooled_std = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2))\n    \n    cohens_d = (mean1 - mean2) / pooled_std\n    \n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'reject_null': p_value &lt;= alpha,\n        'group1_stats': {'mean': mean1, 'std': s1, 'n': n1},\n        'group2_stats': {'mean': mean2, 'std': s2, 'n': n2}\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 3: Power Analysis\n# -----------------------------------------------------------------------------\ndef power_analysis(effect_size, alpha=0.05, power=0.8):\n    \"\"\"\n    Calculate required sample size for desired power\n    \"\"\"\n    from scipy.stats import norm\n    \n    z_alpha = norm.ppf(1 - alpha/2)\n    z_beta = norm.ppf(power)\n    \n    n = ((z_alpha + z_beta) / effect_size) ** 2\n    \n    return int(np.ceil(n))\n\n# -----------------------------------------------------------------------------\n# Example Usage\n# -----------------------------------------------------------------------------\n\n# Generate sample data\nnp.random.seed(42)\nsample_data = np.random.normal(105, 15, 25)\n\n# Perform one-sample t-test\nresults = one_sample_ttest(sample_data, null_value=100, alternative='greater')\n\nprint(\"One-Sample t-test Results:\")\nprint(f\"Test statistic: {results['test_statistic']:.3f}\")\nprint(f\"P-value: {results['p_value']:.4f}\")\nprint(f\"Effect size (d): {results['effect_size']:.3f}\")\nprint(f\"95% CI: ({results['confidence_interval'][0]:.2f}, {results['confidence_interval'][1]:.2f})\")\nprint(f\"Reject null: {results['reject_null']}\")\n\n# Power analysis\nrequired_n = power_analysis(effect_size=0.5, power=0.8)\nprint(f\"\\nRequired sample size for d=0.5, power=0.8: {required_n}\")\n\n\n\n\n\n\n\n\n\n\nHypothesis testing provides a framework for making decisions under uncertainty\nP-values quantify how surprising our data would be if H‚ÇÄ were true\nStatistical significance ‚â† practical importance - always consider effect size\nType I and II errors represent different kinds of mistakes with different costs\nPower is the ability to detect true effects when they exist\n\n\n\n\n\n\nPlan before you analyze - specify hypotheses and Œ± level in advance\nCheck assumptions and use appropriate tests\nReport effect sizes and confidence intervals, not just p-values\nConsider practical significance alongside statistical significance\nBe honest about limitations and acknowledge uncertainty"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#quick-announcements",
    "href": "files/lecture_notes/lecture13/lecture13.html#quick-announcements",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "When:\n- üìÖ Date: Friday, July 25\n- ‚è∞ Window: 7 AM ‚Äì 12 AM\n- ‚è≥ Duration: 1 hour once started\nWhere: üíª Online via Canvas\n\n\n\n\n\nFoundation: Logic of hypothesis testing\nPractice: Real examples with Python\nSkills: Making statistical decisions\nApplications: From medicine to marketing"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#learning-journey-today",
    "href": "files/lecture_notes/lecture13/lecture13.html#learning-journey-today",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Understand the logic of hypothesis testing\nMaster the language of statistical decisions\nRecognize different types of errors and their consequences\nConnect to confidence intervals from last lecture\n\n\n\n\n\n\nFormulate hypotheses from research questions\nCalculate and interpret p-values correctly\nPerform hypothesis tests in Python\nMake informed decisions using statistical evidence\nCommunicate results effectively"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#what-is-hypothesis-testing",
    "href": "files/lecture_notes/lecture13/lecture13.html#what-is-hypothesis-testing",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Hypothesis testing helps us answer: ‚ÄúIs what we observed in our sample strong enough evidence to conclude something about the population?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#the-courtroom-analogy",
    "href": "files/lecture_notes/lecture13/lecture13.html#the-courtroom-analogy",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Key Insight: Just like in court, we never ‚Äúprove‚Äù innocence or ‚Äúaccept‚Äù the null hypothesis. We only determine if there‚Äôs sufficient evidence to reject it!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#understanding-p-values",
    "href": "files/lecture_notes/lecture13/lecture13.html#understanding-p-values",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Key Message: P-value tells us ‚ÄúHow surprised should we be by this data if H‚ÇÄ were true?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#types-of-errors-the-trade-off",
    "href": "files/lecture_notes/lecture13/lecture13.html#types-of-errors-the-trade-off",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Bottom Line: There‚Äôs always a trade-off between Type I and Type II errors. Choose Œ± based on which error is more costly in your context!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#statistical-power-detecting-true-effects",
    "href": "files/lecture_notes/lecture13/lecture13.html#statistical-power-detecting-true-effects",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Key Insight: Higher power means you‚Äôre more likely to detect a true effect when it exists. Aim for power ‚â• 0.80!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#example-1-one-sample-t-test",
    "href": "files/lecture_notes/lecture13/lecture13.html#example-1-one-sample-t-test",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Research Question: A new study technique claims to improve test scores. The current average is 75. We test 25 students using the new method.\n\n\nüìä Sample Data Summary:\n========================================\nSample size (n): 25\nSample mean (xÃÑ): 77.19\nSample std (s): 7.65\nCurrent average (Œº‚ÇÄ): 75\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\nüéØ DETAILED RESULTS:\n==================================================\nTest Statistic: t = 1.432\nP-value: 0.0825\nCritical Value: 1.711\nEffect Size (Cohen's d): 0.286\n\n‚ùå DECISION: Fail to reject H‚ÇÄ\nüìä CONCLUSION: There is insufficient evidence (p = 0.0825) that the new study method improves test scores.\nüí° PRACTICAL IMPACT: The observed difference could reasonably be due to chance.\n\n\n\n\n\n\n\nüêç PYTHON IMPLEMENTATION:\n========================================\nMethod 1: scipy.stats.ttest_1samp\nt-statistic: 1.432\np-value (two-tailed): 0.1650\np-value (one-tailed): 0.0825\n\nMethod 2: Manual with 95% Confidence Interval\n95% CI: (74.03, 80.35)\nInterpretation: We're 95% confident the true mean is between 74.0 and 80.4\n\nEffect Size (Cohen's d): 0.286\nEffect size interpretation: small effect"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#example-2-two-sample-t-test",
    "href": "files/lecture_notes/lecture13/lecture13.html#example-2-two-sample-t-test",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Research Question: Compare effectiveness of two teaching methods\n\n\nüìä TWO-GROUP COMPARISON:\n========================================\nMethod A (Traditional):\n  n = 30, mean = 75.45, std = 11.87\n\nMethod B (New):\n  n = 28, mean = 82.72, std = 14.82\n\nDifference in means: 7.27 points"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#statistical-vs-practical-significance",
    "href": "files/lecture_notes/lecture13/lecture13.html#statistical-vs-practical-significance",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "üîë KEY LESSON: Statistical Significance ‚â† Practical Importance\n============================================================\nLeft: Tiny effect (0.02) but significant due to large sample\nRight: Large effect (8.7) but significant with small sample\n\nüí° Always consider BOTH statistical significance AND effect size!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#python-code-templates",
    "href": "files/lecture_notes/lecture13/lecture13.html#python-code-templates",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "# =============================================================================\n# COMPLETE HYPOTHESIS TESTING TOOLKIT\n# =============================================================================\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# -----------------------------------------------------------------------------\n# Template 1: One-Sample t-test\n# -----------------------------------------------------------------------------\ndef one_sample_ttest(data, null_value, alpha=0.05, alternative='two-sided'):\n    \"\"\"\n    Perform one-sample t-test with complete analysis\n    \n    Parameters:\n    -----------\n    data : array-like\n        Sample data\n    null_value : float\n        Hypothesized population mean\n    alpha : float\n        Significance level (default 0.05)\n    alternative : str\n        'two-sided', 'greater', or 'less'\n    \"\"\"\n    \n    # Calculate statistics\n    n = len(data)\n    x_bar = np.mean(data)\n    s = np.std(data, ddof=1)\n    se = s / np.sqrt(n)\n    \n    # Test statistic\n    t_stat = (x_bar - null_value) / se\n    df = n - 1\n    \n    # P-value calculation\n    if alternative == 'two-sided':\n        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    elif alternative == 'greater':\n        p_value = 1 - stats.t.cdf(t_stat, df)\n    elif alternative == 'less':\n        p_value = stats.t.cdf(t_stat, df)\n    \n    # Effect size (Cohen's d)\n    cohens_d = (x_bar - null_value) / s\n    \n    # Confidence interval\n    t_crit = stats.t.ppf(1 - alpha/2, df)\n    ci_lower = x_bar - t_crit * se\n    ci_upper = x_bar + t_crit * se\n    \n    # Results\n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'confidence_interval': (ci_lower, ci_upper),\n        'reject_null': p_value &lt;= alpha,\n        'sample_mean': x_bar,\n        'sample_std': s,\n        'sample_size': n\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 2: Two-Sample t-test\n# -----------------------------------------------------------------------------\ndef two_sample_ttest(group1, group2, alpha=0.05, equal_var=True):\n    \"\"\"\n    Perform two-sample t-test with complete analysis\n    \"\"\"\n    \n    # Calculate statistics\n    n1, n2 = len(group1), len(group2)\n    mean1, mean2 = np.mean(group1), np.mean(group2)\n    s1, s2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n    \n    if equal_var:\n        # Pooled variance\n        pooled_var = ((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2)\n        se = np.sqrt(pooled_var * (1/n1 + 1/n2))\n        df = n1 + n2 - 2\n    else:\n        # Welch's t-test\n        se = np.sqrt(s1**2/n1 + s2**2/n2)\n        df = (s1**2/n1 + s2**2/n2)**2 / ((s1**2/n1)**2/(n1-1) + (s2**2/n2)**2/(n2-1))\n    \n    # Test statistic\n    t_stat = (mean1 - mean2) / se\n    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    \n    # Effect size (Cohen's d)\n    if equal_var:\n        pooled_std = np.sqrt(pooled_var)\n    else:\n        pooled_std = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2))\n    \n    cohens_d = (mean1 - mean2) / pooled_std\n    \n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'reject_null': p_value &lt;= alpha,\n        'group1_stats': {'mean': mean1, 'std': s1, 'n': n1},\n        'group2_stats': {'mean': mean2, 'std': s2, 'n': n2}\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 3: Power Analysis\n# -----------------------------------------------------------------------------\ndef power_analysis(effect_size, alpha=0.05, power=0.8):\n    \"\"\"\n    Calculate required sample size for desired power\n    \"\"\"\n    from scipy.stats import norm\n    \n    z_alpha = norm.ppf(1 - alpha/2)\n    z_beta = norm.ppf(power)\n    \n    n = ((z_alpha + z_beta) / effect_size) ** 2\n    \n    return int(np.ceil(n))\n\n# -----------------------------------------------------------------------------\n# Example Usage\n# -----------------------------------------------------------------------------\n\n# Generate sample data\nnp.random.seed(42)\nsample_data = np.random.normal(105, 15, 25)\n\n# Perform one-sample t-test\nresults = one_sample_ttest(sample_data, null_value=100, alternative='greater')\n\nprint(\"One-Sample t-test Results:\")\nprint(f\"Test statistic: {results['test_statistic']:.3f}\")\nprint(f\"P-value: {results['p_value']:.4f}\")\nprint(f\"Effect size (d): {results['effect_size']:.3f}\")\nprint(f\"95% CI: ({results['confidence_interval'][0]:.2f}, {results['confidence_interval'][1]:.2f})\")\nprint(f\"Reject null: {results['reject_null']}\")\n\n# Power analysis\nrequired_n = power_analysis(effect_size=0.5, power=0.8)\nprint(f\"\\nRequired sample size for d=0.5, power=0.8: {required_n}\")"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#summary-key-takeaways",
    "href": "files/lecture_notes/lecture13/lecture13.html#summary-key-takeaways",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Hypothesis testing provides a framework for making decisions under uncertainty\nP-values quantify how surprising our data would be if H‚ÇÄ were true\nStatistical significance ‚â† practical importance - always consider effect size\nType I and II errors represent different kinds of mistakes with different costs\nPower is the ability to detect true effects when they exist\n\n\n\n\n\n\nPlan before you analyze - specify hypotheses and Œ± level in advance\nCheck assumptions and use appropriate tests\nReport effect sizes and confidence intervals, not just p-values\nConsider practical significance alongside statistical significance\nBe honest about limitations and acknowledge uncertainty"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "",
    "text": "Introduction to Probability\nUnderstanding uncertainty through statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#welcome-to-lecture-4",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#welcome-to-lecture-4",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "",
    "text": "Introduction to Probability\nUnderstanding uncertainty through statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-objectives",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities\nDetermine when events are independent\nUse Bayes‚Äô theorem in simple applications"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-prob",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-prob",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is Probability?",
    "text": "What is Probability?\n\nüéØ Definition\nProbability is a measure of the likelihood that an event will occur"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-range",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-range",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Range",
    "text": "Probability Range\n\n\n\nRanges from 0 to 1 (or 0% to 100%)\n0: Event will never occur (impossible)\n1: Event will certainly occur (certain)\n0.5: Event has equal chance of occurring or not"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#three-ways-to-express-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#three-ways-to-express-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Three Ways to Express Probability",
    "text": "Three Ways to Express Probability\n\nFraction: \\(\\frac{1}{2}\\), \\(\\frac{3}{4}\\), \\(\\frac{2}{6}\\)\nDecimal: 0.5, 0.75, 0.33\nPercentage: 50%, 75%, 33%"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example",
    "text": "Example\nWhen we roll a die, there are six possible outcomes:\n1, 2, 3, 4, 5, 6.\nThe probability of any of them turning up is 1/6 or 16%."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#why-study-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#why-study-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Why Study Probability?",
    "text": "Why Study Probability?\nProbability helps us:\n\nMake decisions under uncertainty\nUnderstand random processes\nAnalyze data and draw conclusions\nModel real-world phenomena\nAssess risk and likelihood\n\n\n\nApplications: Weather forecasting, medical diagnosis, finance, quality control, gaming, insurance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#random-experiments",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#random-experiments",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Random Experiments",
    "text": "Random Experiments\nA random experiment is a process that:\n\nCan be repeated under similar conditions\nHas multiple possible outcomes\nThe outcome cannot be predicted with certainty\n\n\n\nExamples\n\nü™ô Flipping a coin\nüé≤ Rolling a die\nüÉè Drawing a card from a deck\nüí° Measuring the lifetime of a light bulb"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space",
    "text": "Sample Space\n\nüéØ Definition The sample space (denoted \\(S\\) or \\(\\Omega\\)) is the set of all possible outcomes of a random experiment\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# Create a blank canvas with a rectangle representing the sample space\nfig, ax = plt.subplots(figsize=(6, 4))\nrect = patches.Rectangle(\n    (0.1, 0.1), 0.8, 0.8,\n    linewidth=3, edgecolor='black', facecolor='none'\n)\nax.add_patch(rect)\n\n# Label the sample space inside the rectangle\nax.text(0.5, 0.88, r'$\\Omega$', fontsize=24, fontweight='bold', ha='center', va='top')\nax.text(0.5, 0.5, 'All possible outcomes', fontsize=14, ha='center')\n\n# Clean up axes\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nax.axis('off')\n\nplt.title('Sample Space (Œ©)', fontsize=16, pad=20)\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space-examples",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space Examples",
    "text": "Sample Space Examples\n\nCoin flip: \\(S = \\{H, T\\}\\)\nTwo coin flips: \\(S = \\{HH, HT, TH, TT\\}\\)\n\n\n\n\n\n\n\n\nüé≤ Die roll: \\(S = \\{1, 2, 3, 4, 5, 6\\}\\)\nTwo die rolls \n\n\n\n\\(S = \\{A\\heartsuit,\\ 2\\heartsuit,\\ \\dots,\\ K\\heartsuit,\\\\\n\\phantom{S = \\{}A\\diamondsuit,\\ 2\\diamondsuit,\\ \\dots,\\ K\\diamondsuit,\\\\\n\\phantom{S = \\{}A\\clubsuit,\\ 2\\clubsuit,\\ \\dots,\\ K\\clubsuit,\\\\\n\\phantom{S = \\{}A\\spadesuit,\\ 2\\spadesuit,\\ \\dots,\\ K\\spadesuit\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#types-of-sample-spaces",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#types-of-sample-spaces",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Types of Sample Spaces",
    "text": "Types of Sample Spaces\n\n\nFinite Sample Space\n\nLimited number of outcomes\n\nExample: Rolling a die\n\n\n\n\n\n\n\n\n\n\n\n\nInfinite Sample Space\n\nUnlimited outcomes (countable or uncountable)\n\nExample: Measuring exact height of students"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#events",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Events",
    "text": "Events\n\nüéØ Definition An event is a subset of the sample space\n\nSimple event: Contains exactly one outcome (Ex: \\(A = \\{3\\}\\) (rolling a 3))\nCompound event: Contains multiple outcomes (Ex: \\(B = \\{2, 4, 6\\}\\) (rolling an even number))\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.lines as mlines\n\n# Coordinates and styling\noutcomes = list(range(1, 7))\ny = 0.5\nradius = 0.3\ndot_y = y\nfig, ax = plt.subplots(figsize=(8, 4))\nax.axis('off')\n\n# Rectangle bounds to fit all circles\nmin_x = min(outcomes) - radius\nmax_x = max(outcomes) + radius\nmin_y = dot_y - radius\nmax_y = dot_y + radius\nrect = patches.Rectangle((min_x, min_y), max_x-min_x, max_y-min_y,\n                         linewidth=2, edgecolor='black', facecolor='none')\nax.add_patch(rect)\n\n# Label the sample space inside\nax.text((min_x+max_x)/2, max_y + 0.05, r'$\\Omega$', fontsize=20, fontweight='bold', ha='center')\n\n# Plot all outcomes marked by gray crosses\nax.scatter(outcomes, [dot_y]*6, s=200, color='gray', marker='x', linewidths=3, zorder=2)\n\n# Highlight simple event {3} in red\ncircle_simple = patches.Circle((3, dot_y), radius, facecolor='red', alpha=0.3,\n                               edgecolor='black', linewidth=2, zorder=1)\nax.add_patch(circle_simple)\n\n# Highlight compound event {2,4,6} in blue\nfor x in [2, 4, 6]:\n    circle = patches.Circle((x, dot_y), radius, facecolor='blue', alpha=0.3,\n                            edgecolor='black', linewidth=2, zorder=1)\n    ax.add_patch(circle)\n\n# Legend for events\nlegend_handles = [\n    mlines.Line2D([], [], color='red', marker='o', linestyle='None',\n                  markersize=15, label='Simple event {3}', alpha=0.3),\n    mlines.Line2D([], [], color='blue', marker='o', linestyle='None',\n                  markersize=15, label='Compound event {2,4,6}', alpha=0.3)\n]\nax.legend(handles=legend_handles, loc='lower center', ncol=2, frameon=False, bbox_to_anchor=(0.5, -0.3))\n\n# Adjust limits\nax.set_xlim(min_x - 0.5, max_x + 0.5)\nax.set_ylim(min_y - 0.2, max_y + 0.2)\n\nplt.title('Sample Space and Events', fontsize=16, pad=20)\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#event-notation",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#event-notation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Event Notation",
    "text": "Event Notation\nFor a die roll with \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (rolling an odd number)\n\\(B = \\{4, 5, 6\\}\\) (rolling 4 or higher)\n\\(C = \\{6\\}\\) (rolling a six)\n\n\n\n\n\n\n\nWe can describe events in words or using set notation"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#set-operations-overview",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#set-operations-overview",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Set Operations Overview",
    "text": "Set Operations Overview\n\n\n\n\nüéØ Definition:\n\nSet: Collection of distinct objects\nUnion: A OR B occurs\n\nIntersection: A AND B occurs\nComplement: A does NOT occur\nSample Space: All possible outcomes\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# 1) Draw the Venn, but format subset labels to be blank\nv = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    ax=ax,\n    subset_label_formatter=lambda x: \"\"     # removes the \"1\" labels\n)\n\n# 2) Color each region (optional)\nv.get_patch_by_id('10').set_color('lightblue')\nv.get_patch_by_id('01').set_color('lightcoral')\nv.get_patch_by_id('11').set_color('lightgreen')\n\n# 3) Add a dashed universe rectangle around S, with high z‚Äêorder\nrect = patches.Rectangle(\n    (-1, -1),    # lower‚Äêleft corner\n    2, 2,        # width, height\n    linewidth=2,\n    edgecolor='black',\n    facecolor='none',\n    linestyle='--',\n    zorder=10     # put on top of the circles\n)\nax.add_patch(rect)\n\n# 4) Label the universe \"S\"\nax.text(-.95,  0.95, 'S', fontsize=14, fontweight='bold',\n        va='top', ha='left', zorder=11)\n\n# 5) Tidy up\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.set_axis_off()\n\nplt.title('Sample Space $S$ with Events $A$ and $B$')\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#what-is-a-set",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#what-is-a-set",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is a Set?",
    "text": "What is a Set?\n\n\n\n\nüéØ Definition: A collection of things that share common characteristics. They can be elements, members, objects or similar terms.\nExamples:\n\nSet of even numbers:\n\n{2, 4, 6, 8, ‚Ä¶}\n\nSet of vowels: {a, e, i, o, u}\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\n# Create the figure and axes\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# Draw the Venn with no default set labels and blank subset labels\nv = venn2(\n    subsets=(1, 0, 0),\n    set_labels=('', ''),                       # no set labels\n    subset_label_formatter=lambda x: \"\",       # hide subset‚Äêsize labels\n    ax=ax\n)\n\n# Color and shade the A region\npatch = v.get_patch_by_id('10')\npatch.set_color('lightblue')\npatch.set_alpha(0.7)\n\n# Add the dashed universe rectangle for S\nrect = patches.Rectangle(\n    (-1, -1),   # lower‚Äêleft corner\n    2,          # width\n    2,          # height\n    linewidth=2,\n    edgecolor='black',\n    facecolor='none',\n    linestyle='--',\n    zorder=2     # above the circles\n)\nax.add_patch(rect)\n\n# Label the universe \"S\"\nax.text(\n    -0.95, 0.95, 'S',\n    fontsize=14, fontweight='bold',\n    va='top', ha='left',\n    zorder=3\n)\n\n# Label set A inside the circle\nax.text(\n    0, 0, 'SET A',\n    fontsize=14, fontweight='bold',\n    ha='center',\n    zorder=3\n)\n\n# Adjust limits and styling\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\n\nplt.title('A Single Set $A$ within Sample Space $S$')\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#union-a-b",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#union-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Union: A ‚à™ B",
    "text": "Union: A ‚à™ B\n\n\n\n\nüéØ Definition: Contains all set elements, including intersections.\nIn Probability: The event that A OR B occurs (or both).\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\n# Create figure and axes\nfig, ax = plt.subplots(figsize=(6, 6))\n\n# Draw Venn without default numeric labels\nv = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    subset_label_formatter=lambda x: \"\",\n    ax=ax\n)\n\n# Fill entire circles for A and B with semi-transparent colors\nfor region in ('10', '11'):  # parts of A\n    patch = v.get_patch_by_id(region)\n    patch.set_facecolor('skyblue')\n    patch.set_alpha(0.5)\n    patch.set_edgecolor('black')\n    patch.set_linewidth(2)\nfor region in ('01', '11'):  # parts of B\n    patch = v.get_patch_by_id(region)\n    patch.set_facecolor('lightcoral')\n    patch.set_alpha(0.5)\n    patch.set_edgecolor('black')\n    patch.set_linewidth(2)\n\n# Union label at center\nax.text(\n    0, 0, r'$\\mathbf{A \\cup B}$',\n    fontsize=18, fontweight='bold', ha='center', va='center'\n)\n\n# Add the universe rectangle (sample space)\nrect = patches.Rectangle(\n    (-1.1, -1.1), 2.2, 2.2,\n    linewidth=2, edgecolor='black', facecolor='none', linestyle='--'\n)\nax.add_patch(rect)\n\n# Label the universe \"Œ©\"\nax.text(\n    -1.05, 1.05, 'Œ©',\n    fontsize=16, fontweight='bold', va='top', ha='left'\n)\n\n# Increase set label font size\nv.get_label_by_id('A').set_fontsize(14)\nv.get_label_by_id('B').set_fontsize(14)\n\n# Title and styling\nax.set_title('Union of Events: $A \\\\cup B$', fontsize=16, pad=20)\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\n\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#intersection-a-b",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#intersection-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Intersection: A ‚à© B",
    "text": "Intersection: A ‚à© B\n\n\n\n\nüéØ Definition: Area where two or more sets overlap.\nIn Probability: The event that A AND B occurs.\nProperties:\n\nAlways smaller than or equal to individual sets\nCan be empty (disjoint sets)\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\n# Create figure and axes\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# Draw Venn without subset‚Äêsize labels\nv = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    subset_label_formatter=lambda x: \"\",  # hide the \"1\" labels\n    ax=ax\n)\n\n# Shade the non‚Äêintersection regions light gray\nfor region in ('10', '01'):\n    patch = v.get_patch_by_id(region)\n    patch.set_color('lightgray')\n    patch.set_alpha(0.8)\n\n# Shade the intersection region red\npatch = v.get_patch_by_id('11')\npatch.set_color('red')\npatch.set_alpha(0.8)\n\n# Add the universe rectangle\nrect = patches.Rectangle(\n    (-1, -1),    # lower‚Äêleft corner\n    2,           # width\n    2,           # height\n    linewidth=2,\n    edgecolor='black',\n    facecolor='none',\n    linestyle='--',\n    zorder=2      # above circles\n)\nax.add_patch(rect)\n\n# Label the universe \"S\"\nax.text(\n    -0.95, 0.95, 'S',\n    fontsize=14, fontweight='bold',\n    va='top', ha='left',\n    zorder=3\n)\n\n# Label the intersection inside\nax.text(\n    0, 0, 'A ‚à© B',\n    fontsize=14, fontweight='bold',\n    ha='center', va='center',\n    zorder=3\n)\n\n# Tidy up\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\n\nplt.title('Intersection: $A \\\\cap B$ (A AND B)')\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#absolute-complement-ac",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#absolute-complement-ac",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Absolute Complement: \\(A^c\\)",
    "text": "Absolute Complement: \\(A^c\\)\n\n\n\nüéØ Definition: All elements that do not belong to the set.\nIn Probability: The event that A does NOT occur.\n\n\\(P(A^c) = 1 - P(A)\\)\n\nKey Property:\n\n\\(A \\cup A^c = S\\) (Sample Space)\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2, venn2_circles\n\n# 1) Create figure and axes\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# 2) Draw the universe rectangle (purple background)\nrect = patches.Rectangle(\n    (-1, -1),  # lower-left corner\n    2, 2,      # width, height\n    linewidth=2,\n    edgecolor='black',\n    facecolor='purple',\n    alpha=0.3,\n    zorder=1\n)\nax.add_patch(rect)\n\n# 3) Draw Venn diagram with blank subset labels\nv = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    subset_label_formatter=lambda x: \"\",\n    ax=ax\n)\n\n# 4) Mask out A (both A‚Äêonly and intersection) with white\nfor region in ('10', '11'):\n    p = v.get_patch_by_id(region)\n    p.set_facecolor('white')\n    p.set_edgecolor('none')\n    p.set_alpha(1)\n\n# 5) Hide the B‚Äêonly region so purple shows through\np_b = v.get_patch_by_id('01')\np_b.set_facecolor('none')\np_b.set_edgecolor('none')\np_b.set_alpha(1)\n\n# 6) Draw crisp circle outlines on top\nvenn2_circles((1, 1, 1), ax=ax, linestyle='solid', linewidth=2, color='black')\n\n# 7) Label universe and complement\nax.text(-0.95, 0.95, 'S', fontsize=14, fontweight='bold', va='top', ha='left', zorder=3)\nax.text(-.6, 0.75, r'$A^c$', fontsize=14, fontweight='bold', ha='center', va='center', zorder=3)\n\n# 8) Final styling\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\nplt.title('Complement: $A^c$ (NOT A)')\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#summary-table",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#summary-table",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Summary Table",
    "text": "Summary Table\n\n\n\n\n\n\n\n\n\nOperation\nSymbol\nMeaning\nProbability\n\n\n\n\nUnion\n\\(A \\cup B\\)\nOccurs if \\(A\\) or \\(B\\)\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\nIntersection\n\\(A \\cap B\\)\nOccurs if \\(A\\) and \\(B\\)\n\\(P(A \\cap B)\\)\n\n\nComplement\n\\(A^c\\)\nOccurs if \\(A\\) does not occur\n\\(P(A^c) = 1 - P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-commutative",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-commutative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Commutative",
    "text": "Probability Axioms: Commutative\n\nCommutative\n\\(A \\cup B = B \\cup A\\)\n\\(A \\cap B = B \\cap A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-associative",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-associative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Associative",
    "text": "Probability Axioms: Associative\n\nAssociative\n\\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\)\n\\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-distributive",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-distributive",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Distributive",
    "text": "Probability Axioms: Distributive\n\nDistributive\n\\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\n\\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-de-morgans-laws",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-de-morgans-laws",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: De Morgan‚Äôs Laws",
    "text": "Probability Axioms: De Morgan‚Äôs Laws\n\nDe Morgan‚Äôs Laws\n\\((A \\cup B)^c = A^c \\cap B^c\\)\n\\((A \\cap B)^c = A^c \\cup B^c\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-examples",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Examples",
    "text": "Practice Examples\n\nExample 1: In a class of students:\n\nSet A = Students who like Math\nSet B = Students who like Science\n\nQ: What does A ‚à™ B represent?\n\n\n\nSolution. Students who like Math OR Science (or both)\n\n\n\n\nExample 2: What does A ‚à© B represent?\n\n\n\nSolution. Students who like BOTH Math AND Science\n\n\n\n\nExample 3: What does \\(A^c\\) represent?\n\n\n\nSolution. Students who do NOT like Math"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#example-set-operations",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#example-set-operations",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example: Set Operations",
    "text": "Example: Set Operations\n\n\nFor die roll \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (odd numbers)\n\\(B = \\{4, 5, 6\\}\\) (4 or higher)\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\n# Create the figure and axes\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# Correct subset sizes: A only = 2, B only = 2, A ‚à© B = 1\nv = venn2(\n    subsets=(2, 2, 1),\n    set_labels=('A', 'B'),\n    subset_label_formatter=lambda x: \"\",  # hide the count labels\n    ax=ax\n)\n\n# Label each region\nv.get_label_by_id('10').set_text('A ‚àñ B\\n{1, 3}')\nv.get_label_by_id('01').set_text('B ‚àñ A\\n{4, 6}')\nv.get_label_by_id('11').set_text('A ‚à© B\\n{5}')\n\n# Draw the universe rectangle for S\nrect = patches.Rectangle(\n    (-1, -1),   # lower-left corner\n    2, 2,       # width, height\n    linewidth=2,\n    edgecolor='black',\n    facecolor='none',\n    linestyle='--',\n    zorder=1\n)\nax.add_patch(rect)\n\n# Label the universe\nax.text(\n    -0.95, 0.95, 'S = {1,2,3,4,5,6}',\n    fontsize=12, fontweight='bold',\n    va='top', ha='left',\n    zorder=2\n)\n\n# Final styling\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\n\nplt.title('Odd Numbers vs. 4 or Higher')\nplt.show()\n\n\n\n\nFind:\n\n\\(A \\cup B\\)\n\\(A \\cap B\\)\n\\(A^c\\)\n\n\n\n\n\nSolution. \n\n\\(A \\cup B = \\{1, 3, 4, 5, 6\\}\\)\n\\(A \\cap B = \\{5\\}\\)\n\\(A^c = \\{2, 4, 6\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-events",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive Events",
    "text": "Mutually Exclusive Events\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive (or disjoint) if they cannot occur simultaneously\n\\[A \\cap B = \\emptyset\\]\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\n# Create figure and axes\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# Draw Venn diagram with blank subset labels\nv = venn2(\n    subsets=(3, 3, 0),\n    set_labels=('A', 'B'),\n    subset_label_formatter=lambda x: \"\",\n    ax=ax\n)\n\n# Color and shade regions\nv.get_patch_by_id('10').set_color('lightblue')\nv.get_patch_by_id('01').set_color('lightcoral')\nv.get_patch_by_id('10').set_alpha(0.7)\nv.get_patch_by_id('01').set_alpha(0.7)\n\n# Label each region explicitly\nv.get_label_by_id('10').set_text('A: {1,3,5}')\nv.get_label_by_id('01').set_text('B: {2,4,6}')\n\n# Add universe rectangle for S\nrect = patches.Rectangle(\n    (-1, -1), 2, 2,\n    linewidth=2,\n    edgecolor='black',\n    facecolor='none',\n    linestyle='--',\n    zorder=1\n)\nax.add_patch(rect)\n\n# Label the universe\nax.text(\n    -0.95, 0.95, 'S = {1, 2, 3, 4, 5, 6}',\n    fontsize=12, fontweight='bold',\n    va='top', ha='left',\n    zorder=2\n)\n\n# Final styling\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\n\nplt.title('Mutually Exclusive: Odd vs. Even')\nplt.show()\n\n\n\n\nWhen rolling a die\n\n\\(A = \\{1, 3, 5\\}\\) (odd)\n\\(B = \\{2, 4, 6\\}\\) (even)\n\n\\(A\\) and \\(B\\) are mutually exclusive"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#the-classical-definition-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#the-classical-definition-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Classical Definition of Probability",
    "text": "The Classical Definition of Probability\n\nüéØ Definition: For equally likely outcomes:\n\\[P(A) = \\frac{\\text{Number of outcomes in } A}{\\text{Total number of outcomes in } S}\\]\n\n\nProbability of rolling an even number on a fair die\n\n\n\\[P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#properties-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#properties-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Properties of Probability",
    "text": "Properties of Probability\n\nNon-negativity: \\(P(A) \\geq 0\\) for any event \\(A\\)\nNormalization: \\(P(S) = 1\\)\nAdditivity: If \\(A\\) and \\(B\\) are mutually exclusive, then\n\n\n\\[P(A \\cup B) = P(A) + P(B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#the-complement-rule",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#the-complement-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Complement Rule",
    "text": "The Complement Rule\n\n\\[P(A) + P(A^c) = 1\\]\n\\[P(A^c) = 1 - P(A)\\]\n\n\n\nIf the probability of rain is 0.3, what‚Äôs the probability of no rain?\n\n\n\n\nSolution. \\[P(\\text{no rain}) = 1 - P(\\text{rain}) = 1 - 0.3 = 0.7\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-1",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\n\n\n\nA standard deck has 52 cards. What is the probability of drawing:\n\nA heart \\(\\heartsuit\\)?\nA face card (Jack, Queen, King)?\nThe ace of spades \\(\\spadesuit\\)?\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{heart}) = \\frac{13}{52} = \\frac{1}{4}\\)\n\\(P(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\\)\n\\(P(\\text{ace of spades}) = \\frac{1}{52}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#the-addition-rule",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#the-addition-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Addition Rule",
    "text": "The Addition Rule\nFor any two events \\(A\\) and \\(B\\):\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\n\nWhy subtract \\(P(A \\cap B)\\)?\n\n\n\nSolution. We don‚Äôt want to double-count outcomes that are in both events"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#addition-rule-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#addition-rule-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Addition Rule Example",
    "text": "Addition Rule Example\n\n\n\n\nDrawing from a standard deck:\n\n\\(A\\): Drawing a heart \\(\\heartsuit\\) (\\(P(A) = \\frac{13}{52}\\))\n\\(B\\): Drawing a face card (\\(P(B) = \\frac{12}{52}\\))\nWhat‚Äôs \\(P(A \\cup B)\\) (heart OR face card)?\n\n\n\n\n\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\nplt.figure(figsize=(6,4))\nv = venn2(subsets=(10, 9, 3))\nv.get_label_by_id('10').set_text('A: Hearts')\nv.get_label_by_id('01').set_text('B: Face Cards')\nv.get_label_by_id('11').set_text('A ‚à© B')\nplt.title('Hearts vs. Face Cards')\nplt.show()\n\n\n\n\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\n\n# Compute region sizes\nonly_hearts = 13 - 3\nonly_face = 12 - 3\nintersection = 3\n\nplt.figure(figsize=(6,4))\nvenn2(subsets=(only_hearts, only_face, intersection), set_labels=('Hearts', 'Face Cards'))\nplt.title('Hearts vs. Face Cards')\nplt.show()\n\n\n\nSolution. \\(P(A \\cap B) = \\frac{3}{52}\\) (face cards that are hearts)\n\\(P(A \\cup B) = \\frac{13}{52} + \\frac{12}{52} - \\frac{3}{52} = \\frac{22}{52} = \\frac{11}{26}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\n\n\n\nüéØConditional probability is the probability of event \\(A\\) given that event \\(B\\) has occurred\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nprovided \\(P(B) &gt; 0\\)\n\n\n\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\n\n# Define colors and edge style\ncolor_intersection = '#1f77b4'  # blue\ncolor_B = '#ff7f0e'             # orange\nedge_color = 'black'\nlinewidth = 2\ntext_fontsize = 20\nlabel_fontsize = 20\ntitle_fontsize = 20\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# --- First plot: Intersection Only ---\nv1 = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    ax=axes[0],\n    subset_label_formatter=lambda x: ''\n)\n# Style regions\nfor region in ('10', '01'):\n    patch = v1.get_patch_by_id(region)\n    patch.set_facecolor('none')\n    patch.set_edgecolor(edge_color)\n    patch.set_linewidth(linewidth)\npatch_int1 = v1.get_patch_by_id('11')\npatch_int1.set_facecolor(color_intersection)\npatch_int1.set_alpha(0.5)\npatch_int1.set_edgecolor(edge_color)\npatch_int1.set_linewidth(linewidth)\n# Increase label font sizes\nv1.get_label_by_id('A').set_fontsize(label_fontsize)\nv1.get_label_by_id('B').set_fontsize(label_fontsize)\n# Add bolded P(A‚à©B) text\nx_int, y_int = v1.get_label_by_id('11').get_position()\naxes[0].text(x_int, y_int, r'$\\mathbf{P(A\\cap B)}$', \n             ha='center', va='center', fontsize=text_fontsize)\naxes[0].set_title('Intersection Only', fontsize=title_fontsize)\n\n# --- Second plot: B Only (including intersection) ---\nv2 = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    ax=axes[1],\n    subset_label_formatter=lambda x: ''\n)\n# Style regions\npatch_A2 = v2.get_patch_by_id('10')\npatch_A2.set_facecolor('none')\npatch_A2.set_edgecolor(edge_color)\npatch_A2.set_linewidth(linewidth)\nfor region in ('01', '11'):\n    patch = v2.get_patch_by_id(region)\n    patch.set_facecolor(color_B)\n    patch.set_alpha(0.5)\n    patch.set_edgecolor(edge_color)\n    patch.set_linewidth(linewidth)\n# Increase label font sizes\nv2.get_label_by_id('A').set_fontsize(label_fontsize)\nv2.get_label_by_id('B').set_fontsize(label_fontsize)\n# Add bolded B text inside B circle\nx_B, y_B = v2.get_label_by_id('01').get_position()\naxes[1].text(x_B, y_B, r'$\\mathbf{B}$', \n             ha='center', va='center', fontsize=text_fontsize)\naxes[1].set_title('B Only', fontsize=title_fontsize)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-interpretation",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-interpretation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Interpretation",
    "text": "Conditional Probability Interpretation\n\\(P(A|B)\\) means:\n\nWe know event  \\(B\\) has occurred \nWhat‚Äôs the probability that \\(A\\) also occurred?\nWe ‚Äúrestrict‚Äù our sample space to only outcomes in \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Example",
    "text": "Conditional Probability Example\n\n\n\nDrawing a card from a standard deck:\n\n\\(A\\): Card is a heart \\(\\heartsuit\\)\n\\(B\\): Card is red\nQ: Find \\(P(A|B)\\)\n\n\n\n\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\nplt.figure(figsize=(6,4))\nv = venn2(subsets=(13, 13, 0))\nv.get_label_by_id('10').set_text('A: Hearts')\nv.get_label_by_id('01').set_text('B: Red Cards')\nplt.title('Hearts vs. Red Cards')\nplt.show()\n\n\n\nSolution. \\(P(A \\cap B) = P(\\text{heart}) = \\frac{13}{52}\\)\n\\(P(B) = P(\\text{red}) = \\frac{26}{52}\\)\n\\(P(A|B) = \\frac{13/52}{26/52} = \\frac{13}{26} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#independence",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#independence",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\nüéØ Definition Events \\(A\\) and \\(B\\) are independent if:\n\\[P(A|B) = P(A)\\]\nor equivalently:\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\n\n\nKnowing that \\(B\\) occurred doesn‚Äôt change the probability of \\(A\\)\n\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n\n# Define probabilities for independent events\nP_A = 0.4\nP_B = 0.5\nP_AB = P_A * P_B  # 0.2\n\n# Subset sizes: only A, only B, intersection\nsubsets = (P_A - P_AB, P_B - P_AB, P_AB)\n\nfig, ax = plt.subplots(figsize=(6, 6))\nv = venn2(subsets=subsets, set_labels=('A', 'B'), ax=ax)\n\n# Style regions\nv.get_patch_by_id('10').set_color('skyblue')    # A only\nv.get_patch_by_id('10').set_alpha(0.5)\nv.get_patch_by_id('01').set_color('lightgreen') # B only\nv.get_patch_by_id('01').set_alpha(0.5)\nv.get_patch_by_id('11').set_color('orange')     # Intersection\nv.get_patch_by_id('11').set_alpha(0.7)\n\n# Annotate margins and intersection inside\nv.get_label_by_id('10').set_text(f'{subsets[0]:.1f}')\nv.get_label_by_id('01').set_text(f'{subsets[1]:.1f}')\nv.get_label_by_id('11').set_text(f'{subsets[2]:.1f}')\n\n# Print P(A) and P(B) to the sides\nax.text(-0.8, 0.6, f'$P(A)={P_A}$', fontsize=14, fontweight='bold')\nax.text(0.8, 0.6, f'$P(B)={P_B}$', fontsize=14, fontweight='bold')\n\nplt.title('Independent Events\\n$P(A\\\\cap B)=P(A)P(B)$', fontsize=16)\nax.axis('equal')\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#independence-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#independence-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence Example",
    "text": "Independence Example\n\nTwo coin flips:\n\n\\(A\\): First flip is heads\n\\(B\\): Second flip is heads\n\nQ: Are \\(A\\) and \\(B\\) independent?\n\n\n\nSolution. \\(P(A) = \\frac{1}{2}\\), \\(P(B) = \\frac{1}{2}\\)\n\\(P(A \\cap B) = P(\\text{HH}) = \\frac{1}{4}\\)\n\\(P(A) \\times P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\)\nYes, they are independent!"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.¬†Independent",
    "text": "Mutually Exclusive vs.¬†Independent\n\nMutually Exclusive (left): the circles A and B do not overlap, so \\(P(A\\cap B)=0\\).\nIndependent (right): the circles overlap, and we‚Äôve sized the intersection so that \\(P(A\\cap B)=P(A)\\,P(B)\\).\n\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\n\n# Create side-by-side Venn diagrams\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# 1) Mutually Exclusive: no overlap\nvenn2(\n    subsets=(1, 1, 0),\n    set_labels=('A', 'B'),\n    ax=axes[0],\n    subset_label_formatter=lambda x: ''\n)\naxes[0].set_title('Mutually Exclusive\\nP(A‚à©B) = 0')\n\n# 2) Independent: overlap equals product of areas (e.g., 0.5 * 0.5 = 0.25)\n# Scale counts arbitrarily (25, 25, 25) to represent proportions\nvenn2(\n    subsets=(25, 25, 25),\n    set_labels=('A', 'B'),\n    ax=axes[1],\n    subset_label_formatter=lambda x: ''\n)\naxes[1].set_title('Independent\\nP(A‚à©B) = P(A)P(B)')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.¬†Independent Example",
    "text": "Mutually Exclusive vs.¬†Independent Example\n\n\n\nDraw a single card from a 52-card deck:\n\nLet A={‚Äúdraw an Ace‚Äù}, so P(A)=4/52.\nLet B={‚Äúdraw a King‚Äù}, so P(B)=4/52.\n\nQ: What is \\(P(A\\cap B)\\) ?\n\n\n\n\n\nSolution. They‚Äôre disjoint (you can‚Äôt draw an Ace and a King), so \\(P(A\\cap B) = 0\\).\nBut \\(P(A)\\,P(B) = \\frac{4}{52}\\times\\frac{4}{52} = \\frac{16}{2704} \\neq 0\\).\nHence, \\(P(A\\cap B)\\neq P(A)P(B)\\), so they‚Äôre not independent."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#multiplication-rule",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#multiplication-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Multiplication Rule",
    "text": "Multiplication Rule\nGeneral case: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nIndependent events: \\(P(A \\cap B) = P(A) \\times P(B)\\)\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\n\n# Define scaled subset sizes for illustration\n# General case: P(A)=40 (10+30), P(B|A)=0.75 so intersection=30, B-only=20 (if P(B)=50)\n# Independent case: P(A)=40, P(B)=50, intersection=P(A)*P(B)=20\ngeneral_subsets = (10, 20, 30)   # (A-only, B-only, intersection)\nindep_subsets = (20, 30, 20)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# --- General Multiplication Rule ---\nvenn2(subsets=general_subsets, set_labels=('A', 'B'), ax=axes[0])\naxes[0].set_title('General: P(A‚à©B) = P(A)¬∑P(B|A)', fontsize=14)\n\n# --- Independent Events ---\nvenn2(subsets=indep_subsets, set_labels=('A', 'B'), ax=axes[1])\naxes[1].set_title('Independent: P(A‚à©B) = P(A)¬∑P(B)', fontsize=14)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagrams",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagrams",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\n\nüéØ Definition Tree diagrams help visualize sequential events and calculate probabilities.\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle, FancyArrowPatch\n\n# Coordinates for nodes\ncoords = {\n    'root': (0.1, 0.5),\n    'A': (0.4, 0.7),\n    'B': (0.4, 0.3),\n    'A_Red': (0.7, 0.8),\n    'A_Blue': (0.7, 0.6),\n    'B_Red': (0.7, 0.4),\n    'B_Blue': (0.7, 0.2),\n}\n\n# Probabilities\np_A = 0.7\np_B = 0.3\np_R_A = 0.6\np_B_A = 0.4\np_R_B = 0.3\np_B_B = 0.7\n\n# Create figure\nfig, ax = plt.subplots(figsize=(8, 6))\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nax.axis('off')\n\n# Draw nodes\nfor node, (x, y) in coords.items():\n    circle = Circle((x, y), 0.05, edgecolor='black', facecolor='white', linewidth=2)\n    ax.add_patch(circle)\n    label = node.replace('_', '\\n')\n    if node == 'root':\n        label = 'Start'\n    ax.text(x, y, label, ha='center', va='center', fontsize=12, fontweight='bold')\n\n# Draw arrows and annotate probabilities\ndef draw_branch(start, end, text):\n    x1, y1 = coords[start]\n    x2, y2 = coords[end]\n    arrow = FancyArrowPatch((x1+0.05, y1), (x2-0.05, y2), arrowstyle='-&gt;', mutation_scale=20)\n    ax.add_patch(arrow)\n    ax.text((x1+x2)/2, (y1+y2)/2, text, fontsize=12, backgroundcolor='white', ha='center')\n\ndraw_branch('root', 'A', f'{p_A}')\ndraw_branch('root', 'B', f'{p_B}')\ndraw_branch('A', 'A_Red', f'{p_R_A}')\ndraw_branch('A', 'A_Blue', f'{p_B_A}')\ndraw_branch('B', 'B_Red', f'{p_R_B}')\ndraw_branch('B', 'B_Blue', f'{p_B_B}')\n\n# Title\nax.set_title('Tree Diagram: Drawing from Urn A (70%) or B (30%)', fontsize=14, pad=20)\n\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagram-examples",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagram-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagram Examples",
    "text": "Tree Diagram Examples\n\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle, FancyArrowPatch\n\n# Coordinates for nodes in the full tree\ncoords = {\n    'root':       (0.1, 0.5),\n    'A':          (0.35, 0.75),\n    'NotA':       (0.35, 0.25),\n    'A_B':        (0.7, 0.8),\n    'A_notB':     (0.7, 0.65),\n    'NotA_B':     (0.7, 0.35),\n    'NotA_notB':  (0.7, 0.2)\n}\n\n# Probabilities (example values)\npA     = 0.4\npNotA  = 0.6\npB_A   = 0.75\npNotB_A= 0.25\npB_notA= 0.333\npNotB_notA=0.667\n\n# Colors\ncolor_intersection = '#1f77b4'  # blue\ncolor_B            = '#ff7f0e'  # orange\ngray               = 'lightgray'\n\ndef draw_tree(highlight_branches, branch_color, node_to_color):\n    fig, ax = plt.subplots(figsize=(6, 4))\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.axis('off')\n\n    # Draw nodes\n    node_patches = {}\n    for node, (x, y) in coords.items():\n        circ = Circle((x, y), 0.035, edgecolor='black', facecolor='white', lw=2)\n        ax.add_patch(circ)\n        node_patches[node] = circ\n        label = {\n            'root': 'Start',\n            'A': 'A',\n            'NotA': '¬¨A',\n            'A_B': 'B',\n            'A_notB': '¬¨B',\n            'NotA_B': 'B',\n            'NotA_notB': '¬¨B'\n        }[node]\n        ax.text(x, y, label, ha='center', va='center', fontsize=12)\n\n    # Function to draw a branch\n    def draw_branch(start, end, text, color, lw=1.5):\n        x1, y1 = coords[start]\n        x2, y2 = coords[end]\n        arr = FancyArrowPatch((x1+0.035, y1), (x2-0.035, y2),\n                              arrowstyle='-|&gt;', mutation_scale=15,\n                              lw=lw, color=color)\n        ax.add_patch(arr)\n        ax.text((x1+x2)/2, (y1+y2)/2, text, ha='center', va='center',\n                backgroundcolor='white', fontsize=10)\n\n    # Draw all branches in gray\n    branches = [\n        ('root','A', f'{pA}'),\n        ('root','NotA', f'{pNotA}'),\n        ('A','A_B', f'{pB_A}'),\n        ('A','A_notB', f'{pNotB_A}'),\n        ('NotA','NotA_B', f'{pB_notA:.3f}'),\n        ('NotA','NotA_notB', f'{pNotB_notA:.3f}')\n    ]\n    for b in branches:\n        draw_branch(*b, color=gray)\n\n    # Highlight requested branches\n    for b in highlight_branches:\n        # find text label for branch\n        prob = {\n            ('root','A'): f'{pA}',\n            ('root','NotA'): f'{pNotA}',\n            ('A','A_B'): f'{pB_A}',\n            ('A','A_notB'): f'{pNotB_A}',\n            ('NotA','NotA_B'): f'{pB_notA:.3f}',\n            ('NotA','NotA_notB'): f'{pNotB_notA:.3f}'\n        }[b]\n        draw_branch(b[0], b[1], prob, color=branch_color, lw=3)\n    \n    # Color the end-node if desired\n    for node in node_to_color:\n        node_patches[node].set_facecolor(branch_color)\n\n    return fig, ax\n\n# Tree 1: highlight only the intersection branch root-&gt;A-&gt;A_B in blue\nfig1, ax1 = draw_tree(highlight_branches=[('root','A'),('A','A_B')],\n                      branch_color=color_intersection,\n                      node_to_color=['A_B'])\nax1.set_title('Intersection Only (P(A‚à©B))', fontsize=14)\nplt.show()\n\n\n\n# Tree 2: highlight both B branches (A-&gt;B and ¬¨A-&gt;B) in orange\nfig2, ax2 = draw_tree(highlight_branches=[('root','A'),('A','A_B'),\n                                          ('root','NotA'),('NotA','NotA_B')],\n                      branch_color=color_B,\n                      node_to_color=['A_B','NotA_B'])\nax2.set_title('Event B Only (P(B))', fontsize=14)\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-2",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-2",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\n\n\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement.\n\nWhat‚Äôs the probability both balls are red?\nWhat‚Äôs the probability the first is red and second is blue?\n\n\n\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle\nfrom matplotlib.lines import Line2D\n\n# Set up figure\nfig, ax = plt.subplots(figsize=(10, 6))\nax.axis('off')\n\n# Node positions\npositions = {\n    'root': (0.1, 0.5),\n    'R': (0.35, 0.7),\n    'B': (0.35, 0.3),\n    'RR': (0.7, 0.8),\n    'RB': (0.7, 0.6),\n    'BR': (0.7, 0.4),\n    'BB': (0.7, 0.2),\n}\n\n# Define colors\ncolor_root = '#ecf0f1'\ncolor_R = '#e74c3c'       # red for R or RR\ncolor_B = '#3498db'       # blue for B or BB\ncolor_mixed = '#ff7f0e'   # orange for mixed (RB, BR)\nedge_color = 'black'\nlinewidth = 2\ntext_fs = 12\n\n# Draw nodes with colored backgrounds and bold labels\nnode_colors = {\n    'root': color_root,\n    'R': color_R,\n    'B': color_B,\n    'RR': color_R,\n    'RB': color_mixed,\n    'BR': color_mixed,\n    'BB': color_B\n}\n\nfor name, (x, y) in positions.items():\n    circ = Circle((x, y), 0.05, facecolor=node_colors[name],\n                  edgecolor=edge_color, linewidth=linewidth, zorder=2)\n    ax.add_patch(circ)\n    ax.text(x, y, name, ha='center', va='center', fontsize=text_fs, fontweight='bold', zorder=3)\n\n# Function to draw an arrow and label\ndef draw_arrow(src, dst, label):\n    x1, y1 = positions[src]\n    x2, y2 = positions[dst]\n    ax.annotate('', xy=(x2-0.05, y2), xytext=(x1+0.05, y1),\n                arrowprops=dict(arrowstyle='-&gt;', color=node_colors[dst], lw=linewidth), zorder=1)\n    ax.text((x1+x2)/2, (y1+y2)/2, label, ha='center', va='center',\n            backgroundcolor='white', fontsize=text_fs, fontweight='bold', zorder=3)\n\n# Draw branches with probabilities\ndraw_arrow('root', 'R', '5/8')\ndraw_arrow('root', 'B', '3/8')\ndraw_arrow('R', 'RR', '4/7')\ndraw_arrow('R', 'RB', '3/7')\ndraw_arrow('B', 'BR', '5/7')\ndraw_arrow('B', 'BB', '2/7')\n\n# Label leaves with final probabilities in bold\nleaf_probs = {\n    'RR': '20/56',\n    'RB': '15/56',\n    'BR': '15/56',\n    'BB': '6/56'\n}\nfor leaf, prob in leaf_probs.items():\n    x, y = positions[leaf]\n    ax.text(x+0.12, y, prob, ha='left', va='center', fontsize=text_fs, fontweight='bold')\n\n# Legend\nlegend_elements = [\n    Line2D([0], [0], marker='o', color='w', label='RR / R',\n           markerfacecolor=color_R, markersize=12, markeredgecolor=edge_color),\n    Line2D([0], [0], marker='o', color='w', label='BB / B',\n           markerfacecolor=color_B, markersize=12, markeredgecolor=edge_color),\n    Line2D([0], [0], marker='o', color='w', label='RB / BR',\n           markerfacecolor=color_mixed, markersize=12, markeredgecolor=edge_color),\n]\nax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(0.02, 0.95))\n\nplt.tight_layout()\nplt.show()\n\n\nSolution. \n\n\\(P(\\text{both red}) = \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)\n\\(P(\\text{red then blue}) = \\frac{5}{8} \\times \\frac{3}{7} = \\frac{15}{56}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nüéØ Definition\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space, then:\n\\[P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \\cdots + P(A|B_n)P(B_n)\\]\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle, Ellipse, Rectangle\n\n# Example probabilities\nP_B = [0.3, 0.5, 0.2]\nP_A_given_B = [0.2, 0.6, 0.5]\nP_A_and_B = [P_B[i] * P_A_given_B[i] for i in range(3)]\n\n# Create figure\nfig, ax = plt.subplots(figsize=(9, 5))\nax.set_aspect('equal')\nax.axis('off')\n\n# Draw sample space rectangle\nrect = Rectangle((-1, -2), width=8, height=4, edgecolor='black', facecolor='none', linewidth=2)\nax.add_patch(rect)\nax.text(-0.9, 1.7, r'$\\Omega$', fontsize=14, fontweight='bold', va='top', ha='left')\n\n# Draw B partitions as circles\npositions_B = [(1, 0), (3, 0), (5, 0)]\ncolors_B = ['#ffcc00', '#ff6600', '#ff0066']\n\nfor i, (x, y) in enumerate(positions_B):\n    circle = Circle((x, y), radius=1, facecolor=colors_B[i], edgecolor='black', alpha=0.3)\n    ax.add_patch(circle)\n    ax.text(x, y-1.3, f'$P(B_{i+1})={P_B[i]:.2f}$', ha='center', va='center', fontsize=12, fontweight='bold')\n\n# Draw A as a large ellipse overlapping all B's\nellipse = Ellipse((3, 0), width=8, height=3, angle=0, facecolor='#1f77b4', edgecolor='black', alpha=0.2)\nax.add_patch(ellipse)\nax.text(3, 1.2, '$A$', ha='center', va='center', fontsize=14, fontweight='bold')\n\n# Annotate intersections P(A ‚à© Bi)\nfor i, (x, y) in enumerate(positions_B):\n    ax.text(x, 0, f'$P(A\\\\cap B_{i+1})={P_A_and_B[i]:.2f}$', ha='center', va='center', fontsize=12, color='black', fontweight='bold')\n\nax.set_xlim(-1, 7)\nax.set_ylim(-2, 2)\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\n\nA factory has two machines:\n\nMachine 1: Produces 60% of items, 5% defective\nMachine 2: Produces 40% of items, 3% defective\n\nQ: What‚Äôs the overall probability an item is defective?\n\n\n\nSolution. \\(P(\\text{defective}) = P(D|M_1)P(M_1) + P(D|M_2)P(M_2)\\)\n\\(= 0.05 \\times 0.6 + 0.03 \\times 0.4 = 0.03 + 0.012 = 0.042\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem",
    "text": "Bayes‚Äô Theorem\n\nüéØ Definition \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\nThis allows us to ‚Äúreverse‚Äù conditional probabilities\nNamed after Thomas Bayes (1701-1761)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-components",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-components",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Components",
    "text": "Bayes‚Äô Theorem Components\n\n\\(A,B\\): Events\n\\(P(A|B)\\): Posterior probability - what we want to find\n\\(P(B|A)\\): Likelihood - given \\(A\\), probability of observing \\(B\\)\n\\(P(A)\\): Prior probability - initial probability of \\(A\\)\n\\(P(B)\\): Marginal probability - total probability of \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Example",
    "text": "Bayes‚Äô Theorem Example\n\n\n\nMedical test for a disease: 1\n\nDisease affects 1% of population\nTest is 95% accurate for sick people\nTest is 90% accurate for healthy people\n\nQ:If someone tests positive, what‚Äôs the probability they have the disease?\n\n\n\nimport plotly.express as px\nimport pandas as pd\n\n# Given probabilities\nP_D = 0.01\nP_notD = 0.99\nP_pos_given_D = 0.95\nP_pos_given_notD = 0.10\n\n# Joint probabilities\nP_D_and_pos = P_D * P_pos_given_D       # True positives\nP_notD_and_pos = P_notD * P_pos_given_notD  # False positives\nP_D_and_neg = P_D * (1 - P_pos_given_D)     # False negatives\nP_notD_and_neg = P_notD * (1 - P_pos_given_notD)  # True negatives\n\n# Prepare DataFrame for treemap (mosaic)\ndf = pd.DataFrame({\n    'Test Result': ['Positive', 'Positive', 'Negative', 'Negative'],\n    'Condition':   ['Disease',   'No Disease', 'Disease',   'No Disease'],\n    'Probability': [P_D_and_pos, P_notD_and_pos, P_D_and_neg, P_notD_and_neg]\n})\n\n# Create treemap mosaic plot\nfig = px.treemap(\n    df,\n    path=['Test Result', 'Condition'],\n    values='Probability',\n    color='Condition',\n    color_discrete_map={'Disease':'tomato', 'No Disease':'skyblue'}\n)\nfig.update_traces(textinfo='label+percent entry')\nfig.update_layout(\n    title='Bayes' Theorem: Distribution by Test Result and Condition',\n    margin=dict(t=50, l=25, r=25, b=25)\n)\nfig.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Solution",
    "text": "Bayes‚Äô Theorem Solution\nLet:\n\n\\(D\\): Person has disease\n\\(T^+\\): Test is positive\n\nGiven:\n\n\\(P(D) = 0.01\\)\n\\(P(T^+|D) = 0.95\\)\n\\(P(T^-|D^c) = 0.90\\), so \\(P(T^+|D^c) = 0.10\\)\n\n\n\nSolution. \\(P(T^+) = P(T^+|D)P(D) + P(T^+|D^c)P(D^c)\\)\n\\(= 0.95 \\times 0.01 + 0.10 \\times 0.99 = 0.1085\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution-cont.",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution-cont.",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Solution (cont.)",
    "text": "Bayes‚Äô Theorem Solution (cont.)\n\\[P(D|T^+) = \\frac{P(T^+|D) \\times P(D)}{P(T^+)} = \\frac{0.95 \\times 0.01}{0.1085} \\approx 0.088\\]\n\nimport matplotlib.pyplot as plt\n\n# Posterior probabilities given a positive test\nP_D_and_pos = 0.0095\nP_notD_and_pos = 0.099\nP_positive = P_D_and_pos + P_notD_and_pos\n\nP_D_given_pos = P_D_and_pos / P_positive\nP_notD_given_pos = P_notD_and_pos / P_positive\n\n# Pie chart\nlabels = ['Disease (P‚âà8.8%)', 'No Disease (P‚âà91.2%)']\nsizes = [P_D_given_pos, P_notD_given_pos]\ncolors = ['tomato', 'skyblue']\n\nfig, ax = plt.subplots(figsize=(6, 6))\nax.pie(\n    sizes, labels=labels, colors=colors, autopct='%.1f%%',\n    startangle=90, textprops={'fontsize': 14, 'fontweight': 'bold'}\n)\nax.set_title('Posterior Probability Given Positive Test', fontsize=16, fontweight='bold')\nax.axis('equal')  # Equal aspect ensures pie is circular.\nplt.show()\n\n\n\nSurprising result: Even with a positive test, there‚Äôs only an 8.8% chance of having the disease!\nThis is due to the low base rate of the disease"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nConfusing \\(P(A|B)\\) with \\(P(B|A)\\)\n\n\nProsecutor‚Äôs fallacy is a specific error in interpreting conditional probabilities. Confusing\n\\(P(\\text{Evidence}\\mid\\text{Innocent})\n\\quad\\text{with}\\quad\nP(\\text{Innocent}\\mid\\text{Evidence})\\).\nEx: OJ Simpson Case 2"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes-1",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nAssuming independence when events are dependent\nIgnoring base rates (as in the medical test example)\n\n\nBase rate fallacy is when you ignore or underweight the prior probability \\(P(H)\\) of a hypothesis, focusing only on the new evidence \\(E\\).\n\n\nDouble counting in union calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-3",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-3",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nTwo fair dice are rolled. Find:\n\n\\(P(\\text{sum} = 7)\\)\n\\(P(\\text{sum} = 7 | \\text{first die shows 3})\\)\nAre these events independent?\n\n\n\n\nSolution. \n\n6 ways out of 36: \\(P(\\text{sum} = 7) = \\frac{6}{36} = \\frac{1}{6}\\)\nGiven first die is 3, need second die to be 4: \\(P(\\text{sum} = 7 | \\text{first} = 3) = \\frac{1}{6}\\)\nYes, they‚Äôre independent since \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-and-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-and-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Counting and Probability",
    "text": "Counting and Probability\n\nSometimes we need to count outcomes:\n\nMultiplication Principle: If task 1 can be done in \\(m\\) ways and task 2 in \\(n\\) ways, both can be done in \\(m \\times n\\) ways\n\n\nPermutations: Arrangements where order matters \\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\n\nCombinations: Selections where order doesn‚Äôt matter \\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Counting Example",
    "text": "Counting Example\n\nQ: How many ways can you arrange 5 people in a row?\n\n\n\nSolution. This is a permutation: \\(P(5,5) = 5! = 120\\) ways\n\n\n\n\n\nQ:How many ways can you choose 3 people from 5 for a committee?\n\n\n\n\nSolution. This is a combination: \\(C(5,3) = \\binom{5}{3} = \\frac{5!}{3!2!} = 10\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-with-counting",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-with-counting",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability with Counting",
    "text": "Probability with Counting\n\nExample: A committee of 3 people is chosen from 8 people (5 women, 3 men). What‚Äôs the probability all 3 are women?\n\n\n\nSolution. Total ways to choose 3 from 8: \\(\\binom{8}{3} = 56\\)\nWays to choose 3 women from 5: \\(\\binom{5}{3} = 10\\)\nProbability: \\(\\frac{10}{56} = \\frac{5}{28}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#real-world-applications",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#real-world-applications",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Diagnosis: Using Bayes‚Äô theorem for test interpretation\nQuality Control: Probability of defective items\nFinance: Risk assessment and portfolio theory\nSports: Probability of wins, fantasy sports\nInsurance: Calculating premiums based on risk"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#key-formulas-summary",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\nBasic probability: \\(P(A) = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\\)\nComplement: \\(P(A^c) = 1 - P(A)\\)\nAddition: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nConditional: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nIndependence: \\(P(A \\cap B) = P(A) \\times P(B)\\)\nBayes‚Äô: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#problem-solving-strategy",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\nIdentify the sample space and events\nDetermine if events are independent or mutually exclusive\nChoose the appropriate rule or formula\nCalculate step by step\nCheck if your answer makes sense"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\n\nA bag contains 4 red, 3 blue, and 2 green marbles. Three marbles are drawn without replacement.\nFind the probability that: a) All three are red b) No two are the same color c) At least one is blue"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4-solutions",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4-solutions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 4 Solutions",
    "text": "Practice Problem 4 Solutions\n\nSolution. \n\nAll red: \\(\\frac{4}{9} \\times \\frac{3}{8} \\times \\frac{2}{7} = \\frac{24}{504} = \\frac{1}{21}\\)\nDifferent colors: \\(\\frac{4 \\times 3 \\times 2}{9 \\times 8 \\times 7} \\times 3! = \\frac{24 \\times 6}{504} = \\frac{144}{504} = \\frac{2}{7}\\)\nAt least one blue: \\(1 - P(\\text{no blue}) = 1 - \\frac{6 \\times 5 \\times 4}{9 \\times 8 \\times 7} = 1 - \\frac{120}{504} = \\frac{384}{504} = \\frac{16}{21}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#common-questions",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#common-questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Questions",
    "text": "Common Questions\n\nQ1.: ‚ÄúWhy isn‚Äôt \\(P(A \\cup B) = P(A) + P(B)\\) always?‚Äù\nA: We‚Äôd double-count outcomes in both events\nQ2.: ‚ÄúHow do I know if events are independent?‚Äù\nA: Check if \\(P(A|B) = P(A)\\) or if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nQ3.: ‚ÄúWhen do I use Bayes‚Äô theorem?‚Äù\nA: When you want to ‚Äúreverse‚Äù a conditional probability\n\n\nQ3 note (Bayes Example)\n\nForward: I know my test picks up disease 95% of the time ‚áí \\(P(+\\mid D)=0.95\\).\nReverse: I want the chance I really have the disease when the test is positive ‚áí \\(P(D\\mid +)\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#looking-ahead",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#looking-ahead",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture:\n\nRandom Variables and Probability Distributions\nDiscrete vs.¬†continuous random variables\nExpected value and variance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#final-thoughts",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#final-thoughts",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Final Thoughts",
    "text": "Final Thoughts\n\nProbability is the foundation of statistics:\n\nHelps us quantify uncertainty\nProvides tools for making decisions with incomplete information\nEssential for understanding statistical inference\n\n\n\nPractice: The key to mastering probability is working through many problems!"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#questions",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday‚Äôs 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Random Variables and Distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#resources",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#footnotes",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#footnotes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\\(P(\\neg D \\,\\wedge\\, \\text{Negative})\n\\;=\\;P(\\neg D)\\times P(\\text{Negative}\\mid \\neg D)\n\\;=\\;0.99\\times0.90\n\\;=\\;0.891\\;(89.1\\%)\\)‚Ü©Ô∏é\nthe DNA evidence in the O. J. Simpson trial are a classic example of the prosecutor‚Äôs fallacy. Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was ‚Äúone in 170 million,‚Äù then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent.‚Ü©Ô∏é"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html",
    "href": "files/resources/prob_cheat_sheet.html",
    "title": "Probability Rules Cheat Sheet",
    "section": "",
    "text": "Download PDF"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#basic-probability-concepts",
    "href": "files/resources/prob_cheat_sheet.html#basic-probability-concepts",
    "title": "Probability Rules Cheat Sheet",
    "section": "Basic Probability Concepts",
    "text": "Basic Probability Concepts\n\nProbability Definition: \\[P(A) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total number of outcomes}}\\]\nProperties: - \\(0 \\leq P(A) \\leq 1\\) - \\(P(\\emptyset) = 0\\) (impossible event) - \\(P(S) = 1\\) (certain event, where \\(S\\) is sample space)\n\n\nExample: Rolling a fair die, probability of getting an even number:\n\\[P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2} = 0.5\\]\n\n\nPractice: What is the probability of drawing a face card from a standard deck?\nAnswer: \\(P(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#complement-rule",
    "href": "files/resources/prob_cheat_sheet.html#complement-rule",
    "title": "Probability Rules Cheat Sheet",
    "section": "Complement Rule",
    "text": "Complement Rule\n\nFormula: \\[P(A^c) = 1 - P(A)\\] Alternative notation: \\(P(A') = 1 - P(A)\\)\n\nExplanation: The probability that event \\(A\\) does not occur.\n\nIf the probability that Anya will graduate is 0.9, then the probability she will not graduate is:\n\\[P(\\text{not graduate}) = 1 - 0.9 = 0.1\\]\n\n\nIf \\(P(\\text{rain}) = 0.3\\), what is \\(P(\\text{no rain})\\)?\nAnswer: \\(P(\\text{no rain}) = 1 - 0.3 = 0.7\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#addition-rules",
    "href": "files/resources/prob_cheat_sheet.html#addition-rules",
    "title": "Probability Rules Cheat Sheet",
    "section": "Addition Rules",
    "text": "Addition Rules\n\nGeneral Addition Rule (For Any Two Events)\n\nFormula: \\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\nExplanation: We subtract \\(P(A \\cap B)\\) to avoid double-counting the overlap.\n\nIn a class of 24 students, 10 are girls, 11 are A students, and 6 are girls who are A students.\nProbability of selecting a girl or an A student:\n\\[P(\\text{girl or A}) = \\frac{10}{24} + \\frac{11}{24} - \\frac{6}{24} = \\frac{15}{24} = 0.625\\]\n\n\n\nAddition Rule for Mutually Exclusive Events\n\nFormula: \\[P(A \\cup B) = P(A) + P(B)\\] Condition: \\(P(A \\cap B) = 0\\) (events cannot occur simultaneously)\n\n\nProbability of rolling a 2 or 6 on a die:\n\\[P(2 \\text{ or } 6) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6} = 0.333\\]\n\n\nA bag contains 4 red, 3 blue, and 2 green marbles. What‚Äôs the probability of drawing a red or green marble?\nAnswer: \\(P(\\text{red or green}) = \\frac{4}{9} + \\frac{2}{9} = \\frac{6}{9} = \\frac{2}{3}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#multiplication-rules",
    "href": "files/resources/prob_cheat_sheet.html#multiplication-rules",
    "title": "Probability Rules Cheat Sheet",
    "section": "Multiplication Rules",
    "text": "Multiplication Rules\n\nMultiplication Rule for Dependent Events\n\nFormula: \\[P(A \\cap B) = P(A) \\times P(B|A)\\] Alternative: \\(P(A \\cap B) = P(B) \\times P(A|B)\\)\n\n\nDrawing two red cards without replacement from a standard deck:\n\\[P(\\text{red and red}) = \\frac{26}{52} \\times \\frac{25}{51} = 0.245\\]\n\n\n\nMultiplication Rule for Independent Events\n\nFormula: \\[P(A \\cap B) = P(A) \\times P(B)\\] Condition: Events are independent if \\(P(A|B) = P(A)\\)\n\n\nDrawing two red cards with replacement:\n\\[P(\\text{red and red}) = \\frac{26}{52} \\times \\frac{26}{52} = 0.25\\]\n\n\nTwo fair coins are flipped. What‚Äôs the probability of getting two heads?\nAnswer: \\(P(HH) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#conditional-probability",
    "href": "files/resources/prob_cheat_sheet.html#conditional-probability",
    "title": "Probability Rules Cheat Sheet",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nFormula: \\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\] Condition: \\(P(B) &gt; 0\\)\n\nExplanation: The probability of event \\(A\\) occurring given that event \\(B\\) has occurred.\n\nIn a group of 100 people, 60 are employed and 40 are unemployed. Of the employed, 45 are satisfied with their job.\nWhat‚Äôs the probability someone is satisfied given they are employed?\n\\[P(\\text{satisfied} | \\text{employed}) = \\frac{45}{60} = 0.75\\]\n\n\nA card is drawn from a deck. Given that it‚Äôs red, what‚Äôs the probability it‚Äôs a heart?\nAnswer: \\(P(\\text{heart} | \\text{red}) = \\frac{13}{26} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#set-operations-and-probability",
    "href": "files/resources/prob_cheat_sheet.html#set-operations-and-probability",
    "title": "Probability Rules Cheat Sheet",
    "section": "Set Operations and Probability",
    "text": "Set Operations and Probability\n\nUnion (OR): - Symbol: \\(A \\cup B\\) - Meaning: Event \\(A\\) OR event \\(B\\) (or both) occurs - Formula: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\nIntersection (AND): - Symbol: \\(A \\cap B\\) - Meaning: Both events \\(A\\) AND \\(B\\) occur - Formula: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\n\n\nComplement (NOT): - Symbol: \\(A^c\\) or \\(A'\\) - Meaning: Event \\(A\\) does NOT occur - Formula: \\(P(A^c) = 1 - P(A)\\)"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2_sln.html",
    "href": "files/labs/lab4/lab4_v2_sln.html",
    "title": "Lab 4 Solutions: Discrete Random Variables and Distributions",
    "section": "",
    "text": "Setup\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport pandas as pd\n\n# Set up plotting\n%matplotlib inline\nplt.style.use('seaborn-v0_8-whitegrid')\n\n\n\nTask 1 Solution\nProblem: Consider a biased coin where P(Heads) = 0.7 and P(Tails) = 0.3. Let X be a random variable where X = 1 for Heads and X = 0 for Tails.\n\n# Task 1 Solution\n# 1. Create lists for values and probabilities\ncoin_values = [0, 1]  # 0 for Tails, 1 for Heads\ncoin_probabilities = [0.3, 0.7]  # P(Tails) = 0.3, P(Heads) = 0.7\n\nprint(\"Coin Values (X):\", coin_values)\nprint(\"Probabilities:\", coin_probabilities)\n\n# 2. Verify probabilities sum to 1\nprob_sum = sum(coin_probabilities)\nprint(f\"Sum of probabilities: {prob_sum}\")\nprint(f\"Probabilities sum to 1: {prob_sum == 1.0}\")\n\n# 3. Create bar plot\nplt.figure(figsize=(8, 5))\nplt.bar(coin_values, coin_probabilities, alpha=0.7, color='lightcoral', edgecolor='black', width=0.6)\nplt.xlabel('Value (X)')\nplt.ylabel('Probability')\nplt.title('PMF of Biased Coin (P(Heads) = 0.7)')\nplt.xticks([0, 1], ['Tails (0)', 'Heads (1)'])\nplt.ylim(0, 0.8)\nplt.show()\n\nCoin Values (X): [0, 1]\nProbabilities: [0.3, 0.7]\nSum of probabilities: 1.0\nProbabilities sum to 1: True\n\n\n\n\n\n\n\n\n\n\n\nTask 2 Solution\nProblem: Calculate the expected value and variance for the biased coin from Task 1.\n\n# Task 2 Solution\n# Expected value calculation: E[X] = Œ£ k * P(X = k)\nexpected_value = sum(k * p for k, p in zip(coin_values, coin_probabilities))\nprint(f\"Expected value E[X]: {expected_value}\")\n\n# Step-by-step calculation\nprint(\"\\nStep-by-step calculation:\")\nprint(f\"E[X] = 0 √ó P(X=0) + 1 √ó P(X=1)\")\nprint(f\"E[X] = 0 √ó 0.3 + 1 √ó 0.7 = {0*0.3 + 1*0.7}\")\n\n# Variance calculation: Var(X) = E[X¬≤] - (E[X])¬≤\n# First calculate E[X¬≤]\nexpected_x_squared = sum(k**2 * p for k, p in zip(coin_values, coin_probabilities))\nvariance = expected_x_squared - expected_value**2\n\nprint(f\"\\nVariance calculation:\")\nprint(f\"E[X¬≤] = 0¬≤ √ó 0.3 + 1¬≤ √ó 0.7 = {0**2 * 0.3 + 1**2 * 0.7}\")\nprint(f\"Var(X) = E[X¬≤] - (E[X])¬≤ = {expected_x_squared} - ({expected_value})¬≤ = {variance}\")\nprint(f\"Standard deviation: {np.sqrt(variance):.4f}\")\n\n# Verify using theoretical formula for Bernoulli: Var(X) = p(1-p)\ntheoretical_variance = 0.7 * (1 - 0.7)\nprint(f\"\\nVerification using Bernoulli formula: Var(X) = p(1-p) = 0.7 √ó 0.3 = {theoretical_variance}\")\n\nExpected value E[X]: 0.7\n\nStep-by-step calculation:\nE[X] = 0 √ó P(X=0) + 1 √ó P(X=1)\nE[X] = 0 √ó 0.3 + 1 √ó 0.7 = 0.7\n\nVariance calculation:\nE[X¬≤] = 0¬≤ √ó 0.3 + 1¬≤ √ó 0.7 = 0.7\nVar(X) = E[X¬≤] - (E[X])¬≤ = 0.7 - (0.7)¬≤ = 0.21000000000000002\nStandard deviation: 0.4583\n\nVerification using Bernoulli formula: Var(X) = p(1-p) = 0.7 √ó 0.3 = 0.21000000000000002\n\n\n\n\nTask 3 Solution\nProblem: A basketball player makes 70% of their free throws. They take 15 free throws.\n\n# Task 3 Solution\n# This is a binomial distribution with n=15, p=0.7\nn = 15\np = 0.7\n\nbinom = stats.binom(n, p)\n\n# 1. Probability of making exactly 10 free throws\nprob_exactly_10 = binom.pmf(10)\nprint(f\"1. P(X = 10) = {prob_exactly_10:.4f}\")\n\n# 2. Probability of making at least 12 free throws\nprob_at_least_12 = 1 - binom.cdf(11)  # P(X ‚â• 12) = 1 - P(X ‚â§ 11)\n# Alternative: prob_at_least_12 = sum(binom.pmf(k) for k in range(12, 16))\nprint(f\"2. P(X ‚â• 12) = {prob_at_least_12:.4f}\")\n\n# 3. Expected number of free throws made\nexpected_makes = binom.mean()\nprint(f\"3. Expected number of makes: {expected_makes}\")\nprint(f\"   (Theoretical: n√óp = {n}√ó{p} = {n*p})\")\n\n# 4. Create bar plot showing PMF\nk_values = range(0, n+1)\nprobabilities = [binom.pmf(k) for k in k_values]\n\nplt.figure(figsize=(12, 6))\nplt.bar(k_values, probabilities, alpha=0.7, color='lightgreen', edgecolor='black')\nplt.xlabel('Number of Successful Free Throws')\nplt.ylabel('Probability')\nplt.title(f'Binomial Distribution: Basketball Free Throws (n={n}, p={p})')\nplt.axvline(x=expected_makes, color='red', linestyle='--', linewidth=2, label=f'Expected Value = {expected_makes}')\nplt.legend()\nplt.show()\n\nprint(f\"\\nSummary Statistics:\")\nprint(f\"Mean: {binom.mean()}\")\nprint(f\"Variance: {binom.var()}\")\nprint(f\"Standard Deviation: {binom.std():.4f}\")\n\n1. P(X = 10) = 0.2061\n2. P(X ‚â• 12) = 0.2969\n3. Expected number of makes: 10.5\n   (Theoretical: n√óp = 15√ó0.7 = 10.5)\n\n\n\n\n\n\n\n\n\n\nSummary Statistics:\nMean: 10.5\nVariance: 3.1500000000000012\nStandard Deviation: 1.7748\n\n\n\n\nTask 4 Solution\nProblem: A call center receives an average of 5 calls per minute.\n\n# Task 4 Solution\n# This is a Poisson distribution with Œª = 5\nlam = 5\npoisson = stats.poisson(lam)\n\n# 1. Probability of receiving exactly 7 calls\nprob_exactly_7 = poisson.pmf(7)\nprint(f\"1. P(X = 7) = {prob_exactly_7:.4f}\")\n\n# 2. Probability of receiving no calls\nprob_no_calls = poisson.pmf(0)\nprint(f\"2. P(X = 0) = {prob_no_calls:.4f}\")\n\n# 3. Probability of receiving more than 8 calls\nprob_more_than_8 = 1 - poisson.cdf(8)  # P(X &gt; 8) = 1 - P(X ‚â§ 8)\nprint(f\"3. P(X &gt; 8) = {prob_more_than_8:.4f}\")\n\n# 4. Plot PMF for k = 0 to 15\nk_values = range(0, 16)\nprobabilities = [poisson.pmf(k) for k in k_values]\n\nplt.figure(figsize=(12, 6))\nplt.bar(k_values, probabilities, alpha=0.7, color='purple', edgecolor='black')\nplt.xlabel('Number of Calls per Minute')\nplt.ylabel('Probability')\nplt.title(f'Poisson Distribution: Call Center (Œª = {lam})')\nplt.axvline(x=lam, color='red', linestyle='--', linewidth=2, label=f'Expected Value = {lam}')\nplt.legend()\nplt.show()\n\nprint(f\"\\nSummary Statistics:\")\nprint(f\"Expected value (Œª): {poisson.mean()}\")\nprint(f\"Variance (Œª): {poisson.var()}\")\nprint(f\"Standard Deviation: {poisson.std():.4f}\")\n\n1. P(X = 7) = 0.1044\n2. P(X = 0) = 0.0067\n3. P(X &gt; 8) = 0.0681\n\n\n\n\n\n\n\n\n\n\nSummary Statistics:\nExpected value (Œª): 5.0\nVariance (Œª): 5.0\nStandard Deviation: 2.2361\n\n\n\n\nTask 5 Solution\nProblem: Distribution Identification Practice\n\n# Task 5 Solutions\n\nprint(\"=== SCENARIO A ===\")\nprint(\"Flip a fair coin 20 times. Probability of exactly 12 heads?\")\nprint(\"Distribution: Binomial(n=20, p=0.5)\")\n\nn_a = 20\np_a = 0.5\nbinom_a = stats.binom(n_a, p_a)\nprob_a = binom_a.pmf(12)\nprint(f\"Answer: P(X = 12) = {prob_a:.4f}\")\n\nprint(\"\\n=== SCENARIO B ===\")\nprint(\"Roll a die until you get a 6. Probability it takes exactly 4 rolls?\")\nprint(\"Distribution: Geometric(p=1/6)\")\n\np_b = 1/6\ngeom_b = stats.geom(p_b)\nprob_b = geom_b.pmf(4)\nprint(f\"Answer: P(X = 4) = {prob_b:.4f}\")\n\nprint(\"\\n=== SCENARIO C ===\")\nprint(\"Website gets average 2 visitors per minute. Probability of exactly 3 visitors?\")\nprint(\"Distribution: Poisson(Œª=2)\")\n\nlam_c = 2\npoisson_c = stats.poisson(lam_c)\nprob_c = poisson_c.pmf(3)\nprint(f\"Answer: P(X = 3) = {prob_c:.4f}\")\n\nprint(\"\\n=== SCENARIO D ===\")\nprint(\"5% of items are defective. Probability first defective item found on 8th test?\")\nprint(\"Distribution: Geometric(p=0.05)\")\n\np_d = 0.05\ngeom_d = stats.geom(p_d)\nprob_d = geom_d.pmf(8)\nprint(f\"Answer: P(X = 8) = {prob_d:.4f}\")\n\n=== SCENARIO A ===\nFlip a fair coin 20 times. Probability of exactly 12 heads?\nDistribution: Binomial(n=20, p=0.5)\nAnswer: P(X = 12) = 0.1201\n\n=== SCENARIO B ===\nRoll a die until you get a 6. Probability it takes exactly 4 rolls?\nDistribution: Geometric(p=1/6)\nAnswer: P(X = 4) = 0.0965\n\n=== SCENARIO C ===\nWebsite gets average 2 visitors per minute. Probability of exactly 3 visitors?\nDistribution: Poisson(Œª=2)\nAnswer: P(X = 3) = 0.1804\n\n=== SCENARIO D ===\n5% of items are defective. Probability first defective item found on 8th test?\nDistribution: Geometric(p=0.05)\nAnswer: P(X = 8) = 0.0349\n\n\n\n\nTask 6 Solution\nProblem: Simulation of basketball free throw scenario\n\n# Task 6 Solution\nnp.random.seed(42)  # For reproducible results\n\n# Parameters from Task 3\nn_shots = 15\np_success = 0.7\nn_simulations = 1000\n\n# Theoretical probability of exactly 10 makes\ntheoretical_prob = stats.binom(n_shots, p_success).pmf(10)\nprint(f\"Theoretical P(X = 10): {theoretical_prob:.4f}\")\n\n# Simulate the scenario 1000 times\nsimulation_results = []\nexactly_10_count = 0\n\nfor i in range(n_simulations):\n    # Simulate 15 free throws (1 = make, 0 = miss)\n    shots = np.random.binomial(1, p_success, n_shots)\n    makes = np.sum(shots)\n    simulation_results.append(makes)\n    \n    if makes == 10:\n        exactly_10_count += 1\n\n# Calculate proportion of simulations with exactly 10 makes\nsimulated_prob = exactly_10_count / n_simulations\nprint(f\"Simulated P(X = 10): {simulated_prob:.4f}\")\nprint(f\"Difference: {abs(theoretical_prob - simulated_prob):.4f}\")\n\n# Create histogram with theoretical PMF overlay\nplt.figure(figsize=(14, 8))\n\n# Histogram of simulation results\nplt.hist(simulation_results, bins=range(0, n_shots+2), alpha=0.7, density=True, \n         color='lightblue', edgecolor='black', label='Simulation Results')\n\n# Theoretical PMF overlay\nbinom_theory = stats.binom(n_shots, p_success)\nk_values = range(0, n_shots+1)\ntheoretical_probs = [binom_theory.pmf(k) for k in k_values]\nplt.plot(k_values, theoretical_probs, 'ro-', linewidth=2, markersize=8, \n         label='Theoretical PMF')\n\nplt.xlabel('Number of Successful Free Throws')\nplt.ylabel('Probability/Density')\nplt.title(f'Simulation vs Theory: Basketball Free Throws\\n({n_simulations} simulations, n={n_shots}, p={p_success})')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(f\"\\nSimulation Summary:\")\nprint(f\"Mean of simulations: {np.mean(simulation_results):.2f}\")\nprint(f\"Theoretical mean: {binom_theory.mean():.2f}\")\nprint(f\"Standard deviation of simulations: {np.std(simulation_results):.2f}\")\nprint(f\"Theoretical standard deviation: {binom_theory.std():.2f}\")\n\nTheoretical P(X = 10): 0.2061\nSimulated P(X = 10): 0.2150\nDifference: 0.0089\n\n\n\n\n\n\n\n\n\n\nSimulation Summary:\nMean of simulations: 10.59\nTheoretical mean: 10.50\nStandard deviation of simulations: 1.74\nTheoretical standard deviation: 1.77\n\n\n\n\nFinal Challenge Solution\nProblem: Customer service center analysis\n\n# Final Challenge Solution\n\nprint(\"=== CUSTOMER SERVICE CENTER ANALYSIS ===\\n\")\n\n# Given information:\n# - 20% of calls result in a sale (Bernoulli process)\n# - Calls arrive at average rate of 4 per hour (Poisson process)  \n# - Agents work until first sale (Geometric process)\n\np_sale = 0.2  # Probability of sale per call\ncalls_per_hour = 4\nhours_per_day = 8\n\nprint(\"Given:\")\nprint(f\"- Probability of sale per call: {p_sale}\")\nprint(f\"- Average calls per hour: {calls_per_hour}\")\nprint(f\"- Hours of operation per day: {hours_per_day}\")\n\n# 1. Expected number of calls in 8-hour day\nexpected_calls_per_day = calls_per_hour * hours_per_day\nprint(f\"\\n1. Expected calls in {hours_per_day}-hour day: {expected_calls_per_day}\")\n\n# 2. Probability that exactly 2 of next 10 calls result in sales\nn_calls = 10\nbinom_sales = stats.binom(n_calls, p_sale)\nprob_2_sales = binom_sales.pmf(2)\nprint(f\"\\n2. P(exactly 2 sales in 10 calls): {prob_2_sales:.4f}\")\n\n# 3. Expected number of calls until first sale\ngeom_first_sale = stats.geom(p_sale)\nexpected_calls_until_sale = geom_first_sale.mean()\nprint(f\"\\n3. Expected calls until first sale: {expected_calls_until_sale:.1f}\")\n\n# 4. Comprehensive visualization\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# Plot 1: Poisson - Calls per hour\npoisson_calls = stats.poisson(calls_per_hour)\nk_poisson = range(0, 15)\nprob_poisson = [poisson_calls.pmf(k) for k in k_poisson]\n\naxes[0, 0].bar(k_poisson, prob_poisson, alpha=0.7, color='skyblue', edgecolor='black')\naxes[0, 0].set_title(f'Calls per Hour\\nPoisson(Œª={calls_per_hour})')\naxes[0, 0].set_xlabel('Number of Calls')\naxes[0, 0].set_ylabel('Probability')\naxes[0, 0].axvline(x=calls_per_hour, color='red', linestyle='--', label=f'Mean = {calls_per_hour}')\naxes[0, 0].legend()\n\n# Plot 2: Binomial - Sales in 10 calls\nk_binom = range(0, n_calls + 1)\nprob_binom = [binom_sales.pmf(k) for k in k_binom]\n\naxes[0, 1].bar(k_binom, prob_binom, alpha=0.7, color='lightgreen', edgecolor='black')\naxes[0, 1].set_title(f'Sales in {n_calls} Calls\\nBinomial(n={n_calls}, p={p_sale})')\naxes[0, 1].set_xlabel('Number of Sales')\naxes[0, 1].set_ylabel('Probability')\naxes[0, 1].axvline(x=binom_sales.mean(), color='red', linestyle='--', \n                   label=f'Mean = {binom_sales.mean():.1f}')\naxes[0, 1].legend()\n\n# Plot 3: Geometric - Calls until first sale\nk_geom = range(1, 21)\nprob_geom = [geom_first_sale.pmf(k) for k in k_geom]\n\naxes[1, 0].bar(k_geom, prob_geom, alpha=0.7, color='orange', edgecolor='black')\naxes[1, 0].set_title(f'Calls Until First Sale\\nGeometric(p={p_sale})')\naxes[1, 0].set_xlabel('Call Number')\naxes[1, 0].set_ylabel('Probability')\naxes[1, 0].axvline(x=expected_calls_until_sale, color='red', linestyle='--', \n                   label=f'Mean = {expected_calls_until_sale:.1f}')\naxes[1, 0].legend()\n\n# Plot 4: Poisson - Calls per day\npoisson_day = stats.poisson(expected_calls_per_day)\nk_day = range(15, 50)  # Focus on reasonable range around mean\nprob_day = [poisson_day.pmf(k) for k in k_day]\n\naxes[1, 1].bar(k_day, prob_day, alpha=0.7, color='purple', edgecolor='black')\naxes[1, 1].set_title(f'Calls per Day\\nPoisson(Œª={expected_calls_per_day})')\naxes[1, 1].set_xlabel('Number of Calls')\naxes[1, 1].set_ylabel('Probability')\naxes[1, 1].axvline(x=expected_calls_per_day, color='red', linestyle='--', \n                   label=f'Mean = {expected_calls_per_day}')\naxes[1, 1].legend()\n\nplt.tight_layout()\nplt.show()\n\n# Additional insights\nprint(f\"\\n=== ADDITIONAL INSIGHTS ===\")\nprint(f\"Daily sales expectations:\")\nexpected_daily_sales = expected_calls_per_day * p_sale\nprint(f\"- Expected calls per day: {expected_calls_per_day}\")\nprint(f\"- Expected sales per day: {expected_daily_sales:.1f}\")\n\nprint(f\"\\nProbability calculations:\")\nprint(f\"- P(no sales in 10 calls): {binom_sales.pmf(0):.4f}\")\nprint(f\"- P(at least 1 sale in 10 calls): {1 - binom_sales.pmf(0):.4f}\")\nprint(f\"- P(first sale on call 1): {geom_first_sale.pmf(1):.4f}\")\nprint(f\"- P(first sale within 5 calls): {geom_first_sale.cdf(5):.4f}\")\n\n=== CUSTOMER SERVICE CENTER ANALYSIS ===\n\nGiven:\n- Probability of sale per call: 0.2\n- Average calls per hour: 4\n- Hours of operation per day: 8\n\n1. Expected calls in 8-hour day: 32\n\n2. P(exactly 2 sales in 10 calls): 0.3020\n\n3. Expected calls until first sale: 5.0\n\n\n\n\n\n\n\n\n\n\n=== ADDITIONAL INSIGHTS ===\nDaily sales expectations:\n- Expected calls per day: 32\n- Expected sales per day: 6.4\n\nProbability calculations:\n- P(no sales in 10 calls): 0.1074\n- P(at least 1 sale in 10 calls): 0.8926\n- P(first sale on call 1): 0.2000\n- P(first sale within 5 calls): 0.6723\n\n\n\n\nSummary\nThis lab covered the fundamental concepts of discrete random variables and probability distributions:\n\nBasic Concepts: PMF, expected value, variance\nKey Distributions: Bernoulli, Binomial, Geometric, Poisson\nPython Tools: scipy.stats for probability calculations\nSimulation: Verifying theoretical results with Monte Carlo methods\nReal Applications: Identifying appropriate distributions for real-world scenarios\n\nKey Takeaways: - Always identify the underlying process to choose the right distribution - Use simulation to verify theoretical calculations - Visualizations help understand distribution shapes and parameters - scipy.stats provides powerful tools for probability work"
  },
  {
    "objectID": "files/worksheets/drafts/worksheet4_sln_draft.html",
    "href": "files/worksheets/drafts/worksheet4_sln_draft.html",
    "title": "PSTAT 5A Practice Worksheet 3 - SOLUTIONS",
    "section": "",
    "text": "Section A: Probability - SOLUTIONS\n‚è±Ô∏è Estimated time: 8 minutes\n\nProblem A1: Probability Distributions - SOLUTION\nFor a valid probability distribution, two conditions must be met:\n\nAll probabilities must be non-negative (‚â• 0)\nThe sum of all probabilities must equal 1\n\nAnalysis:\n(a) Invalid\n\nSum = 0.3 + 0.3 + 0.3 + 0.2 + 0.1 = 1.2 &gt; 1 The probabilities sum to more than 1, violating the second condition.\n\n(b) Valid\n\nSum = 0 + 0 + 1 + 0 + 0 = 1 All probabilities are non-negative and sum to 1. This represents a class where everyone receives a C.\n\n(c) Invalid\n\nSum = 0.3 + 0.3 + 0.3 + 0 + 0 = 0.9 &lt; 1 The probabilities sum to less than 1, violating the second condition.\n\n(d) Invalid\n\nContains F = -0.1 &lt; 0 Although the sum would equal 1.0, the probability for grade F is negative, violating the first condition.\n\n(e) Valid\n\nSum = 0.2 + 0.4 + 0.2 + 0.1 + 0.1 = 1.0 All probabilities are non-negative and sum to 1.\n\n(f) Invalid\n\nContains B = -0.1 &lt; 0 Although the sum equals 1.0, the probability for grade B is negative, violating the first condition.\n\n\n\n\nSection B: Permutations and Combinations - SOLUTIONS\n‚è±Ô∏è Estimated time: 15 minutes\n\nProblem B1: Permutations and Combinations - SOLUTION\nPart (a): How many 6-character passwords can be formed using 3 specific letters and 3 specific digits if repetitions are not allowed and letters must come before digits?\nSolution: Since letters must come before digits, we have a fixed structure: LLL DDD\n\nStep 1: Arrange 3 letters in the first 3 positions\n\nThis is a permutation: P(3,3) = 3! = 6 ways\n\nStep 2: Arrange 3 digits in the last 3 positions\n\nThis is a permutation: P(3,3) = 3! = 6 ways\n\nStep 3: Apply multiplication principle\n\nTotal passwords = 6 √ó 6 = 36 passwords\n\n\nPart (b): If the team wants to select 4 people from 12 employees to form a security committee where order doesn‚Äôt matter, how many ways can this be done?\nSolution: Since order doesn‚Äôt matter, this is a combination problem.\n\\[C(12,4) = \\binom{12}{4} = \\frac{12!}{4!(12-4)!} = \\frac{12!}{4! \\cdot 8!}\\]\n\\[= \\frac{12 \\times 11 \\times 10 \\times 9}{4 \\times 3 \\times 2 \\times 1} = \\frac{11880}{24} = \\textbf{495 ways}\\]\n\n\n\nSection C: Conditional Probability - SOLUTIONS\n‚è±Ô∏è Estimated time: 15 minutes\n\nProblem B1: Conditional Probability and Medical Testing - SOLUTION\nGiven Information:\n\nP(has variant) = 0.03\nP(test positive | has variant) = 0.95 (sensitivity)\nP(test negative | no variant) = 0.92 (specificity)\nTherefore: P(test positive | no variant) = 1 - 0.92 = 0.08\n\nPart (a): What is the probability that a randomly selected person tests positive?\nSolution:\nUsing the Law of Total Probability:\n\\[P(\\text{test positive}) = P(\\text{test positive | has variant}) \\times P(\\text{has variant}) + P(\\text{test positive | no variant}) \\times P(\\text{no variant})\\]\n\\[P(\\text{test positive}) = 0.95 \\times 0.03 + 0.08 \\times 0.97\\] \\[= 0.0285 + 0.0776 = \\textbf{0.1061}\\]\nPart (b): If someone tests positive, what is the probability they actually have the variant?\nSolution: Using Bayes‚Äô Theorem:\n\\[P(\\text{has variant | test positive}) = \\frac{P(\\text{test positive | has variant}) \\times P(\\text{has variant})}{P(\\text{test positive})}\\]\n\\[= \\frac{0.95 \\times 0.03}{0.1061} = \\frac{0.0285}{0.1061} = \\textbf{0.2686}\\]\nPart (c): If someone tests negative, what is the probability they actually don‚Äôt have the variant?\nSolution: First, find P(test negative): \\[P(\\text{test negative}) = 1 - P(\\text{test positive}) = 1 - 0.1061 = 0.8939\\]\nUsing Bayes‚Äô Theorem: \\[P(\\text{no variant | test negative}) = \\frac{P(\\text{test negative | no variant}) \\times P(\\text{no variant})}{P(\\text{test negative})}\\]\n\\[= \\frac{0.92 \\times 0.97}{0.8939} = \\frac{0.8924}{0.8939} = \\textbf{0.9983}\\]\nPart (d) [Challenge]: Two consecutive positive tests - what is the probability they actually have the variant?\nSolution: Assuming independence between tests:\n\\[P(\\text{two positive | has variant}) = 0.95^2 = 0.9025\\] \\[P(\\text{two positive | no variant}) = 0.08^2 = 0.0064\\]\n\\[P(\\text{two positive}) = 0.9025 \\times 0.03 + 0.0064 \\times 0.97 = 0.027075 + 0.006208 = 0.033283\\]\n\\[P(\\text{has variant | two positive}) = \\frac{0.027075}{0.033283} = \\textbf{0.8134}\\]\n\n\nProblem C1: Advanced Counting with Restrictions - SOLUTION\nPart (a): How many valid meal combinations are possible?\nSolution: We need to consider cases based on the restrictions.\nCase 1: Seafood appetizer is chosen\n\n1 appetizer option (seafood)\n7 main course options (cannot choose vegetarian)\n5 dessert options\nCombinations: 1 √ó 7 √ó 5 = 35\n\nCase 2: Non-seafood appetizer + chocolate dessert\n\n5 appetizer options (non-seafood)\n3 main course options (only beef or chicken allowed with chocolate)\n1 dessert option (chocolate)\nCombinations: 5 √ó 3 √ó 1 = 15\n\nCase 3: Non-seafood appetizer + non-chocolate dessert - 5 appetizer options (non-seafood)\n\n8 main course options (no restrictions)\n4 dessert options (non-chocolate)\nCombinations: 5 √ó 8 √ó 4 = 160\n\nTotal valid combinations: 35 + 15 + 160 = 210 combinations\nPart (b): If customers choose randomly among valid combinations, what is the probability someone chooses the chocolate dessert?\nSolution: Combinations with chocolate dessert: 15 (from Case 2 above) Total valid combinations: 210\n\\[P(\\text{chocolate dessert}) = \\frac{15}{210} = \\frac{1}{14} = \\textbf{0.0714}\\]\n\n\n\nSection D: Review - SOLUTIONS\n‚è±Ô∏è Estimated time: 12 minutes\n\nProblem B3: Daily Expenses - SOLUTION\nGiven:\n\nCoffee: Mean = $1.40, SD = $0.30\nMuffin: Mean = $2.50, SD = $0.15\nPrices are independent\n\nPart (a): What is the mean and standard deviation of the amount she spends on breakfast daily?\nSolution: For the sum of independent random variables:\nMean of daily expenses: \\[E[\\text{Daily}] = E[\\text{Coffee}] + E[\\text{Muffin}] = \\$1.40 + \\$2.50 = \\textbf{\\$3.90}\\]\nVariance of daily expenses: \\[\\text{Var}[\\text{Daily}] = \\text{Var}[\\text{Coffee}] + \\text{Var}[\\text{Muffin}] = (0.30)^2 + (0.15)^2 = 0.09 + 0.0225 = 0.1125\\]\nStandard deviation of daily expenses: \\[SD[\\text{Daily}] = \\sqrt{0.1125} = \\textbf{\\$0.3354}\\]\nPart (b): What is the mean and standard deviation of the amount she spends on breakfast weekly (7 days)?\nSolution: For the sum of 7 independent daily expenses:\nMean of weekly expenses: \\[E[\\text{Weekly}] = 7 \\times E[\\text{Daily}] = 7 \\times \\$3.90 = \\textbf{\\$27.30}\\]\nVariance of weekly expenses: \\[\\text{Var}[\\text{Weekly}] = 7 \\times \\text{Var}[\\text{Daily}] = 7 \\times 0.1125 = 0.7875\\]\nStandard deviation of weekly expenses: \\[SD[\\text{Weekly}] = \\sqrt{0.7875} = \\textbf{\\$0.8874}\\]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "",
    "text": "Conditional Probabilities\nUnderstanding probability when information changes the game"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#welcome-to-lecture-6",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#welcome-to-lecture-6",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "",
    "text": "Conditional Probabilities\nUnderstanding probability when information changes the game"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#todays-learning-objectives",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#todays-learning-objectives",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine and calculate conditional probabilities\nApply the multiplication rule for dependent events\nUse tree diagrams to solve multi-stage problems\nApply the law of total probability\nUse Bayes‚Äô theorem to solve real-world problems\nDistinguish between independence and conditional independence\nRecognize and avoid common conditional probability fallacies"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#motivation-why-conditional-probability",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#motivation-why-conditional-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Motivation: Why Conditional Probability?",
    "text": "Motivation: Why Conditional Probability?\nIn real life, we rarely make decisions with no information\nExamples: - Medical diagnosis with test results - Weather forecast with current conditions\n- Investment decisions with market data - Sports betting with team statistics - Insurance premiums based on risk factors\n\nConditional probability helps us update our beliefs when we gain new information"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#what-is-conditional-probability",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#what-is-conditional-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "What is Conditional Probability?",
    "text": "What is Conditional Probability?\nConditional Probability is the probability of an event occurring, given that another event has already occurred\nNotation: \\(P(A|B)\\) read as ‚Äúprobability of A given B‚Äù\n\nKey insight: When we know B has occurred, our sample space effectively ‚Äúshrinks‚Äù to only outcomes where B is true"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#intuitive-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#intuitive-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Intuitive Example",
    "text": "Intuitive Example\nYou roll a fair six-sided die, but before revealing the result, someone tells you ‚Äúthe number is even‚Äù\nWhat‚Äôs the probability it‚Äôs a 4?\n\nWithout information: \\(P(\\text{rolling 4}) = \\frac{1}{6}\\)\nWith information: \\(P(\\text{4 | even}) = ?\\)\nGiven it‚Äôs even, possible outcomes: \\(\\{2, 4, 6\\}\\) So \\(P(\\text{4 | even}) = \\frac{1}{3}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#formal-definition",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#formal-definition",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Formal Definition",
    "text": "Formal Definition\nFor events A and B where \\(P(B) &gt; 0\\):\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\n\nInterpretation:\n\nNumerator: Outcomes where both A and B occur\nDenominator: All outcomes where B occurs\nRatio: Fraction of B-outcomes where A also occurs"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#understanding-the-formula",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#understanding-the-formula",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Understanding the Formula",
    "text": "Understanding the Formula\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nWhy this formula makes sense:\n\nWe restrict our attention to outcomes where B occurs\nAmong those outcomes, what fraction also have A?\nThis is exactly \\(\\frac{P(A \\cap B)}{P(B)}\\)\n\n\nRearranging: \\(P(A \\cap B) = P(A|B) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-1",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-1",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\nA card is drawn from a standard 52-card deck. Find:\n\n\\(P(\\text{King | Face card})\\)\n\\(P(\\text{Heart | Red card})\\)\n\n\\(P(\\text{Ace | Black card})\\)\n\n\nSolutions:\n\n\\(P(\\text{King | Face}) = \\frac{4}{12} = \\frac{1}{3}\\) (4 kings among 12 face cards)\n\\(P(\\text{Heart | Red}) = \\frac{13}{26} = \\frac{1}{2}\\) (13 hearts among 26 red cards)\n\\(P(\\text{Ace | Black}) = \\frac{2}{26} = \\frac{1}{13}\\) (2 black aces among 26 black cards)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#two-way-tables",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#two-way-tables",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Two-Way Tables",
    "text": "Two-Way Tables\nTwo-way tables are excellent for conditional probability problems\nExample: Survey of 1000 people about coffee preference\n\n\n\n\nCoffee\nNo Coffee\nTotal\n\n\n\n\nMorning\n350\n150\n500\n\n\nEvening\n200\n300\n500\n\n\nTotal\n550\n450\n1000"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#using-two-way-tables",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#using-two-way-tables",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Using Two-Way Tables",
    "text": "Using Two-Way Tables\nFind: \\(P(\\text{Coffee | Morning person})\\)\nFrom the table:\n\nMorning people: 500\nMorning people who drink coffee: 350\n\n\n\\(P(\\text{Coffee | Morning}) = \\frac{350}{500} = 0.7\\)\nCompare to: \\(P(\\text{Coffee}) = \\frac{550}{1000} = 0.55\\)\nBeing a morning person increases coffee probability!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-2",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-2",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\nUsing the coffee table, find:\n\n\\(P(\\text{Morning | Coffee drinker})\\)\n\\(P(\\text{No Coffee | Evening person})\\)\n\\(P(\\text{Evening | No Coffee})\\)\n\n\nSolutions:\n\n\\(P(\\text{Morning | Coffee}) = \\frac{350}{550} = \\frac{7}{11} \\approx 0.636\\)\n\\(P(\\text{No Coffee | Evening}) = \\frac{300}{500} = 0.6\\)\n\\(P(\\text{Evening | No Coffee}) = \\frac{300}{450} = \\frac{2}{3} \\approx 0.667\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#independence-revisited",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#independence-revisited",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Independence Revisited",
    "text": "Independence Revisited\nEvents A and B are independent if knowing that B occurred doesn‚Äôt change the probability of A\n\\[P(A|B) = P(A)\\]\nEquivalently: \\[P(A \\cap B) = P(A) \\times P(B)\\]\n\nExample: Two coin flips are independent because \\(P(\\text{H}_2 | \\text{H}_1) = P(\\text{H}_2) = 0.5\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#testing-for-independence",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#testing-for-independence",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Testing for Independence",
    "text": "Testing for Independence\nMethod 1: Check if \\(P(A|B) = P(A)\\)\nMethod 2: Check if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nMethod 3: Check if \\(P(B|A) = P(B)\\)\n\nCoffee Example: Are coffee preference and time preference independent?\n\\(P(\\text{Coffee}) = 0.55\\)\n\\(P(\\text{Coffee | Morning}) = 0.7\\)\nSince \\(0.7 \\neq 0.55\\), they are not independent"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#the-multiplication-rule",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#the-multiplication-rule",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "The Multiplication Rule",
    "text": "The Multiplication Rule\nGeneral Multiplication Rule: \\[P(A \\cap B) = P(A) \\times P(B|A) = P(B) \\times P(A|B)\\]\nFor Independent Events: \\[P(A \\cap B) = P(A) \\times P(B)\\]\n\nExtension to Multiple Events: \\[P(A_1 \\cap A_2 \\cap A_3) = P(A_1) \\times P(A_2|A_1) \\times P(A_3|A_1 \\cap A_2)\\]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#multiplication-rule-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#multiplication-rule-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Multiplication Rule Example",
    "text": "Multiplication Rule Example\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement. What‚Äôs the probability both are red?\n\nLet \\(R_1\\) = first ball is red, \\(R_2\\) = second ball is red\n\\(P(R_1 \\cap R_2) = P(R_1) \\times P(R_2|R_1)\\)\n\\(= \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-3",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-3",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\nA box contains 4 defective and 6 working items. Three items are selected without replacement. Find the probability that:\n\nAll three work\nThe first two work and the third is defective\nExactly two work\n\n\nSolutions: a) \\(P(\\text{WWW}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}\\)\n\n\\(P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-3-continued",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-3-continued",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 3 (continued)",
    "text": "Practice Problem 3 (continued)\n\nExactly two work (three scenarios: WWD, WDW, DWW)\n\n\\(P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{1}{6}\\)\n\\(P(\\text{WDW}) = \\frac{6}{10} \\times \\frac{4}{9} \\times \\frac{5}{8} = \\frac{1}{6}\\)\n\\(P(\\text{DWW}) = \\frac{4}{10} \\times \\frac{6}{9} \\times \\frac{5}{8} = \\frac{1}{6}\\)\n\nTotal: \\(\\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagrams",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagrams",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\nTree diagrams help visualize sequential events and conditional probabilities\n                    0.5   Red\n            0.6 ‚îÄ‚îÄ‚îê\n                    0.5   Blue\nBall 1      \n                    0.4   Red  \n            0.4 ‚îÄ‚îÄ‚îê\n                    0.6   Blue\nEach branch shows conditional probabilities"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagram-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagram-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagram Example",
    "text": "Tree Diagram Example\nMedical test scenario: - 2% of population has disease - Test is 95% accurate for sick people\n- Test is 90% accurate for healthy people\nWhat‚Äôs the probability of testing positive?"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagram-solution",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagram-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagram Solution",
    "text": "Tree Diagram Solution\n                    0.95   Test +\n            0.02 ‚îÄ‚îÄ‚îê\n                    0.05   Test -\nDisease?    \n                    0.10   Test +\n            0.98 ‚îÄ‚îÄ‚îê\n                    0.90   Test -\n\n\\(P(\\text{Test+}) = P(\\text{Test+|Disease}) \\times P(\\text{Disease}) + P(\\text{Test+|Healthy}) \\times P(\\text{Healthy})\\)\n\\(= 0.95 \\times 0.02 + 0.10 \\times 0.98 = 0.019 + 0.098 = 0.117\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#law-of-total-probability",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#law-of-total-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space (mutually exclusive and exhaustive), then:\n\\[P(A) = \\sum_{i=1}^{n} P(A|B_i) \\times P(B_i)\\]\n\nPartition means:\n\n\\(B_i \\cap B_j = \\emptyset\\) for \\(i \\neq j\\) (mutually exclusive)\n\\(\\bigcup_{i=1}^{n} B_i = S\\) (exhaustive)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#law-of-total-probability-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\nA factory has three machines: - Machine A: 50% of production, 1% defective - Machine B: 30% of production, 2% defective\n- Machine C: 20% of production, 3% defective\nWhat‚Äôs the overall defect rate?\n\n\\(P(\\text{Defective}) = P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)\\)\n\\(= 0.01 \\times 0.5 + 0.02 \\times 0.3 + 0.03 \\times 0.2\\)\n\\(= 0.005 + 0.006 + 0.006 = 0.017 = 1.7\\%\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-4",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-4",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\nA student studies for an exam with three possible outcomes based on study time: - Studies hard (40%): 90% chance of passing - Studies moderately (35%): 70% chance of passing\n- Doesn‚Äôt study (25%): 30% chance of passing\nWhat‚Äôs the overall probability of passing?\n\n\\(P(\\text{Pass}) = 0.9 \\times 0.4 + 0.7 \\times 0.35 + 0.3 \\times 0.25\\)\n\\(= 0.36 + 0.245 + 0.075 = 0.68\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem",
    "text": "Bayes‚Äô Theorem\nThe Foundation: We often want to ‚Äúreverse‚Äù conditional probabilities\nGiven: \\(P(B|A)\\), \\(P(A)\\), \\(P(B)\\) Want: \\(P(A|B)\\)\nBayes‚Äô Theorem: \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem-components",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem-components",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem Components",
    "text": "Bayes‚Äô Theorem Components\n\\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\n\n\\(P(A|B)\\): Posterior probability (what we want)\n\\(P(B|A)\\): Likelihood (what we observe)\n\n\\(P(A)\\): Prior probability (initial belief)\n\\(P(B)\\): Evidence (marginal probability)\n\n\n‚ÄúIn light of evidence B, how should we update our belief in A?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem-with-total-probability",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem-with-total-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem with Total Probability",
    "text": "Bayes‚Äô Theorem with Total Probability\nWhen we need to find \\(P(B)\\):\n\\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B|A) \\times P(A) + P(B|A^c) \\times P(A^c)}\\]\nThis is the most common form for applications"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#medical-diagnosis-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#medical-diagnosis-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Medical Diagnosis Example",
    "text": "Medical Diagnosis Example\nRevisiting our medical test: - 2% of population has disease (prior) - Test positive (evidence)\n- Test is 95% accurate for sick, 90% accurate for healthy\nGiven a positive test, what‚Äôs the probability of having the disease?"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#medical-diagnosis-solution",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#medical-diagnosis-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Medical Diagnosis Solution",
    "text": "Medical Diagnosis Solution\nLet D = disease, T+ = positive test\n\\[P(D|T+) = \\frac{P(T+|D) \\times P(D)}{P(T+|D) \\times P(D) + P(T+|D^c) \\times P(D^c)}\\]\n\\[= \\frac{0.95 \\times 0.02}{0.95 \\times 0.02 + 0.10 \\times 0.98}\\]\n\\[= \\frac{0.019}{0.019 + 0.098} = \\frac{0.019}{0.117} \\approx 0.162\\]\n\nSurprising: Only 16.2% chance of disease despite positive test!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#why-the-low-probability",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#why-the-low-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Why the Low Probability?",
    "text": "Why the Low Probability?\nBase Rate Fallacy: When disease is rare (2%), most positive tests are false positives\nIntuition: Out of 10,000 people: - 200 have disease ‚Üí 190 test positive\n- 9,800 healthy ‚Üí 980 test positive - Total positive tests: 1,170 - True positives: 190\n\\(P(\\text{Disease | Positive}) = \\frac{190}{1,170} \\approx 0.162\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-5",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-5",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 5",
    "text": "Practice Problem 5\nEmail spam filter: - 60% of emails are spam - Filter catches 95% of spam - Filter incorrectly flags 8% of legitimate emails\nIf an email is flagged as spam, what‚Äôs the probability it‚Äôs actually spam?\n\n\\(P(\\text{Spam | Flagged}) = \\frac{0.95 \\times 0.6}{0.95 \\times 0.6 + 0.08 \\times 0.4}\\)\n\\(= \\frac{0.57}{0.57 + 0.032} = \\frac{0.57}{0.602} \\approx 0.947\\)\nThe filter is quite reliable!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#multiple-events-and-bayes",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#multiple-events-and-bayes",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Multiple Events and Bayes‚Äô",
    "text": "Multiple Events and Bayes‚Äô\nExtended Bayes‚Äô Theorem: If \\(A_1, A_2, \\ldots, A_n\\) partition the sample space:\n\\[P(A_i|B) = \\frac{P(B|A_i) \\times P(A_i)}{\\sum_{j=1}^{n} P(B|A_j) \\times P(A_j)}\\]\nThis allows us to update probabilities for multiple hypotheses"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#three-machine-example-revisited",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#three-machine-example-revisited",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Three Machine Example Revisited",
    "text": "Three Machine Example Revisited\nA defective item is found. Which machine most likely produced it?\nFrom before: - Machine A: 50% production, 1% defective\n- Machine B: 30% production, 2% defective - Machine C: 20% production, 3% defective - Overall defect rate: 1.7%"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#three-machine-solution",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#three-machine-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Three Machine Solution",
    "text": "Three Machine Solution\n\\[P(A|\\text{Defective}) = \\frac{0.01 \\times 0.5}{0.017} = \\frac{0.005}{0.017} \\approx 0.294\\]\n\\[P(B|\\text{Defective}) = \\frac{0.02 \\times 0.3}{0.017} = \\frac{0.006}{0.017} \\approx 0.353\\]\n\\[P(C|\\text{Defective}) = \\frac{0.03 \\times 0.2}{0.017} = \\frac{0.006}{0.017} \\approx 0.353\\]\n\nMachine B or C are most likely sources of the defective item"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-6",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-6",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\nThree boxes contain colored balls: - Box 1: 3 red, 2 blue (chosen 40% of time) - Box 2: 2 red, 3 blue (chosen 35% of time)\n- Box 3: 1 red, 4 blue (chosen 25% of time)\nA red ball is drawn. Which box was it most likely from?\n\n\\(P(\\text{Red}) = \\frac{3}{5} \\times 0.4 + \\frac{2}{5} \\times 0.35 + \\frac{1}{5} \\times 0.25 = 0.24 + 0.14 + 0.05 = 0.43\\)\n\\(P(\\text{Box 1 | Red}) = \\frac{0.6 \\times 0.4}{0.43} \\approx 0.558\\) \\(P(\\text{Box 2 | Red}) = \\frac{0.4 \\times 0.35}{0.43} \\approx 0.326\\)\n\\(P(\\text{Box 3 | Red}) = \\frac{0.2 \\times 0.25}{0.43} \\approx 0.116\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#conditional-independence",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#conditional-independence",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Conditional Independence",
    "text": "Conditional Independence\nEvents A and B are conditionally independent given C if:\n\\[P(A \\cap B | C) = P(A|C) \\times P(B|C)\\]\nImportant: Conditional independence doesn‚Äôt imply independence!\n\nExample: Weather in two cities may be independent normally, but conditionally dependent given a major weather system"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#simpsons-paradox",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#simpsons-paradox",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Simpson‚Äôs Paradox",
    "text": "Simpson‚Äôs Paradox\nSimpson‚Äôs Paradox: A trend in subgroups can reverse when groups are combined\nClassic Example: University admissions by gender\n\n\n\n\nMen\nWomen\n\n\n\n\nDept A\n62% (825/1327)\n82% (108/131)\n\n\nDept B\n63% (560/893)\n68% (25/37)\n\n\nOverall\n44% (1385/2220)\n30% (133/168)\n\n\n\nWomen have higher rates in each department but lower overall!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#common-fallacies",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#common-fallacies",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Common Fallacies",
    "text": "Common Fallacies\n1. Confusion of the Inverse - Confusing \\(P(A|B)\\) with \\(P(B|A)\\) - ‚ÄúIf it rains, the ground is wet‚Äù ‚â† ‚ÄúIf the ground is wet, it rained‚Äù\n2. Base Rate Neglect\n- Ignoring prior probabilities - Medical test example\n3. Prosecutor‚Äôs Fallacy - \\(P(\\text{Evidence | Innocent}) \\neq P(\\text{Innocent | Evidence})\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#prosecutors-fallacy-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#prosecutors-fallacy-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Prosecutor‚Äôs Fallacy Example",
    "text": "Prosecutor‚Äôs Fallacy Example\nDNA evidence matches defendant with probability 1 in a million for random person\nWrong reasoning: ‚ÄúProbability of innocence is 1 in a million‚Äù\nCorrect reasoning: Need to consider: - How many people could have committed the crime? - What‚Äôs the prior probability of guilt? - Possibility of lab error, planted evidence, etc."
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-7",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-7",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\nQuality control: 5% of items are defective. A test detects 96% of defective items but has a 4% false positive rate.\n\nWhat‚Äôs the probability an item testing positive is actually defective?\nWhat‚Äôs the probability an item testing negative is actually good?\n\n\n\n\\(P(\\text{Defective | Positive}) = \\frac{0.96 \\times 0.05}{0.96 \\times 0.05 + 0.04 \\times 0.95} = \\frac{0.048}{0.086} \\approx 0.558\\)\n\\(P(\\text{Good | Negative}) = \\frac{0.96 \\times 0.95}{0.96 \\times 0.95 + 0.04 \\times 0.05} = \\frac{0.912}{0.914} \\approx 0.998\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#real-world-applications",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#real-world-applications",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Screening: - Mammograms, COVID tests - Balancing sensitivity vs specificity\nMachine Learning: - Naive Bayes classifiers - Spam detection, recommendation systems\nFinance: - Credit scoring - Fraud detection\nLegal System: - DNA evidence interpretation - Probability of guilt/innocence"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#technology-and-tools",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#technology-and-tools",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Technology and Tools",
    "text": "Technology and Tools\nCalculators: - Basic probability calculations - Watch for rounding errors\nSoftware: - R: conditional probability tables - Python: pandas for two-way tables - Excel: pivot tables for conditional analysis\nVisualization: - Tree diagrams\n- Contingency tables - Bayes networks"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#diagnostic-thinking",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#diagnostic-thinking",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Diagnostic Thinking",
    "text": "Diagnostic Thinking\nQuestions to ask: 1. What information am I conditioning on? 2. How does this information change the probability? 3. What‚Äôs the base rate or prior probability? 4. Am I confusing \\(P(A|B)\\) with \\(P(B|A)\\)? 5. Are the events independent?"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#problem-solving-strategy",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#problem-solving-strategy",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\nIdentify the type: Direct conditional, Bayes‚Äô, or law of total probability?\nDefine events clearly: Use precise notation\nOrganize information: Two-way tables or tree diagrams\nCheck for independence: Does additional info matter?\nApply appropriate formula: Don‚Äôt forget denominators!\nVerify answer: Does it make intuitive sense?"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-8",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-8",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 8",
    "text": "Practice Problem 8\nA survey shows: - 70% of people like pizza - 60% of people like movies\n- 40% like both pizza and movies\n\nAre liking pizza and movies independent?\nWhat‚Äôs \\(P(\\text{Pizza | Movies})\\)?\nWhat‚Äôs \\(P(\\text{Movies | Pizza})\\)?"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-8-solutions",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-8-solutions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 8 Solutions",
    "text": "Practice Problem 8 Solutions\n\nCheck independence: \\(P(\\text{Pizza}) \\times P(\\text{Movies}) = 0.7 \\times 0.6 = 0.42 \\neq 0.4\\) Not independent!\n\\(P(\\text{Pizza | Movies}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Movies})} = \\frac{0.4}{0.6} = \\frac{2}{3}\\)\n\\(P(\\text{Movies | Pizza}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Pizza})} = \\frac{0.4}{0.7} = \\frac{4}{7}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#advanced-topics-preview",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#advanced-topics-preview",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Advanced Topics Preview",
    "text": "Advanced Topics Preview\nMarkov Chains: - Sequences where future depends only on present - \\(P(X_{n+1} | X_n, X_{n-1}, \\ldots, X_1) = P(X_{n+1} | X_n)\\)\nBayesian Statistics: - Using Bayes‚Äô theorem for statistical inference - Updating beliefs with data\nInformation Theory: - Conditional entropy - Mutual information"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#historical-context",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#historical-context",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Historical Context",
    "text": "Historical Context\nThomas Bayes (1701-1761): - Presbyterian minister and mathematician - Bayes‚Äô theorem published posthumously\nPierre-Simon Laplace (1749-1827): - Developed and popularized Bayesian methods - ‚ÄúProbability is nothing but common sense reduced to calculation‚Äù\nModern Applications: AI, machine learning, medical diagnosis, finance"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#common-student-questions",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#common-student-questions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: ‚ÄúHow do I know when to use Bayes‚Äô theorem?‚Äù A: When you want to ‚Äúreverse‚Äù a conditional probability\nQ: ‚ÄúWhy are medical test problems so counterintuitive?‚Äù\nA: Base rates matter more than we intuitively expect\nQ: ‚ÄúWhat‚Äôs the difference between independence and conditional independence?‚Äù A: Independence means no relationship; conditional independence means no relationship given specific information"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#key-formulas-summary",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#key-formulas-summary",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\nConditional Probability: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nMultiplication Rule: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nLaw of Total Probability: \\(P(A) = \\sum P(A|B_i) \\times P(B_i)\\)\nBayes‚Äô Theorem: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)\nIndependence: \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#looking-ahead",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#looking-ahead",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture: Discrete Random Variables - Random variables as functions - Probability mass functions - Expected value and variance - Common discrete distributions (binomial, geometric, Poisson)\nConnection: Conditional probability is essential for understanding dependence in random variables"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#study-tips",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#study-tips",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Study Tips",
    "text": "Study Tips\n\nPractice with real scenarios: Medical tests, quality control\nDraw diagrams: Tree diagrams and two-way tables\nCheck your intuition: Do answers make sense?\nMaster the basics: Conditional probability formula\nWatch for fallacies: Don‚Äôt confuse \\(P(A|B)\\) and \\(P(B|A)\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#final-thoughts",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#final-thoughts",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nConditional probability is everywhere: - Updates beliefs with new information - Foundation of Bayesian thinking - Critical for proper statistical reasoning - Essential for machine learning and AI\n\nKey insight: Information changes probability - embrace this uncertainty!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#questions",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#questions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: [Your office hours] Email: [Your email]\nNext Class: Discrete Random Variables\nRemember: Homework due [date]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#bonus-monty-hall-problem",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#bonus-monty-hall-problem",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bonus: Monty Hall Problem",
    "text": "Bonus: Monty Hall Problem\nThree doors: one has a car, two have goats 1. You choose a door 2. Host opens a door with a goat 3. Do you switch?\n\nAnswer: Yes! Switch! - \\(P(\\text{Car behind your door}) = \\frac{1}{3}\\) - \\(P(\\text{Car behind other remaining door}) = \\frac{2}{3}\\)\nConditional probability in action!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#bonus-birthday-paradox-connection",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#bonus-birthday-paradox-connection",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bonus: Birthday Paradox Connection",
    "text": "Bonus: Birthday Paradox Connection\nIn a room of 23 people, probability of shared birthday ‚âà 50%\nConditional approach: What‚Äôs \\(P(\\text{no match | first $k$ people have different birthdays})\\)?\nThis helps build intuition for why the probability grows so quickly!\nSurprising results often involve conditional probability!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html",
    "href": "files/lecture_notes/lecture6/lecture6.html",
    "title": "PSTAT 5A: Counting",
    "section": "",
    "text": "The art and science of systematic enumeration"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#welcome-to-lecture-6-part-1",
    "href": "files/lecture_notes/lecture6/lecture6.html#welcome-to-lecture-6-part-1",
    "title": "PSTAT 5A: Counting",
    "section": "",
    "text": "The art and science of systematic enumeration"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#learning-objectives",
    "href": "files/lecture_notes/lecture6/lecture6.html#learning-objectives",
    "title": "PSTAT 5A: Counting",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\n\n\n\n\n\n\nLearning Objectives\n\n\n\nBy the end of this lecture, you will be able to:\n\nApply the fundamental counting principles (Section¬†0.4)\nCalculate permutations with and without repetition (Section¬†0.8, Section¬†0.11, Section¬†0.14)\nCalculate combinations and understand when to use them (Section¬†0.16, Section¬†0.17)\nDistinguish between permutations and combinations (Section¬†0.19)\nUse counting techniques to solve probability problems (Section¬†0.24)\nApply the inclusion-exclusion principle (Section¬†0.28)\nSolve complex counting problems systematically (Section¬†0.32)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#why-study-counting",
    "href": "files/lecture_notes/lecture6/lecture6.html#why-study-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Why Study Counting?",
    "text": "Why Study Counting?\n\n\n\n\n\nCounting helps us:\n\nCalculate probabilities for complex events\n\nSolve optimization problems\n\nUnderstand combinations in genetics, computer science\n\nAnalyze algorithms and data structures\n\nMake decisions involving arrangements and selections\n\n\n\nReal-world applications of counting include:\n\nCryptography: Password strength and encryption key space\nGenetics: DNA sequence analysis and gene combinations\n\nTournament brackets: March Madness and sports competitions\nLottery odds: Probability calculations for games of chance\nPassword security: Character combinations and brute force protection"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-fundamental-counting",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-fundamental-counting",
    "title": "PSTAT 5A: Counting",
    "section": "The Fundamental Counting Principle",
    "text": "The Fundamental Counting Principle\n\n\n\n\n\n\n\n\nMultiplication Rule\n\n\n\nIf a procedure consists of \\(k\\) separate tasks where:\n\nTask 1 can be performed in \\(n_1\\) ways\nTask 2 can be performed in \\(n_2\\) ways\n‚Ä¶\nTask \\(k\\) can be performed in \\(n_k\\) ways\n\nThen, the entire procedure can be performed in \\(n_1 \\times n_2 \\times \\cdots \\times n_k\\) ways\n\n\n\n\n\n\n\n\n\nflowchart LR\n    Start([Start]) --&gt; T1[\"Task¬†1:¬†n‚ÇÅ¬†ways\"]\n    T1 --&gt; C1[Choice¬†1]\n    T1 --&gt; C2[Choice¬†2]\n    T1 --&gt; Cn1[Choice¬†n‚ÇÅ]\n    C1 --&gt; T2[\"Task¬†2:¬†n‚ÇÇ¬†ways\"]\n    C2 --&gt; T2\n    Cn1 --&gt; T2\n    T2 --&gt; C21[Choice¬†1]\n    T2 --&gt; C22[Choice¬†2]\n    T2 --&gt; C2n[Choice¬†n‚ÇÇ]\n    C21 --&gt; Total((\"Total¬†ways:\\n¬†n‚ÇÅ¬†√ó¬†n‚ÇÇ¬†√ó¬†...¬†√ó¬†n‚Çñ\"))\n    C22 --&gt; Total\n    C2n --&gt; Total"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#simple-counting-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#simple-counting-example",
    "title": "PSTAT 5A: Counting",
    "section": "Simple Counting Example",
    "text": "Simple Counting Example\n\nFormat ABC-123\n\nFirst position: 26 letters\nSecond position: 26 letters\nThird position: 26 letters\nFourth position: 10 digits\nFifth position: 10 digits\nSixth position: 10 digits\n\n\n\n\nSolution. Total possibilities: \\(26 \\times 26 \\times 26 \\times 10 \\times 10 \\times 10 = 26^3 \\times 10^3 = 17,576,000\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#restaurant-menu-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#restaurant-menu-example",
    "title": "PSTAT 5A: Counting",
    "section": "Restaurant Menu Example",
    "text": "Restaurant Menu Example\n\nA restaurant offers:\nüç§ Appetizers: 4\nüç≤ Main Courses: 6\nüç∞ Desserts: 3\nHow many different three-course meals are possible?\n\n\nSolution. \\(4 \\times 6 \\times 3 = 72\\) different meals"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-1",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-1",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\nA password must contain:\n\nExactly 8 characters\nEach character is either a letter (26 possibilities) or digit (10 possibilities)\n\nHow many possible passwords are there?\n\n\n\n\n\n\n\nSolution. Each position has \\(26 + 10 = 36\\) choices.\nTotal: \\(36^8 = 2,821,109,907,456\\) passwords"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-permutations",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-permutations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Permutations?",
    "text": "What Are Permutations?\n\n\n\n\n\n\nPermutation\n\n\n\nAn arrangement of objects where order matters\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nAll permutations of ABC:\n1. ABC\n2. ACB\n3. BAC\n4. BCA\n5. CAB\n6. CBA\n\n\n\n\n\nRace finish positions (1st, 2nd, 3rd)\nSeating arrangements\nPasswords\nDNA sequences"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#permutations-of-n-distinct-objects",
    "href": "files/lecture_notes/lecture6/lecture6.html#permutations-of-n-distinct-objects",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(n\\) Distinct Objects",
    "text": "Permutations of \\(n\\) Distinct Objects\n\n\n\n\n\n\n\n\nKey Formula\n\n\n\nThe number of ways to arrange \\(n\\) distinct objects is:\n\\[n! = n \\times (n-1) \\times (n-2) \\times \\cdots \\times 2 \\times 1\\]\n\n\n\n\n\n\n\n\n\nSeating Process:\n1st position: 5 choices (Alice, Bob, Carol, David, Eve)\n2nd position: 4 choices (whoever is left)\n3rd position: 3 choices (whoever is left)\n4th position: 2 choices (whoever is left)\n5th position: 1 choice (last person)\nHow many ways can 5 people sit in a row?\n\n\nSolution. \\(5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#factorial-values",
    "href": "files/lecture_notes/lecture6/lecture6.html#factorial-values",
    "title": "PSTAT 5A: Counting",
    "section": "Factorial Values",
    "text": "Factorial Values\n\n\n\n\n\n\\(n\\)\n\\(n!\\)\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n2\n2\n\n\n3\n6\n\n\n4\n24\n\n\n5\n120\n\n\n10\n3,628,800\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nNote\n\n\n\n\\(0! = 1\\) by definition"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-permutations-r-from-n",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-permutations-r-from-n",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(r\\) Objects from \\(n\\)",
    "text": "Permutations of \\(r\\) Objects from \\(n\\)\n\n\n\n\n\n\nKey Formula\n\n\n\n\\(P(n,r)\\) or \\(_nP_r\\): Number of ways to arrange \\(r\\) objects selected from \\(n\\) distinct objects\n\\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\n\n\nHow many ways can we select and arrange 3 people from a group of 8 for president, vice-president, and secretary?\n\n\nSolution. \\(P(8,3) = \\frac{8!}{(8-3)!} = \\frac{8!}{5!} = 8 \\times 7 \\times 6 = 336\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#understanding-pnr",
    "href": "files/lecture_notes/lecture6/lecture6.html#understanding-pnr",
    "title": "PSTAT 5A: Counting",
    "section": "Understanding \\(P(n,r)\\)",
    "text": "Understanding \\(P(n,r)\\)\nWhy is \\(P(n,r) = \\frac{n!}{(n-r)!}\\)?\n\nFirst position: \\(n\\) choices\nSecond position: \\((n-1)\\) choices\n\nThird position: \\((n-2)\\) choices\n‚Ä¶\n\\(r\\)-th position: \\((n-r+1)\\) choices\n\n\nTotal: \\(n \\times (n-1) \\times (n-2) \\times \\cdots \\times (n-r+1) = \\frac{n!}{(n-r)!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-2",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-2",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\nA baseball team has 15 players. How many ways can the coach:\n\nArrange all 15 players in a line?\nChoose and arrange 9 players for the starting lineup (batting order matters)?\n\n\n\nSolution. \n\n\\(15! = 1,307,674,368,000\\)\n\\(P(15,9) = \\frac{15!}{6!} = 1,816,214,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-permutations-repetition",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-permutations-repetition",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition",
    "text": "Permutations with Repetition\n\n\n\n\n\n\nPermutations with Repetition\n\n\n\nWhen some objects are identical, we have fewer distinct arrangements\nIf we have \\(n\\) objects where:\n\n\\(n_1\\) are of type 1\n\\(n_2\\) are of type 2\n‚Ä¶\n\\(n_k\\) are of type \\(k\\)\n\nNumber of distinct arrangements: \\(\\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#permutations-with-repetition-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#permutations-with-repetition-example",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition Example",
    "text": "Permutations with Repetition Example\n\n\n\nHow many distinct arrangements are there of the letters in ‚ÄúSTATISTICS‚Äù?\n\nS-T-A-T-I-S-T-I-C-S\n\nTotal letters: 10\nS appears 3 times\nT appears 3 times\nA appears 1 time\nI appears 2 times\nC appears 1 time\n\n\n\nSolution. \\(\\frac{10!}{3! \\times 3! \\times 1! \\times 2! \\times 1!} = \\frac{3,628,800}{6 \\times 6 \\times 1 \\times 2 \\times 1} = \\frac{3,628,800}{72} = 50,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-combinations",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Combinations?",
    "text": "What Are Combinations?\n\n\n\n\n\n\n\n\nCombination\n\n\n\nA selection of objects where order does NOT matter\n\n\n\nCommittee Selection:\nABC, BAC, CAB ‚Üí Same committee!\n\nRace Results:\nABC, BAC, CAB ‚Üí Different outcomes!\n\nKey Point: Order doesn't matter for combinations\n\n\n\nChoosing committee members\nSelecting pizza toppings\nForming study groups\nLottery number selection\n\n\n\n\n\n\n                            \n                                            \n\n\nAll combinations of 4 items taken 2 at a time:\n1. A, B\n2. A, C\n3. A, D\n4. B, C\n5. B, D\n6. C, D"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-combinations-formula",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-combinations-formula",
    "title": "PSTAT 5A: Counting",
    "section": "Combinations Formula",
    "text": "Combinations Formula\n\n\n\n\n\n\nKey Formula\n\n\n\n\\(C(n,r)\\) or \\(\\binom{n}{r}\\): Number of ways to choose \\(r\\) objects from \\(n\\) distinct objects (order doesn‚Äôt matter)\n\\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]\n\n\n\nHow many ways can we choose 3 people from a group of 8 for a committee?\n\\(C(8,3) = \\frac{8!}{3!(8-3)!} = \\frac{8!}{3! \\times 5!} = \\frac{8 \\times 7 \\times 6}{3 \\times 2 \\times 1} = 56\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#relationship-permutations-vs-combinations",
    "href": "files/lecture_notes/lecture6/lecture6.html#relationship-permutations-vs-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "Relationship: Permutations vs Combinations",
    "text": "Relationship: Permutations vs Combinations\n\n\n\n\n\n\nRelationship\n\n\n\n\\(P(n,r) = C(n,r) \\times r!\\)\nWhy? For each combination of \\(r\\) objects, there are \\(r!\\) ways to arrange them\n\n\n\nRelationship: P(n,r) = C(n,r) √ó r!\n\nExample: Choose 3 from 8 people\n- C(8,3) = 56 combinations\n- For each combination, arrange 3 people: 3! = 6 ways\n- Total: 56 √ó 6 = 336 = P(8,3)\n\nCombination ABC ‚Üí Permutations: ABC, ACB, BAC, BCA, CAB, CBA\n\n\n\\(P(8,3) = C(8,3) \\times 3! = 56 \\times 6 = 336\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-permutation-vs-combination",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-permutation-vs-combination",
    "title": "PSTAT 5A: Counting",
    "section": "Key Decision: Permutation or Combination?",
    "text": "Key Decision: Permutation or Combination?\n\n\n\n\n\n\n\n\nHow to Decide\n\n\n\nAsk yourself: Does order matter?\nOrder matters ‚Üí Use Permutations - Arrangements, sequences, rankings\nOrder doesn‚Äôt matter ‚Üí Use Combinations\n- Selections, groups, subsets\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nTip\n\n\n\n‚úÖ \\(P(n,r)\\) = counts both selection & arrangement ‚Üí grows faster\n‚úÖ \\(C(n,r)\\) = counts only selection ‚Üí grows slower\n‚úÖ The difference comes from \\(r!\\), which is big even for modest \\(r\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-3",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-3",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nFrom a class of 20 students:\n\nHow many ways to choose 5 students for a study group?\nHow many ways to choose a president, vice-president, and secretary?\n\n\n\nSolution. \n\n\\(C(20,5) = \\frac{20!}{5! \\times 15!} = 15,504\\) (order doesn‚Äôt matter)\n\\(P(20,3) = \\frac{20!}{17!} = 6,840\\) (order matters)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#properties-of-combinations",
    "href": "files/lecture_notes/lecture6/lecture6.html#properties-of-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "Properties of Combinations",
    "text": "Properties of Combinations\n\n\n\n\n\n\nProperties\n\n\n\n\nSymmetry: \\(\\binom{n}{r} = \\binom{n}{n-r}\\)\nPascal‚Äôs Identity: \\(\\binom{n}{r} = \\binom{n-1}{r-1} + \\binom{n-1}{r}\\)\nBoundary conditions: \\(\\binom{n}{0} = \\binom{n}{n} = 1\\)\n\n\n\n\n\\(\\binom{8}{3} = \\binom{8}{5} = 56\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#pascals-triangle",
    "href": "files/lecture_notes/lecture6/lecture6.html#pascals-triangle",
    "title": "PSTAT 5A: Counting",
    "section": "Pascal‚Äôs Triangle",
    "text": "Pascal‚Äôs Triangle\n\n\n\n           1\n         1   1\n       1   2   1\n     1   3   3   1\n   1   4   6   4   1\n 1   5  10  10   5   1\n1   6  15  20  15   6   1\nPattern: Each number is the sum of the two numbers above it.\nFormula: \\(\\binom{n}{r} = \\binom{n-1}{r-1} + \\binom{n-1}{r}\\)\nEach number is \\(\\binom{n}{r}\\) where \\(n\\) is the row and \\(r\\) is the position\nExample: \\(\\binom{4}{2} = 6\\) (row 4, position 2)\nRow 3:       1   3   3   1\n            ‚Üô ‚Üò ‚Üô ‚Üò ‚Üô ‚Üò ‚Üô ‚Üò\nRow 4:     1   4   6   4   1\n\n\n\n\n\n\n                            \n                                            \n\n\nPascal's Triangle (showing C(n,r) values):\nRow 0: [1]\nRow 1: [1, 1]\nRow 2: [1, 2, 1]\nRow 3: [1, 3, 3, 1]\nRow 4: [1, 4, 6, 4, 1]\nRow 5: [1, 5, 10, 10, 5, 1]\nRow 6: [1, 6, 15, 20, 15, 6, 1]\nRow 7: [1, 7, 21, 35, 35, 21, 7, 1]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#binomial-theorem",
    "href": "files/lecture_notes/lecture6/lecture6.html#binomial-theorem",
    "title": "PSTAT 5A: Counting",
    "section": "Binomial Theorem",
    "text": "Binomial Theorem\n\n\n\n\n\n\nKey Formula\n\n\n\n\\[(x + y)^n = \\sum_{r=0}^{n} \\binom{n}{r} x^{n-r} y^r\\]\n\n\n\n\\((x + y)^3 = \\binom{3}{0}x^3 + \\binom{3}{1}x^2y + \\binom{3}{2}xy^2 + \\binom{3}{3}y^3\\)\n\\(= x^3 + 3x^2y + 3xy^2 + y^3\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-counting-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-counting-probability",
    "title": "PSTAT 5A: Counting",
    "section": "Counting and Probability",
    "text": "Counting and Probability\n\n\n\nA committee of 4 people is chosen from 7 women and 5 men. What‚Äôs the probability that exactly 2 are women?\n\nTotal ways to choose 4 from 12: \\(\\binom{12}{4} = 495\\)\nWays to choose 2 women from 7: \\(\\binom{7}{2} = 21\\)\nWays to choose 2 men from 5: \\(\\binom{5}{2} = 10\\)\n\nSolution. Favorable outcomes: \\(\\binom{7}{2} \\times \\binom{5}{2} = 21 \\times 10 = 210\\)\nProbability: \\(\\frac{210}{495} = \\frac{14}{33}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-4",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-4",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\n\nA standard deck has 52 cards. What‚Äôs the probability that a 5-card hand contains:\n\nExactly 3 aces?\nAt least 1 ace?\n\n\n\nSolution. \n\nWays to get 3 aces from 4: \\(\\binom{4}{3} = 4\\) Ways to get 2 non-aces from 48: \\(\\binom{48}{2} = 1,128\\) Total 5-card hands: \\(\\binom{52}{5} = 2,598,960\\)\nProbability: \\(\\frac{4 \\times 1,128}{2,598,960} = \\frac{4,512}{2,598,960} \\approx 0.00174\\)\nWays to choose 5 cards with no aces: \\(\\binom{48}{5} = 1,712,304\\)\n\\(P(\\text{at least 1 ace}) = 1 - \\frac{\\binom{48}{5}}{\\binom{52}{5}} = 1 - \\frac{1,712,304}{2,598,960} \\approx 0.341\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-4-continued",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-4-continued",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 4 (continued)",
    "text": "Practice Problem 4 (continued)\n\n\nAt least 1 ace = 1 - (no aces)\n\n\n\n\n\n\n\n\nTip\n\n\n\nWays to choose 5 cards with no aces: \\(\\binom{48}{5} = 1,712,304\\)\n\n\n\nSolution. \\(P(\\text{at least 1 ace}) = 1 - \\frac{\\binom{48}{5}}{\\binom{52}{5}} = 1 - \\frac{1,712,304}{2,598,960} \\approx 0.341\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#permutations-with-restrictions",
    "href": "files/lecture_notes/lecture6/lecture6.html#permutations-with-restrictions",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Restrictions",
    "text": "Permutations with Restrictions\n\nHow many 6-letter ‚Äúwords‚Äù can be formed from the letters A, B, C, D, E, F if:\n\nNo letter is repeated\nA and B must be adjacent\n\n\n\nSolution. Treat AB as a single unit\n\n5 units to arrange: (AB), C, D, E, F ‚Üí \\(5! = 120\\) ways\nA and B can be arranged within their unit: \\(2! = 2\\) ways\nTotal: \\(5! \\times 2! = 240\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-inclusion-exclusion",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-inclusion-exclusion",
    "title": "PSTAT 5A: Counting",
    "section": "The Inclusion-Exclusion Principle",
    "text": "The Inclusion-Exclusion Principle\n\n\n\nFor two sets \\(A\\) and \\(B\\): \\[|A \\cup B| = |A| + |B| - |A \\cap B|\\]\nFor three sets \\(A\\), \\(B\\), and \\(C\\): \\[|A \\cup B \\cup C| = |A| + |B| + |C| - |A \\cap B| \\\\\n- |A \\cap C| - |B \\cap C| + |A \\cap B \\cap C|\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#inclusion-exclusion-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#inclusion-exclusion-example",
    "title": "PSTAT 5A: Counting",
    "section": "Inclusion-Exclusion Example",
    "text": "Inclusion-Exclusion Example\n\nHow many integers from 1 to 100 are divisible by 2, 3, or 5?\n\nLet:\n\n\\(A\\) = divisible by 2: \\(|A| = 50\\)\n\\(B\\) = divisible by 3: \\(|B| = 33\\)\n\\(C\\) = divisible by 5: \\(|C| = 20\\)\n\n\n\n\n\n\n\nNote\n\n\n\n\\(|A \\cap B| = 16\\) (divisible by 6)\n\\(|A \\cap C| = 10\\) (divisible by 10)\n\\(|B \\cap C| = 6\\) (divisible by 15)\n\\(|A \\cap B \\cap C| = 3\\) (divisible by 30)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#inclusion-exclusion-solution",
    "href": "files/lecture_notes/lecture6/lecture6.html#inclusion-exclusion-solution",
    "title": "PSTAT 5A: Counting",
    "section": "Inclusion-Exclusion Solution",
    "text": "Inclusion-Exclusion Solution\n\nSolution. \\[|A \\cup B \\cup C| = 50 + 33 + 20 - 16 - 10 - 6 + 3 = 74\\]\nAnswer: 74 integers from 1 to 100 are divisible by at least one of 2, 3, or 5"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#multinomial-coefficients",
    "href": "files/lecture_notes/lecture6/lecture6.html#multinomial-coefficients",
    "title": "PSTAT 5A: Counting",
    "section": "Multinomial Coefficients",
    "text": "Multinomial Coefficients\n\n\n\n\n\n\nMultinomial Coefficient\n\n\n\nNumber of ways to divide \\(n\\) objects into groups of sizes \\(n_1, n_2, \\ldots, n_k\\):\n\\[\\binom{n}{n_1, n_2, \\ldots, n_k} = \\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\]\n\n\n\nHow many ways can 12 people be divided into 3 teams of 4?\n\\(\\binom{12}{4,4,4} = \\frac{12!}{4! \\times 4! \\times 4!} = 34,650\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-problem-solving-strategy",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-problem-solving-strategy",
    "title": "PSTAT 5A: Counting",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\n\n\n\n\nStrategy\n\n\n\n\nRead carefully: What exactly are we counting?\nIdentify the type: Permutation, combination, or other?\nCheck for restrictions: Are there constraints?\nDoes order matter?: This determines permutation vs combination\nBreak down complex problems: Use multiplication principle\nVerify your answer: Does it make sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/lecture6/lecture6.html#common-mistakes-to-avoid",
    "title": "PSTAT 5A: Counting",
    "section": "Common Mistakes to Avoid",
    "text": "Common Mistakes to Avoid\n\n\n\n\n\n\nCommon Mistakes\n\n\n\n\nConfusing permutations and combinations\n\nAlways ask: ‚ÄúDoes order matter?‚Äù\n\nForgetting about restrictions\n\nRead the problem carefully\n\nDouble counting\n\nMake sure you‚Äôre not counting the same arrangement twice\n\nNot considering the complement\n\nSometimes ‚Äúat least‚Äù problems are easier using complements"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-6",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-6",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\n\nA class has 15 students: 8 women and 7 men. How many ways can we:\n\nForm a committee of 5 people with exactly 3 women?\nArrange 6 people in a row with alternating genders (starting with a woman)?\n\n\n\nSolution. \n\n\\(\\binom{8}{3} \\times \\binom{7}{2} = 56 \\times 21 = 1,176\\)\nChoose 3 women from 8: \\(P(8,3) = 336\\) Choose 3 men from 7: \\(P(7,3) = 210\\) Total: \\(336 \\times 210 = 70,560\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#counting-in-computer-science",
    "href": "files/lecture_notes/lecture6/lecture6.html#counting-in-computer-science",
    "title": "PSTAT 5A: Counting",
    "section": "Counting in Computer Science",
    "text": "Counting in Computer Science\n\nPassword Security:\n\n8-character password with letters, digits, symbols\n\\((26 + 26 + 10 + 32)^8 = 94^8 \\approx 6.1 \\times 10^{15}\\)\n\nHash Functions:\n\nDistributing data into buckets\nCollision probability calculations\n\nAlgorithm Analysis:\n\nCounting operations, comparisons\nBig O notation foundations"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#counting-in-genetics",
    "href": "files/lecture_notes/lecture6/lecture6.html#counting-in-genetics",
    "title": "PSTAT 5A: Counting",
    "section": "Counting in Genetics",
    "text": "Counting in Genetics\n\nDNA Sequences:\n\n4 bases (A, T, G, C)\nGene of length \\(n\\): \\(4^n\\) possible sequences\n\nProtein Folding:\n\nNumber of possible conformations\nCombinatorial explosion\n\nPopulation Genetics:\n\nHardy-Weinberg calculations\nAllele combinations"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#real-world-applications",
    "href": "files/lecture_notes/lecture6/lecture6.html#real-world-applications",
    "title": "PSTAT 5A: Counting",
    "section": "Real-World Applications",
    "text": "Real-World Applications\n\nLottery:\n\nPowerball: Choose 5 from 69, then 1 from 26\nOdds: \\(\\frac{1}{\\binom{69}{5} \\times 26} \\approx \\frac{1}{292,000,000}\\)\n\nCryptography:\n\nKey space size determines security\nRSA encryption relies on large number factorization\n\nSports Tournaments:\n\nMarch Madness bracket: \\(2^{63}\\) possible outcomes\nRound-robin tournaments: \\(\\binom{n}{2}\\) games"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture6/lecture6.html#key-formulas-summary",
    "title": "PSTAT 5A: Counting",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\n\n\n\n\n\n\nSummary of Key Formulas\n\n\n\n\nPermutations: \\(P(n,r) = \\frac{n!}{(n-r)!}\\)\nCombinations: \\(C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\)\nWith repetition: \\(\\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\)\nInclusion-Exclusion: \\(|A \\cup B| = |A| + |B| - |A \\cap B|\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#technology-and-counting",
    "href": "files/lecture_notes/lecture6/lecture6.html#technology-and-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Technology and Counting",
    "text": "Technology and Counting\n\n\n\n\n\n\nTools\n\n\n\nCalculators:\n\nUse nPr and nCr functions\nBe careful with large numbers\n\nSoftware:\n\nR: factorial(), choose(), combn()\nPython: math.factorial(), math.comb()\nExcel: FACT(), COMBIN(), PERMUT()\n\nOnline Tools:\n\nWolfram Alpha for complex calculations\nCombination/permutation calculators"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-7",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-7",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\n\nA standard deck of cards is shuffled. What‚Äôs the probability that:\n\nThe top 4 cards are all hearts?\nIn a 13-card hand, you get exactly one card from each rank?\n\n\n\nSolution. \n\n\\(\\frac{13}{52} \\times \\frac{12}{51} \\times \\frac{11}{50} \\times \\frac{10}{49} = \\frac{13 \\times 12 \\times 11 \\times 10}{52 \\times 51 \\times 50 \\times 49} \\approx 0.0026\\)\nChoose 1 card from each of 13 ranks: \\(4^{13}\\) Total 13-card hands: \\(\\binom{52}{13}\\) Probability: \\(\\frac{4^{13}}{\\binom{52}{13}} \\approx 6.3 \\times 10^{-6}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#extending-to-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#extending-to-probability",
    "title": "PSTAT 5A: Counting",
    "section": "Extending to Probability",
    "text": "Extending to Probability\n\n\n\n\n\n\nDistributions\n\n\n\nHypergeometric Distribution:\n\nDrawing without replacement\nUses combinations: \\(P(X = k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}\\)\n\nBinomial Distribution:\n\nDrawing with replacement\nUses combinations: \\(P(X = k) = \\binom{n}{k}p^k(1-p)^{n-k}\\)\n\nWe‚Äôll explore these distributions in detail in future lectures"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#historical-note",
    "href": "files/lecture_notes/lecture6/lecture6.html#historical-note",
    "title": "PSTAT 5A: Counting",
    "section": "Historical Note",
    "text": "Historical Note\n\n\n\n\n\n\nHistory\n\n\n\nBlaise Pascal (1623-1662) and Pierre de Fermat (1601-1665): - Founded probability theory through gambling problems - Pascal‚Äôs triangle and combinations\nLeonhard Euler (1707-1783): - Advanced combinatorics - Graph theory connections\nModern applications span computer science, biology, physics, and economics"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#common-student-questions",
    "href": "files/lecture_notes/lecture6/lecture6.html#common-student-questions",
    "title": "PSTAT 5A: Counting",
    "section": "Common Student Questions",
    "text": "Common Student Questions\n\nQ: ‚ÄúWhen do I use permutations vs combinations?‚Äù\nA: Ask ‚ÄúDoes order matter?‚Äù Order matters ‚Üí permutation\nQ: ‚ÄúHow do I handle restrictions?‚Äù\nA: Break the problem into cases or use complementary counting\nQ: ‚ÄúWhat if objects are identical?‚Äù\nA: Use the formula for permutations with repetition\nQ: ‚ÄúHow do I check my answer?‚Äù\nA: Verify with small examples or use different methods"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#looking-ahead",
    "href": "files/lecture_notes/lecture6/lecture6.html#looking-ahead",
    "title": "PSTAT 5A: Counting",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\n\n\n\nNext Lecture\n\n\n\nNext lecture: Discrete Probability Distributions - Binomial distribution (using combinations!)\n\nHypergeometric distribution\nGeometric distribution\nExpected value and variance\n\nConnection: Today‚Äôs counting techniques are essential for probability calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#study-tips",
    "href": "files/lecture_notes/lecture6/lecture6.html#study-tips",
    "title": "PSTAT 5A: Counting",
    "section": "Study Tips",
    "text": "Study Tips\n\n\n\n\n\n\nTips\n\n\n\n\nPractice, practice, practice: Work through many examples\nIdentify patterns: Learn to recognize problem types\nStart simple: Build up to complex problems\nCheck your work: Use different approaches when possible\nUnderstand concepts: Don‚Äôt just memorize formulas"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#learning-summary",
    "href": "files/lecture_notes/lecture6/lecture6.html#learning-summary",
    "title": "PSTAT 5A: Counting",
    "section": "Learning Objectives Summary",
    "text": "Learning Objectives Summary\n\n\n\n\n\n\nWhat We‚Äôve Covered\n\n\n\nIn this lecture, we‚Äôve addressed all the learning objectives:\n\n‚úÖ Apply the fundamental counting principles: Covered in Section¬†0.4\n‚úÖ Calculate permutations with and without repetition: Covered in Section¬†0.8, Section¬†0.11, and Section¬†0.14\n\n‚úÖ Calculate combinations and understand when to use them: Covered in Section¬†0.16 and Section¬†0.17\n‚úÖ Distinguish between permutations and combinations: Covered in Section¬†0.19\n‚úÖ Use counting techniques to solve probability problems: Covered in Section¬†0.24\n‚úÖ Apply the inclusion-exclusion principle: Covered in Section¬†0.28\n‚úÖ Solve complex counting problems systematically: Covered in Section¬†0.32"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#final-thoughts",
    "href": "files/lecture_notes/lecture6/lecture6.html#final-thoughts",
    "title": "PSTAT 5A: Counting",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nCounting is fundamental to:\n\nProbability calculations\nStatistical inference\nComputer algorithms\nScientific modeling\n\n\n\n\n\n\n\nKnow the Basics\n\n\n\nPermutations and combinations are the building blocks for advanced statistical concepts"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#questions",
    "href": "files/lecture_notes/lecture6/lecture6.html#questions",
    "title": "PSTAT 5A: Counting",
    "section": "Questions?",
    "text": "Questions?"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "href": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Today‚Äôs Agenda",
    "text": "Today‚Äôs Agenda\n\nIntroduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\nWhy it matters before any modeling\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset they‚Äôve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "href": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Learning Objectives (LOs)",
    "text": "Learning Objectives (LOs)\nBy the end of this lecture you should be able to:\n\nDefine descriptive statistics and explain its importance in data analysis (Section¬†1)\nDistinguish between different types of data and measurement scales (Section¬†2)\nCalculate and interpret measures of central tendency (mean, median, mode)(Section¬†3)\nUnderstand when to use each measure of central tendency\nApply Python to compute descriptive statistics(Section¬†9)\nInterpret basic descriptive statistics in real-world contexts(Section¬†10)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Statistics",
    "text": "Statistics\nFacts are stubborn, but statistics are more pliable.\nMark Twain\n\nStatistics refers to the mathematics and techniques with which we understand data. 1\n\n\n(source)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What are Descriptive Statistics?",
    "text": "What are Descriptive Statistics?\nDescriptive statistics are numerical and graphical methods used to summarize, organize, and describe data in a meaningful way.\n\nPurpose of Descriptive Statistics\n\nSummarize large datasets into manageable information\nIdentify patterns and trends in data\nCommunicate findings clearly to others\nPrepare data for further analysis\nMake initial assessments about data quality"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs.¬†Inferential Statistics",
    "text": "Descriptive vs.¬†Inferential Statistics\n\n\n\n\n\n\n\nDescriptive Statistics\nInferential Statistics\n\n\n\n\nDescribes what the data shows\nMakes predictions about populations\n\n\nSummarizes sample data\nUses sample data to make generalizations\n\n\nNo conclusions beyond the data\nDraws conclusions beyond the immediate data\n\n\nExamples: mean, median, graphs\nExamples: hypothesis testing, confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs.¬†Inferential Statistics",
    "text": "Descriptive vs.¬†Inferential Statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "href": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Why Data Types Matter",
    "text": "Why Data Types Matter\nUnderstanding data types is crucial because:\n\nDifferent statistics are appropriate for different data types\nStatistical methods depend on the level of measurement\nMisapplying statistics can lead to incorrect conclusions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Data",
    "text": "Types of Data\ngraph TD\n    A[Variable Types]\n    A --&gt; B[Categorical]\n    A --&gt; C[Numerical]\n    B --&gt; B1[\"Nominal&lt;br/&gt;e.g., gender, major\"]\n    B --&gt; B2[\"Ordinal&lt;br/&gt;e.g., rating, education level\"]\n    C --&gt; C1[\"Discrete&lt;br/&gt;e.g., count (# of students)\"]\n    C --&gt; C2[\"Continuous&lt;br/&gt;e.g., measurements like height, weight\"]\n    \n    classDef root fill:#e1f5fe,stroke:#01579b,stroke-width:3px\n    classDef categorical fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef numerical fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px\n    classDef nominal fill:#fce4ec,stroke:#880e4f,stroke-width:2px\n    classDef ordinal fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef discrete fill:#e0f2f1,stroke:#00695c,stroke-width:2px\n    classDef continuous fill:#f1f8e9,stroke:#33691e,stroke-width:2px\n    \n    class A root\n    class B categorical\n    class C numerical\n    class B1 nominal\n    class B2 ordinal\n    class C1 discrete\n    class C2 continuous\n\nPrompt: Which summary stat would you pick for ‚Äúmajor‚Äù? For ‚Äúgpa‚Äù?"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Categorical Data (Qualitative)",
    "text": "Categorical Data (Qualitative)\n\n\nNominal Data\n\nCategories with no natural order\nExamples: gender, color, brand names, marital status\nAppropriate statistics: mode, frequency counts, proportions\n\n\nOrdinal Data\n\nCategories with a natural order or ranking\nExamples: education level, satisfaction ratings, letter grades\nAppropriate statistics: mode, median, percentiles"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Numerical Data (Quantitative)",
    "text": "Numerical Data (Quantitative)\n\nDiscrete Data\n\nCountable values, often integers\nExamples: number of children, cars sold, defective items\nCan take on finite or countably infinite values\n\n\n\nContinuous Data\n\nCan take any value within a range\nExamples: height, weight, temperature, time\nMeasured rather than counted"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "href": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Measurement Scales Summary",
    "text": "Measurement Scales Summary\n\n\n\n\n\n\n\n\n\n\nScale\nType\nProperties\nExamples\nAppropriate Statistics\n\n\n\n\nNominal\nCategorical\nCategories only\nGender, Color\nMode, Frequency\n\n\nOrdinal\nCategorical\nOrder matters\nRankings, Grades\nMode, Median\n\n\nInterval\nNumerical\nEqual intervals, no true zero\nTemperature (¬∞C)\nMean, Median, Mode\n\n\nRatio\nNumerical\nEqual intervals, true zero\nHeight, Weight, Income\nAll statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What is Central Tendency?",
    "text": "What is Central Tendency?\nCentral tendency describes the center or typical value of a dataset.\nIt answers the question: ‚ÄúWhat is a representative value for this data?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition and Formula",
    "text": "Definition and Formula\n\nüéØ Definition: The mean is the sum of all values divided by the number of values.\n\n\nFormula\n\nFor a sample: \\(\\bar{x} = \\frac{\\sum x}{n}\\)\nFor a population: \\(\\mu = \\frac{\\sum x}{N}\\)\n\nWhere:\n\n\\(\\bar{x}\\) (x-bar) = sample mean\n\\(\\mu\\) (mu) = population mean\n\\(\\sum x\\) = sum of all values\n\\(n\\) = sample size, \\(N\\) = population size"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example Calculation",
    "text": "Example Calculation\nStudent test scores: 85, 90, 78, 92, 88\n\nMean = \\(\\frac{85 + 90 + 78 + 92 + 88}{5} = \\frac{433}{5} = 86.6\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mean",
    "text": "Properties of the Mean\n\nUses all data points - every value affects the mean\nSensitive to outliers - extreme values can distort the mean\nUnique - there is only one mean for a dataset\nCan be calculated for interval and ratio data\nBalancing point - sum of deviations from mean equals zero"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mean",
    "text": "When to Use the Mean\n‚úÖ Use the mean when:\n\nData is approximately symmetric\nNo extreme outliers present\nWorking with interval or ratio data\nNeed to use the value in further calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "href": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Advantages and Disadvantages",
    "text": "Advantages and Disadvantages\n\n\nAdvantages\n\nUses all information in the dataset\nAlgebraically defined and mathematically tractable\nWidely understood and accepted\n\n\nDisadvantages\n\nAffected by outliers and skewed distributions\nMay not represent a typical value in skewed data\nCannot be used with nominal or ordinal data"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\n\nüéØ Definition: The median is the middle value when data is arranged in ascending or descending order."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "href": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Calculation Steps",
    "text": "Calculation Steps\n\nArrange data in ascending order\nFind the middle position:\n\nIf n is odd: position = \\(\\frac{n + 1}{2}\\)\nIf n is even: average of positions \\(\\frac{n}{2}\\) and \\(\\frac{n}{2} + 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#examples",
    "href": "files/lecture_notes/lecture2/lecture2.html#examples",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Examples",
    "text": "Examples\n\nOdd number of values:\n\nData: 12, 15, 18, 20, 25\nWhat is the median here ?\nMedian = 18 (middle value)\n\n\n\nEven number of values:\n\nData: 10, 15, 20, 25, 30, 35\nWhat is the median here ?\nMedian = \\(\\frac{20 + 25}{2} = 22.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Median",
    "text": "Properties of the Median\n\nNot affected by outliers - resistant measure\nRepresents the 50th percentile\nMay not be an actual data value (when n is even)\nAppropriate for ordinal, interval, and ratio data\nDivides data into two equal halves"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Median",
    "text": "When to Use the Median\n‚úÖ Use the median when:\n\nData is skewed (not symmetric)\nOutliers are present\nWorking with ordinal data\nWant a robust measure of central tendency\nData represents income, housing prices, or similar distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "href": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Median vs Mean with Outliers",
    "text": "Median vs Mean with Outliers\nConsider household incomes: $30,000, $32,000, $35,000, $38,000, $2,000,000\n\n\nMean = $427,000 (not representative of typical household)\nMedian = $35,000 (better represents typical household)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\n\nüéØ Definition: The mode is the value that appears most frequently in a dataset.\n\n%%{init: {'flowchart': {'nodeSpacing': 100, 'rankSpacing': 100}, 'width': 600, 'height': 400}}%%\ngraph TD\n    A[\"Mode Types\"]\n    A --&gt; B[\"Unimodal&lt;br/&gt;One peak\"]\n    A --&gt; C[\"Bimodal&lt;br/&gt;Two peaks\"]\n    A --&gt; D[\"Multimodal&lt;br/&gt;Multiple peaks\"]\n    A --&gt; E[\"No Mode&lt;br/&gt;No repeated values\"]\n    \n    classDef main fill:#e1f5fe,stroke:#01579b,stroke-width:3px,font-size:16px\n    classDef types fill:#f5f5f5,stroke:#424242,stroke-width:2px,font-size:14px\n    \n    class A main\n    class B,C,D,E types"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Distributions by Mode",
    "text": "Types of Distributions by Mode\n\nUnimodal: One mode\nBimodal: Two modes\n\nMultimodal: More than two modes\nNo mode: All values appear with equal frequency"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 1:",
    "text": "Example 1:\nData: 2, 3, 3, 4, 5, 5, 5, 6, 7\n\nAnalysis:\n\nCount each value: 2(1), 3(2), 4(1), 5(3), 6(1), 7(1)\nMost frequent value: 5 appears 3 times\nMode = 5\nType: Unimodal (one mode)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 2:",
    "text": "Example 2:\nData: 1, 2, 2, 3, 4, 4, 5\n\nAnalysis:\n\nCount each value: 1(1), 2(2), 3(1), 4(2), 5(1)\nMost frequent values: 2 and 4 both appear twice\nModes = 2 and 4\nType: Bimodal (two modes)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 3:",
    "text": "Example 3:\nData: 1, 2, 3, 4, 5\n\nAnalysis:\n\nCount each value: 1(1), 2(1), 3(1), 4(1), 5(1)\nAll values appear exactly once\nNo mode (no value repeats)\nType: No mode"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "href": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mode for Different Data Types",
    "text": "Mode for Different Data Types\nCategorical Data:\nFavorite colors: Red, Blue, Blue, Green, Blue, Red, Blue Mode = Blue\nContinuous Data:\nOften requires grouping into intervals or bins Example: Heights grouped into ranges"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mode",
    "text": "Properties of the Mode\n\nCan be used with any type of data (nominal, ordinal, interval, ratio)\nNot affected by outliers\nMay not exist or may not be unique\nRepresents the most common value\nEasy to identify in frequency distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mode",
    "text": "When to Use the Mode\n‚úÖ Use the mode when:\n\nWorking with categorical (nominal) data\nWant to identify the most popular or common choice\nData has clear peaks in frequency\nQuality control applications (most common defect type)\nBusiness applications (best-selling product, most common customer complaint)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Comparing Measures of Central Tendency",
    "text": "Comparing Measures of Central Tendency\n\n\n\n\n\n\n\n\n\n\nMeasure\nBest for Data Type\nStrengths\nWeaknesses\nAffected by Outliers?\n\n\n\n\nMean\nInterval, Ratio\nUses all data, mathematically tractable\nSensitive to outliers\nYes\n\n\nMedian\nOrdinal, Interval, Ratio\nRobust to outliers, represents middle\nIgnores extreme values\nNo\n\n\nMode\nAll types\nWorks with categorical, identifies most common\nMay not exist/be unique\nNo"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "href": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Shape of Distribution Effects",
    "text": "Shape of Distribution Effects\n\nSymmetric distribution: Mean ‚âà Median ‚âà Mode\nRight-skewed (positively skewed): Mean &gt; Median &gt; Mode\n\nLeft-skewed (negatively skewed): Mode &gt; Median &gt; Mean"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "href": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Central Measures",
    "text": "Central Measures\n\n\n\nMean CalculationMedian CalculationMode Calculation\n\n\n\n# Import numpy library for numeric operations\nimport numpy as np \n\n# Import pandas library for data structures\nimport pandas as pd\n\n# Define sample data as a list of test scores\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\n\n# Compute the arithmetic mean using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np:.2f}\")\n\n# Convert the data list into a pandas DataFrame\ndf = pd.DataFrame({'scores': data})\n\n# Compute the arithmetic mean using Pandas\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd:.2f}\")\n\n# Manually sum all scores and divide by count\nmanual_mean = sum(data) / len(data)\nprint(f\"Mean (Manual): {manual_mean:.2f}\")\n\nMean (NumPy): 87.10\nMean (Pandas): 87.10\nMean (Manual): 87.10\n\n\n\n\n\n# Compute the median value using NumPy\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np:.2f}\")\n\n# Compute the median value using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd:.2f}\")\n\n# Sort the data list in ascending order\nsorted_data = sorted(data)\n\n# Determine the number of elements\nn = len(sorted_data)\n\n# If even count, average the two middle elements; else take middle element\nif n % 2 == 0:\n    manual_median = (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2\nelse:\n    manual_median = sorted_data[n//2]\n\nprint(f\"Median (Manual): {manual_median:.2f}\")\n\nMedian (NumPy): 87.50\nMedian (Pandas): 87.50\nMedian (Manual): 87.50\n\n\n\n\n\n# Import SciPy stats module to compute mode\nfrom scipy import stats\n\n# Use SciPy to find the most common value and its count\nmode_result = stats.mode(data, keepdims=True)\nprint(f\"Mode (SciPy): {mode_result.mode[0]}, Count: {mode_result.count[0]}\")\n\n# Use Pandas to get mode(s) from the DataFrame\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\n# Import Counter for manual frequency counting\nfrom collections import Counter\n\n# Count occurrences of each score\ncounter = Counter(data)\n\n# Find the highest frequency\nmax_count = max(counter.values())\n\n# Identify all values that appear with that frequency\nmodes = [k for k, v in counter.items() if v == max_count]\n\nprint(f\"Mode (Manual): {modes}, Count: {max_count}\")\n\nMode (SciPy): 85, Count: 2\nMode (Pandas): [85]\nMode (Manual): [85], Count: 2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "href": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mean, Mode and Median Visualization",
    "text": "Mean, Mode and Median Visualization\n\nCodeVisualization\n\n\n\n# import libraries\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n# define your data and compute statistics here\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\nmean_np   = np.mean(data)\nmedian_np = np.median(data)\n# for mode, use Counter\ncounter   = Counter(data)\nmax_count = max(counter.values())\nmodes     = [k for k,v in counter.items() if v==max_count]\nmode_val  = modes[0]\n\n\n\n\n\n\n\n\nDistribution of Test Scores with Central Tendency Measures"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Business Applications",
    "text": "Business Applications\n\nCustomer Satisfaction: Mean rating shows overall satisfaction, median shows typical experience\nSales Data: Mode identifies best-selling products, median shows typical sale amount\n\nEmployee Performance: Mean for overall team performance, median for typical employee"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Educational Applications",
    "text": "Educational Applications\n\nTest Scores: Mean for class average, median for typical student performance\nGrade Distribution: Mode shows most common grade\nAttendance: Mean for overall attendance rate"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Healthcare Applications",
    "text": "Healthcare Applications\n\nPatient Wait Times: Median often preferred due to skewed distributions\nTreatment Outcomes: Mean for overall effectiveness, mode for most common result\nVital Signs: All three measures provide different insights"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "href": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Interpretation Guidelines",
    "text": "Interpretation Guidelines\n\nAlways consider the context of your data\nReport multiple measures when appropriate\n\nBe aware of data distribution shape\nConsider the presence of outliers\nChoose the most appropriate measure for your specific question"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "href": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Remember These Points",
    "text": "Remember These Points\n\nData type determines which statistics are appropriate\nMean uses all data but is sensitive to outliers\nMedian is robust and represents the middle value\nMode identifies the most common value and works with all data types\nContext matters when choosing and interpreting measures\nPython provides powerful tools for calculating descriptive statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "href": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Next Lecture Preview",
    "text": "Next Lecture Preview\nDescriptive Statistics Part II will cover:\n\nMeasures of variability (range, variance, standard deviation)\nMeasures of position (percentiles, quartiles, z-scores)\nShape of distributions (skewness and kurtosis)\nAdvanced Python visualization techniques"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "href": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Try These Problems",
    "text": "Try These Problems\n\nCalculate mean, median, and mode for: 12, 15, 18, 12, 20, 25, 12, 30\nA dataset has mean = 50 and median = 45. What does this tell you about the distribution?\nWhy might median be preferred over mean for reporting household income?\nCreate a Python function to identify the most appropriate measure of central tendency for a given dataset."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Download the full syllabus as a PDF\n\n\n\n\nüìö\n\n\nCourse Information\n\n\n\n\n\nLecture Time\n\n\nM/W/T/R 8:00 AM‚Äì9:30 AM\n\n\n\n\nLecture Hall\n\n\nHSSB 1173\n\n\n\n\nSections\n\n\nAs scheduled on GOLD (see Canvas for Zoom links)\n\n\n\n\nEmail\n\n\nnmathlouthi@ucsb.edu\n\n\n\n\nOffice\n\n\nEllison Hall 5829\n\n\n\n\nOffice Hours\n\n\nThursdays 11:00 AM‚Äì12:00 PM (via Zoom or by appointment)\n\n\n\n\n\nNote: Zoom links are posted on the Canvas page for the class.\n\n\n\n\n\n\nüë•\n\n\nTeaching Assistants\n\n\n\n\n\nSL\n\n\nSummer Le\n\n\nsle@ucsb.edu\n\n\n\n\nMH\n\n\nMingzhu He\n\n\nmingzhuhe@ucsb.edu\n\n\n\n\n\nEmail policy: Include [PSTAT 5A] in your subject. Allow 24‚Äì48 hours for a reply (avoid weekends).\n\n\n\n\n\n\nüéØ\n\n\nCourse Description\n\n\nThis introductory course covers the foundations of statistical thinking, including data description, probability, and inference. Students will learn how to summarize data, compute basic probabilities, and make informed decisions using statistical tools.\n\nStudent Learning Objectives\nBy the end of this course, you will be able to:\n\nSummarize data using descriptive statistics\nUnderstand fundamental probability rules and distributions\nConduct basic inferential procedures (confidence intervals, hypothesis tests)\nInterpret results and communicate findings\n\n\n\n\n\n\nüìñ\n\n\nCourse Materials\n\n\n\n\n\nCanvas\n\n\nAnnouncements, Zoom links, and grades (canvas.ucsb.edu)\n\n\n\n\nCalculator\n\n\nScientific calculator for in-class and quiz work\n\n\n\n\nComputer\n\n\nUse our JupyterHub instance\n\n\n\n\nRecommended Texts\n\n\nOpenIntro Statistics (free online)\nThink Stats by Allen Downey (free online)\n\n\n\n\n\n\n\nüìÖ\n\n\nClass Schedule\n\n\n\n\nNote: For the most up-to-date details, please visit the Class Schedule tab on our website: Class Schedule\n\n\n\n\n\n\nüìä\n\n\nGrading\n\n\n\n\nGrade Breakdown:\n\n\n\nLecture attendance: 5%\nSection attendance: 5%\nQuiz 1: 30%\nQuiz 2: 30%\nQuiz 3: 30%\n\n\n\nGrading Scale:\n\n\n\n\nA Grades\nB Grades\nC Grades\nD/F Grades\n\n\n\n\nA+: 97‚Äì100\nB+: 87‚Äì89\nC+: 77‚Äì79\nD+: 67‚Äì69\n\n\nA: 93‚Äì96\nB: 83‚Äì86\nC: 73‚Äì76\nD: 60‚Äì66\n\n\nA‚Äì: 90‚Äì92\nB‚Äì: 80‚Äì82\nC‚Äì: 70‚Äì72\nF: &lt; 60\n\n\n\n\n\n\nGrades round to the nearest whole number (e.g., 89.7 ‚Üí 90).\n\n\n\n\n\n\nüìù\n\n\nQuizzes\n\n\n\n\n\n1\n\n\n\nQuiz 1: Weeks 1‚Äì2\n\n\nJuly 11th\n\n\nCovers introduction, descriptive statistics and Intro to Probability\n\n\n\n\n\n2\n\n\n\nQuiz 2: Weeks 3‚Äì4\n\n\nJuly 25th\n\n\nCovers Conditional Probability, Counting & Random Variables (Discrete & Continuous)\n\n\n\n\n\n3\n\n\n\nQuiz 3: Weeks 5‚Äì6\n\n\nJuly 31st\n\n\nCovers Confidence Intervals & Hypothesis testing\n\n\n\n\n\n\nFormat: Multiple choice & short answer (open book)\nPlatform: Canvas /-or Gradescope\nAvailability: Fridays 7 AM‚Äì12 AM (1‚Äëhour limit)\nMake‚Äëup policy: Notify within 48 h; documentation required.\n\n\n\n\n\n\nüéØ\n\n\nHow to Succeed\n\n\n\nAttend lectures & sections\nEngage actively & ask questions\nUse office hours for help\n\n\nClassroom Expectations\nRespect peers & TAs. Stay engaged. Seek support if needed.\n\n\nCommunication Guidelines\n\nUse UCSB email with clear subject\nAllow 24‚Äì48 h for replies\nUse office hours or appointments\n\n\n\n\n\n\nüõ°Ô∏è\n\n\nAcademic Integrity\n\n\nDo your own work. Cite sources properly. See:\n\nAcademic Integrity Policy\nStudent Conduct Code\n\n\n\n\n\nü§ù\n\n\nStudent Resources\n\n\n\n\nü¶Ω DSP & Accommodations Disability services and accommodations\n\n\nüìö CLAS Campus Learning Assistance Services\n\n\nüè• Student Health Health and wellness services\n\n\nüçé Basic Needs Food security and basic needs support\n\n\nüíö CAPS Counseling & Psychological Services\n\n\nüéì EOP Educational Opportunity Program\n\n\nüë• ONDAS First-Generation Support\n\n\nüìã Undocumented Services Support for undocumented students\n\n\nüîÑ Transfer Center Transfer student support\n\n\n\n\n\n\nüìÖ\n\n\nImportant Dates\n\n\n\n\n\nAdd w/o Code\n\n\nJune 29\n\n\n\n\nDrop w/ Refund\n\n\nJune 29\n\n\n\n\nAdd w/ Code\n\n\nJuly 3\n\n\n\n\nDrop Course\n\n\nJuly 9\n\n\n\n\nChange Grade Option\n\n\nAugust 1"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSTAT 5A: Understanding Data",
    "section": "",
    "text": "Learn the fundamentals of data science and statistical thinking\n\n\nSummer Session A 2025 ‚Ä¢ Taught by Narjes Mathlouthi\n\nGet Started ‚Üí"
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Course Overview",
    "text": "Course Overview\n\nTransform raw data into meaningful insights through hands-on learning and real-world applications"
  },
  {
    "objectID": "index.html#quick-navigation",
    "href": "index.html#quick-navigation",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Quick Navigation",
    "text": "Quick Navigation\n\nEverything you need for the course, organized and accessible"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-8",
    "href": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-8",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Welcome to Lecture 8",
    "text": "Welcome to Lecture 8\nDiscrete Random Variables\nFrom outcomes to numbers: quantifying randomness"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine random variables and distinguish discrete from continuous\nWork with probability mass functions (PMFs) and cumulative distribution functions (CDFs)\nCalculate expected values and variances for discrete random variables\nApply properties of expectation and variance\nWork with common discrete distributions (Bernoulli, Binomial, Geometric, Poisson)\nSolve real-world problems using discrete random variables\nUse python to compute probabilities and parameters"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "href": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "What is a Random Variable?",
    "text": "What is a Random Variable?\n\nDefinition: A random variable is a function that assigns a numerical value to each outcome of a random experiment.\nNotation: Usually denoted by capital letters \\(X\\), \\(Y\\), \\(Z\\)\nKey insight: Random variables transform outcomes into numbers, making statistical analysis possible\n\n\n\nTreena - Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#die-roll-example-mapping-outcomes-to-numbers",
    "href": "files/lecture_notes/lecture7/lecture7.html#die-roll-example-mapping-outcomes-to-numbers",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Die Roll Example: Mapping Outcomes to Numbers",
    "text": "Die Roll Example: Mapping Outcomes to Numbers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n\n\n\nRandom Variable X maps each die face to its numerical value."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Why Use Random Variables?",
    "text": "Why Use Random Variables?\n\n\nRandom variables allow us to:\n\nQuantify outcomes numerically\nCalculate means, variances, and other statistics\nModel real-world phenomena\nMake predictions and decisions\nCompare different random processes\n\nExamples: Height, test scores, number of defects, wait times, stock prices\n\n\n\nTreena - Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Types of Random Variables",
    "text": "Types of Random Variables\n\n\nToday we focus on discrete random variables - notice there are gaps between possible values!\n\n\n\nDiscrete vs.¬†Continuous: Demystifying the type of Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "href": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Probability Mass Function (PMF)",
    "text": "Probability Mass Function (PMF)\n\n\nDefinition: The Probability Mass Function (PMF) of a discrete random variable \\(X\\) is:\n\n\n\\[P(X = x) = \\text{probability that } X \\text{ takes the value } x\\]\n\n\nProperties of PMF:\n\n\n\n\\(P(X = x) \\geq 0\\) for all \\(x\\)\n\n\n\\(\\sum_{\\text{all } x} P(X = x) = 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "href": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "PMF Example: Two Coin Flips",
    "text": "PMF Example: Two Coin Flips\n\nTwo Coin Flips - Number of Heads\nLet \\(X\\) = number of heads in two coin flips\nSample Space: \\(\\{HH, HT, TH, TT\\}\\)\n\n\n\nH T H T\n\n\nCurrent outcome: H T H T\n\nClick coins to flip them!\n\nTable summarizes by number of heads, not the exact sequence.\n\n\n\n\n\n\\(x\\) (heads)\n\n\nOutcomes\n\n\n\\(P(X = x)\\)\n\n\nEmpirical\n\n\n\n\n\n\n0\n\n\nTT\n\n\n0.25\n\n\n0\n\n\n\n\n1\n\n\nHT, TH\n\n\n0.50\n\n\n0\n\n\n\n\n2\n\n\nHH\n\n\n0.25\n\n\n0\n\n\n\n\n\nEmpirical probability updates as you flip!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "href": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\n\n\n\nThe cumulative distribution function of a random variable \\(X\\) is:\n\\[F(x) = P(X \\leq x)\\]\nProperties of CDF: 1. \\(F(x)\\) is non-decreasing 2. \\(\\lim_{x \\to -\\infty} F(x) = 0\\) 3. \\(\\lim_{x \\to \\infty} F(x) = 1\\) 4. \\(F(x)\\) is right-continuous"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#expected-value-and-variance",
    "href": "files/lecture_notes/lecture7/lecture7.html#expected-value-and-variance",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value and Variance",
    "text": "Expected Value and Variance\nThe expected value of a discrete random variable \\(X\\) is:\n\\[E[X] = \\mu = \\sum_{\\text{all } x} x \\cdot P(X = x)\\]\nThe variance of a random variable \\(X\\) measures spread around the mean:\n\\[\\text{Var}(X) = \\sigma^2 = E[(X - \\mu)^2] = E[X^2] - (E[X])^2\\]\n\nExpected value represents the long-run average if we repeat the experiment many times."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#law-of-large-numbers-demo",
    "href": "files/lecture_notes/lecture7/lecture7.html#law-of-large-numbers-demo",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Law of Large Numbers Demo",
    "text": "Law of Large Numbers Demo\n\nLaw of Large Numbers Demo\n\n\nRun Simulation\n\n 100 trials 500 trials 1000 trials 5000 trials \n\n\n\n\n\nWatch how the sample mean converges to the expected value! {.smaller}"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#common-discrete-distributions",
    "href": "files/lecture_notes/lecture7/lecture7.html#common-discrete-distributions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Common Discrete Distributions",
    "text": "Common Discrete Distributions\n\nBernoulli\nSingle trial, two outcomes\nParameters: \\(p\\) (success probability)\nPMF: \\(P(X = 1) = p\\), \\(P(X = 0) = 1-p\\)\nMean: \\(p\\)\nVariance: \\(p(1-p)\\)\n\n\nBinomial\n\\(n\\) independent Bernoulli trials\nParameters: \\(n\\) (trials), \\(p\\) (success prob.)\nPMF: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\)\nMean: \\(np\\)\nVariance: \\(np(1-p)\\)\n\n\nGeometric\nTrials until first success\nParameters: \\(p\\) (success probability)\nPMF: \\(P(X = k) = (1-p)^{k-1} p\\)\nMean: \\(1/p\\)\nVariance: \\((1-p)/p^2\\)\n\n\nPoisson\nEvents in fixed interval\nParameters: \\(\\lambda\\) (average rate)\nPMF: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\)\nMean: \\(\\lambda\\)\nVariance: \\(\\lambda\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#interactive-distribution-explorer",
    "href": "files/lecture_notes/lecture7/lecture7.html#interactive-distribution-explorer",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Interactive Distribution Explorer",
    "text": "Interactive Distribution Explorer\n\nDistribution Visualizer\n\n Binomial Geometric Poisson  Parameter 1:  Parameter 2:"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\nA box contains 3 red balls and 2 blue balls. Two balls are drawn without replacement. Let \\(X\\) = number of red balls drawn. Find the PMF of \\(X\\).\n\nShow Solution\n\n\nSolution. \\(X\\) can take values 0, 1, or 2.\n\\(P(X = 0) = \\frac{\\binom{3}{0}\\binom{2}{2}}{\\binom{5}{2}} = \\frac{1 \\times 1}{10} = \\frac{1}{10}\\)\n\\(P(X = 1) = \\frac{\\binom{3}{1}\\binom{2}{1}}{\\binom{5}{2}} = \\frac{3 \\times 2}{10} = \\frac{6}{10}\\)\n\\(P(X = 2) = \\frac{\\binom{3}{2}\\binom{2}{0}}{\\binom{5}{2}} = \\frac{3 \\times 1}{10} = \\frac{3}{10}\\)\nCheck: \\(\\frac{1}{10} + \\frac{6}{10} + \\frac{3}{10} = 1\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2-expected-value",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2-expected-value",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 2: Expected Value",
    "text": "Practice Problem 2: Expected Value\n\nUsing the red balls example from Problem 1, find \\(E[X]\\) and \\(\\text{Var}(X)\\).\n\nShow Solution\n\n\nSolution. Expected Value: \\[E[X] = 0 \\times \\frac{1}{10} + 1 \\times \\frac{6}{10} + 2 \\times \\frac{3}{10} = 0 + \\frac{6}{10} + \\frac{6}{10} = 1.2\\]\nVariance: \\[E[X^2] = 0^2 \\times \\frac{1}{10} + 1^2 \\times \\frac{6}{10} + 2^2 \\times \\frac{3}{10} = 0 + \\frac{6}{10} + \\frac{12}{10} = 1.8\\]\n\\[\\text{Var}(X) = E[X^2] - (E[X])^2 = 1.8 - (1.2)^2 = 1.8 - 1.44 = 0.36\\]\nStandard Deviation: \\(\\sigma = \\sqrt{0.36} = 0.6\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nA student takes a 10-question multiple choice quiz with 4 options per question. If the student guesses randomly, what‚Äôs the probability of getting exactly 3 correct?\n\nShow Solution\n\n\nSolution. This is a binomial distribution with \\(n = 10\\), \\(p = 1/4 = 0.25\\)\n\\[P(X = 3) = \\binom{10}{3} \\times (0.25)^3 \\times (0.75)^7\\]\n\\[P(X = 3) = 120 \\times 0.015625 \\times 0.1335 \\approx 0.2503\\]\nSo there‚Äôs about a 25% chance of getting exactly 3 correct by guessing."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "href": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Properties of Expected Value",
    "text": "Properties of Expected Value\n\n\n\nLinearity of Expectation\n\n\\(E[c] = c\\) (constant)\n\\(E[cX] = c \\cdot E[X]\\) (scaling)\n\\(E[X + Y] = E[X] + E[Y]\\) (additivity)\n\\(E[aX + bY + c] = aE[X] + bE[Y] + c\\)\n\n\nVariance Properties\n\n\\(\\text{Var}(aX + b) = a^2 \\text{Var}(X)\\)\n\\(\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y)\\) (if \\(X\\) and \\(Y\\) are independent)\n\n\nImportant: Property 3 holds even if \\(X\\) and \\(Y\\) are dependent!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#key-takeaways",
    "href": "files/lecture_notes/lecture7/lecture7.html#key-takeaways",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\n\n\nMain Concepts\n\nRandom variables transform outcomes into numbers for mathematical analysis\nPMF gives probabilities for specific values; CDF gives cumulative probabilities\nExpected value is the long-run average; variance measures spread\n\n\nDistribution Selection\nChoose distributions based on the underlying process:\n\nBernoulli for single trials\nBinomial for fixed trials\nGeometric for waiting times\nPoisson for rates\n\nKey Principle\n\nLaw of Large Numbers connects theoretical expectations with observed averages"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "href": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\nNext Lecture: Continuous Random Variables\nTopics we‚Äôll cover:\n\nProbability density functions (PDFs)\nNormal distribution\nExponential distribution\nCentral Limit Theorem applications\n\n\nConnection: Discrete distributions often approximate continuous ones, and vice versa"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#questions",
    "href": "files/lecture_notes/lecture7/lecture7.html#questions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: 11AM on Thursday (link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Continuous Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#resources",
    "href": "files/lecture_notes/lecture7/lecture7.html#resources",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Resources",
    "text": "Resources\n\n\n\n Read OpenIntro Statistics Chapter 3 section 3.4\n\n\n Random Variable - Treena Courses\n\n\n Random Variables and Probability Functions\n\n\n Random Variables - Distribution and Expectation\n\n\n Khan Academy - Unit9: Random Variables"
  }
]