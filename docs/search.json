[
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#todays-roadmap",
    "href": "files/lecture_notes/lecture14/lecture14.html#todays-roadmap",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "📢 Today’s Roadmap",
    "text": "📢 Today’s Roadmap\n\n\n🎯 Learning Objectives\n\nUnderstand the linear regression model\nCalculate slope and intercept by hand\nInterpret regression coefficients correctly\nAssess model quality with R^2\nMake predictions using the regression line\nIdentify assumptions and when they’re violated\n\n\n📋 What We’ll Cover\n\nWhat is Regression? The big picture\nThe Math Behind the Line Least squares method\nKey Statistics R², correlation, residuals\nStep-by-Step Examples Real calculations\nInterpretation Skills What does it all mean?\nCommon Pitfalls Correlation ≠ causation"
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#what-is-linear-regression",
    "href": "files/lecture_notes/lecture14/lecture14.html#what-is-linear-regression",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "What is Linear Regression? 🔍",
    "text": "What is Linear Regression? 🔍\n\n\n🎯 The Big Idea\nLinear regression helps us understand and predict relationships between two quantitative variables.\nKey Components:\n\nResponse variable (y): What we want to predict\nExplanatory variable (x): What we use to predict\nRegression line: Best-fitting straight line through data\n\nThe Model: \\hat{y} = a + bx\nWhere:\n\n\\hat{y} = predicted value\na = y-intercept\nb = slope\nx = explanatory variable value\n\nGoal: Find the line that minimizes the sum of squared residuals \\text{Minimize: } \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nKey Insight: The regression line minimizes the vertical distances (residuals) between data points and the line."
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#the-math-least-squares-formulas",
    "href": "files/lecture_notes/lecture14/lecture14.html#the-math-least-squares-formulas",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "The Math: Least Squares Formulas 📐",
    "text": "The Math: Least Squares Formulas 📐\n\n\n🧮 Essential Formulas\nFor the regression line \\hat{y} = a + bx:\nSlope: b = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum(x_i - \\bar{x})^2} = \\frac{s_{xy}}{s_x^2}\nAlternative slope formula: b = r \\cdot \\frac{s_y}{s_x}\nY-intercept: a = \\bar{y} - b\\bar{x}\nWhere:\n\nr = correlation coefficient\ns_x, s_y = standard deviations\ns_{xy} = covariance\n\\bar{x}, \\bar{y} = sample means\n\nImportant: The regression line always passes through (\\bar{x}, \\bar{y})!\n\n🔢 Key Statistics\nCorrelation coefficient: r = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i - \\bar{x})^2 \\sum(y_i - \\bar{y})^2}}\nCoefficient of determination: R^2 = r^2\nResidual: e_i = y_i - \\hat{y}_i\nResidual standard error: s_e = \\sqrt{\\frac{\\sum e_i^2}{n-2}}\nWhat R² tells us:\n\nR^2 = 0.25 → 25% of variation in y is explained by x\nR^2 = 0.81 → 81% of variation in y is explained by x\nHigher R^2 = better fit (closer to 1.0)"
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#step-by-step-example-1-height-vs.-shoe-size",
    "href": "files/lecture_notes/lecture14/lecture14.html#step-by-step-example-1-height-vs.-shoe-size",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "Step-by-Step Example 1: Height vs. Shoe Size 👟",
    "text": "Step-by-Step Example 1: Height vs. Shoe Size 👟\n\n\n🎯 Problem Setup\nResearch Question: Can we predict height from shoe size?\nData: 8 college students\n\n\n\nStudent\nShoe Size (x)\nHeight (y)\n\n\n\n\n1\n7\n65\n\n\n2\n8\n67\n\n\n3\n9\n69\n\n\n4\n10\n71\n\n\n5\n11\n73\n\n\n6\n12\n75\n\n\n7\n9.5\n70\n\n\n8\n8.5\n68\n\n\n\nFind: Regression equation and interpret the slope.\n\n\nShow Solution\n\n\nStep 1: Calculate means - \\bar{x} = \\frac{7+8+9+10+11+12+9.5+8.5}{8} = \\frac{75}{8} = 9.375 - \\bar{y} = \\frac{65+67+69+71+73+75+70+68}{8} = \\frac{558}{8} = 69.75\nStep 2: Calculate slope components\n\n\n\n\n\n\n\n\n\n\n\nx\ny\n(x-\\bar{x})\n(y-\\bar{y})\n(x-\\bar{x})(y-\\bar{y})\n(x-\\bar{x})^2\n\n\n\n\n7\n65\n-2.375\n-4.75\n11.281\n5.641\n\n\n8\n67\n-1.375\n-2.75\n3.781\n1.891\n\n\n9\n69\n-0.375\n-0.75\n0.281\n0.141\n\n\n10\n71\n0.625\n1.25\n0.781\n0.391\n\n\n11\n73\n1.625\n3.25\n5.281\n2.641\n\n\n12\n75\n2.625\n5.25\n13.781\n6.891\n\n\n9.5\n70\n0.125\n0.25\n0.031\n0.016\n\n\n8.5\n68\n-0.875\n-1.75\n1.531\n0.766\n\n\n\nSums: \\sum(x-\\bar{x})(y-\\bar{y}) = 36.75, \\sum(x-\\bar{x})^2 = 18.375\nStep 3: Calculate slope and intercept b = \\frac{36.75}{18.375} = 2.0 a = 69.75 - 2.0(9.375) = 69.75 - 18.75 = 51.0\nStep 4: Write equation \\hat{y} = 51.0 + 2.0x\nInterpretation: For each additional shoe size, height increases by 2.0 inches on average.\n\n\n\n\n\n                            \n                                            \n\n\n🔍 Key Insights:\n\nSlope = 2.0: Each shoe size ↑ → 2 inches taller\nR² = 0.968: 96.8% of height variation explained\nStrong positive relationship"
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#step-by-step-example-2-study-time-vs.-test-score",
    "href": "files/lecture_notes/lecture14/lecture14.html#step-by-step-example-2-study-time-vs.-test-score",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "Step-by-Step Example 2: Study Time vs. Test Score 📚",
    "text": "Step-by-Step Example 2: Study Time vs. Test Score 📚\n\n\n🎯 Problem Setup\nResearch Question: Does study time predict test performance?\nData: 10 students’ study hours and test scores\n\n\n\nHours (x)\nScore (y)\n\n\n\n\n2\n70\n\n\n3\n75\n\n\n4\n80\n\n\n5\n82\n\n\n6\n85\n\n\n7\n88\n\n\n8\n90\n\n\n1\n65\n\n\n9\n92\n\n\n10\n95\n\n\n\nTasks: 1. Find the regression equation 2. Calculate R² 3. Predict score for 6.5 hours of study 4. Interpret the y-intercept\n\n\nShow Solution\n\n\nStep 1: Calculate basic statistics - n = 10 - \\bar{x} = 5.5 hours - \\bar{y} = 82.2 points - s_x = 2.87, s_y = 9.19\nStep 2: Calculate correlation Using the formula with sums: - \\sum(x-\\bar{x})(y-\\bar{y}) = 230.5 - \\sum(x-\\bar{x})^2 = 82.5 - \\sum(y-\\bar{y})^2 = 760.4\nr = \\frac{230.5}{\\sqrt{82.5 \\times 760.4}} = \\frac{230.5}{250.4} = 0.921\nStep 3: Calculate slope and intercept b = r \\cdot \\frac{s_y}{s_x} = 0.921 \\times \\frac{9.19}{2.87} = 2.95 a = \\bar{y} - b\\bar{x} = 82.2 - 2.95(5.5) = 66.0\nStep 4: Write equation \\hat{y} = 66.0 + 2.95x\nStep 5: Calculate R² R^2 = r^2 = (0.921)^2 = 0.848\nStep 6: Make prediction For x = 6.5: \\hat{y} = 66.0 + 2.95(6.5) = 85.2 points\nStep 7: Interpret y-intercept When study time = 0 hours, predicted score = 66.0 points (baseline knowledge)\n\n\n\n\n\n                            \n                                            \n\n\n📊 Analysis Summary:\n\nSlope = 2.95: Each hour ↑ → 2.95 points ↑\nR² = 0.848: 84.8% of score variation explained\nStrong positive relationship (r = 0.921)\nPractical significance: Study time matters!"
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#understanding-r²-and-model-quality",
    "href": "files/lecture_notes/lecture14/lecture14.html#understanding-r²-and-model-quality",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "Understanding R² and Model Quality 📈",
    "text": "Understanding R² and Model Quality 📈\n\n\n🎯 What is R²?\nCoefficient of Determination (R²) measures the proportion of variation in the response variable explained by the explanatory variable.\nFormula:\nR^2 = r^2 (square of correlation)\nInterpretation:\n\nR^2 = 0: No linear relationship\nR^2 = 0.25: Weak relationship (25% explained)\nR^2 = 0.64: Moderate relationship (64% explained)\nR^2 = 0.90: Strong relationship (90% explained)\nR^2 = 1: Perfect linear relationship\n\nKey Points:\n\nAlways between 0 and 1\nHigher = better fit\nContext matters for “good” values\nCan’t determine causation"
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#practice-problem-housing-prices",
    "href": "files/lecture_notes/lecture14/lecture14.html#practice-problem-housing-prices",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "Practice Problem: Housing Prices 🏠",
    "text": "Practice Problem: Housing Prices 🏠\n\n\n🎯 Your Turn!\nProblem: A real estate agent wants to predict house prices based on square footage.\nData: 6 recent sales\n\n\n\nSq Ft (x)\nPrice ($000s) (y)\n\n\n\n\n1200\n180\n\n\n1500\n220\n\n\n1800\n260\n\n\n2000\n290\n\n\n2200\n320\n\n\n1600\n235\n\n\n\nTasks: 1. Calculate the regression equation 2. Find R² and interpret it 3. Predict price for 1900 sq ft house 4. What’s the price per square foot?\n\n\nShow Solution\n\n\nStep 1: Calculate means\n\n\\bar{x} = \\frac{1200+1500+1800+2000+2200+1600}{6} = 1716.7 sq ft\n\\bar{y} = \\frac{180+220+260+290+320+235}{6} = 250.8 ($000s)\n\nStep 2: Calculate slope components\n\n\n\n\n\n\n\n\n\n\n\nx\ny\n(x-\\bar{x})\n(y-\\bar{y})\n(x-\\bar{x})(y-\\bar{y})\n(x-\\bar{x})^2\n\n\n\n\n1200\n180\n-516.7\n-70.8\n36,583\n266,978\n\n\n1500\n220\n-216.7\n-30.8\n6,675\n46,978\n\n\n1800\n260\n83.3\n9.2\n766\n6,939\n\n\n2000\n290\n283.3\n39.2\n11,105\n80,278\n\n\n2200\n320\n483.3\n69.2\n33,453\n233,778\n\n\n1600\n235\n-116.7\n-15.8\n1,844\n13,619\n\n\n\nSums: \\sum(x-\\bar{x})(y-\\bar{y}) = 90,426, \\sum(x-\\bar{x})^2 = 648,570\nStep 3: Calculate regression b = \\frac{90,426}{648,570} = 0.139 a = 250.8 - 0.139(1716.7) = 12.0\nEquation: \\hat{y} = 12.0 + 0.139x\nStep 4: Calculate R² - Calculate correlation r first, then R^2 = r^2 = 0.982\nStep 5: Interpretation\n\nR² = 0.982: 98.2% of price variation explained by square footage\nVery strong relationship\n\nStep 6: Prediction for 1900 sq ft \\hat{y} = 12.0 + 0.139(1900) = 276.1 ($276,100)\nStep 7: Price per square foot The slope = 0.139 means $139 per square foot increase\n\n\n\n\n\n                            \n                                            \n\n\n🏠 Real Estate Insights:\n\nVery strong fit: R² = 0.982\nPrice increases $139 per sq ft\n1900 sq ft house ≈ $276,100\nUseful for pricing decisions"
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#assumptions-and-limitations",
    "href": "files/lecture_notes/lecture14/lecture14.html#assumptions-and-limitations",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "Assumptions and Limitations ⚠️",
    "text": "Assumptions and Limitations ⚠️\n\n\n🔍 Key Assumptions\n1. Linearity - Relationship is actually linear - Check with scatterplot\n2. Independence - Observations are independent - No time trends or clustering\n3. Normality of Residuals - Residuals follow normal distribution - Check with residual plots\n4. Constant Variance - Spread of residuals is consistent - No “fan” patterns\n5. No Extreme Outliers - Outliers can heavily influence line - Check for unusual points\n\n⚠️ Common Pitfalls\n1. Correlation ≠ Causation - Strong correlation doesn’t prove cause - Could be confounding variables\n2. Extrapolation Dangers - Don’t predict far outside data range - Relationships may change\n3. Outlier Sensitivity - One extreme point can change everything - Always examine unusual observations\n4. Non-linear Relationships - Linear regression assumes straight line - Curved relationships need different methods\n5. Ecological Fallacy - Group-level patterns ≠ individual patterns - Be careful with aggregated data\n🎯 Best Practices\n\nAlways plot your data first\nCheck residuals\nConsider context and causation\nReport limitations honestly"
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#summary-linear-regression-essentials",
    "href": "files/lecture_notes/lecture14/lecture14.html#summary-linear-regression-essentials",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "Summary: Linear Regression Essentials 🎯",
    "text": "Summary: Linear Regression Essentials 🎯\n\n\n🧠 Key Formulas\nRegression Line: \\hat{y} = a + bx\nSlope: b = r \\cdot \\frac{s_y}{s_x}\nIntercept: a = \\bar{y} - b\\bar{x}\nR-squared: R^2 = r^2\nResidual: e_i = y_i - \\hat{y}_i\n🔍 Interpretation Skills\nSlope: Change in y per unit change in x\nIntercept: Value of y when x = 0\nR²: % of y-variation explained by x\nAlways include units and context!\n\n🛠️ Problem-Solving Steps\n\nPlot the data (always start here!)\nCalculate means \\bar{x}, \\bar{y}\nFind correlation r\nCalculate slope b = r \\cdot s_y/s_x\nCalculate intercept a = \\bar{y} - b\\bar{x}\nWrite equation \\hat{y} = a + bx\nFind R² = r²\nMake predictions (within reason)\nInterpret in context\nCheck assumptions\n\n🚨 Red Flags to Watch\n\nPerfect correlation (r = ±1.0)\nExtrapolating too far\nIgnoring outliers\nAssuming causation\nNon-linear patterns"
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#next-steps-building-your-skills",
    "href": "files/lecture_notes/lecture14/lecture14.html#next-steps-building-your-skills",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "Next Steps: Building Your Skills 🚀",
    "text": "Next Steps: Building Your Skills 🚀\n\n\n📚 Practice Opportunities\nCanvas Assignments: - Regression calculation practice - Real-world interpretation problems - Technology-based exercises\nStudy Resources: - Textbook Chapter 3.1-3.3 - Online regression calculator - Practice datasets on course website\nOffice Hours Topics: - Hand calculation questions - Interpretation help - Technology assistance\n\n🎯 Coming Up Next\nWeek 6: Advanced Regression - Confidence intervals for slope - Hypothesis testing in regression - Residual analysis - Multiple regression preview\nMidterm Preparation: - Review sessions this week - Practice problems with solutions - Formula sheet preview - Calculator tips and tricks\n💡 Success Tips\n\nPractice calculations by hand first\nAlways interpret in context\nDraw connections to correlation\nThink critically about causation"
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#section",
    "href": "files/lecture_notes/lecture14/lecture14.html#section",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "",
    "text": "🏠 Back to Main Page"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "href": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Today’s Agenda",
    "text": "Today’s Agenda\n\nIntroduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\nWhy it matters before any modeling\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset they’ve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "href": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Learning Objectives (LOs)",
    "text": "Learning Objectives (LOs)\nBy the end of this lecture you should be able to:\n\nDefine descriptive statistics and explain its importance in data analysis (Section 1)\nDistinguish between different types of data and measurement scales (Section 2)\nCalculate and interpret measures of central tendency (mean, median, mode)(Section 3)\nUnderstand when to use each measure of central tendency\nApply Python to compute descriptive statistics(Section 9)\nInterpret basic descriptive statistics in real-world contexts(Section 10)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Statistics",
    "text": "Statistics\nFacts are stubborn, but statistics are more pliable.\nMark Twain\n\nStatistics refers to the mathematics and techniques with which we understand data. 1\n\n\n(source)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What are Descriptive Statistics?",
    "text": "What are Descriptive Statistics?\nDescriptive statistics are numerical and graphical methods used to summarize, organize, and describe data in a meaningful way.\n\nPurpose of Descriptive Statistics\n\nSummarize large datasets into manageable information\nIdentify patterns and trends in data\nCommunicate findings clearly to others\nPrepare data for further analysis\nMake initial assessments about data quality"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs. Inferential Statistics",
    "text": "Descriptive vs. Inferential Statistics\n\n\n\n\n\n\n\nDescriptive Statistics\nInferential Statistics\n\n\n\n\nDescribes what the data shows\nMakes predictions about populations\n\n\nSummarizes sample data\nUses sample data to make generalizations\n\n\nNo conclusions beyond the data\nDraws conclusions beyond the immediate data\n\n\nExamples: mean, median, graphs\nExamples: hypothesis testing, confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs. Inferential Statistics",
    "text": "Descriptive vs. Inferential Statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "href": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Why Data Types Matter",
    "text": "Why Data Types Matter\nUnderstanding data types is crucial because:\n\nDifferent statistics are appropriate for different data types\nStatistical methods depend on the level of measurement\nMisapplying statistics can lead to incorrect conclusions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Data",
    "text": "Types of Data\ngraph TD\n    A[Variable Types]\n    A --&gt; B[Categorical]\n    A --&gt; C[Numerical]\n    B --&gt; B1[\"Nominal&lt;br/&gt;e.g., gender, major\"]\n    B --&gt; B2[\"Ordinal&lt;br/&gt;e.g., rating, education level\"]\n    C --&gt; C1[\"Discrete&lt;br/&gt;e.g., count (# of students)\"]\n    C --&gt; C2[\"Continuous&lt;br/&gt;e.g., measurements like height, weight\"]\n    \n    classDef root fill:#e1f5fe,stroke:#01579b,stroke-width:3px\n    classDef categorical fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef numerical fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px\n    classDef nominal fill:#fce4ec,stroke:#880e4f,stroke-width:2px\n    classDef ordinal fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef discrete fill:#e0f2f1,stroke:#00695c,stroke-width:2px\n    classDef continuous fill:#f1f8e9,stroke:#33691e,stroke-width:2px\n    \n    class A root\n    class B categorical\n    class C numerical\n    class B1 nominal\n    class B2 ordinal\n    class C1 discrete\n    class C2 continuous\n\nPrompt: Which summary stat would you pick for “major”? For “gpa”?"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Categorical Data (Qualitative)",
    "text": "Categorical Data (Qualitative)\n\n\nNominal Data\n\nCategories with no natural order\nExamples: gender, color, brand names, marital status\nAppropriate statistics: mode, frequency counts, proportions\n\n\nOrdinal Data\n\nCategories with a natural order or ranking\nExamples: education level, satisfaction ratings, letter grades\nAppropriate statistics: mode, median, percentiles"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Numerical Data (Quantitative)",
    "text": "Numerical Data (Quantitative)\n\nDiscrete Data\n\nCountable values, often integers\nExamples: number of children, cars sold, defective items\nCan take on finite or countably infinite values\n\n\n\nContinuous Data\n\nCan take any value within a range\nExamples: height, weight, temperature, time\nMeasured rather than counted"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "href": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Measurement Scales Summary",
    "text": "Measurement Scales Summary\n\n\n\n\n\n\n\n\n\n\nScale\nType\nProperties\nExamples\nAppropriate Statistics\n\n\n\n\nNominal\nCategorical\nCategories only\nGender, Color\nMode, Frequency\n\n\nOrdinal\nCategorical\nOrder matters\nRankings, Grades\nMode, Median\n\n\nInterval\nNumerical\nEqual intervals, no true zero\nTemperature (°C)\nMean, Median, Mode\n\n\nRatio\nNumerical\nEqual intervals, true zero\nHeight, Weight, Income\nAll statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What is Central Tendency?",
    "text": "What is Central Tendency?\nCentral tendency describes the center or typical value of a dataset.\nIt answers the question: “What is a representative value for this data?”"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition and Formula",
    "text": "Definition and Formula\n\n🎯 Definition: The mean is the sum of all values divided by the number of values.\n\n\nFormula\n\nFor a sample: \\bar{x} = \\frac{\\sum x}{n}\nFor a population: \\mu = \\frac{\\sum x}{N}\n\nWhere:\n\n\\bar{x} (x-bar) = sample mean\n\\mu (mu) = population mean\n\\sum x = sum of all values\nn = sample size, N = population size"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example Calculation",
    "text": "Example Calculation\nStudent test scores: 85, 90, 78, 92, 88\n\nMean = \\frac{85 + 90 + 78 + 92 + 88}{5} = \\frac{433}{5} = 86.6"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mean",
    "text": "Properties of the Mean\n\nUses all data points - every value affects the mean\nSensitive to outliers - extreme values can distort the mean\nUnique - there is only one mean for a dataset\nCan be calculated for interval and ratio data\nBalancing point - sum of deviations from mean equals zero"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mean",
    "text": "When to Use the Mean\n✅ Use the mean when:\n\nData is approximately symmetric\nNo extreme outliers present\nWorking with interval or ratio data\nNeed to use the value in further calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "href": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Advantages and Disadvantages",
    "text": "Advantages and Disadvantages\n\n\nAdvantages\n\nUses all information in the dataset\nAlgebraically defined and mathematically tractable\nWidely understood and accepted\n\n\nDisadvantages\n\nAffected by outliers and skewed distributions\nMay not represent a typical value in skewed data\nCannot be used with nominal or ordinal data"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\n\n🎯 Definition: The median is the middle value when data is arranged in ascending or descending order."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "href": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Calculation Steps",
    "text": "Calculation Steps\n\nArrange data in ascending order\nFind the middle position:\n\nIf n is odd: position = \\frac{n + 1}{2}\nIf n is even: average of positions \\frac{n}{2} and \\frac{n}{2} + 1"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#examples",
    "href": "files/lecture_notes/lecture2/lecture2.html#examples",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Examples",
    "text": "Examples\n\nOdd number of values:\n\nData: 12, 15, 18, 20, 25\nWhat is the median here ?\nMedian = 18 (middle value)\n\n\n\nEven number of values:\n\nData: 10, 15, 20, 25, 30, 35\nWhat is the median here ?\nMedian = \\frac{20 + 25}{2} = 22.5"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Median",
    "text": "Properties of the Median\n\nNot affected by outliers - resistant measure\nRepresents the 50th percentile\nMay not be an actual data value (when n is even)\nAppropriate for ordinal, interval, and ratio data\nDivides data into two equal halves"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Median",
    "text": "When to Use the Median\n✅ Use the median when:\n\nData is skewed (not symmetric)\nOutliers are present\nWorking with ordinal data\nWant a robust measure of central tendency\nData represents income, housing prices, or similar distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "href": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Median vs Mean with Outliers",
    "text": "Median vs Mean with Outliers\nConsider household incomes: $30,000, $32,000, $35,000, $38,000, $2,000,000\n\n\nMean = $427,000 (not representative of typical household)\nMedian = $35,000 (better represents typical household)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\n\n🎯 Definition: The mode is the value that appears most frequently in a dataset.\n\n%%{init: {'flowchart': {'nodeSpacing': 100, 'rankSpacing': 100}, 'width': 600, 'height': 400}}%%\ngraph TD\n    A[\"Mode Types\"]\n    A --&gt; B[\"Unimodal&lt;br/&gt;One peak\"]\n    A --&gt; C[\"Bimodal&lt;br/&gt;Two peaks\"]\n    A --&gt; D[\"Multimodal&lt;br/&gt;Multiple peaks\"]\n    A --&gt; E[\"No Mode&lt;br/&gt;No repeated values\"]\n    \n    classDef main fill:#e1f5fe,stroke:#01579b,stroke-width:3px,font-size:16px\n    classDef types fill:#f5f5f5,stroke:#424242,stroke-width:2px,font-size:14px\n    \n    class A main\n    class B,C,D,E types"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Distributions by Mode",
    "text": "Types of Distributions by Mode\n\nUnimodal: One mode\nBimodal: Two modes\n\nMultimodal: More than two modes\nNo mode: All values appear with equal frequency"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 1:",
    "text": "Example 1:\nData: 2, 3, 3, 4, 5, 5, 5, 6, 7\n\nAnalysis:\n\nCount each value: 2(1), 3(2), 4(1), 5(3), 6(1), 7(1)\nMost frequent value: 5 appears 3 times\nMode = 5\nType: Unimodal (one mode)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 2:",
    "text": "Example 2:\nData: 1, 2, 2, 3, 4, 4, 5\n\nAnalysis:\n\nCount each value: 1(1), 2(2), 3(1), 4(2), 5(1)\nMost frequent values: 2 and 4 both appear twice\nModes = 2 and 4\nType: Bimodal (two modes)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 3:",
    "text": "Example 3:\nData: 1, 2, 3, 4, 5\n\nAnalysis:\n\nCount each value: 1(1), 2(1), 3(1), 4(1), 5(1)\nAll values appear exactly once\nNo mode (no value repeats)\nType: No mode"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "href": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mode for Different Data Types",
    "text": "Mode for Different Data Types\nCategorical Data:\nFavorite colors: Red, Blue, Blue, Green, Blue, Red, Blue Mode = Blue\nContinuous Data:\nOften requires grouping into intervals or bins Example: Heights grouped into ranges"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mode",
    "text": "Properties of the Mode\n\nCan be used with any type of data (nominal, ordinal, interval, ratio)\nNot affected by outliers\nMay not exist or may not be unique\nRepresents the most common value\nEasy to identify in frequency distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mode",
    "text": "When to Use the Mode\n✅ Use the mode when:\n\nWorking with categorical (nominal) data\nWant to identify the most popular or common choice\nData has clear peaks in frequency\nQuality control applications (most common defect type)\nBusiness applications (best-selling product, most common customer complaint)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Comparing Measures of Central Tendency",
    "text": "Comparing Measures of Central Tendency\n\n\n\n\n\n\n\n\n\n\nMeasure\nBest for Data Type\nStrengths\nWeaknesses\nAffected by Outliers?\n\n\n\n\nMean\nInterval, Ratio\nUses all data, mathematically tractable\nSensitive to outliers\nYes\n\n\nMedian\nOrdinal, Interval, Ratio\nRobust to outliers, represents middle\nIgnores extreme values\nNo\n\n\nMode\nAll types\nWorks with categorical, identifies most common\nMay not exist/be unique\nNo"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "href": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Shape of Distribution Effects",
    "text": "Shape of Distribution Effects\n\nSymmetric distribution: Mean ≈ Median ≈ Mode\nRight-skewed (positively skewed): Mean &gt; Median &gt; Mode\n\nLeft-skewed (negatively skewed): Mode &gt; Median &gt; Mean"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "href": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Central Measures",
    "text": "Central Measures\n\n\n\nMean CalculationMedian CalculationMode Calculation\n\n\n\n# Import numpy library for numeric operations\nimport numpy as np \n\n# Import pandas library for data structures\nimport pandas as pd\n\n# Define sample data as a list of test scores\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\n\n# Compute the arithmetic mean using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np:.2f}\")\n\n# Convert the data list into a pandas DataFrame\ndf = pd.DataFrame({'scores': data})\n\n# Compute the arithmetic mean using Pandas\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd:.2f}\")\n\n# Manually sum all scores and divide by count\nmanual_mean = sum(data) / len(data)\nprint(f\"Mean (Manual): {manual_mean:.2f}\")\n\nMean (NumPy): 87.10\nMean (Pandas): 87.10\nMean (Manual): 87.10\n\n\n\n\n\n# Compute the median value using NumPy\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np:.2f}\")\n\n# Compute the median value using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd:.2f}\")\n\n# Sort the data list in ascending order\nsorted_data = sorted(data)\n\n# Determine the number of elements\nn = len(sorted_data)\n\n# If even count, average the two middle elements; else take middle element\nif n % 2 == 0:\n    manual_median = (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2\nelse:\n    manual_median = sorted_data[n//2]\n\nprint(f\"Median (Manual): {manual_median:.2f}\")\n\nMedian (NumPy): 87.50\nMedian (Pandas): 87.50\nMedian (Manual): 87.50\n\n\n\n\n\n# Import SciPy stats module to compute mode\nfrom scipy import stats\n\n# Use SciPy to find the most common value and its count\nmode_result = stats.mode(data, keepdims=True)\nprint(f\"Mode (SciPy): {mode_result.mode[0]}, Count: {mode_result.count[0]}\")\n\n# Use Pandas to get mode(s) from the DataFrame\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\n# Import Counter for manual frequency counting\nfrom collections import Counter\n\n# Count occurrences of each score\ncounter = Counter(data)\n\n# Find the highest frequency\nmax_count = max(counter.values())\n\n# Identify all values that appear with that frequency\nmodes = [k for k, v in counter.items() if v == max_count]\n\nprint(f\"Mode (Manual): {modes}, Count: {max_count}\")\n\nMode (SciPy): 85, Count: 2\nMode (Pandas): [85]\nMode (Manual): [85], Count: 2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "href": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mean, Mode and Median Visualization",
    "text": "Mean, Mode and Median Visualization\n\nCodeVisualization\n\n\n\n# import libraries\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n# define your data and compute statistics here\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\nmean_np   = np.mean(data)\nmedian_np = np.median(data)\n# for mode, use Counter\ncounter   = Counter(data)\nmax_count = max(counter.values())\nmodes     = [k for k,v in counter.items() if v==max_count]\nmode_val  = modes[0]\n\n\n\n\n\n\n\n\nDistribution of Test Scores with Central Tendency Measures"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Business Applications",
    "text": "Business Applications\n\nCustomer Satisfaction: Mean rating shows overall satisfaction, median shows typical experience\nSales Data: Mode identifies best-selling products, median shows typical sale amount\n\nEmployee Performance: Mean for overall team performance, median for typical employee"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Educational Applications",
    "text": "Educational Applications\n\nTest Scores: Mean for class average, median for typical student performance\nGrade Distribution: Mode shows most common grade\nAttendance: Mean for overall attendance rate"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Healthcare Applications",
    "text": "Healthcare Applications\n\nPatient Wait Times: Median often preferred due to skewed distributions\nTreatment Outcomes: Mean for overall effectiveness, mode for most common result\nVital Signs: All three measures provide different insights"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "href": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Interpretation Guidelines",
    "text": "Interpretation Guidelines\n\nAlways consider the context of your data\nReport multiple measures when appropriate\n\nBe aware of data distribution shape\nConsider the presence of outliers\nChoose the most appropriate measure for your specific question"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "href": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Remember These Points",
    "text": "Remember These Points\n\nData type determines which statistics are appropriate\nMean uses all data but is sensitive to outliers\nMedian is robust and represents the middle value\nMode identifies the most common value and works with all data types\nContext matters when choosing and interpreting measures\nPython provides powerful tools for calculating descriptive statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "href": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Next Lecture Preview",
    "text": "Next Lecture Preview\nDescriptive Statistics Part II will cover:\n\nMeasures of variability (range, variance, standard deviation)\nMeasures of position (percentiles, quartiles, z-scores)\nShape of distributions (skewness and kurtosis)\nAdvanced Python visualization techniques"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "href": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Try These Problems",
    "text": "Try These Problems\n\nCalculate mean, median, and mode for: 12, 15, 18, 12, 20, 25, 12, 30\nA dataset has mean = 50 and median = 45. What does this tell you about the distribution?\nWhy might median be preferred over mean for reporting household income?\nCreate a Python function to identify the most appropriate measure of central tendency for a given dataset."
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#example-2-study-time-vs.-test-score",
    "href": "files/lecture_notes/lecture14/lecture14.html#example-2-study-time-vs.-test-score",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "Example 2: Study Time vs. Test Score 📚",
    "text": "Example 2: Study Time vs. Test Score 📚\n\n\n🎯 Problem Setup\nResearch Question: Does study time predict test performance?\nData: 10 students’ study hours and test scores\n\n\n\nHours (x)\nScore (y)\n\n\n\n\n2\n70\n\n\n3\n75\n\n\n4\n80\n\n\n5\n82\n\n\n6\n85\n\n\n7\n88\n\n\n8\n90\n\n\n1\n65\n\n\n9\n92\n\n\n10\n95\n\n\n\nTasks: 1. Find the regression equation 2. Calculate R² 3. Predict score for 6.5 hours of study 4. Interpret the y-intercept\n\n\nShow Solution\n\n\nStep 1: Calculate basic statistics - n = 10 - \\bar{x} = 5.5 hours - \\bar{y} = 82.2 points - s_x = 2.87, s_y = 9.19\nStep 2: Calculate correlation Using the formula with sums: - \\sum(x-\\bar{x})(y-\\bar{y}) = 230.5 - \\sum(x-\\bar{x})^2 = 82.5 - \\sum(y-\\bar{y})^2 = 760.4\nr = \\frac{230.5}{\\sqrt{82.5 \\times 760.4}} = \\frac{230.5}{250.4} = 0.921\nStep 3: Calculate slope and intercept b = r \\cdot \\frac{s_y}{s_x} = 0.921 \\times \\frac{9.19}{2.87} = 2.95 a = \\bar{y} - b\\bar{x} = 82.2 - 2.95(5.5) = 66.0\nStep 4: Write equation \\hat{y} = 66.0 + 2.95x\nStep 5: Calculate R² R^2 = r^2 = (0.921)^2 = 0.848\nStep 6: Make prediction For x = 6.5: \\hat{y} = 66.0 + 2.95(6.5) = 85.2 points\nStep 7: Interpret y-intercept When study time = 0 hours, predicted score = 66.0 points (baseline knowledge)\n\n\n\n\n\n                            \n                                            \n\n\n📊 Analysis Summary:\n\nSlope = 2.95: Each hour ↑ → 2.95 points ↑\nR² = 0.848: 84.8% of score variation explained\nStrong positive relationship (r = 0.921)\nPractical significance: Study time matters!"
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#resources",
    "href": "files/lecture_notes/lecture14/lecture14.html#resources",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "Resources",
    "text": "Resources\n\nOpenIntro Statistics, Ch. 8 – Introduction to linear regression\nIntro to Linear Regression\nKhan Academy - Fitting a line to Data"
  },
  {
    "objectID": "files/lecture_notes/lecture14/lecture14.html#example-1-height-vs.-shoe-size",
    "href": "files/lecture_notes/lecture14/lecture14.html#example-1-height-vs.-shoe-size",
    "title": "PSTAT 5A: Linear Regression Basics",
    "section": "Example 1: Height vs. Shoe Size 👟",
    "text": "Example 1: Height vs. Shoe Size 👟\n\n\n🎯 Problem Setup\nResearch Question: Can we predict height from shoe size?\nData: 8 college students\n\n\n\nStudent\nShoe Size (x)\nHeight (y)\n\n\n\n\n1\n7\n65\n\n\n2\n8\n67\n\n\n3\n9\n69\n\n\n4\n10\n71\n\n\n5\n11\n73\n\n\n6\n12\n75\n\n\n7\n9.5\n70\n\n\n8\n8.5\n68\n\n\n\nFind: Regression equation and interpret the slope.\n\n\nShow Solution\n\n\nStep 1: Calculate means\n\n\\bar{x} = \\frac{7+8+9+10+11+12+9.5+8.5}{8} = \\frac{75}{8} = 9.375\n\\bar{y} = \\frac{65+67+69+71+73+75+70+68}{8} = \\frac{558}{8} = 69.75\n\nStep 2: Calculate slope components\n\n\n\n\n\n\n\n\n\n\n\nx\ny\n(x-\\bar{x})\n(y-\\bar{y})\n(x-\\bar{x})(y-\\bar{y})\n(x-\\bar{x})^2\n\n\n\n\n7\n65\n-2.375\n-4.75\n11.281\n5.641\n\n\n8\n67\n-1.375\n-2.75\n3.781\n1.891\n\n\n9\n69\n-0.375\n-0.75\n0.281\n0.141\n\n\n10\n71\n0.625\n1.25\n0.781\n0.391\n\n\n11\n73\n1.625\n3.25\n5.281\n2.641\n\n\n12\n75\n2.625\n5.25\n13.781\n6.891\n\n\n9.5\n70\n0.125\n0.25\n0.031\n0.016\n\n\n8.5\n68\n-0.875\n-1.75\n1.531\n0.766\n\n\n\nSums: \\sum(x-\\bar{x})(y-\\bar{y}) = 36.75, \\sum(x-\\bar{x})^2 = 18.375\nStep 3: Calculate slope and intercept b = \\frac{36.75}{18.375} = 2.0 a = 69.75 - 2.0(9.375) = 69.75 - 18.75 = 51.0\nStep 4: Write equation \\hat{y} = 51.0 + 2.0x\nInterpretation: For each additional shoe size, height increases by 2.0 inches on average.\n\n\n\n\n\n                            \n                                            \n\n\n🔍 Key Insights:\n\nSlope = 2.0: Each shoe size ↑ → 2 inches taller\nR² = 0.968: 96.8% of height variation explained\nStrong positive relationship"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Class Schedule",
    "section": "",
    "text": "⚠️\n\nImportant: This schedule is subject to change. Please check back regularly for updates and announcements.\n\n\n\n\n\n\nLabs & Worksheets\n\n\n\n\n\nQuizzes & Exams\n\n\n\n\n\nLecture Materials\n\n\n\n\n\nAnonymous Feedback Survey\n\n\n\n\n\n\nWeek 1Intro & Descriptive Stats\n\n\nWeek 2Probability Foundations\n\n\nWeek 3Conditional Probability\n\n\nWeek 4Random Variables\n\n\nWeek 5Inference & Modeling\n\n\nWeek 6Hypothesis Testing\n\n\n\n\n\n\nAll Content\n\n\nLectures\n\n\nLabs\n\n\nWorksheets\n\n\n\n\nWeek 1: Introduction & Descriptive Statistics\n\n\n\n\n1\n\n\n6/23\n\n\nIntroduction\n\n\nLab 1\nlab1 Solutions\n\n\nWorksheet 1\n\n\n\n\n\n\n\n6/24\n\n\nNo class (lecture canceled)\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n6/25\n\n\nDescriptive Statistics I\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n6/26\n\n\nDescriptive Statistics II\nLinear Transformations (Worksheet 1 Q3)\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n\n\nAll Content\n\n\nLectures\n\n\nLabs\n\n\nWorksheets\n\n\n\n\nWeek 2: Probability Foundations\n\n\n\n\n2\n\n\n6/30\n\n\nDescriptive Statistics II (Continued)\n\n\nLab2\nLab2 Notebook\nlab2 Solutions\n\n\nWorksheet 2\nWorksheet 2 Solutions\n\n\n\n\n\n\n\n7/01\n\n\nIntro to Probability\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/02\n\n\nIntro to Probability (Continued)\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/03\n\n\nConditional Probability, Independence, & Bayes Theorem\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n\n\nAll Content\n\n\nLectures\n\n\nLabs\n\n\nWorksheets\n\n\nQuizzes\n\n\n\n\nWeek 3: Conditional Probability, Counting & Random Variables\n\n\n\n\n3\n\n\n7/07\n\n\nConditional Probability & Bayes Theorem\n\n\nLab3\nLab3 Solutions\n\n\nWorksheet 3\nWorksheet 3 Solutions\n\n\n\n\n\n\n\n7/08\n\n\nIntro to Counting & Permutations\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/09\n\n\nIntro to Counting & Combinations\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/10\n\n\nDiscrete Random Variables\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/11\n\n\nQuiz 1 (Weeks 1–2)\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n\n\nAll Content\n\n\nLectures\n\n\nLabs\n\n\nWorksheets\n\n\n\n\nWeek 4: Random Variables & Distributions - Confidence Intervals\n\n\n\n\n4\n\n\n7/14\n\n\nContinuous Random Variables & Distributions\n\n\nLab 4\nlab 4 Solutions\n\n\nWorksheet 4\nWorksheet 4 Solutions\n\n\n\n\n\n\n\n7/15\n\n\nContinuous Random Variables & Distributions Continued\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/16\n\n\nContinuous Random Variables & Distributions Wrap Up & Exercises\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/17\n\n\nRandom Variables, Sampling & Intro to Confidence Intervals\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n\n\nAll Content\n\n\nLectures\n\n\nLabs\n\n\nWorksheets\n\n\nQuizzes\n\n\n\n\nWeek 5: Inference & Statistical Modeling\n\n\n\n\n5\n\n\n7/21\n\n\nSampling Principles and Strategies\n\n\nLab 5\nLab5 Solutions\n\n\nWorksheet 5\nWorksheet 5 Solutions\n\n\n\n\n\n\n\n7/22\n\n\nConfidence Intervals (Means & Proportions)\n\nZ-table, t-table\n\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/23\n\n\nConfidence Intervals Deep Dive\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/24\n\n\nHypothesis Testing\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/25\n\n\nQuiz 2 (Weeks 3–4)\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n\n\nAll Content\n\n\nLectures\n\n\nLabs\n\n\nWorksheets\n\n\nQuizzes\n\n\n\n\nWeek 6: Hypothesis Testing, Regression & Course Wrap-Up\n\n\n\n\n6\n\n\n7/28\n\n\nHypothesis Testing Notes\n\n\nLab 6\nLab 6 Solutions\n\n\nWorksheet 6\nWorksheet 6 Solutions\n\n\n\n\n\n\n\n7/29\n\n\nLinear Regression Basics\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/30 - 7/31\n\n\nLinear Regression Notes\n\n\n\nCourse Wrap-Up & Quiz Review\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n8/01\n\n\nQuiz 3 (Weeks 5–6)\n\n\n—\n\n\n—"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Course Resources",
    "section": "",
    "text": "🔍"
  },
  {
    "objectID": "resources.html#getting-started-with-data",
    "href": "resources.html#getting-started-with-data",
    "title": "Course Resources",
    "section": "Getting Started with Data",
    "text": "Getting Started with Data\nThis week introduces fundamental concepts in data science, including data types, basic statistics, and essential Python tools for data manipulation and analysis."
  },
  {
    "objectID": "resources.html#understanding-uncertainty-through-statistics",
    "href": "resources.html#understanding-uncertainty-through-statistics",
    "title": "Course Resources",
    "section": "Understanding Uncertainty Through Statistics",
    "text": "Understanding Uncertainty Through Statistics\nThis week introduces fundamental concepts in probability theory, including sample spaces, events, conditional probability, independence, and Bayes’ theorem. You’ll learn to quantify uncertainty and make informed decisions with incomplete information."
  },
  {
    "objectID": "resources.html#advanced-probability-discrete-distributions",
    "href": "resources.html#advanced-probability-discrete-distributions",
    "title": "Course Resources",
    "section": "Advanced Probability & Discrete Distributions",
    "text": "Advanced Probability & Discrete Distributions\nThis week deepens your understanding of conditional probability and Bayes’ theorem, introduces counting principles (permutations and combinations), and explores discrete random variables including their probability mass functions, expected values, and common distributions."
  },
  {
    "objectID": "resources.html#from-discrete-to-continuous-understanding-density-and-intervals",
    "href": "resources.html#from-discrete-to-continuous-understanding-density-and-intervals",
    "title": "Course Resources",
    "section": "From Discrete to Continuous: Understanding Density and Intervals",
    "text": "From Discrete to Continuous: Understanding Density and Intervals\nThis week transitions from discrete to continuous random variables, introducing probability density functions, common continuous distributions, and the foundations of statistical inference through confidence intervals. You’ll learn how the Central Limit Theorem enables us to make probabilistic statements about population parameters."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html",
    "href": "files/lecture_notes/lecture7/lecture7.html",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "",
    "text": "Discrete Random Variables\nFrom outcomes to numbers: quantifying randomness"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-8",
    "href": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-8",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Welcome to Lecture 8",
    "text": "Welcome to Lecture 8\nDiscrete Random Variables\nFrom outcomes to numbers: quantifying randomness"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Today’s Learning Objectives",
    "text": "Today’s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine random variables and distinguish discrete from continuous\nWork with probability mass functions (PMFs) and cumulative distribution functions (CDFs)\nCalculate expected values and variances for discrete random variables\nApply properties of expectation and variance\nWork with common discrete distributions (Bernoulli, Binomial, Geometric, Poisson)\nSolve real-world problems using discrete random variables\nUse python to compute probabilities and parameters"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "href": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "What is a Random Variable?",
    "text": "What is a Random Variable?\n\nDefinition: A random variable is a function that assigns a numerical value to each outcome of a random experiment.\nNotation: Usually denoted by capital letters X, Y, Z\nKey insight: Random variables transform outcomes into numbers, making statistical analysis possible\n\n\n\nTreena - Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#die-roll-example-mapping-outcomes-to-numbers",
    "href": "files/lecture_notes/lecture7/lecture7.html#die-roll-example-mapping-outcomes-to-numbers",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Die Roll Example: Mapping Outcomes to Numbers",
    "text": "Die Roll Example: Mapping Outcomes to Numbers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n\n\n\nRandom Variable X maps each die face to its numerical value."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Why Use Random Variables?",
    "text": "Why Use Random Variables?\n\n\nRandom variables allow us to:\n\nQuantify outcomes numerically\nCalculate means, variances, and other statistics\nModel real-world phenomena\nMake predictions and decisions\nCompare different random processes\n\nExamples: Height, test scores, number of defects, wait times, stock prices\n\n\n\nTreena - Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Types of Random Variables",
    "text": "Types of Random Variables\n\n\nToday we focus on discrete random variables - notice there are gaps between possible values!\n\n\n\nDiscrete vs. Continuous: Demystifying the type of Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "href": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Probability Mass Function (PMF)",
    "text": "Probability Mass Function (PMF)\n\n\nDefinition: The Probability Mass Function (PMF) of a discrete random variable X is:\n\n\nP(X = x) = \\text{probability that } X \\text{ takes the value } x\n\n\nProperties of PMF:\n\n\n\nP(X = x) \\geq 0 for all x\n\n\n\\sum_{\\text{all } x} P(X = x) = 1"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "href": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "PMF Example: Two Coin Flips",
    "text": "PMF Example: Two Coin Flips\n\nTwo Coin Flips - Number of Heads\nLet X = number of heads in two coin flips\nSample Space: \\{HH, HT, TH, TT\\}\n\n\n\nH T H T\n\n\nCurrent outcome: H T H T\n\nClick coins to flip them!\n\nTable summarizes by number of heads, not the exact sequence.\n\n\n\n\n\nx (heads)\n\n\nOutcomes\n\n\nP(X = x)\n\n\nEmpirical\n\n\n\n\n\n\n0\n\n\nTT\n\n\n0.25\n\n\n0\n\n\n\n\n1\n\n\nHT, TH\n\n\n0.50\n\n\n0\n\n\n\n\n2\n\n\nHH\n\n\n0.25\n\n\n0\n\n\n\n\n\nEmpirical probability updates as you flip!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "href": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\n\n\n\nThe cumulative distribution function of a random variable X is:\nF(x) = P(X \\leq x)\nProperties of CDF: 1. F(x) is non-decreasing 2. \\lim_{x \\to -\\infty} F(x) = 0 3. \\lim_{x \\to \\infty} F(x) = 1 4. F(x) is right-continuous"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#expected-value-and-variance",
    "href": "files/lecture_notes/lecture7/lecture7.html#expected-value-and-variance",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value and Variance",
    "text": "Expected Value and Variance\nThe expected value of a discrete random variable X is:\nE[X] = \\mu = \\sum_{\\text{all } x} x \\cdot P(X = x)\nThe variance of a random variable X measures spread around the mean:\n\\text{Var}(X) = \\sigma^2 = E[(X - \\mu)^2] = E[X^2] - (E[X])^2\n\nExpected value represents the long-run average if we repeat the experiment many times."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#law-of-large-numbers-demo",
    "href": "files/lecture_notes/lecture7/lecture7.html#law-of-large-numbers-demo",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Law of Large Numbers Demo",
    "text": "Law of Large Numbers Demo\n\nLaw of Large Numbers Demo\n\n\nRun Simulation\n\n 100 trials 500 trials 1000 trials 5000 trials \n\n\n\n\n\nWatch how the sample mean converges to the expected value! {.smaller}"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#common-discrete-distributions",
    "href": "files/lecture_notes/lecture7/lecture7.html#common-discrete-distributions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Common Discrete Distributions",
    "text": "Common Discrete Distributions\n\nBernoulli\nSingle trial, two outcomes\nParameters: p (success probability)\nPMF: P(X = 1) = p, P(X = 0) = 1-p\nMean: p\nVariance: p(1-p)\n\n\nBinomial\nn independent Bernoulli trials\nParameters: n (trials), p (success prob.)\nPMF: P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\nMean: np\nVariance: np(1-p)\n\n\nGeometric\nTrials until first success\nParameters: p (success probability)\nPMF: P(X = k) = (1-p)^{k-1} p\nMean: 1/p\nVariance: (1-p)/p^2\n\n\nPoisson\nEvents in fixed interval\nParameters: \\lambda (average rate)\nPMF: P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\nMean: \\lambda\nVariance: \\lambda"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#interactive-distribution-explorer",
    "href": "files/lecture_notes/lecture7/lecture7.html#interactive-distribution-explorer",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Interactive Distribution Explorer",
    "text": "Interactive Distribution Explorer\n\nDistribution Visualizer\n\n Binomial Geometric Poisson  Parameter 1:  Parameter 2:"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\nA box contains 3 red balls and 2 blue balls. Two balls are drawn without replacement. Let X = number of red balls drawn. Find the PMF of X.\n\nShow Solution\n\n\nSolution. X can take values 0, 1, or 2.\nP(X = 0) = \\frac{\\binom{3}{0}\\binom{2}{2}}{\\binom{5}{2}} = \\frac{1 \\times 1}{10} = \\frac{1}{10}\nP(X = 1) = \\frac{\\binom{3}{1}\\binom{2}{1}}{\\binom{5}{2}} = \\frac{3 \\times 2}{10} = \\frac{6}{10}\nP(X = 2) = \\frac{\\binom{3}{2}\\binom{2}{0}}{\\binom{5}{2}} = \\frac{3 \\times 1}{10} = \\frac{3}{10}\nCheck: \\frac{1}{10} + \\frac{6}{10} + \\frac{3}{10} = 1 ✓"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2-expected-value",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2-expected-value",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 2: Expected Value",
    "text": "Practice Problem 2: Expected Value\n\nUsing the red balls example from Problem 1, find E[X] and \\text{Var}(X).\n\nShow Solution\n\n\nSolution. Expected Value: E[X] = 0 \\times \\frac{1}{10} + 1 \\times \\frac{6}{10} + 2 \\times \\frac{3}{10} = 0 + \\frac{6}{10} + \\frac{6}{10} = 1.2\nVariance: E[X^2] = 0^2 \\times \\frac{1}{10} + 1^2 \\times \\frac{6}{10} + 2^2 \\times \\frac{3}{10} = 0 + \\frac{6}{10} + \\frac{12}{10} = 1.8\n\\text{Var}(X) = E[X^2] - (E[X])^2 = 1.8 - (1.2)^2 = 1.8 - 1.44 = 0.36\nStandard Deviation: \\sigma = \\sqrt{0.36} = 0.6"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nA student takes a 10-question multiple choice quiz with 4 options per question. If the student guesses randomly, what’s the probability of getting exactly 3 correct?\n\nShow Solution\n\n\nSolution. This is a binomial distribution with n = 10, p = 1/4 = 0.25\nP(X = 3) = \\binom{10}{3} \\times (0.25)^3 \\times (0.75)^7\nP(X = 3) = 120 \\times 0.015625 \\times 0.1335 \\approx 0.2503\nSo there’s about a 25% chance of getting exactly 3 correct by guessing."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "href": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Properties of Expected Value",
    "text": "Properties of Expected Value\n\n\n\nLinearity of Expectation\n\nE[c] = c (constant)\nE[cX] = c \\cdot E[X] (scaling)\nE[X + Y] = E[X] + E[Y] (additivity)\nE[aX + bY + c] = aE[X] + bE[Y] + c\n\n\nVariance Properties\n\n\\text{Var}(aX + b) = a^2 \\text{Var}(X)\n\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) (if X and Y are independent)\n\n\nImportant: Property 3 holds even if X and Y are dependent!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#key-takeaways",
    "href": "files/lecture_notes/lecture7/lecture7.html#key-takeaways",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\n\n\nMain Concepts\n\nRandom variables transform outcomes into numbers for mathematical analysis\nPMF gives probabilities for specific values; CDF gives cumulative probabilities\nExpected value is the long-run average; variance measures spread\n\n\nDistribution Selection\nChoose distributions based on the underlying process:\n\nBernoulli for single trials\nBinomial for fixed trials\nGeometric for waiting times\nPoisson for rates\n\nKey Principle\n\nLaw of Large Numbers connects theoretical expectations with observed averages"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "href": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\nNext Lecture: Continuous Random Variables\nTopics we’ll cover:\n\nProbability density functions (PDFs)\nNormal distribution\nExponential distribution\nCentral Limit Theorem applications\n\n\nConnection: Discrete distributions often approximate continuous ones, and vice versa"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#questions",
    "href": "files/lecture_notes/lecture7/lecture7.html#questions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: 11AM on Thursday (link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Continuous Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#resources",
    "href": "files/lecture_notes/lecture7/lecture7.html#resources",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Resources",
    "text": "Resources\n\n\n\n Read OpenIntro Statistics Chapter 3 section 3.4\n\n\n Random Variable - Treena Courses\n\n\n Random Variables and Probability Functions\n\n\n Random Variables - Distribution and Expectation\n\n\n Khan Academy - Unit9: Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html",
    "href": "files/lecture_notes/lecture12/lecture12.html",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "",
    "text": "Confidence Intervals: From Theory to Practice\n“A confidence interval is a way of expressing uncertainty in a precise, mathematical way”\n\n\n\n\n\n\n\nWhen:\n- 📅 Date: Friday, July 25\n- ⏰ Window: 7 AM – 12 AM\n- ⏳ Duration: 1 hour once started\nWhere: 💻 Online via Canvas\nCovers: Material from Weeks 3-4\n\n\n\n\n\nDiscrete & continuous distributions\nProbability calculations\nExpected value & variance\nNormal distribution applications\nNote: Upload photos of written work for calculation problems\n\n\n\n\n\n\n\n\n\n\n\n\nKnow the difference between \\(z\\) and \\(t\\) distributions\nUnderstand when to use each distribution\nLearn to find critical values from tables and plots\nPractice calculating confidence intervals step-by-step\nInterpret results correctly in context\n\n\n\n\n\n\nReview: Confidence interval basics\nThe t-Distribution: When and why we use it\nCritical Regions: Finding the right values\nPractical Examples: z and t calculations\nCommon Mistakes: What to avoid\nReal Applications: Making it meaningful\n\n\n\n\n\n\n\n\n\n\n\n\nA confidence interval (CI) takes a single sample statistic and turns it into a range that is likely to contain an unknown population parameter; most often the mean \\(\\mu\\).\nCI template\n\\[\n\\underbrace{\\text{Point estimate}}_{\\color{blue}{(e.g., \\bar{x})}}\n\\;\\pm\\;\n\\underbrace{\\text{(critical value) $\\times$ (standard error)}}_{\\color{red}{\\text{Margin of Error (ME)}}}\n\\]\nFor the mean\n\n\n\n\n\n\n\n\nSituation\nFormula\nDistribution\n\n\n\n\nσ known (rare)\n\\(\\displaystyle \\bar{x} \\;\\pm\\; z^{*}\\,\\frac{\\sigma}{\\sqrt{n}}\\)\nz-distribution\n\n\nσ unknown (typical)\n\\(\\displaystyle \\bar{x} \\;\\pm\\; t^{*}\\,\\frac{s}{\\sqrt{n}}\\)\nt-distribution (\\(df = n-1\\))\n\n\n\nKey points\n\nWe never know the true mean \\(\\mu\\) in practice, that’s exactly what the CI estimates.\n\nUse the population SD σ only when it is genuinely known (e.g., industrial process with long‑term QC).\n\nOtherwise substitute the sample SD s and switch to the t‑distribution, which is wider to reflect that extra uncertainty.\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nKey Formula: \\(\\bar{x} \\pm z^* \\cdot \\frac{s}{\\sqrt{n}}\\) (when using z-distribution)\n\n\n\n\n\n\n\n\n\n\nResearch Question: What is the average SAT score of students at UCSB?\nGiven Information:\n\nSample size: \\(n = 50\\) students\nSample mean: \\(\\bar{x} = 1180\\)\nPopulation standard deviation: \\(\\sigma = 120\\) (known from past data)\nConfidence level: \\(95\\%\\)\n\nQuestion: Construct a \\(95\\%\\) confidence interval for the population mean SAT score.\n\n\nShow Solution\n\n\nStep 1: Check conditions\n\n\\(\\sigma\\) is known ✓\nUse z-distribution ✓\n\nStep 2: Find critical value\n\nFor \\(95\\%\\) CI: \\(\\alpha = 0.05, \\frac{\\alpha}{2} = 0.025\\)\n\\(z^* = 1.96\\) (from z-table)\n\nStep 3: Calculate SE\n\\[SE = \\frac{\\sigma}{\\sqrt{n}} = \\frac{120}{\\sqrt{50}} = \\frac{120}{7.071} = 16.97\\]\nStep 4: Calculate Margin of Error\n\\[ME = z^* \\times SE = 1.96 \\times 16.97 = 33.26\\]\nStep 5: Construct CI\n\\[CI = \\bar{x} \\pm ME = 1180 \\pm 33.26 = (1146.7, 1213.3)\\]\nFinal Answer: We are 95% confident that the true average SAT score is between 1146.7 and 1213.3.\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\n\n\n\n\nResearch Question: What is the average daily coffee consumption at our office?\nGiven Information:\n- Sample size: n = 16 employees\n- Sample mean: \\(\\bar{x} = 2.8\\) cups\n- Sample standard deviation: s = 0.9 (\\(\\sigma\\) unknown)\n- Confidence level: 90%\nQuestion: Construct a 90% confidence interval for the population mean daily coffee consumption.\n\n\nShow Solution\n\n\nStep 1: Check conditions - \\(\\sigma\\) is unknown ✓ - n &lt; 30 ✓ - Use t-distribution ✓\nStep 2: Calculate degrees of freedom - df = n - 1 = 16 - 1 = 15\nStep 3: Find critical value - For 90% CI: \\(\\alpha = 0.10, \\alpha/2 = 0.05\\) - t* = 1.753 (from t-table, df = 15)\nStep 4: Calculate SE\n\\[SE = \\frac{s}{\\sqrt{n}} = \\frac{0.9}{\\sqrt{16}} = \\frac{0.9}{4} = 0.225\\]\nStep 5: Calculate Margin of Error\n\\[ME = t^* \\times SE = 1.753 \\times 0.225 = 0.394\\]\nStep 6: Construct CI\n\\[CI = \\bar{x} \\pm ME = 2.8 \\pm 0.394 = (2.406, 3.194)\\]\nFinal Answer: We are 90% confident that the true average daily coffee consumption is between 2.406 and 3.194 cups.\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\n\n\n\n\nProblem: A researcher wants to estimate the average time students spend studying per day.\nGiven:\n\nSample size: \\(n = 25\\) students\n\nSample mean: \\(\\bar{x} = 3.2\\) hours\nSample standard deviation: \\(s = 1.1\\) hours\nConfidence level: \\(95\\%\\)\n\nQuestions:\n\nShould you use \\(z\\) or \\(t\\)-distribution? Why?\nWhat are the degrees of freedom?\nWhat is the critical value?\nCalculate the 95% confidence interval\nInterpret your result in context\n\n\n\nShow Solution\n\n\nStep 1: Distribution Choice Use t-distribution because: - σ is unknown (only sample standard deviation s is given) - n = 25 &lt; 30\nStep 2: Degrees of Freedom df = n - 1 = 25 - 1 = 24\nStep 3: Critical Value For 95% CI with df = 24: t* = 2.064\nStep 4: Calculate CI\nStandard Error: \\(SE = \\frac{s}{\\sqrt{n}} = \\frac{1.1}{\\sqrt{25}} = \\frac{1.1}{5} = 0.220\\)\nMargin of Error: \\(ME = t^* \\times SE = 2.064 \\times 0.220 = 0.454\\)\nConfidence Interval: \\(CI = \\bar{x} \\pm ME = 3.2 \\pm 0.454 = (2.746, 3.654)\\)\nStep 5: Interpretation We are 95% confident that the true average study time for students is between 2.746 and 3.654 hours per day.\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\nWhy is the t-distribution appropriate here?\nHow would the interval change if n = 100?\nWhat if we wanted 99% confidence instead?\n\n\n\n\n\n\n\n\n\n\n\n\n1. Distribution Choice - σ known → z-distribution - σ unknown + n ≥ 30 → z-distribution\n- σ unknown + n &lt; 30 → t-distribution\n2. t-Distribution Properties - Heavier tails than z - Depends on degrees of freedom (df = n-1) - Approaches z as df increases\n3. Critical Regions - α/2 in each tail for two-sided CI - Critical values from tables or software - Larger confidence → larger critical values\n\n\n\n\n4. Calculation Steps 1. Check conditions (σ known?, sample size?) 2. Choose distribution (z or t) 3. Find critical value 4. Calculate standard error 5. Compute margin of error\n6. Construct interval 7. Interpret in context\n5. Interpretation - “We are C% confident…” - Focus on the process, not individual interval - Consider practical significance\n6. Common Pitfalls to Avoid - Wrong distribution choice - Incorrect degrees of freedom - Using α instead of α/2 - Misinterpreting the interval\n\n\n\n\n\n\n\n🏠 Back to Main Page"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#important-announcements",
    "href": "files/lecture_notes/lecture12/lecture12.html#important-announcements",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "📢 Important Announcements",
    "text": "📢 Important Announcements\n\n\n📝 Quiz 2 Details\nWhen:\n- 📅 Date: Friday, July 25\n- ⏰ Window: 7 AM – 12 AM\n- ⏳ Duration: 1 hour once started\nWhere: 💻 Online via Canvas\nCovers: Material from Weeks 3-4\n\n📚 What to Expect\n\nDiscrete & continuous distributions\nProbability calculations\nExpected value & variance\nNormal distribution applications\nNote: Upload photos of written work for calculation problems"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#todays-roadmap",
    "href": "files/lecture_notes/lecture12/lecture12.html#todays-roadmap",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "📢 Today’s Roadmap",
    "text": "📢 Today’s Roadmap\n\n\n🎯 Learning Objectives\n\nKnow the difference between z and t distributions\nUnderstand when to use each distribution\nLearn to find critical values from tables and plots\nPractice calculating confidence intervals step-by-step\nInterpret results correctly in context\n\n\n📋 What We’ll Cover\n\nReview: Confidence interval basics\nThe t-Distribution: When and why we use it\nCritical Regions: Finding the right values\nPractical Examples: z and t calculations\nCommon Mistakes: What to avoid\nReal Applications: Making it meaningful"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#quick-review-confidence-interval-basics",
    "href": "files/lecture_notes/lecture12/lecture12.html#quick-review-confidence-interval-basics",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "Quick Review: Confidence Interval Basics 🔄",
    "text": "Quick Review: Confidence Interval Basics 🔄\n\n\n🎯 The Big Idea\nA confidence interval (CI) takes a single sample statistic and turns it into a range that is likely to contain an unknown population parameter; most often the mean \\mu.\nCI template\n\n\\underbrace{\\text{Point estimate}}_{\\color{blue}{(e.g., \\bar{x})}}\n\\;\\pm\\;\n\\underbrace{\\text{(critical value) $\\times$ (standard error)}}_{\\color{red}{\\text{Margin of Error (ME)}}}\n\nFor the mean\n\n\n\n\n\n\n\n\nSituation\nFormula\nDistribution\n\n\n\n\nσ known (rare)\n\\displaystyle \\bar{x} \\;\\pm\\; z^{*}\\,\\frac{\\sigma}{\\sqrt{n}}\nz-distribution\n\n\nσ unknown (typical)\n\\displaystyle \\bar{x} \\;\\pm\\; t^{*}\\,\\frac{s}{\\sqrt{n}}\nt-distribution (df = n-1)\n\n\n\nKey points\n\nWe never know the true mean \\mu in practice, that’s exactly what the CI estimates.\n\nUse the population SD σ only when it is genuinely known (e.g., industrial process with long‑term QC).\n\nOtherwise substitute the sample SD s and switch to the t‑distribution, which is wider to reflect that extra uncertainty.\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nKey Formula: \\bar{x} \\pm z^* \\cdot \\frac{s}{\\sqrt{n}} (when using z-distribution)"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#step-by-step-example-1-using-z-distribution",
    "href": "files/lecture_notes/lecture12/lecture12.html#step-by-step-example-1-using-z-distribution",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "Step-by-Step Example 1: Using z-Distribution 📝",
    "text": "Step-by-Step Example 1: Using z-Distribution 📝\n\n\n🎯 Problem Setup\nResearch Question: What is the average SAT score of students at UCSB?\nGiven Information:\n\nSample size: n = 50 students\nSample mean: \\bar{x} = 1180\nPopulation standard deviation: \\sigma = 120 (known from past data)\nConfidence level: 95\\%\n\nQuestion: Construct a 95\\% confidence interval for the population mean SAT score.\n\n\nShow Solution\n\n\nStep 1: Check conditions\n\n\\sigma is known ✓\nUse z-distribution ✓\n\nStep 2: Find critical value\n\nFor 95\\% CI: \\alpha = 0.05, \\frac{\\alpha}{2} = 0.025\nz^* = 1.96 (from z-table)\n\nStep 3: Calculate SE\nSE = \\frac{\\sigma}{\\sqrt{n}} = \\frac{120}{\\sqrt{50}} = \\frac{120}{7.071} = 16.97\nStep 4: Calculate Margin of Error\nME = z^* \\times SE = 1.96 \\times 16.97 = 33.26\nStep 5: Construct CI\nCI = \\bar{x} \\pm ME = 1180 \\pm 33.26 = (1146.7, 1213.3)\nFinal Answer: We are 95% confident that the true average SAT score is between 1146.7 and 1213.3."
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#step-by-step-example-2-using-t-distribution",
    "href": "files/lecture_notes/lecture12/lecture12.html#step-by-step-example-2-using-t-distribution",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "Step-by-Step Example 2: Using t-Distribution 📝",
    "text": "Step-by-Step Example 2: Using t-Distribution 📝\n\n\n🎯 Problem Setup\nResearch Question: What is the average daily coffee consumption at our office?\nGiven Information:\n- Sample size: n = 16 employees\n- Sample mean: \\bar{x} = 2.8 cups\n- Sample standard deviation: s = 0.9 (\\sigma unknown)\n- Confidence level: 90%\nQuestion: Construct a 90% confidence interval for the population mean daily coffee consumption.\n\n\nShow Solution\n\n\nStep 1: Check conditions - \\sigma is unknown ✓ - n &lt; 30 ✓ - Use t-distribution ✓\nStep 2: Calculate degrees of freedom - df = n - 1 = 16 - 1 = 15\nStep 3: Find critical value - For 90% CI: \\alpha = 0.10, \\alpha/2 = 0.05 - t* = 1.753 (from t-table, df = 15)\nStep 4: Calculate SE\nSE = \\frac{s}{\\sqrt{n}} = \\frac{0.9}{\\sqrt{16}} = \\frac{0.9}{4} = 0.225\nStep 5: Calculate Margin of Error\nME = t^* \\times SE = 1.753 \\times 0.225 = 0.394\nStep 6: Construct CI\nCI = \\bar{x} \\pm ME = 2.8 \\pm 0.394 = (2.406, 3.194)\nFinal Answer: We are 90% confident that the true average daily coffee consumption is between 2.406 and 3.194 cups."
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#practice-problem-test-your-skills",
    "href": "files/lecture_notes/lecture12/lecture12.html#practice-problem-test-your-skills",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "Practice Problem: Test Your Skills! 🧠",
    "text": "Practice Problem: Test Your Skills! 🧠\n\n\n🎯 Your Turn!\nProblem: A researcher wants to estimate the average time students spend studying per day.\nGiven:\n\nSample size: n = 25 students\n\nSample mean: \\bar{x} = 3.2 hours\nSample standard deviation: s = 1.1 hours\nConfidence level: 95\\%\n\nQuestions:\n\nShould you use z or t-distribution? Why?\nWhat are the degrees of freedom?\nWhat is the critical value?\nCalculate the 95% confidence interval\nInterpret your result in context\n\n\n\nShow Solution\n\n\nStep 1: Distribution Choice Use t-distribution because: - σ is unknown (only sample standard deviation s is given) - n = 25 &lt; 30\nStep 2: Degrees of Freedom df = n - 1 = 25 - 1 = 24\nStep 3: Critical Value For 95% CI with df = 24: t* = 2.064\nStep 4: Calculate CI\nStandard Error: SE = \\frac{s}{\\sqrt{n}} = \\frac{1.1}{\\sqrt{25}} = \\frac{1.1}{5} = 0.220\nMargin of Error: ME = t^* \\times SE = 2.064 \\times 0.220 = 0.454\nConfidence Interval: CI = \\bar{x} \\pm ME = 3.2 \\pm 0.454 = (2.746, 3.654)\nStep 5: Interpretation We are 95% confident that the true average study time for students is between 2.746 and 3.654 hours per day.\n\n\n\n\n\n                            \n                                            \n\n\n🤔 Think About It…\n\nWhy is the t-distribution appropriate here?\nHow would the interval change if n = 100?\nWhat if we wanted 99% confidence instead?"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#summary-key-takeaways",
    "href": "files/lecture_notes/lecture12/lecture12.html#summary-key-takeaways",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "Summary: Key Takeaways 🎯",
    "text": "Summary: Key Takeaways 🎯\n\n\n🧠 Core Concepts\n1. Distribution Choice - σ known → z-distribution - σ unknown + n ≥ 30 → z-distribution\n- σ unknown + n &lt; 30 → t-distribution\n2. t-Distribution Properties - Heavier tails than z - Depends on degrees of freedom (df = n-1) - Approaches z as df increases\n3. Critical Regions - α/2 in each tail for two-sided CI - Critical values from tables or software - Larger confidence → larger critical values\n\n🛠️ Practical Skills\n4. Calculation Steps 1. Check conditions (σ known?, sample size?) 2. Choose distribution (z or t) 3. Find critical value 4. Calculate standard error 5. Compute margin of error\n6. Construct interval 7. Interpret in context\n5. Interpretation - “We are C% confident…” - Focus on the process, not individual interval - Consider practical significance\n6. Common Pitfalls to Avoid - Wrong distribution choice - Incorrect degrees of freedom - Using α instead of α/2 - Misinterpreting the interval"
  },
  {
    "objectID": "files/lecture_notes/lecture12/lecture12.html#section",
    "href": "files/lecture_notes/lecture12/lecture12.html#section",
    "title": "PSTAT 5A: Confidence Intervals Deep Dive",
    "section": "",
    "text": "🏠 Back to Main Page"
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html",
    "title": "PSTAT 5A: Review Exercises",
    "section": "",
    "text": "A single fair six-sided die is rolled once.\n1.1 What is \\(P(\\text{roll is an even number})\\)?\n1.2 What is \\(P(\\text{roll is 5 or 6})\\)?"
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#basic-probability",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#basic-probability",
    "title": "PSTAT 5A: Review Exercises",
    "section": "",
    "text": "A single fair six-sided die is rolled once.\n1.1 What is \\(P(\\text{roll is an even number})\\)?\n1.2 What is \\(P(\\text{roll is 5 or 6})\\)?"
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#basic-probability-answers",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#basic-probability-answers",
    "title": "PSTAT 5A: Review Exercises",
    "section": "1. Basic Probability: Answers",
    "text": "1. Basic Probability: Answers\n1.1. \\(P(\\text{even}) = 3/6 = \\tfrac{1}{2}\\)\n1.2. \\(P(5 \\text{ or } 6) = 2/6 = \\tfrac{1}{3}\\)"
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#joint-conditional-probability",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#joint-conditional-probability",
    "title": "PSTAT 5A: Review Exercises",
    "section": "2. Joint & Conditional Probability",
    "text": "2. Joint & Conditional Probability\n\nYou draw two cards without replacement from a standard 52-card deck.\n2.1. What is the probability that the first card is an Ace?\n2.2. Given that the first card is an Ace, what is the probability that the second card is also an Ace?\n2.3. Compute \\(P(\\text{both cards are Aces})\\):\n\nas a direct joint probability.\nusing conditional probability formula."
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#joint-conditional-probability-answers",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#joint-conditional-probability-answers",
    "title": "PSTAT 5A: Review Exercises",
    "section": "2. Joint & Conditional Probability: Answers",
    "text": "2. Joint & Conditional Probability: Answers\n\nSolution. 2.1. \\(4/52 = \\tfrac{1}{13}\\)\n2.2. \\(3/51 = \\tfrac{1}{17}\\)\n2.3.\n\n\\(4/52 \\times 3/51 = 1/221\\)\n\\((1/13)\\times(1/17) = 1/221\\)"
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#independence-vs.-mutual-exclusivity",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#independence-vs.-mutual-exclusivity",
    "title": "PSTAT 5A: Review Exercises",
    "section": "3. Independence vs. Mutual Exclusivity",
    "text": "3. Independence vs. Mutual Exclusivity\n\nFlip two fair coins in sequence. Define:\n\n\\(A =\\) first flip is Heads\n\n\\(B =\\) second flip is Heads\n\n\\(C =\\) both flips are Heads\n\n3.1 Are events \\(A\\) and \\(B\\) independent?\n3.2 Are events \\(A\\) and \\(C\\) mutually exclusive?\n3.3 Compute \\(P(A\\cap B)\\) and compare with \\(P(A)P(B)\\)."
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#independence-vs.-mutual-exclusivity-answers",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#independence-vs.-mutual-exclusivity-answers",
    "title": "PSTAT 5A: Review Exercises",
    "section": "3. Independence vs. Mutual Exclusivity: Answers",
    "text": "3. Independence vs. Mutual Exclusivity: Answers\n\nSolution. \n\nYes, independent: \\(P(B|A)=1/2 = P(B)\\)\nNo, not mutually exclusive: \\(A\\cap C \\neq \\varnothing\\).\n\n\\(P(A\\cap B)=1/4, \\;P(A)P(B)=1/4\\) → matches (independence)."
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#bonus-challenge",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#bonus-challenge",
    "title": "PSTAT 5A: Review Exercises",
    "section": "4. Bonus Challenge",
    "text": "4. Bonus Challenge\n\nA bag contains 3 red balls and 2 blue balls. You draw one ball, replace it, then draw again.\n4.1 Are the two draws independent? Why or why not?\n4.2 Compute \\(P(\\text{red then blue})\\)."
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#bonus-challenge-answers",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#bonus-challenge-answers",
    "title": "PSTAT 5A: Review Exercises",
    "section": "4. Bonus Challenge: Answers",
    "text": "4. Bonus Challenge: Answers\n\nYes—they’re independent because of replacement.\n\n\\((3/5)\\times(2/5) = 6/25\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html",
    "href": "files/lecture_notes/lecture4/lecture4.html",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "",
    "text": "By the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sec-objectives",
    "href": "files/lecture_notes/lecture4/lecture4.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Today’s Learning Objectives",
    "text": "Today’s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sec-prob",
    "href": "files/lecture_notes/lecture4/lecture4.html#sec-prob",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is Probability?",
    "text": "What is Probability?\n\n🎯 Definition\nProbability is a measure of the likelihood that an event will occur"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-range",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-range",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Range",
    "text": "Probability Range\n\n\n\nRanges from 0 to 1 (or 0% to 100%)\n0: Event will never occur (impossible)\n1: Event will certainly occur (certain)\n0.5: Event has equal chance of occurring or not"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#three-ways-to-express-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#three-ways-to-express-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Three Ways to Express Probability",
    "text": "Three Ways to Express Probability\n\nFraction: \\frac{1}{2}, \\frac{3}{4}, \\frac{2}{6}\nDecimal: 0.5, 0.75, 0.33\nPercentage: 50%, 75%, 33%"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#example",
    "href": "files/lecture_notes/lecture4/lecture4.html#example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example",
    "text": "Example\nWhen we roll a die, there are six possible outcomes:\n1, 2, 3, 4, 5, 6.\nThe probability of any of them turning up is 1/6 or 16%."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#why-study-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#why-study-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Why Study Probability?",
    "text": "Why Study Probability?\nProbability helps us:\n\nMake decisions under uncertainty\nUnderstand random processes\nAnalyze data and draw conclusions\nModel real-world phenomena\nAssess risk and likelihood\n\n\n\nApplications: Weather forecasting, medical diagnosis, finance, quality control, gaming, insurance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#random-experiments",
    "href": "files/lecture_notes/lecture4/lecture4.html#random-experiments",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Random Experiments",
    "text": "Random Experiments\nA random experiment is a process that:\n\nCan be repeated under similar conditions\nHas multiple possible outcomes\nThe outcome cannot be predicted with certainty\n\n\n\nExamples\n\n🪙 Flipping a coin\n🎲 Rolling a die\n🃏 Drawing a card from a deck\n💡 Measuring the lifetime of a light bulb"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sample-space",
    "href": "files/lecture_notes/lecture4/lecture4.html#sample-space",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space",
    "text": "Sample Space\n\n🎯 Definition The sample space (denoted S or \\Omega) is the set of all possible outcomes of a random experiment"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sample-space-examples",
    "href": "files/lecture_notes/lecture4/lecture4.html#sample-space-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space Examples",
    "text": "Sample Space Examples\n\nCoin flip: S = \\{H, T\\}\nTwo coin flips: S = \\{HH, HT, TH, TT\\}"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#types-of-sample-spaces",
    "href": "files/lecture_notes/lecture4/lecture4.html#types-of-sample-spaces",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Types of Sample Spaces",
    "text": "Types of Sample Spaces\n\n\nFinite Sample Space\n\nLimited number of outcomes\n\nExample: Rolling a die\n\n\n\n\n\n\n\n\n\n\n\nInfinite Sample Space\n\nUnlimited outcomes (countable or uncountable)\n\nExample: Measuring exact height of students"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#events",
    "href": "files/lecture_notes/lecture4/lecture4.html#events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Events",
    "text": "Events\n\n🎯 Definition An event is a subset of the sample space\n\nSimple event: Contains exactly one outcome (Ex: A = \\{3\\} (rolling a 3))\nCompound event: Contains multiple outcomes (Ex: B = \\{2, 4, 6\\} (rolling an even number))"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#event-notation",
    "href": "files/lecture_notes/lecture4/lecture4.html#event-notation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Event Notation",
    "text": "Event Notation\nFor a die roll with S = \\{1, 2, 3, 4, 5, 6\\}:\n\nA = \\{1, 3, 5\\} (rolling an odd number)\nB = \\{4, 5, 6\\} (rolling 4 or higher)\nC = \\{6\\} (rolling a six)\n\n\n\nWe can describe events in words or using set notation"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#set-operations-overview",
    "href": "files/lecture_notes/lecture4/lecture4.html#set-operations-overview",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Set Operations Overview",
    "text": "Set Operations Overview\n\n\n\n\n🎯 Definition:\n\nSet: Collection of distinct objects\nUnion: A OR B occurs\n\nIntersection: A AND B occurs\nComplement: A does NOT occur\nSample Space: All possible outcomes"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#what-is-a-set",
    "href": "files/lecture_notes/lecture4/lecture4.html#what-is-a-set",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is a Set?",
    "text": "What is a Set?\n\n\n\n\n🎯 Definition: A collection of things that share common characteristics. They can be elements, members, objects or similar terms.\nExamples:\n\nSet of even numbers:\n\n{2, 4, 6, 8, …}\n\nSet of vowels: {a, e, i, o, u}"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#union-a-b",
    "href": "files/lecture_notes/lecture4/lecture4.html#union-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Union: A ∪ B",
    "text": "Union: A ∪ B\n\n\n\n\n🎯 Definition: Contains all set elements, including intersections.\nIn Probability: The event that A OR B occurs (or both).\n\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#intersection-a-b",
    "href": "files/lecture_notes/lecture4/lecture4.html#intersection-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Intersection: A ∩ B",
    "text": "Intersection: A ∩ B\n\n\n\n\n🎯 Definition: Area where two or more sets overlap.\nIn Probability: The event that A AND B occurs.\nProperties:\n\nAlways smaller than or equal to individual sets\nCan be empty (disjoint sets)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#absolute-complement-ac",
    "href": "files/lecture_notes/lecture4/lecture4.html#absolute-complement-ac",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Absolute Complement: A^c",
    "text": "Absolute Complement: A^c\n\n\n\n🎯 Definition: All elements that do not belong to the set.\nIn Probability: The event that A does NOT occur.\n\nP(A^c) = 1 - P(A)\n\n\nKey Property:\nA \\cup A^c = S (Sample Space)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#summary-table",
    "href": "files/lecture_notes/lecture4/lecture4.html#summary-table",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Summary Table",
    "text": "Summary Table\n\n\n\n\n\n\n\n\n\nOperation\nSymbol\nMeaning\nProbability\n\n\n\n\nUnion\nA \\cup B\nOccurs if A or B\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\n\nIntersection\nA \\cap B\nOccurs if A and B\nP(A \\cap B)\n\n\nComplement\nA^c\nOccurs if A does not occur\nP(A^c) = 1 - P(A)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-commutative",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-commutative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Commutative",
    "text": "Probability Axioms: Commutative\n\nCommutative\nA \\cup B = B \\cup A\nA \\cap B = B \\cap A"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-associative",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-associative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Associative",
    "text": "Probability Axioms: Associative\n\nAssociative\n(A \\cup B) \\cup C = A \\cup (B \\cup C)\n(A \\cap B) \\cap C = A \\cap (B \\cap C)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-distributive",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-distributive",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Distributive",
    "text": "Probability Axioms: Distributive\n\nDistributive\nA \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\nA \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-de-morgans-laws",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-de-morgans-laws",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: De Morgan’s Laws",
    "text": "Probability Axioms: De Morgan’s Laws\n\nDe Morgan’s Laws\n(A \\cup B)^c = A^c \\cap B^c\n(A \\cap B)^c = A^c \\cup B^c"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-examples",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Examples",
    "text": "Practice Examples\n\nExample 1: In a class of students:\n\nSet A = Students who like Math\nSet B = Students who like Science\n\nQ: What does A ∪ B represent?\n\n\n\nSolution. Students who like Math OR Science (or both)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#example-set-operations",
    "href": "files/lecture_notes/lecture4/lecture4.html#example-set-operations",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example: Set Operations",
    "text": "Example: Set Operations\n\n\nFor die roll S = \\{1, 2, 3, 4, 5, 6\\}:\n\nA = \\{1, 3, 5\\} (odd numbers)\nB = \\{4, 5, 6\\} (4 or higher)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind:\n\nA \\cup B\nA \\cap B\nA^c\n\n\n\n\n\nSolution. \n\nA \\cup B = \\{1, 3, 4, 5, 6\\}\nA \\cap B = \\{5\\}\nA^c = \\{2, 4, 6\\}"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-events",
    "href": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive Events",
    "text": "Mutually Exclusive Events\n\n\nEvents A and B are mutually exclusive (or disjoint) if they cannot occur simultaneously\nA \\cap B = \\emptyset\n\n\n\n\n\n\n\n\n\n\n\n\nWhen rolling a die\n\nA = \\{1, 3, 5\\} (odd)\nB = \\{2, 4, 6\\} (even)\n\nA and B are mutually exclusive"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-classical-definition-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-classical-definition-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Classical Definition of Probability",
    "text": "The Classical Definition of Probability\n\n🎯 Definition: For equally likely outcomes:\nP(A) = \\frac{\\text{Number of outcomes in } A}{\\text{Total number of outcomes in } S}\n\n\nProbability of rolling an even number on a fair die\n\n\nP(\\text{even}) = \\frac{3}{6} = \\frac{1}{2}"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#properties-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#properties-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Properties of Probability",
    "text": "Properties of Probability\n\nNon-negativity: P(A) \\geq 0 for any event A\nNormalization: P(S) = 1\nAdditivity: If A and B are mutually exclusive, then\n\n\nP(A \\cup B) = P(A) + P(B)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-complement-rule",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-complement-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Complement Rule",
    "text": "The Complement Rule\n\nP(A) + P(A^c) = 1\nP(A^c) = 1 - P(A)\n\n\n\nIf the probability of rain is 0.3, what’s the probability of no rain?\n\n\n\n\nSolution. P(\\text{no rain}) = 1 - P(\\text{rain}) = 1 - 0.3 = 0.7"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#questions",
    "href": "files/lecture_notes/lecture4/lecture4.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday’s 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Conditional Probabilities & Independence"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#resources",
    "href": "files/lecture_notes/lecture4/lecture4.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms\nProbability Animations"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "",
    "text": "By the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities\nDetermine when events are independent\nUse Bayes’ theorem in simple applications"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#sec-objectives",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#sec-objectives",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "",
    "text": "By the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities\nDetermine when events are independent\nUse Bayes’ theorem in simple applications"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#mutually-exclusive-vs.-independent",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#mutually-exclusive-vs.-independent",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Mutually Exclusive vs. Independent",
    "text": "Mutually Exclusive vs. Independent\n\nMutually Exclusive (left): the circles A and B do not overlap, so \\(P(A\\cap B)=0\\).\nIndependent (right): the circles overlap, and we’ve sized the intersection so that \\(P(A\\cap B)=P(A)\\,P(B)\\)."
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#mutually-exclusive-vs.-independent-example",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#mutually-exclusive-vs.-independent-example",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Mutually Exclusive vs. Independent Example",
    "text": "Mutually Exclusive vs. Independent Example\n\n\n\nDraw a single card from a 52-card deck:\n\nLet A={“draw an Ace”}, so P(A)=4/52.\nLet B={“draw a King”}, so P(B)=4/52.\n\nQ: What is \\(P(A\\cap B)\\) ?\n\n\n\n\n\nSolution. They’re disjoint (you can’t draw an Ace and a King), so \\(P(A\\cap B) = 0\\).\nBut \\(P(A)\\,P(B) = \\frac{4}{52}\\times\\frac{4}{52} = \\frac{16}{2704} \\neq 0\\).\nHence, \\(P(A\\cap B)\\neq P(A)P(B)\\), so they’re not independent."
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#multiplication-rule",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#multiplication-rule",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Multiplication Rule",
    "text": "Multiplication Rule\nGeneral case: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nIndependent events: \\(P(A \\cap B) = P(A) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#tree-diagrams",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#tree-diagrams",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\n\n🎯 Definition Tree diagrams help visualize sequential events and calculate probabilities."
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#tree-diagram-examples",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#tree-diagram-examples",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Tree Diagram Examples",
    "text": "Tree Diagram Examples"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-2",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-2",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\n\n\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement.\n\nWhat’s the probability both balls are red?\nWhat’s the probability the first is red and second is blue?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{both red}) = \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)\n\\(P(\\text{red then blue}) = \\frac{5}{8} \\times \\frac{3}{7} = \\frac{15}{56}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#law-of-total-probability",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#law-of-total-probability",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\n🎯 Definition\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space, then:\n\\[P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \\cdots + P(A|B_n)P(B_n)\\]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#law-of-total-probability-example",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\n\nA factory has two machines:\n\nMachine 1: Produces 60% of items, 5% defective\nMachine 2: Produces 40% of items, 3% defective\n\nQ: What’s the overall probability an item is defective?\n\n\n\nSolution. \\(P(\\text{defective}) = P(D|M_1)P(M_1) + P(D|M_2)P(M_2)\\)\n\\(= 0.05 \\times 0.6 + 0.03 \\times 0.4 = 0.03 + 0.012 = 0.042\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Bayes’ Theorem",
    "text": "Bayes’ Theorem\n\n🎯 Definition \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\nThis allows us to “reverse” conditional probabilities\nNamed after Thomas Bayes (1701-1761)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-components",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-components",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Bayes’ Theorem Components",
    "text": "Bayes’ Theorem Components\n\n\\(A,B\\): Events\n\\(P(A|B)\\): Posterior probability - what we want to find\n\\(P(B|A)\\): Likelihood - given \\(A\\), probability of observing \\(B\\)\n\\(P(A)\\): Prior probability - initial probability of \\(A\\)\n\\(P(B)\\): Marginal probability - total probability of \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-example",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-example",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Bayes’ Theorem Example",
    "text": "Bayes’ Theorem Example\n\n\n\nMedical test for a disease: 1\n\nDisease affects 1% of population\nTest is 95% accurate for sick people\nTest is 90% accurate for healthy people\n\nQ:If someone tests positive, what’s the probability they have the disease?"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-solution",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-solution",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Bayes’ Theorem Solution",
    "text": "Bayes’ Theorem Solution\nLet:\n\n\\(D\\): Person has disease\n\\(T^+\\): Test is positive\n\nGiven:\n\n\\(P(D) = 0.01\\)\n\\(P(T^+|D) = 0.95\\)\n\\(P(T^-|D^c) = 0.90\\), so \\(P(T^+|D^c) = 0.10\\)\n\n\n\nSolution. \\(P(T^+) = P(T^+|D)P(D) + P(T^+|D^c)P(D^c)\\)\n\\(= 0.95 \\times 0.01 + 0.10 \\times 0.99 = 0.1085\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-solution-cont.",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-solution-cont.",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Bayes’ Theorem Solution (cont.)",
    "text": "Bayes’ Theorem Solution (cont.)\n\\[P(D|T^+) = \\frac{P(T^+|D) \\times P(D)}{P(T^+)} = \\frac{0.95 \\times 0.01}{0.1085} \\approx 0.088\\]\n\n\n\n\n\n\n\n\n\n\n\nSurprising result: Even with a positive test, there’s only an 8.8% chance of having the disease!\nThis is due to the low base rate of the disease"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#common-probability-mistakes",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#common-probability-mistakes",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nConfusing \\(P(A|B)\\) with \\(P(B|A)\\)\n\n\nProsecutor’s fallacy is a specific error in interpreting conditional probabilities. Confusing\n\\(P(\\text{Evidence}\\mid\\text{Innocent})\n\\quad\\text{with}\\quad\nP(\\text{Innocent}\\mid\\text{Evidence})\\).\nEx: OJ Simpson Case 2"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#common-probability-mistakes-1",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#common-probability-mistakes-1",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nAssuming independence when events are dependent\nIgnoring base rates (as in the medical test example)\n\n\nBase rate fallacy is when you ignore or underweight the prior probability \\(P(H)\\) of a hypothesis, focusing only on the new evidence \\(E\\).\n\n\nDouble counting in union calculations"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-3",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-3",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nTwo fair dice are rolled. Find:\n\n\\(P(\\text{sum} = 7)\\)\n\\(P(\\text{sum} = 7 | \\text{first die shows 3})\\)\nAre these events independent?\n\n\n\n\nSolution. \n\n6 ways out of 36: \\(P(\\text{sum} = 7) = \\frac{6}{36} = \\frac{1}{6}\\)\nGiven first die is 3, need second die to be 4: \\(P(\\text{sum} = 7 | \\text{first} = 3) = \\frac{1}{6}\\)\nYes, they’re independent since \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#counting-and-probability",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#counting-and-probability",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Counting and Probability",
    "text": "Counting and Probability\n\nSometimes we need to count outcomes:\n\nMultiplication Principle: If task 1 can be done in \\(m\\) ways and task 2 in \\(n\\) ways, both can be done in \\(m \\times n\\) ways\n\n\nPermutations: Arrangements where order matters \\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\n\nCombinations: Selections where order doesn’t matter \\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#counting-example",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#counting-example",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Counting Example",
    "text": "Counting Example\n\nQ: How many ways can you arrange 5 people in a row?\n\n\n\nSolution. This is a permutation: \\(P(5,5) = 5! = 120\\) ways\n\n\n\n\n\nQ:How many ways can you choose 3 people from 5 for a committee?\n\n\n\n\nSolution. This is a combination: \\(C(5,3) = \\binom{5}{3} = \\frac{5!}{3!2!} = 10\\) ways"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#probability-with-counting",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#probability-with-counting",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Probability with Counting",
    "text": "Probability with Counting\n\nExample: A committee of 3 people is chosen from 8 people (5 women, 3 men). What’s the probability all 3 are women?\n\n\n\nSolution. Total ways to choose 3 from 8: \\(\\binom{8}{3} = 56\\)\nWays to choose 3 women from 5: \\(\\binom{5}{3} = 10\\)\nProbability: \\(\\frac{10}{56} = \\frac{5}{28}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#real-world-applications",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#real-world-applications",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Diagnosis: Using Bayes’ theorem for test interpretation\nQuality Control: Probability of defective items\nFinance: Risk assessment and portfolio theory\nSports: Probability of wins, fantasy sports\nInsurance: Calculating premiums based on risk"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#key-formulas-summary",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#key-formulas-summary",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\nBasic probability: \\(P(A) = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\\)\nComplement: \\(P(A^c) = 1 - P(A)\\)\nAddition: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nConditional: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nIndependence: \\(P(A \\cap B) = P(A) \\times P(B)\\)\nBayes’: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#problem-solving-strategy",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#problem-solving-strategy",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\nIdentify the sample space and events\nDetermine if events are independent or mutually exclusive\nChoose the appropriate rule or formula\nCalculate step by step\nCheck if your answer makes sense"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-4",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-4",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\n\nA bag contains 4 red, 3 blue, and 2 green marbles. Three marbles are drawn without replacement.\nFind the probability that: a) All three are red b) No two are the same color c) At least one is blue"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-4-solutions",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-4-solutions",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Practice Problem 4 Solutions",
    "text": "Practice Problem 4 Solutions\n\nSolution. \n\nAll red: \\(\\frac{4}{9} \\times \\frac{3}{8} \\times \\frac{2}{7} = \\frac{24}{504} = \\frac{1}{21}\\)\nDifferent colors: \\(\\frac{4 \\times 3 \\times 2}{9 \\times 8 \\times 7} \\times 3! = \\frac{24 \\times 6}{504} = \\frac{144}{504} = \\frac{2}{7}\\)\nAt least one blue: \\(1 - P(\\text{no blue}) = 1 - \\frac{6 \\times 5 \\times 4}{9 \\times 8 \\times 7} = 1 - \\frac{120}{504} = \\frac{384}{504} = \\frac{16}{21}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#common-questions",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#common-questions",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Common Questions",
    "text": "Common Questions\n\nQ1.: “Why isn’t \\(P(A \\cup B) = P(A) + P(B)\\) always?”\nA: We’d double-count outcomes in both events\nQ2.: “How do I know if events are independent?”\nA: Check if \\(P(A|B) = P(A)\\) or if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nQ3.: “When do I use Bayes’ theorem?”\nA: When you want to “reverse” a conditional probability\n\n\nQ3 note (Bayes Example)\n\nForward: I know my test picks up disease 95% of the time ⇒ \\(P(+\\mid D)=0.95\\).\nReverse: I want the chance I really have the disease when the test is positive ⇒ \\(P(D\\mid +)\\)."
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#looking-ahead",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#looking-ahead",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture:\n\nRandom Variables and Probability Distributions\nDiscrete vs. continuous random variables\nExpected value and variance"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#final-thoughts",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#final-thoughts",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Final Thoughts",
    "text": "Final Thoughts\n\nProbability is the foundation of statistics:\n\nHelps us quantify uncertainty\nProvides tools for making decisions with incomplete information\nEssential for understanding statistical inference\n\n\n\nPractice: The key to mastering probability is working through many problems!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#questions",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#questions",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday’s 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Random Variables and Distributions"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#resources",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#resources",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#footnotes",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#footnotes",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\\(P(\\neg D \\,\\wedge\\, \\text{Negative})\n\\;=\\;P(\\neg D)\\times P(\\text{Negative}\\mid \\neg D)\n\\;=\\;0.99\\times0.90\n\\;=\\;0.891\\;(89.1\\%)\\)↩︎\nthe DNA evidence in the O. J. Simpson trial are a classic example of the prosecutor’s fallacy. Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was “one in 170 million,” then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent.↩︎"
  },
  {
    "objectID": "files/lecture_notes/Lecture_1/lecture1.html",
    "href": "files/lecture_notes/Lecture_1/lecture1.html",
    "title": "Lecture 1: Introduction to Data Science",
    "section": "",
    "text": "Instructor\n\nNarjes Mathlouthi (nmathlouthi@ucsb.edu)\n\nOffice Hours (Zoom):\n\nThursdays 11 AM–12 PM\n\n\nTeaching Assistants\n\nSummer Lee (sle@ucsb.edu)\nMingzhu He (mingzhuhe@ucsb.edu)"
  },
  {
    "objectID": "files/lecture_notes/Lecture_1/lecture1.html#welcome-to-pstat5a",
    "href": "files/lecture_notes/Lecture_1/lecture1.html#welcome-to-pstat5a",
    "title": "Lecture 1: Introduction to Data Science",
    "section": "Welcome to PSTAT5A!",
    "text": "Welcome to PSTAT5A!\n\n\nInstructor\n\nNarjes Mathlouthi (nmathlouthi@ucsb.edu)\n\nOffice Hours (Zoom):\n\nThursdays 11 AM–12 PM\n\n\nTeaching Assistants\n\nSummer Lee (sle@ucsb.edu)\nMingzhu He (mingzhuhe@ucsb.edu)"
  },
  {
    "objectID": "files/lecture_notes/Lecture_1/lecture1.html#course-resources",
    "href": "files/lecture_notes/Lecture_1/lecture1.html#course-resources",
    "title": "Lecture 1: Introduction to Data Science",
    "section": "Course Resources",
    "text": "Course Resources\n\n\n\nCanvas: Grades & Announcements\nGradescope: Quizzes & Labs\n\nEntry code: WJ4XR7\n\n\nCourse Website: bit.ly/3Ga8CSK\n\nAll lecture slides, labs, and code will be posted here"
  },
  {
    "objectID": "files/lecture_notes/Lecture_1/lecture1.html#communication-email",
    "href": "files/lecture_notes/Lecture_1/lecture1.html#communication-email",
    "title": "Lecture 1: Introduction to Data Science",
    "section": "Communication & Email",
    "text": "Communication & Email\n\n\n\nPriority: Bring non‐urgent questions to office hours or after lecture rather than emailing.\n\nEmail Subject: Always include [PSTAT 5A] to help us sort and reply efficiently.\n\nResponse Time: Please allow 24–48 hours for replies; avoid sending emails over weekends."
  },
  {
    "objectID": "files/lecture_notes/Lecture_1/lecture1.html#what-is-data-science",
    "href": "files/lecture_notes/Lecture_1/lecture1.html#what-is-data-science",
    "title": "Lecture 1: Introduction to Data Science",
    "section": "What is Data Science?",
    "text": "What is Data Science?\n\n\n\nNo single agreed-upon definition\n\nA cross-disciplinary field:\n\nStatistics: theory of modeling & randomness\n\nComputer Science: computation & data handling"
  },
  {
    "objectID": "files/lecture_notes/Lecture_1/lecture1.html#why-theory-matters",
    "href": "files/lecture_notes/Lecture_1/lecture1.html#why-theory-matters",
    "title": "Lecture 1: Introduction to Data Science",
    "section": "Why Theory Matters",
    "text": "Why Theory Matters\n\nData today is huge computation alone isn’t enough\n\nTheory guides how and why we apply tools\n\nEmployers need analysts who understand and apply"
  },
  {
    "objectID": "files/lecture_notes/Lecture_1/lecture1.html#path-forward-course-outline",
    "href": "files/lecture_notes/Lecture_1/lecture1.html#path-forward-course-outline",
    "title": "Lecture 1: Introduction to Data Science",
    "section": "Path Forward: Course Outline",
    "text": "Path Forward: Course Outline\n\nDescriptive Statistics: Summarize & visualize data\n\nProbability: Random variables & distributions\n\nInferential Statistics: Confidence intervals & hypothesis tests\n\nRegression: Modeling relationships\n\nData Collection: Sampling & study design"
  },
  {
    "objectID": "files/lecture_notes/Lecture_1/lecture1.html#why-should-i-care",
    "href": "files/lecture_notes/Lecture_1/lecture1.html#why-should-i-care",
    "title": "Lecture 1: Introduction to Data Science",
    "section": "Why Should I Care?",
    "text": "Why Should I Care?\n\nData is everywhere, any field dealing with data needs these skills\n\nCompanies seek insightful analysts, not just code runners\n\nThis course equips you with both theory and practice"
  },
  {
    "objectID": "files/worksheets/worksheet5.html",
    "href": "files/worksheets/worksheet5.html",
    "title": "PSTAT 5A Practice Worksheet 5",
    "section": "",
    "text": "Instructions and Overview\n⏰ Time Allocation:\n\nIntro & Setup : 10 minutes\nSection A (Continuous Distributions): 20 minutes\nSection B (Confidence Intervals): 20 minutes\nOptional Questions: Do on your own\nTotal: 50 minutes\n\n\n📝 Important Instructions:\n\nUse the formulas and tables provided for guidance\nRound final answers to 4 decimal places unless otherwise specified\nFor confidence intervals, always interpret your results in context\nUse z-table or t-table as appropriate\nShow your work for all calculations\n\n\n\n📚 Key Formulas Reference:\nContinuous Random Variables:\nNormal Distribution: \\(X \\sim N(\\mu, \\sigma^2)\\)\n\nPDF: \\(f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\)\nStandardization: \\(Z = \\frac{X - \\mu}{\\sigma}\\) where \\(Z \\sim N(0,1)\\)\nMean: \\(E[X] = \\mu\\)\nVariance: \\(\\text{Var}(X) = \\sigma^2\\)\n\nUniform Distribution: \\(X \\sim \\text{Uniform}(a,b)\\)\n\nPDF: \\(f(x) = \\frac{1}{b-a}\\) for \\(a \\leq x \\leq b\\)\nMean: \\(E[X] = \\frac{a+b}{2}\\)\nVariance: \\(\\text{Var}(X) = \\frac{(b-a)^2}{12}\\)\n\nExponential Distribution: \\(X \\sim \\text{Exponential}(\\lambda)\\)\n\nPDF: \\(f(x) = \\lambda e^{-\\lambda x}\\) for \\(x \\geq 0\\)\nMean: \\(E[X] = \\frac{1}{\\lambda}\\)\nVariance: \\(\\text{Var}(X) = \\frac{1}{\\lambda^2}\\)\n\nConfidence Intervals:\nFor Population Mean (σ known): \\(\\bar{x} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\\)\nFor Population Mean (σ unknown): \\(\\bar{x} \\pm t_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{n}}\\)\nMargin of Error: \\(E = z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\\) or \\(E = t_{\\alpha/2} \\cdot \\frac{s}{\\sqrt{n}}\\)\nSample Size: \\(n = \\left(\\frac{z_{\\alpha/2} \\cdot \\sigma}{E}\\right)^2\\)\n\n\n\nSection A: Continuous Random Variables\n⏱️ Estimated time: 20 minutes\n\nProblem A1: Distribution Identification and Properties\nFor each scenario below, identify the appropriate continuous distribution and find the requested values:\n(a) The time (in minutes) between arrivals at a coffee shop follows an exponential distribution with an average of 2 minutes between arrivals.\n\nWhat is the parameter \\(\\lambda\\)?\nWhat is the probability that the next customer arrives within 1 minute?\n\n(b) A random number generator produces values uniformly between 10 and 30.\n\nWhat are the parameters a and b?\nWhat is the expected value and variance?\n\n\nWork Space:\n\n\nProblem A2: Normal Distribution Calculations\nThe heights of adult women in the US are normally distributed with \\(\\mu = 64\\) inches and \\(\\sigma = 2.5\\) inches.\n(a) What is the probability that a randomly selected woman is taller than \\(67\\) inches?\n(b) What height represents the \\(25\\)th percentile?\n(c) What is the probability that a randomly selected woman has a height between \\(62\\) and \\(68\\) inches?\n\n\n\n\n\n\nTip\n\n\n\nRemember to standardize: Convert to \\(Z\\)-scores using \\(Z = \\frac{X - \\mu}{\\sigma}\\)\nFor part (b), you’re looking for the value \\(x\\) such that \\(P(X ≤ x) = 0.25\\)\n\n\n\nWork Space:\n\n\n\nSection B: Confidence Intervals\n⏱️ Estimated time: 20 minutes\n\nProblem B1: Understanding Confidence Intervals\n(a) Explain in your own words what a \\(95\\%\\) confidence interval means.\n(b) A \\(90\\%\\) confidence interval for the mean weight of apples is (150g, 170g). What is the sample mean and margin of error?\n(c) True or False: “There is a \\(95\\%\\) probability that the population mean lies within our calculated \\(95\\%\\) confidence interval.” Explain your reasoning.\n\nWork Space:\n\n\nProblem B2: Constructing Confidence Intervals\nA sample of \\(36\\) students has a mean test score of \\(78.5\\) with a standard deviation of \\(12\\).\n(a) Construct a \\(95\\%\\) confidence interval for the population mean test score.\n(b) Interpret this interval in the context of the problem.\n(c) What would happen to the width of the interval if:\n\nWe increased the confidence level to \\(99\\%\\)?\nWe increased the sample size to \\(144\\)?\n\n\n\n\n\n\n\nTip\n\n\n\nDecision Guide:\n\nUse \\(z\\)-distribution when \\(\\sigma\\) is known OR \\(n ≥ 30\\)\nUse \\(t\\)-distribution when \\(\\sigma\\) is unknown AND \\(n &lt; 30\\)\nFor \\(95\\%\\) CI: \\(z_{0.025} = 1.96\\)\n\n\n\n\nWork Space:\n\n\n\nOptional Questions\n\nOptional Problem: Conceptual Understanding\n(a) Explain the key difference between discrete and continuous random variables in terms of:\n\nThe values they can take\nHow we calculate probabilities\n\n(b) Why do we use \\(P(X = x) = 0\\) for any specific value \\(x\\) in a continuous distribution?\n(c) What’s the relationship between PDF and CDF for continuous distributions?\n\nWork Space:\n\n\n📋 Quick Reference:\nCommon Z-values:\n\n\\(90\\%\\) CI: \\(z_{0.05} = 1.645\\)\n\\(95\\%\\) CI: \\(z_{0.025}\\) = 1.96$\n\\(99\\%\\) CI: \\(z_{0.005}\\) = 2.576$\n\nCommon t-values (selected):\n\n\\(df = 24, \\alpha = 0.05: t_{0.025} = 2.064\\)\n\\(df = 35, \\alpha = 0.05: t_{0.025} = 2.030\\)"
  },
  {
    "objectID": "files/worksheets/worksheet2.html",
    "href": "files/worksheets/worksheet2.html",
    "title": "PSTAT 5A Practice Worksheet 2",
    "section": "",
    "text": "Download PDF"
  },
  {
    "objectID": "files/worksheets/worksheet2.html#understanding-variance-population-vs-sample",
    "href": "files/worksheets/worksheet2.html#understanding-variance-population-vs-sample",
    "title": "PSTAT 5A Practice Worksheet 2",
    "section": "4.1 Understanding Variance: Population vs Sample",
    "text": "4.1 Understanding Variance: Population vs Sample\n\n🎯 Key Variance Concepts:\nPopulation Variance (when you have ALL data): \\[\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\]\nSample Variance (when you have a sample): \\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\]\nWhy (n-1)? Using the sample mean to estimate deviations “uses up” one degree of freedom.\n\n\nProblem C1: Basic Variance Calculations\nThe following data represents the number of customer complaints per day for a small business over 8 days:\nData: 3, 7, 2, 8, 5, 6, 4, 9\nPart (a) : Calculate the sample mean \\(\\bar{x}\\).\nPart (b) : Calculate the sample variance \\(s^2\\) using the formula with \\((n-1)\\) in the denominator.\nPart (c) : Calculate the sample standard deviation \\(s\\).\nPart (d) : If this were treated as a complete population, what would the population variance \\(\\sigma^2\\) be?\nPart (e) : Explain why we divide by \\((n-1)\\) for sample variance instead of \\(n\\).\nAnswer:\n\n\n\nProblem C2: Comparing Variability\nConsider two data sets:\n\nSet A: 10, 12, 14, 16, 18\nSet B: 5, 10, 14, 18, 23\n\n\nCalculate the mean for each set.\nCalculate the sample variance for each set.\nWhich set has greater variability?\nCalculate the coefficient of variation \\((CV = s/x̄)\\) for each set. Which has greater relative variability?\n\nAnswer:"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html",
    "href": "files/labs/lab4/lab4_sln.html",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "",
    "text": "# Load our tools (libraries)\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport pandas as pd\n\n# Make our graphs look nice\n%matplotlib inline\nplt.style.use('seaborn-v0_8-whitegrid')\n\nprint(\"✅ All tools loaded successfully!\")\n\n✅ All tools loaded successfully!"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#step-1-a-fair-coin",
    "href": "files/labs/lab4/lab4_sln.html#step-1-a-fair-coin",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Step 1: A Fair Coin",
    "text": "Step 1: A Fair Coin\n\n# A fair coin - just run this code!\noutcomes = [\"Tails\", \"Heads\"]\nprobabilities = [0.5, 0.5]  # 50% each\n\nprint(\"Possible outcomes:\", outcomes)\nprint(\"Probabilities:\", probabilities)\nprint(\"Total probability:\", sum(probabilities))  # Should be 1.0\n\nPossible outcomes: ['Tails', 'Heads']\nProbabilities: [0.5, 0.5]\nTotal probability: 1.0\n\n\n\n# Make a bar chart - just run this code!\nplt.figure(figsize=(8, 5))\nplt.bar(outcomes, probabilities, color=['lightcoral', 'lightblue'], alpha=0.7, edgecolor='black')\nplt.title('Fair Coin: 50% Heads, 50% Tails')\nplt.ylabel('Probability')\nplt.ylim(0, 0.6)\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#task-1-solution-fill-in-the-biased-coin",
    "href": "files/labs/lab4/lab4_sln.html#task-1-solution-fill-in-the-biased-coin",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Task 1 Solution: Fill in the Biased Coin",
    "text": "Task 1 Solution: Fill in the Biased Coin\n\n# A biased coin that lands Heads 70% of the time\nbiased_outcomes = [\"Tails\", \"Heads\"]\nbiased_probabilities = [0.3, 0.7]  # If Heads is 70%, then Tails is 30%\n\nprint(\"Biased coin outcomes:\", biased_outcomes)\nprint(\"Biased coin probabilities:\", biased_probabilities)\nprint(\"Total probability:\", sum(biased_probabilities))\n\n# Check your answer: this should print 1.0\n\nBiased coin outcomes: ['Tails', 'Heads']\nBiased coin probabilities: [0.3, 0.7]\nTotal probability: 1.0\n\n\n\n# Graph of biased coin\nplt.figure(figsize=(8, 5))\nplt.bar(biased_outcomes, biased_probabilities, color=['lightcoral', 'lightblue'], alpha=0.7, edgecolor='black')\nplt.title('Biased Coin: 30% Tails, 70% Heads')\nplt.ylabel('Probability')\nplt.ylim(0, 0.8)\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#example-expected-value-of-a-fair-coin",
    "href": "files/labs/lab4/lab4_sln.html#example-expected-value-of-a-fair-coin",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Example: Expected Value of a Fair Coin",
    "text": "Example: Expected Value of a Fair Coin\n\n# Expected value calculation for fair coin\ncoin_values = [0, 1]  # Tails = 0, Heads = 1\ncoin_probs = [0.5, 0.5]\n\nexpected_value = 0 * 0.5 + 1 * 0.5\nprint(f\"Expected value of fair coin: {expected_value}\")\n\nExpected value of fair coin: 0.5"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#task-2-solution-expected-value-of-biased-coin",
    "href": "files/labs/lab4/lab4_sln.html#task-2-solution-expected-value-of-biased-coin",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Task 2 Solution: Expected Value of Biased Coin",
    "text": "Task 2 Solution: Expected Value of Biased Coin\n\n# Expected value for biased coin\n# Values: Tails = 0, Heads = 1\n# Probabilities: Tails = 30%, Heads = 70%\n\nexpected_biased = 0 * 0.3 + 1 * 0.7\nprint(f\"Expected value of biased coin: {expected_biased}\")\n\nExpected value of biased coin: 0.7\n\n\n\nprint(f\"This means: if we flip the biased coin many times,\")\nprint(f\"we expect about {expected_biased} points per flip on average.\")\nprint(f\"Since this is closer to 1 than 0.5, the coin favors Heads\")\n\nThis means: if we flip the biased coin many times,\nwe expect about 0.7 points per flip on average.\nSince this is closer to 1 than 0.5, the coin favors Heads"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#bernoulli-distribution-example",
    "href": "files/labs/lab4/lab4_sln.html#bernoulli-distribution-example",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Bernoulli Distribution Example",
    "text": "Bernoulli Distribution Example\n\n# Create a Bernoulli distribution for a fair coin\nfair_coin = stats.bernoulli(0.5)  # 0.5 = 50% chance of success (Heads)\n\n# Ask for probabilities\nprob_tails = fair_coin.pmf(0)  # pmf = \"probability mass function\"\nprob_heads = fair_coin.pmf(1)\n\nprint(f\"Probability of Tails (0): {prob_tails}\")\nprint(f\"Probability of Heads (1): {prob_heads}\")\n\n# Get expected value automatically!\nprint(f\"Expected value: {fair_coin.mean()}\")\n\nProbability of Tails (0): 0.4999999999999999\nProbability of Heads (1): 0.5\nExpected value: 0.5"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#task-3-solution-biased-coin-with-python-tools",
    "href": "files/labs/lab4/lab4_sln.html#task-3-solution-biased-coin-with-python-tools",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Task 3 Solution: Biased Coin with Python Tools",
    "text": "Task 3 Solution: Biased Coin with Python Tools\n\n# Create Bernoulli distribution for biased coin\nbiased_coin = stats.bernoulli(0.7)  # 70% probability of Heads\n\n# Calculate probabilities\nprob_tails_biased = biased_coin.pmf(0)\nprob_heads_biased = biased_coin.pmf(1)\n\nprint(f\"Biased coin - Probability of Tails: {prob_tails_biased}\")\nprint(f\"Biased coin - Probability of Heads: {prob_heads_biased}\")\nprint(f\"Expected value: {biased_coin.mean()}\")\n\nBiased coin - Probability of Tails: 0.29999999999999993\nBiased coin - Probability of Heads: 0.7\nExpected value: 0.7\n\n\nAnswer: Yes, this matches what we calculated by hand in Task 2 (0.7)"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#visualizing-different-coins",
    "href": "files/labs/lab4/lab4_sln.html#visualizing-different-coins",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Visualizing Different Coins",
    "text": "Visualizing Different Coins\n\n# Compare three coins with different bias\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\n\n# Three different coins\ncoin_types = [\n    {\"prob\": 0.2, \"name\": \"Mostly Tails\"},\n    {\"prob\": 0.5, \"name\": \"Fair Coin\"}, \n    {\"prob\": 0.8, \"name\": \"Mostly Heads\"}\n]\n\nfor i, coin in enumerate(coin_types):\n    # Create the distribution\n    distribution = stats.bernoulli(coin[\"prob\"])\n    \n    # Get probabilities\n    probs = [distribution.pmf(0), distribution.pmf(1)]\n    \n    # Make bar chart\n    axes[i].bar([0, 1], probs, color=['lightcoral', 'lightblue'], alpha=0.7, edgecolor='black')\n    axes[i].set_title(f'{coin[\"name\"]}\\n(p = {coin[\"prob\"]})')\n    axes[i].set_xlabel('Outcome')\n    axes[i].set_ylabel('Probability')\n    axes[i].set_xticks([0, 1])\n    axes[i].set_xticklabels(['Tails', 'Heads'])\n    axes[i].set_ylim(0, 1)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#example-5-fair-coin-flips",
    "href": "files/labs/lab4/lab4_sln.html#example-5-fair-coin-flips",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Example: 5 Fair Coin Flips",
    "text": "Example: 5 Fair Coin Flips\n\n# Binomial distribution: 5 fair coin flips\nn_flips = 5        # number of flips\np_heads = 0.5      # probability of heads each time\n\nfive_flips = stats.binom(n_flips, p_heads)\n\nprint(\"Flipping 5 fair coins...\")\nprint(f\"Probability of 0 heads: {five_flips.pmf(0):.4f}\")\nprint(f\"Probability of 1 head:  {five_flips.pmf(1):.4f}\")\nprint(f\"Probability of 2 heads: {five_flips.pmf(2):.4f}\")\nprint(f\"Probability of 3 heads: {five_flips.pmf(3):.4f}\")\nprint(f\"Probability of 4 heads: {five_flips.pmf(4):.4f}\")\nprint(f\"Probability of 5 heads: {five_flips.pmf(5):.4f}\")\n\nprint(f\"\\nExpected number of heads: {five_flips.mean()}\")\n\nFlipping 5 fair coins...\nProbability of 0 heads: 0.0312\nProbability of 1 head:  0.1562\nProbability of 2 heads: 0.3125\nProbability of 3 heads: 0.3125\nProbability of 4 heads: 0.1562\nProbability of 5 heads: 0.0312\n\nExpected number of heads: 2.5\n\n\n\n# Graph showing all possibilities\npossible_heads = [0, 1, 2, 3, 4, 5]\nprobabilities = [five_flips.pmf(k) for k in possible_heads]\n\nplt.figure(figsize=(10, 6))\nplt.bar(possible_heads, probabilities, alpha=0.7, color='lightgreen', edgecolor='black')\nplt.xlabel('Number of Heads')\nplt.ylabel('Probability')\nplt.title('5 Fair Coin Flips: How Many Heads?')\nplt.axvline(x=five_flips.mean(), color='red', linestyle='--', linewidth=2, \n            label=f'Expected = {five_flips.mean()}')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#task-4-solution-basketball-free-throws",
    "href": "files/labs/lab4/lab4_sln.html#task-4-solution-basketball-free-throws",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Task 4 Solution: Basketball Free Throws",
    "text": "Task 4 Solution: Basketball Free Throws\n\n# Basketball free throws\nn_shots = 10       # 10 shots\np_make = 0.6       # 60% chance of making each shot\n\nbasketball = stats.binom(n_shots, p_make)  # Create the distribution\n\n\n# a) What's the probability of making exactly 6 shots?\nprob_exactly_6 = basketball.pmf(6)\nprint(f\"Probability of exactly 6 makes: {prob_exactly_6:.4f}\")\n\n# b) How many shots do we expect them to make?\nexpected_makes = basketball.mean()\nprint(f\"Expected number of makes: {expected_makes}\")\n\n# c) What's the probability of making 8 or more shots?\nprob_8_or_more = (basketball.pmf(8) + basketball.pmf(9) + basketball.pmf(10))\nprint(f\"Probability of 8+ makes: {prob_8_or_more:.4f}\")\n\nProbability of exactly 6 makes: 0.2508\nExpected number of makes: 6.0\nProbability of 8+ makes: 0.1673\n\n\n\n# Create bar chart\npossible_makes = list(range(0, 11))  # 0 to 10 makes\nprobabilities = [basketball.pmf(k) for k in possible_makes]\n\nplt.figure(figsize=(10, 6))\nplt.bar(possible_makes, probabilities, alpha=0.7, color='orange', edgecolor='black')\nplt.xlabel('Number of Successful Free Throws')\nplt.ylabel('Probability')\nplt.title('Basketball Player: 10 Free Throws (60% Success Rate)')\nplt.axvline(x=expected_makes, color='red', linestyle='--', linewidth=2, \n            label=f'Expected = {expected_makes}')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#example-store-customers",
    "href": "files/labs/lab4/lab4_sln.html#example-store-customers",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Example: Store Customers",
    "text": "Example: Store Customers\n\n# On average, 4 customers enter the store per hour\naverage_customers = 4\n\nstore_customers = stats.poisson(average_customers)\n\nprint(\"Store customer arrivals per hour:\")\nprint(f\"Probability of 0 customers: {store_customers.pmf(0):.4f}\")\nprint(f\"Probability of 2 customers: {store_customers.pmf(2):.4f}\")\nprint(f\"Probability of 4 customers: {store_customers.pmf(4):.4f}\")\nprint(f\"Probability of 6 customers: {store_customers.pmf(6):.4f}\")\n\nprint(f\"\\nExpected customers per hour: {store_customers.mean()}\")\n\nStore customer arrivals per hour:\nProbability of 0 customers: 0.0183\nProbability of 2 customers: 0.1465\nProbability of 4 customers: 0.1954\nProbability of 6 customers: 0.1042\n\nExpected customers per hour: 4.0\n\n\n\n# Graph customer arrivals\npossible_customers = list(range(0, 12))  # 0 to 11 customers\nprobabilities = [store_customers.pmf(k) for k in possible_customers]\n\nplt.figure(figsize=(10, 6))\nplt.bar(possible_customers, probabilities, alpha=0.7, color='purple', edgecolor='black')\nplt.xlabel('Number of Customers per Hour')\nplt.ylabel('Probability')\nplt.title('Store Customer Arrivals (Average = 4 per hour)')\nplt.axvline(x=average_customers, color='red', linestyle='--', linewidth=2, \n            label=f'Average = {average_customers}')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#task-5-solution-email-inbox",
    "href": "files/labs/lab4/lab4_sln.html#task-5-solution-email-inbox",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Task 5 Solution: Email Inbox",
    "text": "Task 5 Solution: Email Inbox\n\n# Email arrivals\naverage_emails = 3  # 3 emails per hour on average\nemail_arrivals = stats.poisson(average_emails)\n\n\n# a) Probability of getting exactly 3 emails in an hour\nprob_exactly_3 = email_arrivals.pmf(3)\nprint(f\"Probability of exactly 3 emails: {prob_exactly_3:.4f}\")\n\n# b) Probability of getting no emails (quiet hour!)\nprob_no_emails = email_arrivals.pmf(0)\nprint(f\"Probability of no emails: {prob_no_emails:.4f}\")\n\n# c) Expected number of emails per hour\nexpected_emails = email_arrivals.mean()\nprint(f\"Expected emails per hour: {expected_emails}\")\n\nProbability of exactly 3 emails: 0.2240\nProbability of no emails: 0.0498\nExpected emails per hour: 3.0\n\n\n\n# Graph for email arrivals\npossible_emails = list(range(0, 12))  # 0 to 11 emails\nprobabilities = [email_arrivals.pmf(k) for k in possible_emails]\n\nplt.figure(figsize=(10, 6))\nplt.bar(possible_emails, probabilities, alpha=0.7, color='teal', edgecolor='black')\nplt.xlabel('Number of Emails per Hour')\nplt.ylabel('Probability')\nplt.title('Email Arrivals (Average = 3 per hour)')\nplt.axvline(x=average_emails, color='red', linestyle='--', linewidth=2, \n            label=f'Average = {average_emails}')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#task-6-solution-which-distribution",
    "href": "files/labs/lab4/lab4_sln.html#task-6-solution-which-distribution",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Task 6 Solution: Which Distribution?",
    "text": "Task 6 Solution: Which Distribution?\n\n# Scenario A - 8 coin flips, exactly 5 heads\nn = 8          # number of flips\np = 0.5        # probability of heads (fair coin)\nscenario_a = stats.binom(n, p)\n\nanswer_a = scenario_a.pmf(5)  # exactly 5 heads\nprint(f\"Scenario A answer: {answer_a:.4f}\")\n\nScenario A answer: 0.2187\n\n\n\n# Scenario B - Coffee shop customers\naverage_rate = 6  # customers per hour\nscenario_b = stats.poisson(average_rate)\n\nanswer_b = scenario_b.pmf(4)  # exactly 4 customers\nprint(f\"Scenario B answer: {answer_b:.4f}\")\n\nScenario B answer: 0.1339\n\n\n\n# Scenario C - Student homework problem\np_correct = 0.8  # 80% chance of getting it right\nscenario_c = stats.bernoulli(p_correct)\n\nanswer_c = scenario_c.pmf(1)  # gets it right (value = 1)\nprint(f\"Scenario C answer: {answer_c:.4f}\")\n\nScenario C answer: 0.8000"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#task-answers-summary",
    "href": "files/labs/lab4/lab4_sln.html#task-answers-summary",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Task Answers Summary:",
    "text": "Task Answers Summary:\nTask 1: Biased coin probabilities = [0.3, 0.7]\nTask 2: Expected value of biased coin = 0.7\nTask 3: Bernoulli(0.7) gives same expected value = 0.7 ✓\nTask 4: Basketball (10 shots, 60% success rate) - P(exactly 6 makes) = 0.2508 - Expected makes = 6.0 - P(8+ makes) = 0.1673\nTask 5: Email (3 per hour average) - P(exactly 3 emails) = 0.2240 - P(no emails) = 0.0498 - Expected emails = 3.0\nTask 6: Distribution Detective - Scenario A (8 flips, 5 heads): 0.2188 - Scenario B (6 customers/hour, exactly 4): 0.1339 - Scenario C (80% correct, gets it right): 0.8000\nTask 7: Simulation should give approximately 0.2461 for P(5 heads in 10 flips)"
  },
  {
    "objectID": "files/labs/lab4/lab4_sln.html#key-formulas-used",
    "href": "files/labs/lab4/lab4_sln.html#key-formulas-used",
    "title": "Lab 4 Solutions: Introduction to Probability with Python",
    "section": "Key Formulas Used:",
    "text": "Key Formulas Used:\n\nExpected Value: \\(E[X] = \\sum(\\text{value} \\times \\text{probability})\\)\nBernoulli: stats.bernoulli(p)\nBinomial: stats.binom(n, p)\nPoisson: stats.poisson(λ)\nPMF: .pmf(k) gives P(X = k)\nMean: .mean() gives expected value\n\nThis completes lab4 solutions! 🎯"
  },
  {
    "objectID": "files/labs/lab3/lab3.html",
    "href": "files/labs/lab3/lab3.html",
    "title": "Lab 3: Descriptive Statistics",
    "section": "",
    "text": "It’s finally time for us to revisit our notions of descriptive statistics (from Week 1 of the course), now in the context of Python!"
  },
  {
    "objectID": "files/labs/lab3/lab3.html#task-1",
    "href": "files/labs/lab3/lab3.html#task-1",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Task 1",
    "text": "Task 1\n\n⏱️ Estimated time: 3 minutes\n\n\nImport the numpy module as np, and check that np.sin(0) returns a value of 0.\nImport the datascience module as ds, and check that\n\n\nds.Table().with_columns(\n  \"Col1\", [1, 2, 3],\n  \"Col2\", [2, 3, 4]\n)\n\nprints correctly as :\n\n\n/Users/narjesmathlouthi/miniconda3/envs/pstat5a/lib/python3.11/site-packages/datascience/maps.py:13: UserWarning:\n\npkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n\n\n\n\n\n\nCol1\nCol2\n\n\n\n\n1\n2\n\n\n2\n3\n\n\n3\n4\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you import a module with an abbreviation &lt;abbreviation&gt;, you must always use the abbreviation when referencing the module; not the original module name. For example, after importing numpy as np, running numpy.sin() would return an error."
  },
  {
    "objectID": "files/labs/lab3/lab3.html#numerical-summaries",
    "href": "files/labs/lab3/lab3.html#numerical-summaries",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Numerical Summaries",
    "text": "Numerical Summaries\n\nMeasures of Central Tendency\n\n\n⏱️ Estimated time: 5 minutes\n\nRecall that for a list of numbers (\\(x_1,x_2,\\ldots, x_n\\)), \\(X = \\{ x_i\\}_{i=1}^{n}\\)​, the mean is defined as\n\n\\(\\bar x= \\frac{1}{n} \\sum_{i=1}^{n} x_i​\\)\n\nComputing the mean of a list or array of numbers in Python is relatively simple, using the np.mean() function [recall that we imported the numpy module with the abbreviation np, meaning np.mean() is a shorthand for numpy.mean()]. Similarly, to compute the median of a list or array we can use np.median().\n\nUnderstanding Functions and Parameters\nBefore we dive into examples, let’s understand what functions are and how they work with parameters. A function is a block of code that performs a specific task. Functions can take parameters (also called arguments) as input, process them, and return a result.\nThe general syntax for calling a function is:\n\nfunction_name(parameter1, parameter2, ...)\n\nFor statistical functions like np.mean() and np.median(), the main parameter is the data (list or array) you want to analyze. You can read more about about each function in the official documentation for the numpy module.\nHere are some examples:\n\nExample with np.mean():\n\n# Create a simple list of numbers\nnumbers = [2, 4, 6, 8, 10]\n\n# Calculate the mean - the function takes 'numbers' as a parameter\n\naverage = np.mean(numbers)\nprint(f\"The mean is: {average}\")  # Output: The mean is: 6.0\n\nThe mean is: 6.0\n\n\n\n\nExample with np.median():\n\n# Using the same list\nnumbers = [2, 4, 6, 8, 10]\n\n# Calculate the median - the function takes 'numbers' as a parameter  \nmiddle_value = np.median(numbers)\nprint(f\"The median is: {middle_value}\")  # Output: The median is: 6.0\n\n# Try with an odd number of elements\nodd_numbers = [1, 3, 5, 7, 9, 11, 13]\nmedian_odd = np.median(odd_numbers)\nprint(f\"The median of odd list is: {median_odd}\")  # Output: The median of odd list is: 7.0\n\nThe median is: 6.0\nThe median of odd list is: 7.0\n\n\nAnother example with different data:\n\n# Example with decimal numbers\ngrades = [85.5, 92.0, 78.5, 96.0, 88.5, 91.0]\n\nmean_grade = np.mean(grades)\nmedian_grade = np.median(grades)\n\nprint(f\"Mean grade: {mean_grade:.2f}\")     # Output: Mean grade: 88.58\nprint(f\"Median grade: {median_grade:.2f}\") # Output: Median grade: 89.75\n\nMean grade: 88.58\nMedian grade: 89.75\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice how the functions take our data as a parameter (the input inside the parentheses) and return a calculated value that we can store in a variable or use directly."
  },
  {
    "objectID": "files/labs/lab3/lab3.html#task-2",
    "href": "files/labs/lab3/lab3.html#task-2",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Task 2",
    "text": "Task 2\n\n⏱️ Estimated time: 3 minutes\n\nLet x_list be a list containing the elements 1, 2, and 3, and let x_array be an array containing the elements 1, 2, and 3. Compute the mean and median of x_list and x_array using the appropriate functions from the numpy module."
  },
  {
    "objectID": "files/labs/lab3/lab3.html#measures-of-spread",
    "href": "files/labs/lab3/lab3.html#measures-of-spread",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Measures of Spread",
    "text": "Measures of Spread\n\n⏱️ Estimated time: 5 minutes\n\nRecall that we also discussed several measures of spread including:\n\nStandard deviation\nIQR (Interquartile Range)\nRange\n\nSure enough, the numpy module contains several functions which help us compute these measures. Let’s examine each separately."
  },
  {
    "objectID": "files/labs/lab3/lab3.html#task-3",
    "href": "files/labs/lab3/lab3.html#task-3",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Task 3",
    "text": "Task 3\n\n⏱️ Estimated time: 4 minutes\n\nLook up the documentation of the function np.ptp(), and describe what it does. Also, answer the question: Q: what does ptp actually stand for?\nNow, apply the np.ptp() function on your x_list and x_array variables from Task 1 above and check that it functions like you expect."
  },
  {
    "objectID": "files/labs/lab3/lab3.html#task-4",
    "href": "files/labs/lab3/lab3.html#task-4",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Task 4",
    "text": "Task 4\n\n⏱️ Estimated time: 6 minutes\n\nCompute the standard deviation \\(s\\) of the x_list variable from Task 1 by hand, and write down the answer using a comment or Markdown cell.\nNow, run np.std(x_list). Does this answer agree with what you found in part (a) above?\nNow, recompute the standard deviation \\(s\\) of x_list by hand but this time use n instead of n−1 in the formula. How does this answer compare with the result of np.std(x_list)?"
  },
  {
    "objectID": "files/labs/lab3/lab3.html#task-4-contd",
    "href": "files/labs/lab3/lab3.html#task-4-contd",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Task 4 (cont’d)",
    "text": "Task 4 (cont’d)\n\n⏱️ Estimated time: 2 minutes\n\nRun np.std(x_list, ddof = 1) and check whether this matches the result of part (a) above."
  },
  {
    "objectID": "files/labs/lab3/lab3.html#optional-task-creating-your-own-iqr-function",
    "href": "files/labs/lab3/lab3.html#optional-task-creating-your-own-iqr-function",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Optional Task: Creating Your Own IQR Function",
    "text": "Optional Task: Creating Your Own IQR Function\n\n⏱️ Estimated time: 3 minutes\n\nNow that you understand how to use functions and their parameters, let’s create our own custom function to calculate the IQR! This will help you understand how to define your own functions in Python.\n1. Understanding Function Definition Syntax\nTo create a function in Python, we use the def keyword followed by the function name and parameters:\n\ndef function_name(parameter1, parameter2):\n    # Code that does something with the parameters\n    result = some_calculation\n    return result  # Give back the calculated value\n\n2. Create the IQR Function\nLet’s create a function called calculate_iqr that takes a list or array as input and returns the IQR:\n\ndef calculate_iqr(data):\n    \"\"\"\n    Calculate the Interquartile Range (IQR) of a dataset.\n    \n    Parameter:\n    data - a list or array of numbers\n    \n    Returns:\n    The IQR value (Q3 - Q1)\n    \"\"\"\n    # Calculate the IQR using the numpy method we learned\n    iqr_value = np.diff(np.percentile(data, [25, 75]))[0]\n    return iqr_value\n\n3. Test Your Function\nNow let’s test our custom function with some example data:\n\n# Create some test data\n# Example - test_scores = [72, 85, 90, 78, 92, 88, 76, 94, 82, 89, 91, 77]\n\n# Create your data\ntest_scores = [ ]\n\n# Use our custom function\nmy_iqr = calculate_iqr( ) # Call the function created above here \n\nprint(f\"IQR using our function: {my_iqr}\")\n\n# Compare with the direct method\ndirect_iqr = np.diff(np.percentile(test_scores, [25, 75]))[0]\nprint(f\"IQR using direct method: {direct_iqr}\")\n\n# They should be the same!"
  },
  {
    "objectID": "files/labs/lab3/lab3.html#visualizations",
    "href": "files/labs/lab3/lab3.html#visualizations",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Visualizations",
    "text": "Visualizations\n\n⏱️ Estimated time: 3 minutes\n\nIt’s finally time to make pretty plots! The module we will use to generate visualizations is the matplotlib module (though there are quite a few other modules that work for visualizations as well). The official website for matplotlib can be found at https://matplotlib.org/.\nBefore we generate any plots, we will need to run the following code once:\n\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\nHere’s what these lines of code are doing:\n\n%matplotlib inline tells Jupyter to display our plots directly underneath our code. It removes the need to use plt.show().\nimport matplotlib imports the matplotlib module\nimport matplotlib.pyplot as plt imports the pyplot submodule (a submodule is just a module contained within another larger module) with the abbreviation plt.\nplt.style.use('seaborn-v0_8-whitegrid') tells Jupyter to use a specific theme (called seaborn-v0_8-whitegrid) when generating plots.\n\n\n\n\n\n\n\nNote\n\n\n\nAgain, notice the beauty of the import &lt;module&gt; as &lt;abbreviation&gt; syntax.\n\nafter running the third line above, we no longer need to write matplotlib.pyplot in our code, we just use pltto call the module!\n\n\n\nAlso, there are lots of other themes you can use when generating your plots: after completing this lab, I encourage you to consult this reference guide for a list of a few other pyplot themes.\n\nBoxplots and Histograms\nNow, let’s proceed on to make some plots. The first two types of plots we will look at are the two we used to describe numerical data: namely, boxplots and histograms.\nThe functions we will use are the plt.boxplot() and plt.hist() functions, respectively."
  },
  {
    "objectID": "files/labs/lab3/lab3.html#task-5",
    "href": "files/labs/lab3/lab3.html#task-5",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Task 5",
    "text": "Task 5\n\n⏱️ Estimated time: 6 minutes\n\n\nMake a list called y that contains the following elements: [1, 2, 3, 4, 5, 4, 3, 5, 4, 1, 2].\nRun plt.boxplot(y); (be sure to include the semicolon!). Your plot should look like a basic vertical boxplot.\n\n\n\n\n\n\n\n\n\n\nLet’s make our boxplot horizontal, as opposed to vertical.\n\n\n\n\n\n\nTip\n\n\n\nRecall, that functions take on parameters (or arguments). For detailed list or arguments that can be passed on to plt.boxplot, consult the function documentationmatplotlib.pyplot.boxplot().\n\n\nFor plt.boxplot(), there is an optional param called orientation. It accepts the values “vertical” or “horizental” with ” vertical” being the default.\nTo use in your pyton code, you can simply add , after your data and add orientation =' ' . Inside \" \" specify the desired direction and close the parenthesis.\n\n\n\n\n\n\n\n\n\nNext, let’s add some color to our plot. Within your call to plt.boxplot(), after your data and orientation param, add a semicolon , to seperate the parameters and add the following: patch_artist=True, boxprops = dict(facecolor = \"aquamarine\") . Your boxplot should look like this:\n\n\n\n\n\n\n\n\n\n\nWhat do these parameters do?\n\npatch_artist=True: This parameter tells matplotlib to draw the boxplot elements (like the box itself) as “patch” objects, which can be filled with colors. By default, boxplots are drawn as simple lines without fill capability. Setting this to True enables us to add colors and other visual effects to the box.\nboxprops = dict(facecolor = \"aquamarine\"): This parameter controls the properties of the box (the rectangle part of the boxplot). The dict() creates a dictionary of properties we want to set:\n\nfacecolor specifies the fill color inside the box “aquamarine” is the color name (you could use other colors like “lightblue”, “pink”, “yellow”, etc.)\nThink of it like this: patch_artist=True gives us a “paintable” box, and boxprops = dict(facecolor = \"aquamarine\") tells Python “paint the inside of that box aquamarine color!”\nTry experimenting: after completing this task, try changing “aquamarine” to “lightcoral” or “lightsteelblue” to see different colors!\n\nFinally, let’s add a Title! Right below your call to plt.boxplot(), add the following:\n\nplt.title(\"My First Python Boxplot\"); (again, don’t forget the semicolons).\n\n\n\n\n\n\n\n\n\n\n\nBased on the boxplot we just generated, what is the IQR of y? Write your answer in a Markdown cell. Then, use the syntax discussed in the previous section of this Lab to use Python to compute the IQR of y, and comment on the result."
  },
  {
    "objectID": "files/labs/lab3/lab3.html#task-6",
    "href": "files/labs/lab3/lab3.html#task-6",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Task 6",
    "text": "Task 6\n\n⏱️ Estimated time: 5 minutes\n\nCall the plt.hist() function on the y list defined in Task 5, and use the function documentation to add arguments to your call to plt.hist() function to generate a histogram with appropriate number of bins. Add a label for the x-axis plt.xlabel('Values'), a label for the y-axis plt.ylabel('Frequency') and a title using plt.title('Histogram of y values').\nFor example, to create a basic histogram using plt.hist(), you would use the following:\n\n# Basic histogram\nplt.hist(y);\nplt.show()\n\n\n\n\n\n\n\n\n\nYou can use explicit bin edges like bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5] to center your integer values.\nAlternatively, you could use range=(0.5, 5.5) with bins=5.\nUse rwidth=0.9 to make bars 90% width (creates 10% spacing)\nAdd edge colors with edgecolor='black' for visual separation\n\nYour histogram, will look like this!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nPay attention to the number of bins! With 5 distinct values (1, 2, 3, 4, 5), we use 5 bins to clearly show the frequency of each value."
  },
  {
    "objectID": "files/labs/lab3/lab3.html#scatterplots",
    "href": "files/labs/lab3/lab3.html#scatterplots",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Scatterplots",
    "text": "Scatterplots\nWe should also quickly discuss how to generate scatterplots in Python."
  },
  {
    "objectID": "files/labs/lab3/lab3.html#task-7",
    "href": "files/labs/lab3/lab3.html#task-7",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Task 7",
    "text": "Task 7\n\n⏱️ Estimated time: 4 minutes\n\n\nCopy-paste the following code into a code cell, and then run that cell (don’t worry about what this code is doing- we’ll discuss that in a future lab).\n\n\nnp.random.seed(5)\n\nx1 = np.random.normal(0, 1, 100)\nx2 = x1 + np.random.normal(0, 1, 100)\n\nplt.scatter(x1, x2);\n\n\n\n\n\n\n\n\n\nAdd an x-axis label that says “x1” and a y-axis label that says “x2”, along with the title “My First Python Scatterplot”."
  },
  {
    "objectID": "files/labs/lab3/lab3.html#task-8",
    "href": "files/labs/lab3/lab3.html#task-8",
    "title": "Lab 3: Descriptive Statistics",
    "section": "Task 8",
    "text": "Task 8\n\n⏱️ Estimated time: 4 minutes\n\nGenerate a plot of the function \\(f(x)=x-x^2 \\sin(x)\\) between \\(x=−10\\) and \\(x=10\\).\nExperiment around with the number of values generated using np.linspace(start, stop, num) to ensure your plot is relatively smooth.\nBe sure to include axis labels; also, change the color of the graph to red. Your final plot should look something like this:"
  },
  {
    "objectID": "files/labs/lab5/lab5_sln.html",
    "href": "files/labs/lab5/lab5_sln.html",
    "title": "Lab 5 Solutions: Continuous Random Variables & Confidence Intervals",
    "section": "",
    "text": "# Install any missing packages (will skip those already installed)\n#!%pip install --quiet numpy matplotlib scipy pandas statsmodels\n\n# Load our tools (libraries)\nimport numpy as np # numerical computing (arrays, random numbers, etc.)\nimport matplotlib.pyplot as plt # plotting library for static 2D graphs and visualizations\nfrom scipy import stats #  statistical functions (distributions, tests, etc.)\nimport pandas as pd # data structures (DataFrame) and data analysis tools\nimport statsmodels  # statistical modeling (regression, time series, ANOVA, etc.)\n\n# Make our graphs look nice\n#!%matplotlib inline     # embed Matplotlib plots directly in the notebook\nplt.style.use('seaborn-v0_8-whitegrid')  # Apply a clean whitegrid style from Seaborn\n\n# Set random seed for reproducible results\nnp.random.seed(42)    # fix the random seed so results can be reproduced exactly\n\nprint(\"✅ All tools loaded successfully!\") \n\n✅ All tools loaded successfully!"
  },
  {
    "objectID": "files/labs/lab5/lab5_sln.html#lab-5-complete-solutions-summary",
    "href": "files/labs/lab5/lab5_sln.html#lab-5-complete-solutions-summary",
    "title": "Lab 5 Solutions: Continuous Random Variables & Confidence Intervals",
    "section": "🎯 Lab 5 Complete Solutions Summary",
    "text": "🎯 Lab 5 Complete Solutions Summary\n\n✅ Task 1: Normal distribution calculations with human heights\n✅ Task 2: Exponential distribution for bus waiting times\n\n✅ Task 3: Central Limit Theorem verification with uniform distribution\n✅ Task 4: 90% confidence interval construction for homework data\n✅ Task 5: Distribution matching exercise with reasoning\n\nKey Takeaways:\n\nContinuous distributions use PDFs and calculate probabilities as areas\nNormal distribution is fundamental and appears everywhere via CLT\nConfidence intervals provide ranges of plausible values for parameters\nSample size affects precision; confidence level affects interval width\nPython’s scipy.stats provides powerful tools for distribution analysis"
  },
  {
    "objectID": "files/labs/lab6/lab6_sln.html",
    "href": "files/labs/lab6/lab6_sln.html",
    "title": "Lab 6 Solutions: Basic Hypothesis Testing & Simple Regression",
    "section": "",
    "text": "Welcome to Lab 6 Solutions! This lab focuses on two fundamental areas of statistical analysis that you’ll use throughout your data science journey: hypothesis testing and simple linear regression. These tools allow us to make data-driven decisions and understand relationships between variables."
  },
  {
    "objectID": "files/labs/lab6/lab6_sln.html#what-youll-learn-today",
    "href": "files/labs/lab6/lab6_sln.html#what-youll-learn-today",
    "title": "Lab 6 Solutions: Basic Hypothesis Testing & Simple Regression",
    "section": "What You’ll Learn Today",
    "text": "What You’ll Learn Today\nBy the end of this lab, you’ll be able to:\n\nConduct hypothesis tests to determine if sample data provides evidence against a claim\nModel relationships between variables using simple linear regression\nMake predictions based on data patterns\nInterpret statistical results in plain English for real-world applications"
  },
  {
    "objectID": "files/labs/lab6/lab6_sln.html#what-is-a-one-sample-t-test",
    "href": "files/labs/lab6/lab6_sln.html#what-is-a-one-sample-t-test",
    "title": "Lab 6 Solutions: Basic Hypothesis Testing & Simple Regression",
    "section": "What is a One-Sample T-Test?",
    "text": "What is a One-Sample T-Test?\nA one-sample t-test helps us determine whether a sample mean is significantly different from a claimed or hypothesized population mean. It’s one of the most common statistical tests you’ll encounter.\nReal-world example: A coffee shop advertises that their espresso shots contain an average of 75mg of caffeine. As a health-conscious consumer (or maybe a caffeine researcher!), you want to test this claim. You collect a sample of espresso shots and measure their caffeine content.\nThe Question: Is the actual average caffeine content different from what the coffee shop claims?\n\nScenario\nA coffee shop claims their average espresso shot contains 75 mg of caffeine. You suspect it’s actually higher. You test 20 shots and want to test at \\(\\alpha = 0.05\\) significance level.\nYour Goal: Determine if there’s sufficient evidence that the actual caffeine content exceeds the coffee shop’s claim.\n\n\nStep 1: Explore the Data\n\n# Generate caffeine data for our analysis\nnp.random.seed(123)\ncaffeine_data = np.random.normal(78, 8, 20)  # Sample data: n=20 espresso shots\n\nprint(\"☕ Coffee Shop Caffeine Analysis\")\nprint(\"=\" * 40)\nprint(f\"📊 Sample size: {len(caffeine_data)}\")\nprint(f\"📈 Sample mean: {np.mean(caffeine_data):.2f} mg\")\nprint(f\"📊 Sample std dev: {np.std(caffeine_data, ddof=1):.2f} mg\")\nprint(f\"🏪 Coffee shop's claim: 75 mg\")\n\n# Let's look at our raw data\nprint(f\"\\n🔍 First 10 caffeine measurements:\")\nprint([f\"{x:.1f}\" for x in caffeine_data[:10]])\n\n☕ Coffee Shop Caffeine Analysis\n========================================\n📊 Sample size: 20\n📈 Sample mean: 78.92 mg\n📊 Sample std dev: 10.06 mg\n🏪 Coffee shop's claim: 75 mg\n\n🔍 First 10 caffeine measurements:\n['69.3', '86.0', '80.3', '65.9', '73.4', '91.2', '58.6', '74.6', '88.1', '71.1']\n\n\n\n\nStep 2: Set Up Your Hypotheses\nThink about this carefully: - What does the coffee shop claim? (This becomes your null hypothesis) - What do you suspect? (This becomes your alternative hypothesis) - Are you testing if the caffeine content is different, higher, or lower?\n\nprint(\"📝 STEP 1: Setting Up Hypotheses\")\nprint(\"=\" * 35)\n\n# SOLUTION: Complete these hypotheses\nprint(\"$H_0$ (Null Hypothesis): $\\\\mu$ = 75 mg\")        # Coffee shop's claim\nprint(\"$H_1$ (Alternative Hypothesis): $\\\\mu$ &gt; 75 mg\")  # We suspect it's higher\n\n# SOLUTION: What type of test is this?\nprint(\"Test type: RIGHT-tailed test\")   # Testing if mean is greater than 75\n\nprint(\"\\n💡 Explanation:\")\nprint(\"• $H_0$ represents the coffee shop's claim (status quo)\")\nprint(\"• $H_1$ represents what we suspect is actually true\")\nprint(\"• We use $\\\\alpha$ = 0.05 as our significance level\")\n\n📝 STEP 1: Setting Up Hypotheses\n===================================\n$H_0$ (Null Hypothesis): $\\mu$ = 75 mg\n$H_1$ (Alternative Hypothesis): $\\mu$ &gt; 75 mg\nTest type: RIGHT-tailed test\n\n💡 Explanation:\n• $H_0$ represents the coffee shop's claim (status quo)\n• $H_1$ represents what we suspect is actually true\n• We use $\\alpha$ = 0.05 as our significance level\n\n\n✅ Answer Key: - \\(H_0\\): \\(\\mu\\) = 75 mg (coffee shop’s claim) - \\(H_1\\): \\(\\mu\\) &gt; 75 mg (we suspect it’s higher) - Right-tailed test (testing if mean is greater than 75)\n\n\nStep 3: Calculate the Test Statistic\nThe t-statistic formula is: \\(t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}\\)\n\nprint(\"🔢 STEP 2: Calculating Test Statistic\")\nprint(\"=\" * 38)\n\n# Calculate the components\nsample_mean = np.mean(caffeine_data)\nsample_std = np.std(caffeine_data, ddof=1)  # ddof=1 for sample std dev\nn = len(caffeine_data)\nclaimed_mean = 75\n\nprint(f\"Sample mean ($\\\\bar{{x}}$): {sample_mean:.3f} mg\")\nprint(f\"Sample std dev (s): {sample_std:.3f} mg\")\nprint(f\"Sample size (n): {n}\")\nprint(f\"Claimed mean ($\\\\mu_0$): {claimed_mean} mg\")\n\n# SOLUTION: Calculate the t-statistic using the formula above\nt_statistic = (sample_mean - claimed_mean) / (sample_std / np.sqrt(n))\n\ndegrees_freedom = n - 1\n\nprint(f\"\\n📐 Formula: $t = \\\\frac{{\\\\bar{{x}} - \\\\mu_0}}{{s / \\\\sqrt{{n}}}}$\")\nprint(f\"📐 Calculation: t = ({sample_mean:.3f} - {claimed_mean}) / ({sample_std:.3f} / √{n})\")\nprint(f\"📊 t-statistic: {t_statistic:.3f}\")\nprint(f\"📊 Degrees of freedom: {degrees_freedom}\")\n\n🔢 STEP 2: Calculating Test Statistic\n======================================\nSample mean ($\\bar{x}$): 78.915 mg\nSample std dev (s): 10.060 mg\nSample size (n): 20\nClaimed mean ($\\mu_0$): 75 mg\n\n📐 Formula: $t = \\frac{\\bar{x} - \\mu_0}{s / \\sqrt{n}}$\n📐 Calculation: t = (78.915 - 75) / (10.060 / √20)\n📊 t-statistic: 1.741\n📊 Degrees of freedom: 19\n\n\n\n\nStep 4: Find the P-Value\nFor a right-tailed test, the p-value is the probability of getting a t-statistic as extreme or more extreme than what we observed.\n\n\n\n\n\n\nWhat exactly is a p‑value?\n\n\n\nLoosely speaking, the p‑value answers the question:\n\n“If the null hypothesis were true, how surprising would my sample be?”\n\nFormally, it is the probability, calculated under the assumption that the null hypothesis is correct; of obtaining a test statistic as extreme or more extreme than the one observed.\n\nSmall p‑value (e.g., &lt; 0.05) → data are rare under \\(H_0\\) → strong evidence against \\(H_0\\).\n\nLarge p‑value → data are plausible under \\(H_0\\) → little or no evidence against \\(H_0\\).\n\nImportant: A p‑value does not give the probability that the null hypothesis is true; it quantifies how incompatible your data are with \\(H_0\\).\n\n\n\nprint(\"📈 STEP 3: Finding the P-Value\")\nprint(\"=\" * 32)\n\n# SOLUTION: Calculate p-value for right-tailed test\n# For right-tailed test, p-value = 1 - stats.t.cdf(t_statistic, df)\np_value = 1 - stats.t.cdf(t_statistic, degrees_freedom)\n\nprint(f\"🎯 P-value calculation:\")\nprint(f\"   P(t &gt; {t_statistic:.3f}) = {p_value:.4f}\")\nprint(f\"\\n💭 Interpretation:\")\nprint(f\"   If the coffee shop's claim is true ($\\\\mu$ = 75),\")\nprint(f\"   there's a {p_value:.1%} chance of getting a sample\")\nprint(f\"   mean as high or higher than {sample_mean:.2f} mg\")\n\n📈 STEP 3: Finding the P-Value\n================================\n🎯 P-value calculation:\n   P(t &gt; 1.741) = 0.0490\n\n💭 Interpretation:\n   If the coffee shop's claim is true ($\\mu$ = 75),\n   there's a 4.9% chance of getting a sample\n   mean as high or higher than 78.92 mg\n\n\n\n\nStep 5: Make Your Decision\nCompare your p-value to \\(\\alpha = 0.05\\) and make a statistical decision.\n\nprint(\"⚖️ STEP 4: Making the Decision\")\nprint(\"=\" * 31)\n\nalpha = 0.05\nprint(f\"🎯 Significance level ($\\\\alpha$): {alpha}\")\nprint(f\"📊 P-value: {p_value:.4f}\")\nprint(f\"📋 Decision rule: Reject $H_0$ if p-value &lt; $\\\\alpha$\")\n\nprint(f\"\\n🔍 Comparison:\")\nif p_value &lt; alpha:\n    print(f\"   {p_value:.4f} &lt; {alpha} ✅\")\n    print(f\"   Decision: **REJECT $H_0$**\")\n    print(f\"   Conclusion: There IS sufficient evidence that\")\n    print(f\"             the average caffeine content &gt; 75 mg\")\n    print(f\"   🏪 The coffee shop's claim appears to be FALSE\")\nelse:\n    print(f\"   {p_value:.4f} ≥ {alpha} ❌\")\n    print(f\"   Decision: **FAIL TO REJECT $H_0$**\")\n    print(f\"   Conclusion: There is NOT sufficient evidence that\")\n    print(f\"             the average caffeine content &gt; 75 mg\")\n    print(f\"   🏪 We cannot conclude the coffee shop's claim is false\")\n\n# SOLUTION: Write conclusion in plain English\nprint(f\"\\n📝 Conclusion in plain English:\")\nprint(f\"   Based on our sample of 20 espresso shots, we found\")\nprint(f\"   strong statistical evidence that the coffee shop's\")\nprint(f\"   claim of 75mg caffeine is too low. The actual average\")\nprint(f\"   appears to be significantly higher than advertised.\")\n\n⚖️ STEP 4: Making the Decision\n===============================\n🎯 Significance level ($\\alpha$): 0.05\n📊 P-value: 0.0490\n📋 Decision rule: Reject $H_0$ if p-value &lt; $\\alpha$\n\n🔍 Comparison:\n   0.0490 &lt; 0.05 ✅\n   Decision: **REJECT $H_0$**\n   Conclusion: There IS sufficient evidence that\n             the average caffeine content &gt; 75 mg\n   🏪 The coffee shop's claim appears to be FALSE\n\n📝 Conclusion in plain English:\n   Based on our sample of 20 espresso shots, we found\n   strong statistical evidence that the coffee shop's\n   claim of 75mg caffeine is too low. The actual average\n   appears to be significantly higher than advertised.\n\n\n\n\nStep 6: Verify with Python\nLet’s double-check our work using Python’s built-in statistical functions.\n\nprint(\"✅ VERIFICATION using scipy.stats\")\nprint(\"=\" * 35)\n\n# Use scipy's one-sample t-test function\nt_stat_scipy, p_val_scipy = stats.ttest_1samp(caffeine_data, 75, alternative='greater')\n\nprint(f\"📊 Your calculations:\")\nprint(f\"   t-statistic: {t_statistic:.3f}\")\nprint(f\"   p-value: {p_value:.4f}\")\n\nprint(f\"\\n🐍 Python's calculations:\")\nprint(f\"   t-statistic: {t_stat_scipy:.3f}\")\nprint(f\"   p-value: {p_val_scipy:.4f}\")\n\nprint(f\"\\n🎯 Match? {abs(t_statistic - t_stat_scipy) &lt; 0.001 and abs(p_value - p_val_scipy) &lt; 0.001}\")\n\n✅ VERIFICATION using scipy.stats\n===================================\n📊 Your calculations:\n   t-statistic: 1.741\n   p-value: 0.0490\n\n🐍 Python's calculations:\n   t-statistic: 1.741\n   p-value: 0.0490\n\n🎯 Match? True\n\n\n\n\nStep 7: Visualize Your Results\n\n# Create visualizations to understand our test\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Plot 1: Sample data histogram with means\nax1.hist(caffeine_data, bins=8, density=True, alpha=0.7, color='lightblue', \n         edgecolor='black', label='Sample Data')\nax1.axvline(sample_mean, color='red', linestyle='-', linewidth=3, \n           label=f'Sample Mean = {sample_mean:.1f}mg')\nax1.axvline(claimed_mean, color='orange', linestyle='--', linewidth=3, \n           label=f'Claimed Mean = {claimed_mean}mg')\nax1.set_xlabel('Caffeine Content (mg)', fontsize=12)\nax1.set_ylabel('Density', fontsize=12)\nax1.set_title('☕ Sample vs Claimed Caffeine Content', fontsize=14, fontweight='bold')\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3)\n\n# Plot 2: t-distribution with test statistic and p-value\nx = np.linspace(-4, 4, 1000)\ny = stats.t.pdf(x, degrees_freedom)\nax2.plot(x, y, 'b-', linewidth=2, label=f't-distribution (df={degrees_freedom})')\nax2.fill_between(x, y, alpha=0.3, color='lightblue')\n\n# Shade the rejection region (right tail)\nx_reject = x[x &gt;= t_statistic]\ny_reject = stats.t.pdf(x_reject, degrees_freedom)\nax2.fill_between(x_reject, y_reject, alpha=0.7, color='red', \n                label=f'p-value = {p_value:.4f}')\n\nax2.axvline(t_statistic, color='red', linestyle='-', linewidth=3, \n           label=f'Our t-statistic = {t_statistic:.3f}')\nax2.set_xlabel('t-value', fontsize=12)\nax2.set_ylabel('Density', fontsize=12)\nax2.set_title('📊 T-Distribution with Test Statistic', fontsize=14, fontweight='bold')\nax2.legend(fontsize=11)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n🤔 Reflection Questions - SOLUTIONS\nAnswer these questions to check your understanding:\n\nHypotheses: What were your null and alternative hypotheses? Why did you choose a right-tailed test?\n\nAnswer: \\(H_0\\): \\(\\mu\\) = 75 mg, \\(H_1\\): \\(\\mu\\) &gt; 75 mg. We chose a right-tailed test because we specifically suspected the caffeine content was higher than claimed, not just different.\n\nTest Choice: Why did you use a t-test instead of a z-test for this problem?\n\nAnswer: We used a t-test because: (1) small sample size (n=20 &lt; 30), (2) population standard deviation unknown, (3) assuming approximately normal distribution.\n\nResults: What was your t-statistic and p-value? What do these numbers mean?\n\nAnswer: t ≈ 1.84, p ≈ 0.041. The t-statistic tells us how many standard errors our sample mean is above the claimed mean. The p-value tells us there’s only a 4.1% chance of seeing this result if the true mean were 75mg.\n\nDecision: What was your final conclusion at \\(\\alpha = 0.05\\)? Do you reject or fail to reject the null hypothesis?\n\nAnswer: We REJECT \\(H_0\\) because p-value (0.041) &lt; α (0.05). There’s sufficient evidence that the actual caffeine content exceeds 75mg.\n\nReal-World Impact: If you were advising the coffee shop, what would you tell them based on your analysis?\n\nAnswer: “Your espresso shots appear to contain significantly more caffeine than advertised. You should either update your labeling to reflect the actual content or adjust your brewing process to match your claim.”"
  },
  {
    "objectID": "files/labs/lab6/lab6_sln.html#lab-summary",
    "href": "files/labs/lab6/lab6_sln.html#lab-summary",
    "title": "Lab 6 Solutions: Basic Hypothesis Testing & Simple Regression",
    "section": "🎯 Lab Summary",
    "text": "🎯 Lab Summary\nCongratulations! You’ve successfully completed Lab 6 and learned fundamental statistical analysis techniques:\n\nWhat You Accomplished\n✅ One-Sample T-Test: Tested a coffee shop’s caffeine claims using hypothesis testing\n✅ Simple Linear Regression: Modeled the relationship between study hours and exam performance\n✅ Statistical Interpretation: Translated statistical results into practical insights\n✅ Critical Thinking: Distinguished between correlation and causation\n\n\nKey Skills Developed\n\nSetting up and testing hypotheses\nCalculating and interpreting p-values\nFitting regression models and making predictions\nChecking model assumptions with diagnostic plots\nCommunicating statistical findings clearly"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#introduction",
    "href": "files/labs/lab2/lab2_sln.html#introduction",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "Introduction",
    "text": "Introduction\nThis document contains the complete solutions to Lab 2: Data Classes and Programming Fundamentals. Each task is solved with explanations to help you understand the concepts."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#lists",
    "href": "files/labs/lab2/lab2_sln.html#lists",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "Lists",
    "text": "Lists\n\nTask 1 Solution\nCreate a list containing the elements 1, \"hi\", 3.4, and \"PSTAT 5A\". Assign this list to a variable called list1.\n\n# Solution\nlist1 = [1, \"hi\", 3.4, \"PSTAT 5A\"]\nprint(list1)\n\n[1, 'hi', 3.4, 'PSTAT 5A']\n\n\n\n\nTask 1 (cont’d) Solution\nRun the code type(list1).\n\n# Solution\nprint(type(list1))\n\n&lt;class 'list'&gt;\n\n\nExplanation: The output shows &lt;class 'list'&gt;, confirming that list1 is indeed a list object."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#indexing",
    "href": "files/labs/lab2/lab2_sln.html#indexing",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "Indexing",
    "text": "Indexing\n\nTask 2 Solution\nCreate a list with the numbers 1 through 10, inclusive, and assign this to a variable called x.\n\n# Solution\nx = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n# Alternative using range:\n# x = list(range(1, 11))\nprint(x)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nRun the code x[1].\n\n# Solution\nprint(x[1])\n\n2\n\n\nRun the code x[0].\n\n# Solution\nprint(x[0])\n\n1\n\n\nExplanation: - x[1] returns 2 (the second element, since indexing starts at 0) - x[0] returns 1 (the first element)\n\n\nTask 3 Solution\nCreate a list called x that contains the elements 1, \"two\", 3.5, \"four\", and \"five five\". Answer the questions and verify.\n\n# Create the list\nx = [1, \"two\", 3.5, \"four\", \"five five\"]\n\n# Predictions as comments:\n# 1. type(x) would output: &lt;class 'list'&gt;\n# 2. type(x[1]) would output: &lt;class 'str'&gt;\n# 3. x[0] would output: 1\n\nNow verify the answers:\n\n# Verify answers\nprint(\"1. type(x):\", type(x))\nprint(\"2. type(x[1]):\", type(x[1]))\nprint(\"3. x[0]:\", x[0])\n\n1. type(x): &lt;class 'list'&gt;\n2. type(x[1]): &lt;class 'str'&gt;\n3. x[0]: 1\n\n\nExplanation: 1. type(x) returns &lt;class 'list'&gt; because x is a list 2. type(x[1]) returns &lt;class 'str'&gt; because x[1] is “two”, which is a string 3. x[0] returns 1, the first element of the list"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#tables",
    "href": "files/labs/lab2/lab2_sln.html#tables",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "Tables",
    "text": "Tables\nFirst, let’s install and import the datascience module:\n\n# Install datascience if needed (uncomment if necessary)\n# !pip install datascience\nfrom datascience import *\n\n/Users/narjesmathlouthi/miniconda3/envs/pstat5a/lib/python3.11/site-packages/datascience/maps.py:13: UserWarning:\n\npkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n\n\n\n\nTask 4 Solution\nRead the list of methods for Table objects and write down three different methods:\n\n# Three Table methods with descriptions:\n# .with_columns(): adds specified columns to a table\n# .select(): selects specific columns from a table and returns a new table\n# .where(): filters rows based on a condition and returns a new table with matching rows\n# .num_rows: returns the number of rows in the table\n# .num_columns: returns the number of columns in the table\n\n\n\nTask 5 Solution\nCreate the professor table:\n\n# Solution\nprofs = Table().with_columns(\n    \"Professor\", [\"Dr. Swenson\", \"Dr. Wainwright\", \"Dr. Mouti\"],\n    \"Office\", [\"South Hall\", \"Old Gym\", \"Old Gym\"],\n    \"Course\", [\"PSTAT 130\", \"PSTAT 120A\", \"PSTAT 126\"]\n)\n\nprofs\n\n\n\n\nProfessor\nOffice\nCourse\n\n\n\n\nDr. Swenson\nSouth Hall\nPSTAT 130\n\n\nDr. Wainwright\nOld Gym\nPSTAT 120A\n\n\nDr. Mouti\nOld Gym\nPSTAT 126\n\n\n\n\n\nSelect the column called Course from profs:\n\n# Solution\nprofs.select(\"Course\")\n\n\n\n\nCourse\n\n\n\n\nPSTAT 130\n\n\nPSTAT 120A\n\n\nPSTAT 126\n\n\n\n\n\nCreate a new table called profs_new with an additional row:\n\n# Solution\nprofs_new = profs.with_row([\"Dr. Ravat\", \"South Hall\", \"PSTAT 120B\"])\nprofs_new\n\n\n\n\nProfessor\nOffice\nCourse\n\n\n\n\nDr. Swenson\nSouth Hall\nPSTAT 130\n\n\nDr. Wainwright\nOld Gym\nPSTAT 120A\n\n\nDr. Mouti\nOld Gym\nPSTAT 126\n\n\nDr. Ravat\nSouth Hall\nPSTAT 120B\n\n\n\n\n\nExplanation: The .with_row() method adds a new row to the existing table. We provide the values in the same order as the columns.\n\n\nFiltering Tables Example\n\n# Create example table for filtering\ntable1 = Table().with_columns(\n    \"Course\", [\"PSTAT 5A\", \"PSTAT 120A\", \"PSTAT 130\"],\n    \"Units\", [4, 4, 4],\n    \"Instructor\", [\"Mathlouthi\", \"Johnson\", \"Smith\"]\n)\n\n# Filter for courses taught by Mathlouthi\ntable1.where(\"Instructor\", \"Mathlouthi\")\n\n\n\n\nCourse\nUnits\nInstructor\n\n\n\n\nPSTAT 5A\n4\nMathlouthi\n\n\n\n\n\n\n# Try filtering for an instructor that doesn't exist\ntable1.where(\"Instructor\", \"Wilson\")\n\n\n\n\nCourse\nUnits\nInstructor"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#arrays",
    "href": "files/labs/lab2/lab2_sln.html#arrays",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "Arrays",
    "text": "Arrays\n\nTask 6 Solution\nMake a list and array with the same elements and compare operations:\n\n# Create list and array\nmy_list = [1, 2, 3]\nmy_array = make_array(1, 2, 3)\n\nprint(\"List:\", my_list)\nprint(\"Array:\", my_array)\n\nList: [1, 2, 3]\nArray: [1 2 3]\n\n\n\n# Sum operations\nprint(\"sum(my_list):\", sum(my_list))\nprint(\"sum(my_array):\", sum(my_array))\n\nsum(my_list): 6\nsum(my_array): 6\n\n\n\n# Addition with scalar - this will cause an error for lists\ntry:\n    result = my_list + 2\n    print(\"my_list + 2:\", result)\nexcept TypeError as e:\n    print(\"Error with my_list + 2:\", e)\n\nError with my_list + 2: can only concatenate list (not \"int\") to list\n\n\n\n# Addition with scalar works for arrays\nprint(\"my_array + 2:\", my_array + 2)\n\nmy_array + 2: [3 4 5]\n\n\nExplanation: Arrays support element-wise operations (like adding 2 to each element), while lists do not. Lists use + for concatenation, not arithmetic."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#comparisons",
    "href": "files/labs/lab2/lab2_sln.html#comparisons",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "Comparisons",
    "text": "Comparisons\n\nTask 7 Solution\nCompare \"statistics\" and \"Statistics\":\n\n# Solution\nprint('\"statistics\" &lt; \"Statistics\":', \"statistics\" &lt; \"Statistics\")\nprint('\"Statistics\" &lt; \"statistics\":', \"Statistics\" &lt; \"statistics\")\n\n# Additional comparisons to understand the pattern\nprint('ord(\"S\"):', ord(\"S\"))\nprint('ord(\"s\"):', ord(\"s\"))\n\n\"statistics\" &lt; \"Statistics\": False\n\"Statistics\" &lt; \"statistics\": True\nord(\"S\"): 83\nord(\"s\"): 115\n\n\nAnswer: When Python compares strings, capital letters are given precedence (they have “lower” ASCII values). Capital letters come before lowercase letters in ASCII ordering, so \"Statistics\" &lt; \"statistics\" returns True.\n\n\nTask 8 Solution\nCreate arrays and compare element-wise:\n\n# Solution\nx = make_array(1, 2, 3)\ny = make_array(2, 3, 1)\n\nprint(\"x:\", x)\nprint(\"y:\", y)\nprint(\"x &lt; y:\", x &lt; y)\n\nx: [1 2 3]\ny: [2 3 1]\nx &lt; y: [ True  True False]\n\n\nExplanation: Python compares arrays element-wise, returning an array of boolean values: - 1 &lt; 2 → True - 2 &lt; 3 → True\n- 3 &lt; 1 → False"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#conditionals",
    "href": "files/labs/lab2/lab2_sln.html#conditionals",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "Conditionals",
    "text": "Conditionals\n\nTask 9 Solution\nPredict and verify the conditional statement:\n\n# Prediction: x will be \"goodbye\"\n# Reasoning: x = 2, so x &lt; 2 is False, but x &lt; 3 is True\n\n# Run the code:\nx = 2\n\nif x &lt; 2:\n    x = \"hello\"\nelif x &lt; 3:\n    x = \"goodbye\"\nelse:\n    x = \"take care\"\n\nprint(\"Result:\", x)\n\nResult: goodbye\n\n\nExplanation: Since x = 2: - x &lt; 2 is False (2 is not less than 2) - x &lt; 3 is True (2 is less than 3) - So the elif condition executes, setting x = \"goodbye\""
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#functions",
    "href": "files/labs/lab2/lab2_sln.html#functions",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "Functions",
    "text": "Functions\n\nTask 10 Solution\nThree functions we’ve used in this Lab:\n# Three functions used in this lab:\n# 1. type() - returns the data type of an object\n# 2. print() - displays output to the screen\n# 3. make_array() - creates an array from the given elements\n# Additional: sum(), len(), range()\n\n\nTask 11 Solution\nWrite a Celsius to Fahrenheit conversion function:\n\n# Solution\ndef cent_to_far(c):\n    \"\"\"Convert Celsius to Fahrenheit using the formula F = (9/5) * C + 32\"\"\"\n    fahrenheit = (9/5) * c + 32\n    return fahrenheit\n\n# Test the function\nprint(\"cent_to_far(0):\", cent_to_far(0))    # Should return 32\nprint(\"cent_to_far(20):\", cent_to_far(20))  # Should return 68\n\ncent_to_far(0): 32.0\ncent_to_far(20): 68.0\n\n\nExplanation: The conversion formula is F = (9/5) × C + 32. Our function correctly implements this formula.\n\n\nTask 12 Solution\nWrite a parity function to determine if a number is even or odd:\n\n# Solution\ndef parity(x):\n    \"\"\"Returns 'even' if x is even, 'odd' if x is odd\"\"\"\n    if x % 2 == 0:\n        return \"even\"\n    else:\n        return \"odd\"\n\n# Test the function\nprint(\"parity(2):\", parity(2))  # Should return 'even'\nprint(\"parity(3):\", parity(3))  # Should return 'odd'\n\n# Additional tests\nprint(\"parity(10):\", parity(10))\nprint(\"parity(15):\", parity(15))\n\nparity(2): even\nparity(3): odd\nparity(10): even\nparity(15): odd\n\n\nExplanation: The modulus operator % returns the remainder of division. If x % 2 == 0, then x is divisible by 2 (even). Otherwise, it’s odd."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#complete-examples-and-additional-practice",
    "href": "files/labs/lab2/lab2_sln.html#complete-examples-and-additional-practice",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "Complete Examples and Additional Practice",
    "text": "Complete Examples and Additional Practice\nHere are some additional examples that demonstrate the concepts:\n\nAdvanced List Operations\n\n# List slicing examples\nnumbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nprint(\"First 5 elements:\", numbers[:5])\nprint(\"Last 3 elements:\", numbers[-3:])\nprint(\"Every other element:\", numbers[::2])\n\nFirst 5 elements: [0, 1, 2, 3, 4]\nLast 3 elements: [7, 8, 9]\nEvery other element: [0, 2, 4, 6, 8]\n\n\n\n\nTable Operations\n\n# More complex table operations\nstudents = Table().with_columns(\n    \"Name\", [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"],\n    \"Grade\", [85, 92, 78, 96],\n    \"Year\", [\"Sophomore\", \"Junior\", \"Freshman\", \"Senior\"]\n)\n\n# Multiple operations\nhigh_performers = students.where(\"Grade\", are.above(90))\nprint(\"High performers:\")\nhigh_performers.show()\n\n# Sort by grade\nsorted_students = students.sort(\"Grade\", descending=True)\nprint(\"\\nStudents sorted by grade:\")\nsorted_students.show()\n\nHigh performers:\n\n\n\n\n\nName\nGrade\nYear\n\n\n\n\nBob\n92\nJunior\n\n\nDiana\n96\nSenior\n\n\n\n\n\n\nStudents sorted by grade:\n\n\n\n\n\nName\nGrade\nYear\n\n\n\n\nDiana\n96\nSenior\n\n\nBob\n92\nJunior\n\n\nAlice\n85\nSophomore\n\n\nCharlie\n78\nFreshman\n\n\n\n\n\n\n\nArray Operations\n\nimport numpy as np\n\n# Array mathematical operations\nscores = make_array(85, 92, 78, 96, 89)\nprint(\"Original scores:\", scores)\nprint(\"Curved scores (+5):\", scores + 5)\nprint(\"Squared scores:\", scores ** 2)\nprint(\"Average score:\", np.mean(scores))\n\nOriginal scores: [85 92 78 96 89]\nCurved scores (+5): [ 90  97  83 101  94]\nSquared scores: [7225 8464 6084 9216 7921]\nAverage score: 88.0"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#summary",
    "href": "files/labs/lab2/lab2_sln.html#summary",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "Summary",
    "text": "Summary\nThis lab covered fundamental Python data structures and programming concepts:\n\nLists: Mutable, mixed-type collections with zero-based indexing\nTables: Structured data with named columns for data analysis\nArrays: Homogeneous collections supporting element-wise operations\nComparisons: Boolean logic and various comparison operators\nConditionals: Decision-making with if/elif/else statements\nFunctions: Creating reusable code blocks with proper documentation\n\nThese concepts form the foundation for data analysis and programming in Python!"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html",
    "href": "files/labs/lab4/lab4_v2.html",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "",
    "text": "Welcome to Lab 4! Today we’ll explore discrete random variables and probability distributions using Python. We’ll learn how to calculate probabilities, expected values, and visualize different distributions."
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#probability-mass-function-pmf",
    "href": "files/labs/lab4/lab4_v2.html#probability-mass-function-pmf",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Probability Mass Function (PMF)",
    "text": "Probability Mass Function (PMF)\nFor a discrete random variable X, the Probability Mass Function P(X = k) gives the probability that X takes the value k.\nKey properties of a PMF: - P(X = k) ≥ 0 for all k - Σ P(X = k) = 1 (sum over all possible values)\nLet’s start with a simple example:\n\n# Simple discrete random variable: rolling a fair die\n# X can take values 1, 2, 3, 4, 5, 6 each with probability 1/6\n\ndie_values = [1, 2, 3, 4, 5, 6]\ndie_probabilities = [1/6, 1/6, 1/6, 1/6, 1/6, 1/6]\n\nprint(\"Die Values:\", die_values)\nprint(\"Probabilities:\", die_probabilities)\nprint(\"Sum of probabilities:\", sum(die_probabilities))\n\nDie Values: [1, 2, 3, 4, 5, 6]\nProbabilities: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\nSum of probabilities: 0.9999999999999999\n\n\nLet’s visualize this distribution:\n\nplt.figure(figsize=(8, 5))\nplt.bar(die_values, die_probabilities, alpha=0.7, color='skyblue', edgecolor='black')\nplt.xlabel('Value')\nplt.ylabel('Probability')\nplt.title('Probability Mass Function - Fair Die')\nplt.ylim(0, 0.25)\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#task-1",
    "href": "files/labs/lab4/lab4_v2.html#task-1",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Task 1",
    "text": "Task 1\n\n⏱️ Estimated time: 5 minutes\n\nConsider a biased coin where P(Heads) = 0.7 and P(Tails) = 0.3. Let X be a random variable where X = 1 for Heads and X = 0 for Tails.\n\nCreate lists for the values and probabilities of X\nVerify that the probabilities sum to 1\nCreate a bar plot showing the PMF"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#expected-value-mean",
    "href": "files/labs/lab4/lab4_v2.html#expected-value-mean",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Expected Value (Mean)",
    "text": "Expected Value (Mean)\nThe expected value of a discrete random variable X is:\n\n\\[E[X] = \\mu = \\sum_{k} k \\cdot P(X = k)\\]"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#variance",
    "href": "files/labs/lab4/lab4_v2.html#variance",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Variance",
    "text": "Variance\nThe variance of X is:\n\n\\[\\text{Var}(X) = \\sigma^2 = E[X^2] - (E[X])^2 = \\sum_{k} k^2 \\cdot P(X = k) - \\mu^2\\]\n\nLet’s calculate these for our fair die example:\n\n# Expected value of a fair die\nexpected_value = sum(k * p for k, p in zip(die_values, die_probabilities))\nprint(f\"Expected value of fair die: {expected_value}\")\n\n# Variance calculation\n# First calculate E[X^2]\nexpected_x_squared = sum(k**2 * p for k, p in zip(die_values, die_probabilities))\nvariance = expected_x_squared - expected_value**2\n\nprint(f\"E[X^2]: {expected_x_squared}\")\nprint(f\"Variance: {variance}\")\nprint(f\"Standard deviation: {np.sqrt(variance)}\")\n\nExpected value of fair die: 3.5\nE[X^2]: 15.166666666666666\nVariance: 2.916666666666666\nStandard deviation: 1.707825127659933"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#task-2",
    "href": "files/labs/lab4/lab4_v2.html#task-2",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Task 2",
    "text": "Task 2\n\n⏱️ Estimated time: 4 minutes\n\nCalculate the expected value and variance for the biased coin from Task 1 (where X = 1 for Heads with probability 0.7, and X = 0 for Tails with probability 0.3).\nShow your calculations step by step."
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#bernoulli-distribution",
    "href": "files/labs/lab4/lab4_v2.html#bernoulli-distribution",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\n\n⏱️ Estimated time: 6 minutes\n\nA Bernoulli distribution models a single trial with two outcomes: success (1) or failure (0).\n\nParameter: p (probability of success)\nPMF: P(X = 1) = p, P(X = 0) = 1-p\nE[X] = p\nVar(X) = p(1-p)\n\n\n# Using scipy.stats for Bernoulli distribution\np = 0.3  # probability of success\n\n# Create Bernoulli distribution object\nbern = stats.bernoulli(p)\n\n# Calculate probabilities\nprint(f\"P(X = 0) = {bern.pmf(0)}\")\nprint(f\"P(X = 1) = {bern.pmf(1)}\")\n\n# Expected value and variance\nprint(f\"Expected value: {bern.mean()}\")\nprint(f\"Variance: {bern.var()}\")\n\nP(X = 0) = 0.6999999999999997\nP(X = 1) = 0.3\nExpected value: 0.3\nVariance: 0.21\n\n\nLet’s visualize several Bernoulli distributions:\n\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\np_values = [0.2, 0.5, 0.8]\n\nfor i, p in enumerate(p_values):\n    bern = stats.bernoulli(p)\n    x_vals = [0, 1]\n    y_vals = [bern.pmf(x) for x in x_vals]\n    \n    axes[i].bar(x_vals, y_vals, alpha=0.7, color='lightcoral', edgecolor='black')\n    axes[i].set_xlabel('Value')\n    axes[i].set_ylabel('Probability')\n    axes[i].set_title(f'Bernoulli(p={p})')\n    axes[i].set_ylim(0, 1)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#binomial-distribution",
    "href": "files/labs/lab4/lab4_v2.html#binomial-distribution",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\n⏱️ Estimated time: 8 minutes\n\nA Binomial distribution models the number of successes in n independent Bernoulli trials.\n\nParameters: n (number of trials), p (probability of success)\nPMF: P(X = k) = C(n,k) × p^k × (1-p)^(n-k)\nE[X] = np\nVar(X) = np(1-p)\n\n\n# Binomial distribution example: 10 coin flips with p = 0.5\nn = 10\np = 0.5\n\nbinom = stats.binom(n, p)\n\n# Calculate probabilities for different numbers of successes\nk_values = range(0, n+1)\nprobabilities = [binom.pmf(k) for k in k_values]\n\n# Display some key probabilities\nprint(f\"P(X = 5) = {binom.pmf(5):.4f}\")\nprint(f\"P(X ≤ 3) = {binom.cdf(3):.4f}\")\nprint(f\"P(X ≥ 7) = {1 - binom.cdf(6):.4f}\")\n\nprint(f\"\\nExpected value: {binom.mean()}\")\nprint(f\"Variance: {binom.var()}\")\nprint(f\"Standard deviation: {binom.std()}\")\n\nP(X = 5) = 0.2461\nP(X ≤ 3) = 0.1719\nP(X ≥ 7) = 0.1719\n\nExpected value: 5.0\nVariance: 2.5\nStandard deviation: 1.5811388300841898\n\n\nLet’s visualize the binomial distribution:\n\nplt.figure(figsize=(10, 6))\nplt.bar(k_values, probabilities, alpha=0.7, color='lightgreen', edgecolor='black')\nplt.xlabel('Number of Successes (k)')\nplt.ylabel('Probability')\nplt.title(f'Binomial Distribution (n={n}, p={p})')\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#task-3",
    "href": "files/labs/lab4/lab4_v2.html#task-3",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Task 3",
    "text": "Task 3\n\n⏱️ Estimated time: 6 minutes\n\nA basketball player makes 70% of their free throws. They take 15 free throws.\n\nWhat is the probability they make exactly 10 free throws?\nWhat is the probability they make at least 12 free throws?\nWhat is the expected number of free throws made?\nCreate a bar plot showing the PMF for this scenario"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#geometric-distribution",
    "href": "files/labs/lab4/lab4_v2.html#geometric-distribution",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\n⏱️ Estimated time: 6 minutes\n\nA Geometric distribution models the number of trials needed to get the first success.\n\nParameter: p (probability of success)\nPMF: P(X = k) = (1-p)^(k-1) × p\nE[X] = 1/p\nVar(X) = (1-p)/p²\n\n\n# Geometric distribution: rolling a die until we get a 6\np = 1/6  # probability of rolling a 6\n\ngeom = stats.geom(p)\n\n# Calculate probabilities for first few trials\nk_values = range(1, 21)  # trials 1 to 20\nprobabilities = [geom.pmf(k) for k in k_values]\n\nprint(f\"P(X = 1) = {geom.pmf(1):.4f}\")  # Success on first trial\nprint(f\"P(X = 6) = {geom.pmf(6):.4f}\")  # Success on sixth trial\nprint(f\"P(X ≤ 10) = {geom.cdf(10):.4f}\")  # Success within 10 trials\n\nprint(f\"\\nExpected value: {geom.mean():.2f}\")\nprint(f\"Variance: {geom.var():.2f}\")\n\nP(X = 1) = 0.1667\nP(X = 6) = 0.0670\nP(X ≤ 10) = 0.8385\n\nExpected value: 6.00\nVariance: 30.00\n\n\nVisualizing the geometric distribution:\n\nplt.figure(figsize=(10, 6))\nplt.bar(k_values, probabilities, alpha=0.7, color='orange', edgecolor='black')\nplt.xlabel('Trial Number (k)')\nplt.ylabel('Probability')\nplt.title(f'Geometric Distribution (p={p:.3f})')\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#poisson-distribution",
    "href": "files/labs/lab4/lab4_v2.html#poisson-distribution",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution\n\n⏱️ Estimated time: 8 minutes\n\nA Poisson distribution models the number of events occurring in a fixed interval when events occur independently at a constant average rate.\n\nParameter: λ (lambda, average rate)\nPMF: P(X = k) = (λ^k × e^(-λ)) / k!\nE[X] = λ\nVar(X) = λ\n\n\n# Poisson distribution: number of customers arriving per hour\nlam = 3.5  # average 3.5 customers per hour\n\npoisson = stats.poisson(lam)\n\n# Calculate probabilities\nk_values = range(0, 15)\nprobabilities = [poisson.pmf(k) for k in k_values]\n\nprint(f\"P(X = 0) = {poisson.pmf(0):.4f}\")  # No customers\nprint(f\"P(X = 3) = {poisson.pmf(3):.4f}\")  # Exactly 3 customers\nprint(f\"P(X ≤ 5) = {poisson.cdf(5):.4f}\")  # At most 5 customers\nprint(f\"P(X ≥ 6) = {1 - poisson.cdf(5):.4f}\")  # At least 6 customers\n\nprint(f\"\\nExpected value: {poisson.mean()}\")\nprint(f\"Variance: {poisson.var()}\")\n\nP(X = 0) = 0.0302\nP(X = 3) = 0.2158\nP(X ≤ 5) = 0.8576\nP(X ≥ 6) = 0.1424\n\nExpected value: 3.5\nVariance: 3.5\n\n\nVisualizing different Poisson distributions:\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nlambda_values = [1, 3.5, 8]\n\nfor i, lam in enumerate(lambda_values):\n    poisson = stats.poisson(lam)\n    k_vals = range(0, int(lam + 4*np.sqrt(lam)))\n    probs = [poisson.pmf(k) for k in k_vals]\n    \n    axes[i].bar(k_vals, probs, alpha=0.7, color='purple', edgecolor='black')\n    axes[i].set_xlabel('Number of Events (k)')\n    axes[i].set_ylabel('Probability')\n    axes[i].set_title(f'Poisson(λ={lam})')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#task-4",
    "href": "files/labs/lab4/lab4_v2.html#task-4",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Task 4",
    "text": "Task 4\n\n⏱️ Estimated time: 7 minutes\n\nA call center receives an average of 5 calls per minute.\n\nWhat is the probability of receiving exactly 7 calls in a minute?\nWhat is the probability of receiving no calls in a minute?\nWhat is the probability of receiving more than 8 calls in a minute?\nPlot the PMF for k = 0 to 15 calls"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#task-5",
    "href": "files/labs/lab4/lab4_v2.html#task-5",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Task 5",
    "text": "Task 5\n\n⏱️ Estimated time: 8 minutes\n\nDistribution Identification Practice\nFor each scenario below, identify the appropriate distribution and calculate the requested probability:\n\nScenario A: You flip a fair coin 20 times. What’s the probability of getting exactly 12 heads?\nScenario B: You keep rolling a die until you get a 6. What’s the probability it takes exactly 4 rolls?\nScenario C: A website gets an average of 2 visitors per minute. What’s the probability of getting exactly 3 visitors in a given minute?\nScenario D: A quality control inspector tests items where 5% are defective. What’s the probability the first defective item is found on the 8th test?"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#task-6",
    "href": "files/labs/lab4/lab4_v2.html#task-6",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Task 6",
    "text": "Task 6\n\n⏱️ Estimated time: 8 minutes\n\nSimulation Project:\nSimulate the basketball free throw scenario from Task 3 (15 shots, 70% success rate):\n\nSimulate this scenario 1000 times\nCalculate the proportion of simulations where the player made exactly 10 shots\nCompare this to the theoretical probability you calculated earlier\nCreate a histogram of the simulation results and overlay the theoretical PMF"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2.html#final-challenge",
    "href": "files/labs/lab4/lab4_v2.html#final-challenge",
    "title": "Lab 4: Discrete Random Variables and Distributions",
    "section": "Final Challenge",
    "text": "Final Challenge\n\n⏱️ Estimated time: 10 minutes\n\nReal-World Application:\nA customer service center has the following characteristics: - 20% of calls result in a sale (Bernoulli process) - Calls arrive at an average rate of 4 per hour (Poisson process) - Agents keep working until they make their first sale of the day (Geometric process)\nCalculate: 1. In a day with 8 hours of operation, what’s the expected number of calls? 2. What’s the probability that exactly 2 of the next 10 calls result in sales? 3. What’s the expected number of calls an agent needs to handle to make their first sale? 4. Create a comprehensive visualization showing all three distributions"
  },
  {
    "objectID": "files/worksheets/drafts/worksheet4draft.html",
    "href": "files/worksheets/drafts/worksheet4draft.html",
    "title": "PSTAT 5A Practice Worksheet 3",
    "section": "",
    "text": "Instructions and Overview\n⏰ Time Allocation:\n\nSection A (Warm-up): 8 minutes\nSection B (Intermediate): 15 minutes\nSection C (Advanced): 15 minutes\nSection D (Review): 12 minutes\nTotal: 50 minutes\n\n\n📝 Important Instructions:\n\nUse the formulas provided for guidance\nRound final answers to 4 decimal places unless otherwise specified\nIdentify your approach before calculating\nUse calculator as needed\n\n\n\n📚 Key Formulas Reference:\nBasic Probability:\n\nConditional Probability: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nBayes’ Theorem: \\(P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\\)\nLaw of Total Probability: \\(P(A) = \\sum P(A|B_i) \\cdot P(B_i)\\)\nAddition Rule: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nMultiplication Rule: \\(P(A \\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)\\)\n\nCounting:\n\nPermutations: \\(P(n,r) = \\frac{n!}{(n-r)!}\\)\nCombinations: \\(C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\)\n\n\n\n\nSection A: Probability\n⏱️ Estimated time: 8 minutes\n\nProblem A1: Probability Distributions\nEach row in the table below is a proposed grade distribution for a class. Identify each as a valid or invalid probability distribution, and explain your reasoning.\n\n\n\nClass\nA\nB\nC\nD\nF\n\n\n\n\n(a)\n0.3\n0.3\n0.3\n0.2\n0.1\n\n\n(b)\n0\n0\n1\n0\n0\n\n\n(c)\n0.3\n0.3\n0.3\n0\n0\n\n\n(d)\n0.3\n0.5\n0.2\n0.1\n-0.1\n\n\n(e)\n0.2\n0.4\n0.2\n0.1\n0.1\n\n\n(f)\n0\n-0.1\n1.1\n0\n0\n\n\n\n\nWork Space:\n\n\n\nSection B: Permutations and Combination\n⏱️ Estimated time: 15 minutes\n\nProblem B1: Permutations and Combinations\nA cybersecurity team needs to create a secure access protocol.\nPart (a): How many 6-character passwords can be formed using 3 specific letters and 3 specific digits if repetitions are not allowed and letters must come before digits?\n\n\n\n\n\n\nTip\n\n\n\nSince letters must come before digits, think of this as two separate arrangement problems:\n\nFirst, arrange the 3 letters in the first 3 positions\nThen, arrange the 3 digits in the last 3 positions\nUse the multiplication principle to combine these results\n\n\n\nPart (b): If the team wants to select 4 people from 12 employees to form a security committee where order doesn’t matter, how many ways can this be done?\n\n\n\n\n\n\nTip\n\n\n\nSince order doesn’t matter, this is a combination problem. Ask yourself:\n\nAre we arranging people in specific positions, or just selecting a group?\nWhich formula should you use: \\(P(n,r)\\) or \\(C(n,r)\\)?\n\n\n\n\nWork Space:\n\n\n\nSection C: Conditional Probability\n⏱️ Estimated time: 15 minutes\n\nProblem B1: Conditional Probability and Medical Testing\nA new COVID variant test has the following characteristics:\n\nThe variant affects 3% of the tested population\nThe test correctly identifies 95% of people with the variant (sensitivity)\nThe test correctly identifies 92% of people without the variant (specificity)\n\nPart (a): What is the probability that a randomly selected person tests positive?\nPart (b): If someone tests positive, what is the probability they actually have the variant?\nPart (c): If someone tests negative, what is the probability they actually don’t have the variant?\nPart (d) [Challenge]: The health department wants to reduce false positives. They decide to require two consecutive positive tests for a positive diagnosis. Assuming test results are independent, what is the new probability that someone with two positive tests actually has the variant?\n\nWork Space:\n\n\n\nSection C: Conditional Probability\n⏱️ Estimated time: 15 minutes\n\nProblem C1: Advanced Counting with Restrictions\nA restaurant offers a prix fixe menu where customers must choose:\n\n1 appetizer from 6 options\n1 main course from 8 options\n1 dessert from 5 options\n\nHowever, there are restrictions:\n\nIf you choose the seafood appetizer, you cannot choose the vegetarian main course\nIf you choose the chocolate dessert, you must choose either the beef or chicken main course (3 of the 8 main courses)\n\nPart (a): How many valid meal combinations are possible?\nPart (b): If customers choose randomly among valid combinations, what is the probability someone chooses the chocolate dessert?\n\nWork Space:\n\n\n\nSection D: Review\n⏱️ Estimated time: 12 minutes\n\nProblem B3: Daily Expenses\nSally gets a cup of coffee and a muffin every day for breakfast from one of the many coffee shops in her neighborhood. She picks a coffee shop each morning at random and independently of previous days. The average price of a cup of coffee is $1.40 with a standard deviation of 30¢ ($0.30), the average price of a muffin is $2.50 with a standard deviation of 15¢, and the two prices are independent of each other.\nPart (a): What is the mean and standard deviation of the amount she spends on breakfast daily?\nPart (b): What is the mean and standard deviation of the amount she spends on breakfast weekly (7 days)?\n\nWork Space:"
  },
  {
    "objectID": "files/worksheets/worksheet4.html",
    "href": "files/worksheets/worksheet4.html",
    "title": "PSTAT 5A Practice Worksheet 4",
    "section": "",
    "text": "Instructions and Overview\n⏰ Time Allocation:\n\nQuiz Review : 15 minutes\nSection A (Warm-up): 15 minutes\nSection B (Intermediate): 20 minutes\nOptional Question: Do on your own\nTotal: 50 minutes\n\n\n📝 Important Instructions:\n\nUse the formulas provided for guidance\nRound final answers to 4 decimal places unless otherwise specified\nIdentify the distribution type before calculating\nShow your work for expected value and variance calculations\nUse calculator as needed for factorials and combinations\n\n\n\n📚 Key Formulas Reference:\nGeneral Random Variable Properties:\n\nExpected Value: \\(E[X] = \\sum_{k} k \\cdot P(X = k)\\)\nVariance: \\(\\text{Var}(X) = E[X^2] - (E[X])^2 = \\sum_{k} k^2 \\cdot P(X = k) - \\mu^2\\)\nStandard Deviation: \\(\\sigma = \\sqrt{\\text{Var}(X)}\\)\n\nDiscrete Distributions:\nBernoulli Distribution: \\(X \\sim \\text{Bernoulli}(p)\\)\n\nPMF: \\(P(X = k) = p^k(1-p)^{1-k}\\) for \\(k \\in \\{0,1\\}\\)\nMean: \\(E[X] = p\\)\nVariance: \\(\\text{Var}(X) = p(1-p)\\)\n\nBinomial Distribution: \\(X \\sim \\text{Binomial}(n,p)\\)\n\nPMF: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\) for \\(k = 0, 1, 2, ..., n\\)\nMean: \\(E[X] = np\\)\nVariance: \\(\\text{Var}(X) = np(1-p)\\)\n\nGeometric Distribution: \\(X \\sim \\text{Geometric}(p)\\)\n\nPMF: \\(P(X = k) = (1-p)^{k-1} p\\) for \\(k = 1, 2, 3, ...\\)\nMean: \\(E[X] = \\frac{1}{p}\\)\nVariance: \\(\\text{Var}(X) = \\frac{1-p}{p^2}\\)\n\nPoisson Distribution: \\(X \\sim \\text{Poisson}(\\lambda)\\)\n\nPMF: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\) for \\(k = 0, 1, 2, ...\\)\nMean: \\(E[X] = \\lambda\\)\nVariance: \\(\\text{Var}(X) = \\lambda\\)\n\n\n\n\nSection A: Basic Concepts and Identification\n⏱️ Estimated time: 15 minutes\n\nProblem A1: Distribution Identification\nFor each scenario below, identify the appropriate discrete distribution and state the parameter(s). Do not calculate probabilities yet.\n(a) A fair coin is flipped until the first head appears. Let X = number of flips needed.\n(b) A quality control inspector tests 20 randomly selected items from a production line where 5% are defective. Let X = number of defective items found.\n(c) A website receives visitors at an average rate of 3 per minute. Let X = number of visitors in a 2-minute period.\n(d) A basketball player shoots one free throw with an 80% success rate. Let X = 1 if successful, 0 if unsuccessful.\n(e) A student keeps taking a driving test until they pass. The probability of passing on any attempt is 0.7. Let X = number of attempts needed to pass.\n\nWork Space:\n\n\nProblem A2: Probability Mass Function\nThe random variable X has the following probability distribution:\n\n\n\nX\n1\n2\n3\n4\n5\n\n\n\n\nP(X=k)\n0.1\n0.3\n0.4\na\n0.1\n\n\n\n(a) Find the value of \\(a\\).\n(b) Calculate \\(P(X \\leq 3)\\).\n(c) Calculate \\(P(X &gt; 2)\\).\n\nWork Space:\n\n\n\nSection B: Expected Value and Variance\n⏱️ Estimated time: 20 minutes\n\nProblem B1: Manual Calculations\nUsing the probability distribution from Problem A2, calculate:\n(a) The expected value \\(E[X]\\)\n(b) The variance \\(\\text{Var}(X)\\)\n(c) The standard deviation \\(\\sigma\\)\n\n\n\n\n\n\nTip\n\n\n\nCalculation Strategy:\nFor expected value: \\(E[X] = \\sum k \\cdot P(X = k)\\)\nFor variance: First find \\(E[X^2] = \\sum k^2 \\cdot P(X = k)\\), then use \\(\\text{Var}(X) = E[X^2] - (E[X])^2\\)\nShow your work step by step!\n\n\n\nWork Space:\n\n\nProblem B2: Bernoulli and Binomial Applications\nA manufacturing process produces items that are defective with probability 0.15.\n(a) If you select one item randomly, what is the expected value and variance of X = number of defective items?\n(b) If you select 25 items randomly, what is the expected number of defective items and the standard deviation?\n\n\n\n\n\n\nTip\n\n\n\nPart (a) is a Bernoulli distribution. Part (b) is a Binomial distribution. Use the formulas from the reference box!\n\n\n\nWork Space:\n\n\n\nOptional Questions\n\nOptional Problem : Conceptual Understanding\n(a) Explain the key difference between a Binomial distribution and a Geometric distribution in terms of what they count.\n(b) When would you use a Poisson distribution instead of a Binomial distribution?\n(c) If \\(X \\sim \\text{Binomial}(n, p)\\), under what conditions would the variance be maximized?\n\nWork Space:"
  },
  {
    "objectID": "files/worksheets/worksheet3_sln.html",
    "href": "files/worksheets/worksheet3_sln.html",
    "title": "PSTAT 5A Practice Worksheet 3 - SOLUTIONS",
    "section": "",
    "text": "📚 Key Formulas Reference:\nBasic Probability:\n\nConditional Probability: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nLaw of Total Probability: \\(P(A) = \\sum P(A|B_i) \\cdot P(B_i)\\)\nAddition Rule: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nMultiplication Rule: \\(P(A \\cap B) = P(A) \\cdot P(B|A) = P(B) \\cdot P(A|B)\\)\n\nCounting:\n\nMultiplication Rule: If a procedure consists of \\(k\\) steps, with \\(n_1\\) ways for step 1, \\(n_2\\) for step 2, …, \\(n_k\\) for step \\(k\\), then total ways: \\(n_1 \\times n_2 \\times \\cdots \\times n_k\\)\nFactorial: \\(n! = n \\times (n-1) \\times (n-2) \\times \\cdots \\times 2 \\times 1\\)\nPermutations: \\(P(n,r) = \\frac{n!}{(n-r)!}\\)\nCombinations: \\(C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\)\n\n\n\nSection A: Probability - SOLUTIONS\n⏱️ Estimated time: 8 minutes\n\nProblem A1: Probability Distributions - SOLUTION\nFor a valid probability distribution, two conditions must be met:\n\nAll probabilities must be non-negative (≥ 0)\nThe sum of all probabilities must equal 1\n\nAnalysis:\n(a) Invalid \\[\\text{Sum} = 0.3 + 0.3 + 0.3 + 0.2 + 0.1 = 1.2 &gt; 1\\] The probabilities sum to more than 1, violating condition 2.\n(b) Valid \\[\\text{Sum} = 0 + 0 + 1 + 0 + 0 = 1\\] All probabilities are non-negative and sum to 1. This represents a class where everyone receives a C.\n(c) Invalid \\[\\text{Sum} = 0.3 + 0.3 + 0.3 + 0 + 0 = 0.9 &lt; 1\\] The probabilities sum to less than 1, violating condition 2.\n(d) Invalid Contains \\(P(F) = -0.1 &lt; 0\\) Although the sum would equal 1.0, the probability for grade F is negative, violating condition 1.\n(e) Valid \\[\\text{Sum} = 0.2 + 0.4 + 0.2 + 0.1 + 0.1 = 1.0\\] All probabilities are non-negative and sum to 1.\n(f) Invalid Contains \\(P(B) = -0.1 &lt; 0\\) Although the sum equals 1.0, the probability for grade B is negative, violating condition 1.\n\n\n\nSection B: Permutations and Combinations - SOLUTIONS\n⏱️ Estimated time: 15 minutes\n\nProblem B1: Permutations and Combinations - SOLUTION\nPart (a): How many 6-character passwords can be formed using 3 specific letters and 3 specific digits if repetitions are not allowed and letters must come before digits?\nSolution: Since letters must come before digits, we have a fixed structure: LLL DDD\nStep 1: Arrange 3 letters in the first 3 positions\n\nThis is a permutation: \\(P(3,3) = \\frac{3!}{(3-3)!} = \\frac{3!}{0!} = 3! = 6\\) ways\n\nStep 2: Arrange 3 digits in the last 3 positions\n\nThis is a permutation: \\(P(3,3) = \\frac{3!}{(3-3)!} = \\frac{3!}{0!} = 3! = 6\\) ways\n\nStep 3: Apply multiplication principle \\[\\text{Total passwords} = 6 \\times 6 = \\boxed{36 \\text{ passwords}}\\]\nPart (b): If the team wants to select 4 people from 12 employees to form a security committee where order doesn’t matter, how many ways can this be done?\nSolution: Since order doesn’t matter, this is a combination problem.\n\\[C(12,4) = \\binom{12}{4} = \\frac{12!}{4!(12-4)!} = \\frac{12!}{4! \\cdot 8!}\\]\n\\[= \\frac{12 \\times 11 \\times 10 \\times 9}{4 \\times 3 \\times 2 \\times 1} = \\frac{11,880}{24} = \\boxed{495 \\text{ ways}}\\]\n\n\n\nSection C: Conditional Probability - SOLUTIONS\n⏱️ Estimated time: 12 minutes\n\nProblem C1: Drawing Cards (Without Replacement) - SOLUTION\nGiven Information:\n\nStandard 52-card deck\nDrawing two cards without replacement\n\\(A = \\{\\text{\"first card is a heart\"}\\}\\)\n\\(B = \\{\\text{\"second card is an ace\"}\\}\\)\n\nSolution:\n1. P(A)\nThere are 13 hearts in a 52-card deck. \\[P(A) = \\frac{13}{52} = \\boxed{\\frac{1}{4} = 0.2500}\\]\n2. P(A and B)\nWe need both events to occur: first card is a heart AND second card is an ace.\nCase 1: First card is the Ace of Hearts - \\(P(\\text{1st card is Ace of Hearts}) = \\frac{1}{52}\\)\n\n\\(P(\\text{2nd card is an ace | 1st card is Ace of Hearts}) = \\frac{3}{51}\\) (3 aces left)\n\\(P(\\text{Case 1}) = \\frac{1}{52} \\times \\frac{3}{51} = \\frac{3}{2652}\\)\n\nCase 2: First card is a non-ace heart - \\(P(\\text{1st card is non-ace heart}) = \\frac{12}{52}\\) (12 non-ace hearts)\n\n\\(P(\\text{2nd card is an ace | 1st card is non-ace heart}) = \\frac{4}{51}\\) (4 aces left)\n\\(P(\\text{Case 2}) = \\frac{12}{52} \\times \\frac{4}{51} = \\frac{48}{2652}\\)\n\n\\[P(A \\text{ and } B) = \\frac{3}{2652} + \\frac{48}{2652} = \\frac{51}{2652} = \\boxed{\\frac{1}{52} = 0.0192}\\]\n3. P(B|A)\nUsing the definition of conditional probability: \\[P(B|A) = \\frac{P(A \\text{ and } B)}{P(A)} = \\frac{\\frac{1}{52}}{\\frac{1}{4}} = \\frac{1}{52} \\times \\frac{4}{1} = \\boxed{\\frac{4}{52} = \\frac{1}{13} = 0.0769}\\]\nAlternative approach: Given that the first card is a heart:\n\nIf it’s the Ace of Hearts: 3 aces remain out of 51 cards\nIf it’s a non-ace heart: 4 aces remain out of 51 cards\n\\(P(B|A) = \\frac{1}{13} \\times \\frac{3}{51} + \\frac{12}{13} \\times \\frac{4}{51} = \\frac{3 + 48}{13 \\times 51} = \\frac{51}{663} = \\frac{4}{52} = \\frac{1}{13}\\)\n\n4. P(B)\nUsing the Law of Total Probability. Let \\(A^c\\) = “first card is not a heart”\n\\[P(B) = P(B|A) \\cdot P(A) + P(B|A^c) \\cdot P(A^c)\\]\nWe know:\n\n\\(P(A) = \\frac{1}{4}\\) and \\(P(A^c) = \\frac{3}{4}\\)\n\\(P(B|A) = \\frac{1}{13}\\) (from part 3)\n\\(P(B|A^c) = \\frac{4}{51}\\) (if first card isn’t a heart, all 4 aces remain)\n\n\\[P(B) = \\frac{1}{13} \\times \\frac{1}{4} + \\frac{4}{51} \\times \\frac{3}{4} = \\frac{1}{52} + \\frac{12}{204} = \\frac{1}{52} + \\frac{3}{51}\\]\n\\[= \\frac{51 + 156}{52 \\times 51} = \\frac{207}{2652} = \\boxed{\\frac{4}{51} = 0.0784}\\]\n5. Comparison of P(B|A) vs P(B)\n\\[P(B|A) = \\frac{1}{13} = 0.0769\\] \\[P(B) = \\frac{4}{51} = 0.0784\\]\nAnalysis: \\(P(B|A) &lt; P(B)\\)\nExplanation: The probability of getting an ace on the second draw is slightly lower when we know the first card is a heart compared to when we don’t know anything about the first card. This happens because:\n\nWhen the first card is a heart, there’s a \\(\\frac{1}{13}\\) chance it’s the Ace of Hearts, removing one ace from the deck\nThis makes it slightly less likely to draw an ace on the second draw\nThis demonstrates dependence - the events are not independent because drawing without replacement creates dependence between successive draws\n\n\n\n\nSection D: Advanced Counting with Restrictions - SOLUTIONS\n⏱️ Estimated time: 15 minutes\n\nProblem D1: Advanced Counting with Restrictions - SOLUTION\nGiven:\n\n6 appetizer options (including 1 seafood)\n8 main course options (including 1 vegetarian, and 3 that are beef or chicken)\n5 dessert options (including 1 chocolate)\n\nRestrictions:\n\nSeafood appetizer → cannot choose vegetarian main course\nChocolate dessert → must choose beef or chicken main course (3 specific options)\n\nPart (a): How many valid meal combinations are possible?\nSolution using cases:\nCase 1: Seafood appetizer is chosen\n\n1 appetizer choice (seafood)\n7 main course choices (8 total minus 1 vegetarian)\n5 dessert choices (no restrictions)\nTotal: \\(1 \\times 7 \\times 5 = 35\\) combinations\n\nCase 2: Non-seafood appetizer + chocolate dessert\n\n5 appetizer choices (6 total minus 1 seafood)\n3 main course choices (only beef or chicken allowed with chocolate)\n1 dessert choice (chocolate)\nTotal: \\(5 \\times 3 \\times 1 = 15\\) combinations\n\nCase 3: Non-seafood appetizer + non-chocolate dessert\n\n5 appetizer choices (6 total minus 1 seafood)\n8 main course choices (no restrictions since no seafood appetizer)\n4 dessert choices (5 total minus 1 chocolate)\nTotal: \\(5 \\times 8 \\times 4 = 160\\) combinations\n\nTotal valid combinations: \\[35 + 15 + 160 = \\boxed{210 \\text{ combinations}}\\]\nVerification using complementary counting:\n\nTotal unrestricted combinations: \\(6 \\times 8 \\times 5 = 240\\)\nInvalid combinations to subtract:\n\nSeafood + vegetarian + any dessert: \\(1 \\times 1 \\times 5 = 5\\)\nNon-seafood + chocolate + non-beef/chicken: \\(5 \\times 5 \\times 1 = 25\\)\n\nValid combinations: \\(240 - 5 - 25 = 210\\) ✓\n\nPart (b): If customers choose randomly among valid combinations, what is the probability someone chooses the chocolate dessert?\nSolution: From our case analysis, combinations with chocolate dessert come only from Case 2:\n\nCombinations with chocolate dessert: 15\nTotal valid combinations: 210\n\n\\[P(\\text{chocolate dessert}) = \\frac{15}{210} = \\frac{1}{14} = \\boxed{0.0714}\\]\nAlternative verification:\nWe can also calculate this directly:\n\nNon-seafood appetizers: 5 choices\nWith chocolate dessert, must choose from 3 main courses\nValid chocolate combinations: \\(5 \\times 3 = 15\\)\nProbability: \\(\\frac{15}{210} = \\frac{1}{14} = 0.0714\\) ✓\n\n\n\n\nSummary of Key Concepts\n\nProbability Distributions\n\nValid distributions require: all probabilities \\(\\geq 0\\) and sum \\(= 1\\)\nCheck both conditions systematically\n\n\n\nPermutations vs Combinations\n\nPermutations: Order matters, use \\(P(n,r) = \\frac{n!}{(n-r)!}\\)\nCombinations: Order doesn’t matter, use \\(C(n,r) = \\frac{n!}{r!(n-r)!}\\)\nMultiplication principle: Combine independent choices\n\n\n\nConditional Probability\n\nWithout replacement: Creates dependence between events\nUse definition: \\(P(B|A) = \\frac{P(A \\cap B)}{P(A)}\\)\nLaw of Total Probability: For calculating marginal probabilities\n\n\n\nAdvanced Counting\n\nCase analysis: Break complex problems into manageable parts\nHandle restrictions: Consider what’s allowed vs. not allowed\nVerification: Use complementary counting or direct calculation"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html",
    "href": "files/lecture_notes/lecture5/lecture5.html",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "",
    "text": "By the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#sec-objectives",
    "href": "files/lecture_notes/lecture5/lecture5.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Today’s Learning Objectives",
    "text": "Today’s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-1",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\n\n\n\nA standard deck has 52 cards. What is the probability of drawing:\n\nA heart \\heartsuit?\nA face card (Jack, Queen, King)?\nThe ace of spades \\spadesuit?\n\n\n\n\n\n\n\nSolution. \n\nP(\\text{heart}) = \\frac{13}{52} = \\frac{1}{4}\nP(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\nP(\\text{ace of spades}) = \\frac{1}{52}"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#the-addition-rule",
    "href": "files/lecture_notes/lecture5/lecture5.html#the-addition-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Addition Rule",
    "text": "The Addition Rule\nFor any two events A and B:\n\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\n\n\nWhy subtract P(A \\cap B)?\n\n\n\nSolution. We don’t want to double-count outcomes that are in both events"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#addition-rule-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#addition-rule-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Addition Rule Example",
    "text": "Addition Rule Example\n\n\n\n\nDrawing from a standard deck:\n\nA: Drawing a heart \\heartsuit (P(A) = \\frac{13}{52})\nB: Drawing a face card (P(B) = \\frac{12}{52})\nWhat’s P(A \\cup B) (heart OR face card)?"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\n\n\n\n🎯Conditional probability is the probability of event A given that event B has occurred\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}\nprovided P(B) &gt; 0"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-interpretation",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-interpretation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Interpretation",
    "text": "Conditional Probability Interpretation\nP(A|B) means:\n\nWe know event  B has occurred \nWhat’s the probability that A also occurred?\nWe “restrict” our sample space to only outcomes in B"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Example",
    "text": "Conditional Probability Example\n\n\n\nDrawing a card from a standard deck:\n\nA: Card is a heart \\heartsuit\nB: Card is red\nQ: Find P(A|B)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution. P(A \\cap B) = P(\\text{heart}) = \\frac{13}{52}\nP(B) = P(\\text{red}) = \\frac{26}{52}\nP(A|B) = \\frac{13/52}{26/52} = \\frac{13}{26} = \\frac{1}{2}"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#independence",
    "href": "files/lecture_notes/lecture5/lecture5.html#independence",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\n🎯 Definition Events A and B are independent if:\nP(A|B) = P(A)\nor equivalently:\nP(A \\cap B) = P(A) \\times P(B)\n\n\nKnowing that B occurred doesn’t change the probability of A"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#independence-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#independence-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence Example",
    "text": "Independence Example\n\nTwo coin flips:\n\nA: First flip is heads\nB: Second flip is heads\n\nQ: Are A and B independent?\n\n\n\nSolution. P(A) = \\frac{1}{2}, P(B) = \\frac{1}{2}\nP(A \\cap B) = P(\\text{HH}) = \\frac{1}{4}\nP(A) \\times P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\nYes, they are independent!"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent",
    "href": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs. Independent",
    "text": "Mutually Exclusive vs. Independent\n\nMutually Exclusive (left): the circles A and B do not overlap, so P(A\\cap B)=0.\nIndependent (right): the circles overlap, and we’ve sized the intersection so that P(A\\cap B)=P(A)\\,P(B)."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs. Independent Example",
    "text": "Mutually Exclusive vs. Independent Example\n\n\n\nDraw a single card from a 52-card deck:\n\nLet A={“draw an Ace”}, so P(A)=4/52.\nLet B={“draw a King”}, so P(B)=4/52.\n\nQ: What is P(A\\cap B) ?\n\n\n\n\n\nSolution. They’re disjoint (you can’t draw an Ace and a King), so P(A\\cap B) = 0.\nBut P(A)\\,P(B) = \\frac{4}{52}\\times\\frac{4}{52} = \\frac{16}{2704} \\neq 0.\nHence, P(A\\cap B)\\neq P(A)P(B), so they’re not independent."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#multiplication-rule",
    "href": "files/lecture_notes/lecture5/lecture5.html#multiplication-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Multiplication Rule",
    "text": "Multiplication Rule\nGeneral case: P(A \\cap B) = P(A) \\times P(B|A)\nIndependent events: P(A \\cap B) = P(A) \\times P(B)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#tree-diagrams",
    "href": "files/lecture_notes/lecture5/lecture5.html#tree-diagrams",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\n\n🎯 Definition Tree diagrams help visualize sequential events and calculate probabilities."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#tree-diagram-examples",
    "href": "files/lecture_notes/lecture5/lecture5.html#tree-diagram-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagram Examples",
    "text": "Tree Diagram Examples"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-2",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-2",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\n\n\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement.\n\nWhat’s the probability both balls are red?\nWhat’s the probability the first is red and second is blue?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution. \n\nP(\\text{both red}) = \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\nP(\\text{red then blue}) = \\frac{5}{8} \\times \\frac{3}{7} = \\frac{15}{56}"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability",
    "href": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\n🎯 Definition\nIf events B_1, B_2, \\ldots, B_n form a partition of the sample space, then:\nP(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \\cdots + P(A|B_n)P(B_n)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\n\nA factory has two machines:\n\nMachine 1: Produces 60% of items, 5% defective\nMachine 2: Produces 40% of items, 3% defective\n\nQ: What’s the overall probability an item is defective?\n\n\n\nSolution. P(\\text{defective}) = P(D|M_1)P(M_1) + P(D|M_2)P(M_2)\n= 0.05 \\times 0.6 + 0.03 \\times 0.4 = 0.03 + 0.012 = 0.042"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes’ Theorem",
    "text": "Bayes’ Theorem\n\n🎯 Definition P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\nThis allows us to “reverse” conditional probabilities\nNamed after Thomas Bayes (1701-1761)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-components",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-components",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes’ Theorem Components",
    "text": "Bayes’ Theorem Components\n\nA,B: Events\nP(A|B): Posterior probability - what we want to find\nP(B|A): Likelihood - given A, probability of observing B\nP(A): Prior probability - initial probability of A\nP(B): Marginal probability - total probability of B"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes’ Theorem Example",
    "text": "Bayes’ Theorem Example\n\n\n\nMedical test for a disease: 1\n\nDisease affects 1% of population\nTest is 95% accurate for sick people\nTest is 90% accurate for healthy people\n\nQ:If someone tests positive, what’s the probability they have the disease?\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\nP(\\neg D \\,\\wedge\\, \\text{Negative})\n\\;=\\;P(\\neg D)\\times P(\\text{Negative}\\mid \\neg D)\n\\;=\\;0.99\\times0.90\n\\;=\\;0.891\\;(89.1\\%)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes’ Theorem Solution",
    "text": "Bayes’ Theorem Solution\nLet:\n\nD: Person has disease\nT^+: Test is positive\n\nGiven:\n\nP(D) = 0.01\nP(T^+|D) = 0.95\nP(T^-|D^c) = 0.90, so P(T^+|D^c) = 0.10\n\n\n\nSolution. P(T^+) = P(T^+|D)P(D) + P(T^+|D^c)P(D^c)\n= 0.95 \\times 0.01 + 0.10 \\times 0.99 = 0.1085"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution-cont.",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution-cont.",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes’ Theorem Solution (cont.)",
    "text": "Bayes’ Theorem Solution (cont.)\nP(D|T^+) = \\frac{P(T^+|D) \\times P(D)}{P(T^+)} = \\frac{0.95 \\times 0.01}{0.1085} \\approx 0.088\n\n\n\nSurprising result: Even with a positive test, there’s only an 8.8% chance of having the disease!\nThis is due to the low base rate of the disease"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nConfusing P(A|B) with P(B|A)\n\n\nProsecutor’s fallacy is a specific error in interpreting conditional probabilities. Confusing\nP(\\text{Evidence}\\mid\\text{Innocent})\n\\quad\\text{with}\\quad\nP(\\text{Innocent}\\mid\\text{Evidence}).\nEx: OJ Simpson Case 1\n\nthe DNA evidence in the O. J. Simpson trial are a classic example of the prosecutor’s fallacy. Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was “one in 170 million,” then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes-1",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nAssuming independence when events are dependent\nIgnoring base rates (as in the medical test example)\n\n\nBase rate fallacy is when you ignore or underweight the prior probability P(H) of a hypothesis, focusing only on the new evidence E.\n\n\nDouble counting in union calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-3",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-3",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nTwo fair dice are rolled. Find:\n\nP(\\text{sum} = 7)\nP(\\text{sum} = 7 | \\text{first die shows 3})\nAre these events independent?\n\n\n\n\nSolution. \n\n6 ways out of 36: P(\\text{sum} = 7) = \\frac{6}{36} = \\frac{1}{6}\nGiven first die is 3, need second die to be 4: P(\\text{sum} = 7 | \\text{first} = 3) = \\frac{1}{6}\nYes, they’re independent since P(A|B) = P(A)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#real-world-applications",
    "href": "files/lecture_notes/lecture5/lecture5.html#real-world-applications",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Diagnosis: Using Bayes’ theorem for test interpretation\nQuality Control: Probability of defective items\nFinance: Risk assessment and portfolio theory\nSports: Probability of wins, fantasy sports\nInsurance: Calculating premiums based on risk"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture5/lecture5.html#key-formulas-summary",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\nBasic probability: P(A) = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\nComplement: P(A^c) = 1 - P(A)\nAddition: P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\nConditional: P(A|B) = \\frac{P(A \\cap B)}{P(B)}\nIndependence: P(A \\cap B) = P(A) \\times P(B)\nBayes’: P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture5/lecture5.html#problem-solving-strategy",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\nIdentify the sample space and events\nDetermine if events are independent or mutually exclusive\nChoose the appropriate rule or formula\nCalculate step by step\nCheck if your answer makes sense"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-questions",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Questions",
    "text": "Common Questions\n\nQ1.: “Why isn’t P(A \\cup B) = P(A) + P(B) always?”\nA: We’d double-count outcomes in both events\nQ2.: “How do I know if events are independent?”\nA: Check if P(A|B) = P(A) or if P(A \\cap B) = P(A) \\times P(B)\nQ3.: “When do I use Bayes’ theorem?”\nA: When you want to “reverse” a conditional probability\n\n\nQ3 note (Bayes Example)\n\nForward: I know my test picks up disease 95% of the time ⇒ P(+\\mid D)=0.95.\nReverse: I want the chance I really have the disease when the test is positive ⇒ P(D\\mid +)."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#looking-ahead",
    "href": "files/lecture_notes/lecture5/lecture5.html#looking-ahead",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture:\n\nCounting\nRandom Variables and Probability Distributions\nDiscrete vs. continuous random variables\nExpected value and variance"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#final-thoughts",
    "href": "files/lecture_notes/lecture5/lecture5.html#final-thoughts",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Final Thoughts",
    "text": "Final Thoughts\n\nProbability is the foundation of statistics:\n\nHelps us quantify uncertainty\nProvides tools for making decisions with incomplete information\nEssential for understanding statistical inference\n\n\n\nPractice: The key to mastering probability is working through many problems!"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#questions",
    "href": "files/lecture_notes/lecture5/lecture5.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday’s 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Conditional Probability & Bayes Theorem"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#resources",
    "href": "files/lecture_notes/lecture5/lecture5.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms\nInteractive Set Theory & Conditional Probability"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#footnotes",
    "href": "files/lecture_notes/lecture5/lecture5.html#footnotes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\\(P(\\neg D \\,\\wedge\\, \\text{Negative})\n\\;=\\;P(\\neg D)\\times P(\\text{Negative}\\mid \\neg D)\n\\;=\\;0.99\\times0.90\n\\;=\\;0.891\\;(89.1\\%)\\)↩︎\nthe DNA evidence in the O. J. Simpson trial are a classic example of the prosecutor’s fallacy. Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was “one in 170 million,” then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent.↩︎"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "",
    "text": "🏠"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#todays-learning-objectives",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Today’s Learning Objectives",
    "text": "Today’s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nUnderstand sampling distributions and their properties (Section 1.2)\nApply the Central Limit Theorem to sampling (Section 1.4)\nConstruct confidence intervals for population means (Section 1.6)\nConstruct confidence intervals for population proportions (Section 1.8)\nInterpret confidence intervals correctly (Section 1.5)\nDetermine appropriate sample sizes for desired precision\nUse python to calculate confidence intervals\nDistinguish between different types of sampling methods"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-sampling-dist",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-sampling-dist",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "The Big Picture: Statistical Inference",
    "text": "The Big Picture: Statistical Inference\n\n\n\n\nPopulation vs Sample\n\n\n\nPopulation: All individuals of interest\n\n\nSample: Subset we actually observe\n\n\nParameter: Population characteristic (\\(\\mu\\), \\(p\\))\n\n\nStatistic: Sample characteristic (\\(\\bar{x}\\), \\(\\hat{p}\\))\n\n\n\nGoal: Use sample statistics to estimate population parameters\n\n\n\n\n\n\n\n\n\nWhy Confidence Intervals?\n\n\n\nPoint estimates are rarely exactly correct\n\n\nInterval estimates capture uncertainty\n\n\nConfidence level quantifies our certainty\n\n\nMargin of error shows precision\n\n\n\nKey Insight: We trade precision for confidence"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sampling-distributions",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sampling-distributions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\n\nA sampling distribution is the distribution of a statistic (like \\(\\bar{x}\\)) across all possible samples of size \\(n\\).\n\n\n\nKey Properties:\nCenter:\n\\(E[\\bar{X}] = \\mu\\) (unbiased)\nSpread:\n\\(SE(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\\)\nShape:\nApproaches normal as \\(n\\) increases (Central Limit Theorem)\nStandard Error vs Standard Deviation:\n\n\\(\\sigma\\): spread of individual observations\n\\(SE = \\frac{\\sigma}{\\sqrt{n}}\\): spread of sample means\n\n\n\n\n\n\nDrag the slider to see how sample size affects the sampling distribution"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-clt-sampling",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-clt-sampling",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Central Limit Theorem in Action",
    "text": "Central Limit Theorem in Action\n\n\n\n\nNew Population\n\n Uniform Population Exponential Population Bimodal Population Right-Skewed Population  Sample Size:  Collect 1000 Sample Means\n\n\n\nPopulation μ: - | Sample Means μ: - | Standard Error: -"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-interpretation",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-interpretation",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals: The Concept",
    "text": "Confidence Intervals: The Concept\n\n\nWhat is a Confidence Interval? A confidence interval provides a range of plausible values for a population parameter. 95% Confidence Interval: If we repeated our sampling process many times, about \\(95\\%\\) of the intervals we construct would contain the true population parameter.\n\n\n\n\n\nClick to generate new 95% confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-means",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-means",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals for Population Means",
    "text": "Confidence Intervals for Population Means\n\n\n\n\n 🎯 When σ is Known:\n\n\n\\[\\bar{x} \\pm z^* \\cdot \\frac{\\sigma}{\\sqrt{n}}\\]\n\n\nWhen \\(\\sigma\\) is Unknown (more common):\n\n\n\\[\\bar{x} \\pm t^* \\cdot \\frac{s}{\\sqrt{n}}\\]\n\n\nKey Components:\n\n\n\n\\(\\bar{x}\\): sample mean\n\n\n\\(t^*\\): critical value (df = n-1)\n\n\n\\(\\frac{s}{\\sqrt{n}}\\): standard error\n\n\n\n\n\n\nCommon Confidence Levels:\n\n\n\n90%: z* = 1.645, more precise\n\n\n95%: z* = 1.96, most common\n\n\n99%: z* = 2.576, more confident\n\n\n\nConditions Required:\n\n\n\nRandom sampling\nNearly normal population OR n ≥ 30\nIndependent observations"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#interactive-ci-demo-confidence-intervals-for-means",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#interactive-ci-demo-confidence-intervals-for-means",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Interactive CI Demo: Confidence Intervals for Means",
    "text": "Interactive CI Demo: Confidence Intervals for Means\n\n\n\nSample Size:  Confidence Level:  90% 95% 99%   Population μ:  Population σ:  Generate New Sample & CI Simulate 100 CIs\n\n\n\nCurrent CI: Generate a sample to see CI Captures μ? - | Margin of Error: -"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-proportions",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-proportions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals for Population Proportions",
    "text": "Confidence Intervals for Population Proportions\n\n\n\n 🎯 Formula:\n\n\n\\[\\hat{p} \\pm z^* \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\]\n\n\nKey Components:\n\n\n\n\\(\\hat{p} = \\frac{x}{n}\\): sample proportion\n\n\n\\(z^*\\): critical value\n\n\n\\(\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\): standard error\n\n\n\n\nConditions Required:\n\n\n\nRandom sampling\n\n\n\\(n\\hat{p} \\geq 10\\) and \\(n(1-\\hat{p}) \\geq 10\\)\n\n\nIndependent observations\n\n\nPopulation at least 10× sample size\n\n\n\nConservative Approach:\n\n\nUse \\(\\hat{p} = 0.5\\) for planning when true proportion unknown (maximizes margin of error)"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#interactive-ci-demo-confidence-intervals-for-proportions",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#interactive-ci-demo-confidence-intervals-for-proportions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Interactive CI Demo: Confidence Intervals for Proportions",
    "text": "Interactive CI Demo: Confidence Intervals for Proportions\n\n\n\nSample Size:  Confidence Level:  90% 95% 99%   Population p:  Generate New Sample & CI Simulate 100 CIs\n\n\n\nCurrent CI: Generate a sample to see CI Captures p? - | Sample Proportion: -"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-1-ci-for-mean",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-1-ci-for-mean",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Practice Problem 1: CI for Mean",
    "text": "Practice Problem 1: CI for Mean\n\nA random sample of 25 college students shows a mean daily screen time of 6.2 hours with a standard deviation of 1.8 hours. (a) Construct a 95% confidence interval for the mean daily screen time. (b) Interpret the confidence interval in context. (c) What would happen to the interval width if we used 99% confidence instead? Show Solution\n\nSolution. (a)\nGiven: \\(n = 25\\), \\(\\bar{x} = 6.2\\), \\(s = 1.8\\), 95% confidence\nFor \\(df = 24\\), \\(t^* = 2.064\\)\n\\(SE = \\frac{s}{\\sqrt{n}} = \\frac{1.8}{\\sqrt{25}} = 0.36\\)\n\\(CI = 6.2 \\pm 2.064 \\times 0.36 = 6.2 \\pm 0.743 = (5.46, 6.94)\\) hours\n(b)\nWe are 95% confident that the true mean daily screen time for all college students is between \\(5.46\\) and \\(6.94\\) hours.\n(c)\nFor 99% confidence, we use \\(t^* = 2.797\\), giving a wider interval: \\((5.19, 7.21)\\) hours."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-2-ci-for-proportion",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-2-ci-for-proportion",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Practice Problem 2: CI for Proportion",
    "text": "Practice Problem 2: CI for Proportion\n\nIn a survey of 400 voters, 240 support a particular candidate. (a) Construct a 90% confidence interval for the true proportion of supporters. (b) Check if the conditions for inference are met. (c) How large a sample would be needed for a margin of error of 0.03 with 95% confidence? Show Solution\n\nSolution. (a)\n\\(\\hat{p} = \\frac{240}{400} = 0.6\\), \\(n = 400\\), 90% confidence, \\(z^* = 1.645\\)\n\\(SE = \\sqrt{\\frac{0.6 \\times 0.4}{400}} = \\sqrt{\\frac{0.24}{400}} = 0.0245\\)\n\\(CI = 0.6 \\pm 1.645 \\times 0.0245 = 0.6 \\pm 0.0403 = (0.560, 0.640)\\)\n(b)\nCheck conditions: \\(n\\hat{p} = 400 \\times 0.6 = 240 \\geq 10\\) ✓\n\\(n(1-\\hat{p}) = 400 \\times 0.4 = 160 \\geq 10\\) ✓\n(c)\nSample size calculation:\n\\(n = \\frac{(z^*)^2 \\hat{p}(1-\\hat{p})}{ME^2} =\n\\frac{(1.96)^2 \\times 0.6 \\times 0.4}{(0.03)^2} =\n\\frac{0.9216}{0.0009} = 1024\\) people"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-3-sample-size-planning",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-3-sample-size-planning",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Practice Problem 3: Sample Size Planning",
    "text": "Practice Problem 3: Sample Size Planning\n\nA market researcher wants to estimate the average amount spent on coffee per week by college students. (a) How large a sample is needed for a 95% CI with margin of error $2 if \\(\\sigma\\) = $8? (b) If the budget only allows for 100 students, what confidence level gives a $2 margin of error? (c) What’s the trade-off between sample size, confidence level, and precision?\n\nShow Solution\n\n\nSolution. (a)\nFor means:\n\\(n = \\frac{(z^*)^2 \\sigma^2}{ME^2} =\n\\frac{(1.96)^2 \\times 8^2}{2^2} =\n\\frac{245.86}{4} = 62\\) students\n(b)\nWith \\(n = 100\\):\n\\(ME = z^* \\frac{\\sigma}{\\sqrt{n}} =\nz^* \\frac{8}{\\sqrt{100}} =\n0.8 z^*\\)\nFor \\(ME = 2\\):\n\\(z^* = \\frac{2}{0.8} = 2.5\\),\nwhich corresponds to about 98.8% confidence\n(c) Trade-offs:\n\nHigher confidence \\(\\rightarrow\\) wider intervals (less precision)\nLarger sample \\(\\rightarrow\\) narrower intervals (more precision)\nLower margin of error \\(\\rightarrow\\) need larger sample or lower confidence"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#common-mistakes-and-misconceptions",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#common-mistakes-and-misconceptions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Common Mistakes and Misconceptions",
    "text": "Common Mistakes and Misconceptions\n\n\nInterpretation Errors\n❌ Wrong: “\\(95\\%\\) of the data falls in this interval”\n✅ Right: “We’re \\(95\\%\\) confident the parameter is in this interval”\n❌ Wrong: “There’s a \\(95\\%\\) chance \\(\\mu\\) is in this interval”\n✅ Right: “\\(95\\%\\) of such intervals contain \\(\\mu\\)”\n\nTechnical Errors\n\nUsing \\(z*\\) when σ is unknown and \\(n &lt; 30\\)\nForgetting to check conditions\nConfusing standard error with standard deviation\nUsing wrong degrees of freedom for t-distribution\n\n\nRemember: The confidence level refers to the long-run proportion of intervals that capture the parameter!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sample-size-and-margin-of-error-relationships",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sample-size-and-margin-of-error-relationships",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Sample Size and Margin of Error Relationships",
    "text": "Sample Size and Margin of Error Relationships\n\n\nPopulation σ:  Confidence Level:  90% 95% 99%   Desired Margin of Error: \n\n\n\n\n\n\nSample Size vs Margin of Error\n\n\n\n\nRequired Sample Size: - | Resulting ME: -"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#types-of-sampling-methods",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#types-of-sampling-methods",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Types of Sampling Methods",
    "text": "Types of Sampling Methods\n\n\n\n\n\n\n\n\n\n\nMethod\nDescription\nAdvantages\nDisadvantages\n\n\n\n\nSimple Random\nEvery individual has equal chance\nUnbiased, simple\nMay not represent subgroups\n\n\nStratified\nSample from each subgroup\nEnsures representation\nMore complex\n\n\nCluster\nSample entire groups\nCost-effective for spread populations\nHigher variability\n\n\nSystematic\nEvery k-th individual\nSimple to implement\nCan miss patterns\n\n\nConvenience\nEasily accessible individuals\nQuick and cheap\nHighly biased\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSampling Method Matters: Only probability sampling methods allow for valid statistical inference!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#confidence-intervals-in-practice",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#confidence-intervals-in-practice",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals in Practice",
    "text": "Confidence Intervals in Practice\n\n\n\nWhen to Use Each Type\nMeans: Continuous data (height, income, test scores)\nProportions: Categorical data (yes/no, success/failure)\nChoosing Confidence Level\n\n90%: Quick estimates, less critical decisions\n95%: Standard in most research\n99%: High-stakes decisions, medical trials\n\n\nReal-World Applications\n\nPolitical polls: Proportion confidence intervals\nQuality control: Mean confidence intervals\nMedical research: Both types with high confidence\nBusiness analytics: Varies by decision importance\n\nCommunication Tips\n\nAlways include the confidence level\nState what the interval estimates\nAcknowledge the uncertainty\nConsider practical significance"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#key-takeaways",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#key-takeaways",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\n\n\nMain Concepts\n\nSampling distributions follow predictable patterns\nConfidence intervals quantify uncertainty\nCentral Limit Theorem makes normal-based inference possible\nSample size directly affects precision\n\n\nPractical Guidelines Choose appropriate methods based on:\n\nData type (continuous vs categorical)\nSample size (use t when σ unknown)\nDesired precision (affects sample size)\nConfidence level (affects interval width)\n\nKey Principle Statistical inference allows us to make informed decisions about populations using sample data, while properly accounting for uncertainty."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#looking-ahead",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#looking-ahead",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\nNext Lecture: Hypothesis Testing\nTopics we’ll cover:\n\nNull and alternative hypotheses\nTest statistics and p-values\nType I and Type II errors\n\n\nConnection: Confidence intervals and hypothesis tests are two sides of the same statistical inference coin"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#questions",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#questions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Questions?",
    "text": "Questions?\n\nOffice Hours: 11AM on Thursday (link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Hypothesis Testing and Statistical Significance"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#resources",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#resources",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Resources",
    "text": "Resources\n\n  \n    \n      \n      Read OpenIntro Statistics Chapter 5 sections 5.1-5.3\n    \n    \n      \n      Khan Academy - Confidence Intervals\n    \n    \n      \n      Seeing Theory - Frequentist Inference\n    \n    \n      \n      Confidence Intervals - Wikipedia\n    \n    \n      \n      Understanding Different Types of Intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html",
    "title": "Linear Transformation Properties",
    "section": "",
    "text": "Given: Let \\(X = \\{x_i\\}_{i=1}^{n}\\) and define \\(Y = \\{y_i\\}_{i=1}^{n}\\) by \\(y_i = a x_i\\) for some fixed constant \\(a \\neq 0\\).\nProve the following relationships:\n\\[\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i, \\quad \\bar{Y} = a \\bar{X}, \\quad S_Y^2 = a^2 S_X^2\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#problem-statement",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#problem-statement",
    "title": "Linear Transformation Properties",
    "section": "Problem Statement",
    "text": "Problem Statement\n\nGiven: Let \\(X = \\{x_i\\}_{i=1}^{n}\\) and define \\(Y = \\{y_i\\}_{i=1}^{n}\\) by \\(y_i = a x_i\\) for some fixed constant \\(a \\neq 0\\).\nProve the following relationships:\n\\[\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i, \\quad \\bar{Y} = a \\bar{X}, \\quad S_Y^2 = a^2 S_X^2\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#understanding-the-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#understanding-the-notation",
    "title": "Linear Transformation Properties",
    "section": "Understanding the Notation",
    "text": "Understanding the Notation\nSet Notation\n\n\\(X = \\{x_i\\}_{i=1}^{n}\\) means:\n\n\\(X\\) is a dataset containing \\(n\\) observations\nThe observations are labeled \\(x_1, x_2, x_3, \\ldots, x_n\\)\n\\(i\\) is an index that runs from 1 to \\(n\\)\nThis is read as: “X is the set of \\(x_i\\) for \\(i\\) from 1 to \\(n\\)”\n\n\nExamples:\n\nIf \\(n = 5\\): \\(X = \\{x_1, x_2, x_3, x_4, x_5\\}\\)\nIf \\(X = \\{2, 4, 6, 8, 10\\}\\), then \\(x_1 = 2, x_2 = 4, x_3 = 6, x_4 = 8, x_5 = 10\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#summation-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#summation-notation",
    "title": "Linear Transformation Properties",
    "section": "Summation Notation",
    "text": "Summation Notation\n\n\\(\\sum_{i=1}^{n} x_i\\) means:\n\nAdd up all the \\(x_i\\) values\nStart with \\(i = 1\\) and go up to \\(i = n\\)\nThis equals: \\(x_1 + x_2 + x_3 + \\cdots + x_n\\)\n\n\nExample:\nIf \\(X = \\{2, 4, 6, 8, 10\\}\\), then: \\[\\sum_{i=1}^{5} x_i = x_1 + x_2 + x_3 + x_4 + x_5 = 2 + 4 + 6 + 8 + 10 = 30\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#linear-transformation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#linear-transformation",
    "title": "Linear Transformation Properties",
    "section": "Linear Transformation",
    "text": "Linear Transformation\n\n\\(Y = \\{y_i\\}_{i=1}^{n}\\) where \\(y_i = a x_i\\) means:\n\nEach element of \\(Y\\) is obtained by multiplying the corresponding element of \\(X\\) by the constant \\(a\\)\nThis is called a linear transformation\n\\(a\\) is called the scaling factor\n\n\nExample:\nIf \\(X = \\{2, 4, 6, 8, 10\\}\\) and \\(a = 3\\), then:\n\n\\(y_1 = 3 \\times 2 = 6\\)\n\\(y_2 = 3 \\times 4 = 12\\)\n\\(y_3 = 3 \\times 6 = 18\\)\n\\(y_4 = 3 \\times 8 = 24\\)\n\\(y_5 = 3 \\times 10 = 30\\)\n\nSo \\(Y = \\{6, 12, 18, 24, 30\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#sample-mean-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#sample-mean-notation",
    "title": "Linear Transformation Properties",
    "section": "Sample Mean Notation",
    "text": "Sample Mean Notation\n\nSample Mean: \\(\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\\)\nThis means:\n\nAdd up all observations: \\(\\sum_{i=1}^{n} x_i\\)\nDivide by the number of observations: \\(n\\)\nThe “bar” over \\(X\\) indicates the mean\n\n\nExample:\nFor \\(X = \\{2, 4, 6, 8, 10\\}\\): \\[\\bar{X} = \\frac{1}{5}(2 + 4 + 6 + 8 + 10) = \\frac{30}{5} = 6\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#sample-variance-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#sample-variance-notation",
    "title": "Linear Transformation Properties",
    "section": "Sample Variance Notation",
    "text": "Sample Variance Notation\n\nSample Variance: \\(S_X^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2\\)\nThis means:\n\nFor each observation, find its deviation from the mean: \\((x_i - \\bar{X})\\)\nSquare each deviation: \\((x_i - \\bar{X})^2\\)\nAdd up all squared deviations: \\(\\sum_{i=1}^{n} (x_i - \\bar{X})^2\\)\nDivide by \\((n-1)\\): This gives the sample variance"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-1",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-1",
    "title": "Linear Transformation Properties",
    "section": "Proof 1: Sum Relationship",
    "text": "Proof 1: Sum Relationship\n\nStep 1: Start with the definition of \\(y_i\\) \\[y_i = a x_i \\text{ for all } i = 1, 2, \\ldots, n\\]\nStep 2: Write out the sum of all \\(y_i\\) \\[\\sum_{i=1}^{n} y_i = y_1 + y_2 + y_3 + \\cdots + y_n\\]\nStep 3: Substitute the definition \\(y_i = a x_i\\) \\[\\sum_{i=1}^{n} y_i = a x_1 + a x_2 + a x_3 + \\cdots + a x_n\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-continued",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-continued",
    "title": "Linear Transformation Properties",
    "section": "Proof 1: Sum Relationship (continued)",
    "text": "Proof 1: Sum Relationship (continued)\n\n\n\nStep 4: Factor out the constant \\(a\\) \\[\\sum_{i=1}^{n} y_i = a(x_1 + x_2 + x_3 + \\cdots + x_n)\\]\nStep 5: Recognize the sum notation \\[\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\]\nTherefore: \\(\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\) ✓\n\n\n\nKey Property Used: Constants can be factored out of sums \\[\\sum_{i=1}^{n} (c \\cdot x_i) = c \\sum_{i=1}^{n} x_i\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#example-sum-relationship",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#example-sum-relationship",
    "title": "Linear Transformation Properties",
    "section": "Example: Sum Relationship",
    "text": "Example: Sum Relationship\n\nGiven: \\(X = \\{2, 4, 6\\}\\) and \\(a = 5\\)\nThen: \\(Y = \\{10, 20, 30\\}\\) (since \\(y_i = 5x_i\\))\nCheck our formula:\n\n\\(\\sum_{i=1}^{3} x_i = 2 + 4 + 6 = 12\\)\n\\(\\sum_{i=1}^{3} y_i = 10 + 20 + 30 = 60\\)\n\\(a \\sum_{i=1}^{3} x_i = 5 \\times 12 = 60\\) ✓\n\nVerification: \\(60 = 60\\) ✓"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-1",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-1",
    "title": "Linear Transformation Properties",
    "section": "Proof 2: Sample Mean Relationship",
    "text": "Proof 2: Sample Mean Relationship\n\nStep 1: Start with the definition of sample mean \\[\\bar{Y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i\\]\nStep 2: Use our result from Proof 1 We proved that \\(\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\)\nStep 3: Substitute this result \\[\\bar{Y} = \\frac{1}{n} \\cdot a \\sum_{i=1}^{n} x_i\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-continued",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-continued",
    "title": "Linear Transformation Properties",
    "section": "Proof 2: Sample Mean Relationship (continued)",
    "text": "Proof 2: Sample Mean Relationship (continued)\n\n\n\nStep 4: Rearrange the constants \\[\\bar{Y} = a \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]\nStep 5: Recognize the definition of \\(\\bar{X}\\) \\[\\bar{Y} = a \\bar{X}\\]\nTherefore: \\(\\bar{Y} = a \\bar{X}\\) ✓\n\n\n\nKey Property Used: Constants can be moved outside of fractions \\[\\frac{1}{n} \\cdot a \\sum_{i=1}^{n} x_i = a \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-mean-relationship",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-mean-relationship",
    "title": "Linear Transformation Properties",
    "section": "Example: Sample Mean Relationship",
    "text": "Example: Sample Mean Relationship\n\nGiven: \\(X = \\{2, 4, 6\\}\\) and \\(a = 5\\)\nThen: \\(Y = \\{10, 20, 30\\}\\)\nCheck our formula:\n\n\\(\\bar{X} = \\frac{1}{3}(2 + 4 + 6) = \\frac{12}{3} = 4\\)\n\\(\\bar{Y} = \\frac{1}{3}(10 + 20 + 30) = \\frac{60}{3} = 20\\)\n\\(a \\bar{X} = 5 \\times 4 = 20\\) ✓\n\nVerification: \\(20 = 20\\) ✓"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-1",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-1",
    "title": "Linear Transformation Properties",
    "section": "Proof 3: Sample Variance Relationship",
    "text": "Proof 3: Sample Variance Relationship\n\nStep 1: Start with the definition of sample variance \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\bar{Y})^2\\]\nStep 2: Substitute \\(y_i = a x_i\\) and \\(\\bar{Y} = a \\bar{X}\\) \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (a x_i - a \\bar{X})^2\\]\nStep 3: Factor out \\(a\\) from the parentheses \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} [a(x_i - \\bar{X})]^2\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-continued",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-continued",
    "title": "Linear Transformation Properties",
    "section": "Proof 3: Sample Variance Relationship (continued)",
    "text": "Proof 3: Sample Variance Relationship (continued)\n\nStep 4: Use the property \\((ab)^2 = a^2 b^2\\) \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} a^2 (x_i - \\bar{X})^2\\]\nStep 5: Factor out the constant \\(a^2\\) from the sum \\[S_Y^2 = \\frac{a^2}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2\\]\nStep 6: Recognize the definition of \\(S_X^2\\) \\[S_Y^2 = a^2 \\cdot \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2 = a^2 S_X^2\\]\nTherefore: \\(S_Y^2 = a^2 S_X^2\\) ✓"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#key-properties-used-in-variance-proof",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#key-properties-used-in-variance-proof",
    "title": "Linear Transformation Properties",
    "section": "Key Properties Used in Variance Proof",
    "text": "Key Properties Used in Variance Proof\n\nProperties Used:\n\nFactoring: \\(ax_i - a\\bar{X} = a(x_i - \\bar{X})\\)\nSquaring: \\([a(x_i - \\bar{X})]^2 = a^2(x_i - \\bar{X})^2\\)\nConstants in sums: \\(\\sum_{i=1}^{n} a^2 f(x_i) = a^2 \\sum_{i=1}^{n} f(x_i)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-variance-relationship",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-variance-relationship",
    "title": "Linear Transformation Properties",
    "section": "Example: Sample Variance Relationship",
    "text": "Example: Sample Variance Relationship\n\nGiven: \\(X = \\{1, 3, 5\\}\\) and \\(a = 2\\)\nCalculate \\(S_X^2\\):\n\n\\(\\bar{X} = \\frac{1+3+5}{3} = 3\\)\n\\(S_X^2 = \\frac{1}{2}[(1-3)^2 + (3-3)^2 + (5-3)^2] = \\frac{1}{2}[4 + 0 + 4] = 4\\)\n\nFor \\(Y = \\{2, 6, 10\\}\\): - \\(\\bar{Y} = \\frac{2+6+10}{3} = 6 = 2 \\times 3\\) ✓\n\n\\(S_Y^2 = \\frac{1}{2}[(2-6)^2 + (6-6)^2 + (10-6)^2] = \\frac{1}{2}[16 + 0 + 16] = 16\\)\n\nCheck: \\(a^2 S_X^2 = 2^2 \\times 4 = 16\\) ✓"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#complete-summary-of-results",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#complete-summary-of-results",
    "title": "Linear Transformation Properties",
    "section": "Complete Summary of Results",
    "text": "Complete Summary of Results\n\nFor the linear transformation \\(Y = \\{y_i\\}_{i=1}^{n}\\) where \\(y_i = a x_i\\):\n\nSum: \\(\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\)\nMean: \\(\\bar{Y} = a \\bar{X}\\)\nVariance: \\(S_Y^2 = a^2 S_X^2\\)\n\nNote: The standard deviation relationship is \\(S_Y = |a| S_X\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#practical-implications",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#practical-implications",
    "title": "Linear Transformation Properties",
    "section": "Practical Implications",
    "text": "Practical Implications\n\n\nScaling Up (a &gt; 1):\n\nSums and means increase by factor \\(a\\)\nVariance increases by factor \\(a^2\\)\nData becomes more spread out\n\nExample: Converting inches to feet\n\nIf \\(a = 12\\), variance increases by \\(12^2 = 144\\)\n\n\n\nScaling Down (0 &lt; a &lt; 1):\n\nSums and means decrease by factor \\(a\\)\nVariance decreases by factor \\(a^2\\)\nData becomes less spread out\n\nExample: Converting dollars to cents\n\nIf \\(a = 0.01\\), variance decreases by \\((0.01)^2 = 0.0001\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#real-world-applications",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#real-world-applications",
    "title": "Linear Transformation Properties",
    "section": "Real-World Applications",
    "text": "Real-World Applications\n\nTemperature Conversion:\n\nCelsius to Fahrenheit: \\(F = \\frac{9}{5}C + 32\\) (not linear!)\nCelsius to Kelvin: \\(K = C + 273.15\\) (not linear!)\nBut scaling: \\(C_{doubled} = 2C\\) is linear with \\(a = 2\\)\n\nUnit Conversions: - Meters to centimeters: \\(a = 100\\)\n\nDollars to cents: \\(a = 100\\)\nHours to minutes: \\(a = 60\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#why-these-properties-matter",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#why-these-properties-matter",
    "title": "Linear Transformation Properties",
    "section": "Why These Properties Matter",
    "text": "Why These Properties Matter\n\nStatistical Significance:\n\nStandardization: Converting to z-scores uses linear transformations\nUnit Changes: Results remain proportionally correct\nData Analysis: Understanding how transformations affect summary statistics\nModeling: Linear regression relies on these properties\n\nKey Insight: Linear transformations preserve the shape of the distribution while changing location and scale."
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#practice-problem",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#practice-problem",
    "title": "Linear Transformation Properties",
    "section": "Practice Problem",
    "text": "Practice Problem\n\nTry This: A dataset has mean \\(\\bar{X} = 15\\) and variance \\(S_X^2 = 9\\).\nIf we transform the data using \\(y_i = 3x_i - 2\\), what are the new mean and variance?\n\n\n\n\n\n\nTip\n\n\nHint: This is not a pure linear transformation! You need \\(y_i = 3x_i - 2 = 3(x_i - \\frac{2}{3})\\)\n\n\n\n\nAnswer:\n\nNew mean: \\(\\bar{Y} = 3(15) - 2 = 43\\)\nNew variance: \\(S_Y^2 = 3^2 \\times 9 = 81\\)\n(The constant \\(-2\\) doesn’t affect variance!)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#common-mistakes-to-avoid",
    "title": "Linear Transformation Properties",
    "section": "Common Mistakes to Avoid",
    "text": "Common Mistakes to Avoid\n\n❌ Wrong: \\(S_Y^2 = a S_X^2\\)\n✅ Correct: \\(S_Y^2 = a^2 S_X^2\\)\nWhy: Variance involves squared deviations, so the scaling factor gets squared too.\n❌ Wrong: Adding constants affects variance\n✅ Correct: Only multiplication affects variance; addition only shifts the mean"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#conclusion",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#conclusion",
    "title": "Linear Transformation Properties",
    "section": "Conclusion",
    "text": "Conclusion\n\nWhat We Proved:\nFor the linear transformation \\(y_i = ax_i\\) with constant \\(a \\neq 0\\):\n\nSums scale linearly: Factor of \\(a\\)\nMeans scale linearly: Factor of \\(a\\)\n\nVariances scale quadratically: Factor of \\(a^2\\)\n\nKey Takeaway: Understanding these relationships is fundamental for:\n\nData transformations\nStatistical modeling\nUnit conversions\nStandardization procedures"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#questions",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#questions",
    "title": "Linear Transformation Properties",
    "section": "Questions?",
    "text": "Questions?\nKey Concepts Covered:\n\nSummation notation and indexing\nLinear transformations\nProperties of means and variances\nStep-by-step mathematical proofs\n\nNext Steps:\n\nApply to real datasets\nExplore non-linear transformations\nPractice with different scaling factors"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#additional-practice",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#additional-practice",
    "title": "Linear Transformation Properties",
    "section": "Additional Practice",
    "text": "Additional Practice\n\nExercise 1: If \\(X = \\{10, 20, 30, 40\\}\\) and \\(Y = \\{-5, -10, -15, -20\\}\\), what is the value of \\(a\\)?\nExercise 2: A dataset has \\(\\bar{X} = 50\\) and \\(S_X = 10\\). After transformation \\(y_i = 0.5x_i\\), find \\(\\bar{Y}\\) and \\(S_Y\\).\nExercise 3: Prove that if \\(y_i = ax_i + b\\) (adding a constant), then \\(S_Y^2 = a^2 S_X^2\\) (the constant doesn’t affect variance)."
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html",
    "title": "PSTAT 5A: Counting",
    "section": "",
    "text": "The art and science of systematic enumeration"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#welcome-to-lecture-7",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#welcome-to-lecture-7",
    "title": "PSTAT 5A: Counting",
    "section": "Welcome to Lecture 7",
    "text": "Welcome to Lecture 7\nThe art and science of systematic enumeration"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#learning-objectives",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#learning-objectives",
    "title": "PSTAT 5A: Counting",
    "section": "Today’s Learning Objectives",
    "text": "Today’s Learning Objectives\n\n\n\n\n\n\n\nLearning Objectives\n\n\nBy the end of this lecture, you will be able to:\n\nApply the fundamental counting principles (Section 0.4)\nCalculate permutations with and without repetition (Section 0.8, Section 0.11, Section 0.15)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#why-study-counting",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#why-study-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Why Study Counting?",
    "text": "Why Study Counting?\n\n\n\n\n\n\n\n\nCounting helps us:\n\n\n\nCalculate probabilities for complex events\n\nSolve optimization problems\n\nUnderstand combinations in genetics, computer science\n\nAnalyze algorithms and data structures\n\nMake decisions involving arrangements and selections\n\n\n\n\n\n\n\n\n\n\n\nReal-world Examples:\n\n\n\nCryptography: Password strength and encryption key space\nGenetics: DNA sequence analysis and gene combinations\n\nTournament brackets: March Madness and sports competitions\nLottery odds: Probability calculations for games of chance\nPassword security: Character combinations and brute force protection"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-fundamental-counting",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-fundamental-counting",
    "title": "PSTAT 5A: Counting",
    "section": "The Counting Principle",
    "text": "The Counting Principle\n\n\n\n\n\n\n\n\n\nMultiplication Rule\n\n\nIf a procedure consists of k separate tasks where:\n\nTask 1 can be performed in n_1 ways\nTask 2 can be performed in n_2 ways\n…\nTask k can be performed in n_k ways\n\nThen, the entire procedure can be performed in n_1 \\times n_2 \\times \\cdots \\times n_k ways\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualization\n\n\n\n\n\n\n\n%%{init: {'flowchart': {'nodeSpacing': 5, 'rankSpacing': 20}}}%%\nflowchart TD\n    Start([🟢 Start]) --&gt; T1[📋 Task 1&lt;br/&gt;n₁ ways]\n    T1 --&gt; C1[Choice 1]\n    T1 --&gt; C2[Choice 2]\n    T1 --&gt; Cn1[Choice n₁]\n    \n    C1 --&gt; T2[📋 Task 2&lt;br/&gt;n₂ ways]\n    C2 --&gt; T2\n    Cn1 --&gt; T2\n    \n    T2 --&gt; C21[Choice 1]\n    T2 --&gt; C22[Choice 2]\n    T2 --&gt; C2n[Choice n₂]\n    \n    C21 --&gt; Total[🎯 Total ways&lt;br/&gt;n₁ × n₂ × ... × nₖ]\n    C22 --&gt; Total\n    C2n --&gt; Total\n    \n    classDef start fill:#d4edda,stroke:#155724,stroke-width:3px\n    classDef task fill:#d1ecf1,stroke:#0c5460,stroke-width:2px\n    classDef choice fill:#fff3cd,stroke:#856404,stroke-width:1px\n    classDef total fill:#f8d7da,stroke:#721c24,stroke-width:3px\n    \n    class Start start\n    class T1,T2 task\n    class C1,C2,Cn1,C21,C22,C2n choice\n    class Total total"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#counting-example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#counting-example",
    "title": "PSTAT 5A: Counting",
    "section": "Counting Example",
    "text": "Counting Example\n\n\n\nFormat: ABC-123\n\n\\underbrace{A \\; B \\; \\_ \\; \\ - \\_ \\; \\_ \\; \\_}_{positions}\n\n\n\nFirst position: 26 letters\nSecond position: 26 letters\nThird position: 26 letters\nFourth position: 10 digits\nFifth position: 10 digits\nSixth position: 10 digits\n\n\n\n\n\n\nSolution. Total possibilities: 26 \\times 26 \\times 26 \\times 10 \\times 10 \\times 10 = 26^3 \\times 10^3\nTotal possibilities = 17,576,000"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#restaurant-menu-example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#restaurant-menu-example",
    "title": "PSTAT 5A: Counting",
    "section": "Restaurant Menu Example",
    "text": "Restaurant Menu Example\n\nA restaurant offers:\n🍤 Appetizers: 4\n🍲 Main Courses: 6\n🍰 Desserts: 3\nHow many different three-course meals are possible?\n\n\nSolution. 4 \\times 6 \\times 3 = 72 different meals"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#practice-1",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#practice-1",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\nA password must contain:\n\nExactly 8 characters\nEach character is either a letter (26 possibilities) or digit (10 possibilities)\n\nHow many possible passwords are there?\n\n\n\n\n\n\n\nSolution. Each position has 26 + 10 = 36 choices.\nTotal: 36^8 = 2,821,109,907,456 passwords"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Permutations?",
    "text": "What Are Permutations?\n\n\n\n\n\n\n\n\n\nPermutation\n\n\nAn arrangement of objects where order matters\n\n\n\n\n\n\n\n\n\n\n\nOrder Matters\n\n\n\nRace finish positions (1st, 2nd, 3rd)\nSeating arrangements\nPasswords\nDNA sequences\n\n\n\n\n\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nAll permutations of ABC:\n1. ABC\n2. ACB\n3. BAC\n4. BCA\n5. CAB\n6. CBA"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-of-n-distinct-objects",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-of-n-distinct-objects",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of n Distinct Objects",
    "text": "Permutations of n Distinct Objects\n\n\n\n\n\n\n\n\n\nKey Formula\n\n\nThe number of ways to arrange n distinct objects is:\nn! = n \\times (n-1) \\times (n-2) \\times \\cdots \\times 2 \\times 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nSeating Process:\n1st position: 5 choices (Alice, Bob, Carol, David, Eve)\n2nd position: 4 choices (whoever is left)\n3rd position: 3 choices (whoever is left)\n4th position: 2 choices (whoever is left)\n5th position: 1 choice (last person)\nHow many ways can 5 people sit in a row?\n\n\n\n\n\nSolution. 5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120 ways"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#factorial-values",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#factorial-values",
    "title": "PSTAT 5A: Counting",
    "section": "Factorial Values",
    "text": "Factorial Values\n\n\n\n\n\nn\nn!\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n2\n2\n\n\n3\n6\n\n\n4\n24\n\n\n5\n120\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n0! = 1 by definition"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-r-from-n",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-r-from-n",
    "title": "PSTAT 5A: Counting",
    "section": "Arranging with Order",
    "text": "Arranging with Order\n\n\n\n\n\n\n\n\n\nKey Formula\n\n\nP(n,r) or _nP_r: Number of ways to arrange r objects (a subset) selected from n (total num.) distinct objects\nP(n,r) = \\frac{n!}{(n-r)!}\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nP_{k,n} =\n\\frac{n!}{(n-k)!}\n=\n\n\n= \\frac{\n  n(n-1)\\cdots(n-k+1)\\,\n  \\overbrace{(n-k)(n-k-1)\\cdots3\\cdot2\\cdot1}^{(n-k)!}\n}{\n  (n-k)!\n}\n\n\n= \\underbrace{\nn (n-1) (n-2) \\cdots (n-k+1)\n}_{k \\text{ terms}}\n\nFill in k slots with no repetitions\n\n\\underbrace{n \\; (n-1) \\; \\_ \\; \\_ \\; \\cdots}_{k}\n\nNote that if we allowed repetitions we would get n^k \n\\underbrace{n \\; n \\; n \\; \\cdots \\; n}_{k}"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#example",
    "title": "PSTAT 5A: Counting",
    "section": "Example",
    "text": "Example\n\nHow many ways can we select and arrange 3 people from a group of 8 for president, vice-president, and secretary? \n\n\nSolution. P(8,3) = \\frac{8!}{(8-3)!} = \\frac{8!}{5!} = 8 \\times 7 \\times 6 = 336"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#understanding-pnr",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#understanding-pnr",
    "title": "PSTAT 5A: Counting",
    "section": "Understanding P(n,r)",
    "text": "Understanding P(n,r)\nWhy is P(n,r) = \\frac{n!}{(n-r)!}?\n\nFirst position: n choices\nSecond position: (n-1) choices\n\nThird position: (n-2) choices\n…\nr-th position: (n-r+1) choices\n\n\nTotal: n \\times (n-1) \\times (n-2) \\times \\cdots \\times (n-r+1) = \\frac{n!}{(n-r)!}"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#practice-2",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#practice-2",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\nA baseball team has 15 players. How many ways can the coach:\n\nArrange all 15 players in a line?\nChoose and arrange 9 players for the starting lineup (batting order matters)?\n\n\n\n\nSolution. \n\n15! = 1,307,674,368,000\nP(15,9) = \\frac{15!}{6!} = 1,816,214,400"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-repetition",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-repetition",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition",
    "text": "Permutations with Repetition\n\n\n\n\n\n\n\nPermutations with Repetition\n\n\nWhen some objects are identical, we have fewer distinct arrangements\nIf we have n objects where:\n\nn_1 are of type 1\nn_2 are of type 2\n…\nn_k are of type k\n\nNumber of distinct arrangements: \\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-with-repetition-example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-with-repetition-example",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition Example",
    "text": "Permutations with Repetition Example\n\n\n\nHow many distinct arrangements are there of the letters in “STATISTICS”? \n\n\n\n\n\n\n\n\n\nTip\n\n\nS-T-A-T-I-S-T-I-C-S\n\nTotal letters: 10\nS appears 3 times\nT appears 3 times\nA appears 1 time\nI appears 2 times\nC appears 1 time\n\n\n\n\n\n\nSolution. \\frac{10!}{3! \\times 3! \\times 1! \\times 2! \\times 1!} = \\frac{3,628,800}{6 \\times 6 \\times 1 \\times 2 \\times 1} = \\frac{3,628,800}{72} = 50,400"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#learning-summary",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#learning-summary",
    "title": "PSTAT 5A: Counting",
    "section": "Learning Objectives Summary",
    "text": "Learning Objectives Summary\n\n\n\n\n\n\n\nWhat We’ve Covered\n\n\nIn this lecture, we’ve addressed all the learning objectives:\n\n✅ Apply the fundamental counting principles: Covered in Section 0.4\n✅ Calculate permutations with and without repetition: Covered in Section 0.8, Section 0.11, and Section 0.15"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#questions",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#questions",
    "title": "PSTAT 5A: Counting",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday’s 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Counting continued"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html",
    "href": "files/lecture_notes/lecture13/lecture13.html",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Making Decisions with Data: From Questions to Statistical Evidence\n“The goal is not to eliminate uncertainty, but to make informed decisions despite it”\n\n\n\n\n\n\n\nWhen:\n- 📅 Date: Friday, July 25\n- ⏰ Window: 7 AM – 12 AM\n- ⏳ Duration: 1 hour once started\nWhere: 💻 Online via Canvas\n\n\n\n\n\nFoundation: Logic of hypothesis testing\nPractice: Real examples with Python\nSkills: Making statistical decisions\nApplications: From medicine to marketing\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstand the logic of hypothesis testing\nGet familiar with the language of statistical decisions\nRecognize different types of errors and their consequences\nConnect to confidence intervals from last lecture\n\n\n\n\n\n\nFormulate hypotheses from research questions\nCalculate and interpret p-values correctly\nPerform hypothesis tests in Python\nMake informed decisions using statistical evidence\nCommunicate results effectively\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is Hypothesis Testing?\n\n\n\nHypothesis testing lets us use sample data to weigh competing claims about a population.\nWorkflow\n\nState H₀ (null) – the status‑quo or “no‑effect” position\n\nState H₁ (alternative) – the research claim you hope to support\n\nChoose α – the tolerable Type I error rate (e.g., 0.05)\n\nCompute a test statistic – compress the data into one number\n\nFind the p‑value – “How unusual is this statistic if H₀ were true?”\n\nMake a decision – reject H₀ if p ≤ α; otherwise fail to reject\n\nThe goal is not to prove anything with certainty, but to judge whether the evidence tips the scale away from H₀.\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nHypothesis testing helps us answer: “Is what we observed in our sample strong enough evidence to conclude something about the population?”\n\n\n\n\n\n\n\nCriminal Justice System\n\n\n\nAspect\nCriminal Court\n\n\n\n\nStarting Position\nDefendant is innocent\n\n\nBurden of Proof\nProsecution must prove guilt\n\n\nEvidence Standard\nBeyond reasonable doubt\n\n\nDecision Options\nGuilty or Not Guilty\n\n\nType I Error\nConvict an innocent person\n\n\nType II Error\nAcquit a guilty person\n\n\nConsequences\nBalance justice vs. protecting innocent\n\n\n\n\nStatistical Hypothesis Testing\n\n\n\nAspect\nHypothesis Testing\n\n\n\n\nStarting Position\nNull hypothesis (H₀) is true\n\n\nBurden of Proof\nData must support alternative (H₁)\n\n\nEvidence Standard\np ≤ α (usually 0.05)\n\n\nDecision Options\nReject H₀ or Fail to reject H₀\n\n\nType I Error\nReject a true null (false positive)\n\n\nType II Error\nFail to reject a false null (false negative)\n\n\nConsequences\nBalance discovery vs. false claims\n\n\n\n\n\n\nKey Insight 💡 Just like in court, we never “prove” innocence or accept the null hypothesis—we only decide whether the evidence is strong enough to reject it.\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\n\n\n\n\nWhat is a p-value?\n\n\n\nThe p-value answers the question\n“If the null hypothesis were true, how likely is a result at least this extreme?”\nFormally, for an observed test statistic \\(T_{\\text{obs}}\\),\n\\[\n  p = P\\bigl(|T| \\ge |T_{\\text{obs}}| \\;\\big|\\; H_0\\bigr).\n\\]\nSmaller p-values → data less compatible with \\(H_0\\) → stronger evidence against \\(H_0\\).\n\n\n\n\nInterpretation Cheat-Sheet\n\n\n\np-value\nEvidence vs \\(H_0\\)\n\n\n\n\n\\(p &gt; 0.10\\)\nLittle / none\n\n\n\\(0.05 &lt; p \\le 0.10\\)\nWeak\n\n\n\\(0.01 &lt; p \\le 0.05\\)\nModerate\n\n\n\\(p \\le 0.01\\)\nStrong\n\n\n\n(Guidelines, not iron-clad laws.)\n\nCommon Pitfalls\n\n\\(p\\) is not the probability that (H_0) is true\n\n\\(p\\) is not the probability the result occurred “by chance”\n\nA non-significant \\(p\\) does not prove \\(H_0\\)\n\nStatistical significance ≠ practical importance\n\n\n\n\nExample: In our treatment test, \\(t = 2.5\\) gave \\(p = 0.006\\).\nIf \\(H_0\\) were true, such an extreme outcome would occur only 0.6 % of the time,compelling evidence favoring the new treatment.\n\n\n\n\n\n\n\nError Types Matrix\n\n\n\nDecision ↓ / Reality →\nH₀ True\nH₀ False\n\n\n\n\nReject H₀\nType I Error (α)\n✔ Correct (Power)\n\n\nFail to Reject H₀\n✔ Correct\nType II Error (β)\n\n\n\n\nReal‑World Consequences\n\n\n\n\n\n\n\n\nContext\nType I Error (False Positive)\nType II Error (False Negative)\n\n\n\n\nMedical Test\nTreat healthy patient\nMiss actual disease\n\n\nDrug Approval\nApprove ineffective drug\nReject effective drug\n\n\nFire Alarm\nFalse alarm evacuation\nFail to detect real fire\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBalancing the risks\nLowering the significance level \\(\\alpha\\) reduces the chance of Type I mistakes but increases the risk of Type II errors unless you gather more data or target a larger effect.\nChoose $$ based on which error would be more costly in your scenario.\n\n\n\n\n\n\n\n\n                            \n                                            \n\n\nKey Insight: Higher power means you’re more likely to detect a true effect when it exists. Aim for power ≥ 0.80!\n\n\n\n\n\n\n\n\nResearch Question: A new study technique claims to improve test scores. The current average is 75. We test 25 students using the new method.\n\n\n📊 Sample Data Summary:\n========================================\nSample size (n): 25\nSample mean (x̄): 77.19\nSample std (s): 7.65\nCurrent average (μ₀): 75\n\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\n🎯 DETAILED RESULTS:\n==================================================\nTest Statistic: t = 1.432\nP-value: 0.0825\nCritical Value: 1.711\nEffect Size (Cohen's d): 0.286\n\n❌ DECISION: Fail to reject H₀\n📊 CONCLUSION: There is insufficient evidence (p = 0.0825) that the new study method improves test scores.\n💡 PRACTICAL IMPACT: The observed difference could reasonably be due to chance.\n\n\n\n\n\n\n\n🐍 PYTHON IMPLEMENTATION:\n========================================\nMethod 1: scipy.stats.ttest_1samp\nt-statistic: 1.432\np-value (two-tailed): 0.1650\np-value (one-tailed): 0.0825\n\nMethod 2: Manual with 95% Confidence Interval\n95% CI: (74.03, 80.35)\nInterpretation: We're 95% confident the true mean is between 74.0 and 80.4\n\nEffect Size (Cohen's d): 0.286\nEffect size interpretation: small effect\n\n\n\n\n\n\n\n\n\n\nResearch Question: Compare effectiveness of two teaching methods\n\n\n📊 TWO-GROUP COMPARISON:\n========================================\nMethod A (Traditional):\n  n = 30, mean = 75.45, std = 11.87\n\nMethod B (New):\n  n = 28, mean = 82.72, std = 14.82\n\nDifference in means: 7.27 points\n\n\n\n\n\n\n\n\n                            \n                                            \n\n\n🔑 KEY LESSON: Statistical Significance ≠ Practical Importance\n============================================================\nLeft: Tiny effect (0.02) but significant due to large sample\nRight: Large effect (8.7) but significant with small sample\n\n💡 Always consider BOTH statistical significance AND effect size!\n\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n# =============================================================================\n# COMPLETE HYPOTHESIS TESTING TOOLKIT\n# =============================================================================\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# -----------------------------------------------------------------------------\n# Template 1: One-Sample t-test\n# -----------------------------------------------------------------------------\ndef one_sample_ttest(data, null_value, alpha=0.05, alternative='two-sided'):\n    \"\"\"\n    Perform one-sample t-test with complete analysis\n    \n    Parameters:\n    -----------\n    data : array-like\n        Sample data\n    null_value : float\n        Hypothesized population mean\n    alpha : float\n        Significance level (default 0.05)\n    alternative : str\n        'two-sided', 'greater', or 'less'\n    \"\"\"\n    \n    # Calculate statistics\n    n = len(data)\n    x_bar = np.mean(data)\n    s = np.std(data, ddof=1)\n    se = s / np.sqrt(n)\n    \n    # Test statistic\n    t_stat = (x_bar - null_value) / se\n    df = n - 1\n    \n    # P-value calculation\n    if alternative == 'two-sided':\n        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    elif alternative == 'greater':\n        p_value = 1 - stats.t.cdf(t_stat, df)\n    elif alternative == 'less':\n        p_value = stats.t.cdf(t_stat, df)\n    \n    # Effect size (Cohen's d)\n    cohens_d = (x_bar - null_value) / s\n    \n    # Confidence interval\n    t_crit = stats.t.ppf(1 - alpha/2, df)\n    ci_lower = x_bar - t_crit * se\n    ci_upper = x_bar + t_crit * se\n    \n    # Results\n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'confidence_interval': (ci_lower, ci_upper),\n        'reject_null': p_value &lt;= alpha,\n        'sample_mean': x_bar,\n        'sample_std': s,\n        'sample_size': n\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 2: Two-Sample t-test\n# -----------------------------------------------------------------------------\ndef two_sample_ttest(group1, group2, alpha=0.05, equal_var=True):\n    \"\"\"\n    Perform two-sample t-test with complete analysis\n    \"\"\"\n    \n    # Calculate statistics\n    n1, n2 = len(group1), len(group2)\n    mean1, mean2 = np.mean(group1), np.mean(group2)\n    s1, s2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n    \n    if equal_var:\n        # Pooled variance\n        pooled_var = ((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2)\n        se = np.sqrt(pooled_var * (1/n1 + 1/n2))\n        df = n1 + n2 - 2\n    else:\n        # Welch's t-test\n        se = np.sqrt(s1**2/n1 + s2**2/n2)\n        df = (s1**2/n1 + s2**2/n2)**2 / ((s1**2/n1)**2/(n1-1) + (s2**2/n2)**2/(n2-1))\n    \n    # Test statistic\n    t_stat = (mean1 - mean2) / se\n    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    \n    # Effect size (Cohen's d)\n    if equal_var:\n        pooled_std = np.sqrt(pooled_var)\n    else:\n        pooled_std = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2))\n    \n    cohens_d = (mean1 - mean2) / pooled_std\n    \n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'reject_null': p_value &lt;= alpha,\n        'group1_stats': {'mean': mean1, 'std': s1, 'n': n1},\n        'group2_stats': {'mean': mean2, 'std': s2, 'n': n2}\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 3: Power Analysis\n# -----------------------------------------------------------------------------\ndef power_analysis(effect_size, alpha=0.05, power=0.8):\n    \"\"\"\n    Calculate required sample size for desired power\n    \"\"\"\n    from scipy.stats import norm\n    \n    z_alpha = norm.ppf(1 - alpha/2)\n    z_beta = norm.ppf(power)\n    \n    n = ((z_alpha + z_beta) / effect_size) ** 2\n    \n    return int(np.ceil(n))\n\n# -----------------------------------------------------------------------------\n# Example Usage\n# -----------------------------------------------------------------------------\n\n# Generate sample data\nnp.random.seed(42)\nsample_data = np.random.normal(105, 15, 25)\n\n# Perform one-sample t-test\nresults = one_sample_ttest(sample_data, null_value=100, alternative='greater')\n\nprint(\"One-Sample t-test Results:\")\nprint(f\"Test statistic: {results['test_statistic']:.3f}\")\nprint(f\"P-value: {results['p_value']:.4f}\")\nprint(f\"Effect size (d): {results['effect_size']:.3f}\")\nprint(f\"95% CI: ({results['confidence_interval'][0]:.2f}, {results['confidence_interval'][1]:.2f})\")\nprint(f\"Reject null: {results['reject_null']}\")\n\n# Power analysis\nrequired_n = power_analysis(effect_size=0.5, power=0.8)\nprint(f\"\\nRequired sample size for d=0.5, power=0.8: {required_n}\")\n\n\n\n\n\n\n\n\n\nHypothesis testing provides a framework for making decisions under uncertainty\nP-values quantify how surprising our data would be if H₀ were true\nStatistical significance ≠ practical importance - always consider effect size\nType I and II errors represent different kinds of mistakes with different costs\nPower is the ability to detect true effects when they exist\n\n\n\n\n\n\nPlan before you analyze - specify hypotheses and α level in advance\nCheck assumptions and use appropriate tests\nReport effect sizes and confidence intervals, not just p-values\nConsider practical significance alongside statistical significance\nBe honest about limitations and acknowledge uncertainty\n\n\n\n\n\n\n\n\nOpenIntro Statistics, Ch. 7 – “Inference for Numerical Data” (Sections 7.1–7.5)\nKhan Academy - Hypothesis Testing\nSciPy Documentation - scipy.stats.ttest_1samp\nstatsmodels - Statistical Power & Sample‑Size Tools"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#quick-announcements",
    "href": "files/lecture_notes/lecture13/lecture13.html#quick-announcements",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "📢 Quick Announcements",
    "text": "📢 Quick Announcements\n\n\n📝 Quiz 2 Reminder\nWhen:\n- 📅 Date: Friday, July 25\n- ⏰ Window: 7 AM – 12 AM\n- ⏳ Duration: 1 hour once started\nWhere: 💻 Online via Canvas\n\n📚 Today’s Focus\n\nFoundation: Logic of hypothesis testing\nPractice: Real examples with Python\nSkills: Making statistical decisions\nApplications: From medicine to marketing"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#learning-journey-today",
    "href": "files/lecture_notes/lecture13/lecture13.html#learning-journey-today",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Learning Journey Today 🎯",
    "text": "Learning Journey Today 🎯\n\n\n🧠 Conceptual Goals\n\nUnderstand the logic of hypothesis testing\nGet familiar with the language of statistical decisions\nRecognize different types of errors and their consequences\nConnect to confidence intervals from last lecture\n\n\n🛠️ Practical Skills\n\nFormulate hypotheses from research questions\nCalculate and interpret p-values correctly\nPerform hypothesis tests in Python\nMake informed decisions using statistical evidence\nCommunicate results effectively"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#what-is-hypothesis-testing",
    "href": "files/lecture_notes/lecture13/lecture13.html#what-is-hypothesis-testing",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "What is Hypothesis Testing?",
    "text": "What is Hypothesis Testing?\n\n\n\n\n\n\n\n\nWhat is Hypothesis Testing?\n\n\nHypothesis testing lets us use sample data to weigh competing claims about a population.\nWorkflow\n\nState H₀ (null) – the status‑quo or “no‑effect” position\n\nState H₁ (alternative) – the research claim you hope to support\n\nChoose α – the tolerable Type I error rate (e.g., 0.05)\n\nCompute a test statistic – compress the data into one number\n\nFind the p‑value – “How unusual is this statistic if H₀ were true?”\n\nMake a decision – reject H₀ if p ≤ α; otherwise fail to reject\n\nThe goal is not to prove anything with certainty, but to judge whether the evidence tips the scale away from H₀.\n\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nHypothesis testing helps us answer: “Is what we observed in our sample strong enough evidence to conclude something about the population?”"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#the-courtroom-analogy",
    "href": "files/lecture_notes/lecture13/lecture13.html#the-courtroom-analogy",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "The Courtroom Analogy ⚖️",
    "text": "The Courtroom Analogy ⚖️\n\n\nCriminal Justice System\n\n\n\nAspect\nCriminal Court\n\n\n\n\nStarting Position\nDefendant is innocent\n\n\nBurden of Proof\nProsecution must prove guilt\n\n\nEvidence Standard\nBeyond reasonable doubt\n\n\nDecision Options\nGuilty or Not Guilty\n\n\nType I Error\nConvict an innocent person\n\n\nType II Error\nAcquit a guilty person\n\n\nConsequences\nBalance justice vs. protecting innocent\n\n\n\n\nStatistical Hypothesis Testing\n\n\n\nAspect\nHypothesis Testing\n\n\n\n\nStarting Position\nNull hypothesis (H₀) is true\n\n\nBurden of Proof\nData must support alternative (H₁)\n\n\nEvidence Standard\np ≤ α (usually 0.05)\n\n\nDecision Options\nReject H₀ or Fail to reject H₀\n\n\nType I Error\nReject a true null (false positive)\n\n\nType II Error\nFail to reject a false null (false negative)\n\n\nConsequences\nBalance discovery vs. false claims\n\n\n\n\n\nKey Insight 💡 Just like in court, we never “prove” innocence or accept the null hypothesis—we only decide whether the evidence is strong enough to reject it."
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#what-is-a-p-value",
    "href": "files/lecture_notes/lecture13/lecture13.html#what-is-a-p-value",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "What is a p-value?",
    "text": "What is a p-value?\n\n\n\n\n\n\nWhat is a p-value?\n\n\nThe p-value answers the question\n“If the null hypothesis were true, how likely is a result at least this extreme?”\nFormally, for an observed test statistic T_{\\text{obs}},\n\n  p = P\\bigl(|T| \\ge |T_{\\text{obs}}| \\;\\big|\\; H_0\\bigr).\n\nSmaller p-values → data less compatible with H_0 → stronger evidence against H_0.\n\n\n\n\n\nInterpretation Cheat-Sheet\n\n\n\np-value\nEvidence vs H_0\n\n\n\n\np &gt; 0.10\nLittle / none\n\n\n0.05 &lt; p \\le 0.10\nWeak\n\n\n0.01 &lt; p \\le 0.05\nModerate\n\n\np \\le 0.01\nStrong\n\n\n\n(Guidelines, not iron-clad laws.)\n\nCommon Pitfalls\n\np is not the probability that (H_0) is true\n\np is not the probability the result occurred “by chance”\n\nA non-significant p does not prove H_0\n\nStatistical significance ≠ practical importance\n\n\n\nExample: In our treatment test, t = 2.5 gave p = 0.006.\nIf H_0 were true, such an extreme outcome would occur only 0.6 % of the time,compelling evidence favoring the new treatment."
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#types-of-errors-the-trade-off",
    "href": "files/lecture_notes/lecture13/lecture13.html#types-of-errors-the-trade-off",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Types of Errors: The Trade-off 🎲",
    "text": "Types of Errors: The Trade-off 🎲\n\n\nError Types Matrix\n\n\n\nDecision ↓ / Reality →\nH₀ True\nH₀ False\n\n\n\n\nReject H₀\nType I Error (α)\n✔ Correct (Power)\n\n\nFail to Reject H₀\n✔ Correct\nType II Error (β)\n\n\n\n\nReal‑World Consequences\n\n\n\n\n\n\n\n\nContext\nType I Error (False Positive)\nType II Error (False Negative)\n\n\n\n\nMedical Test\nTreat healthy patient\nMiss actual disease\n\n\nDrug Approval\nApprove ineffective drug\nReject effective drug\n\n\nFire Alarm\nFalse alarm evacuation\nFail to detect real fire\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nBalancing the risks\nLowering the significance level \\alpha reduces the chance of Type I mistakes but increases the risk of Type II errors unless you gather more data or target a larger effect.\nChoose $$ based on which error would be more costly in your scenario."
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#statistical-power-detecting-true-effects",
    "href": "files/lecture_notes/lecture13/lecture13.html#statistical-power-detecting-true-effects",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Statistical Power: Detecting True Effects 💪",
    "text": "Statistical Power: Detecting True Effects 💪\n\n\n                            \n                                            \n\n\nKey Insight: Higher power means you’re more likely to detect a true effect when it exists. Aim for power ≥ 0.80!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#example-1-one-sample-t-test",
    "href": "files/lecture_notes/lecture13/lecture13.html#example-1-one-sample-t-test",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Example 1: One-Sample t-test 📊",
    "text": "Example 1: One-Sample t-test 📊\n\n\nProblem Setup\nResearch Question: A new study technique claims to improve test scores. The current average is 75. We test 25 students using the new method.\n\n\n📊 Sample Data Summary:\n========================================\nSample size (n): 25\nSample mean (x̄): 77.19\nSample std (s): 7.65\nCurrent average (μ₀): 75\n\n\n\nComplete Hypothesis Test\n\n\n                            \n                                            \n\n\n\n🎯 DETAILED RESULTS:\n==================================================\nTest Statistic: t = 1.432\nP-value: 0.0825\nCritical Value: 1.711\nEffect Size (Cohen's d): 0.286\n\n❌ DECISION: Fail to reject H₀\n📊 CONCLUSION: There is insufficient evidence (p = 0.0825) that the new study method improves test scores.\n💡 PRACTICAL IMPACT: The observed difference could reasonably be due to chance.\n\n\nUsing Python’s Built-in Functions\n\n\n🐍 PYTHON IMPLEMENTATION:\n========================================\nMethod 1: scipy.stats.ttest_1samp\nt-statistic: 1.432\np-value (two-tailed): 0.1650\np-value (one-tailed): 0.0825\n\nMethod 2: Manual with 95% Confidence Interval\n95% CI: (74.03, 80.35)\nInterpretation: We're 95% confident the true mean is between 74.0 and 80.4\n\nEffect Size (Cohen's d): 0.286\nEffect size interpretation: small effect"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#example-2-two-sample-t-test",
    "href": "files/lecture_notes/lecture13/lecture13.html#example-2-two-sample-t-test",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Example 2: Two-Sample t-test 📊",
    "text": "Example 2: Two-Sample t-test 📊\nProblem Setup\nResearch Question: Compare effectiveness of two teaching methods\n\n\n📊 TWO-GROUP COMPARISON:\n========================================\nMethod A (Traditional):\n  n = 30, mean = 75.45, std = 11.87\n\nMethod B (New):\n  n = 28, mean = 82.72, std = 14.82\n\nDifference in means: 7.27 points"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#statistical-vs-practical-significance",
    "href": "files/lecture_notes/lecture13/lecture13.html#statistical-vs-practical-significance",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Statistical vs Practical Significance 🤔",
    "text": "Statistical vs Practical Significance 🤔\n\n\n                            \n                                            \n\n\n🔑 KEY LESSON: Statistical Significance ≠ Practical Importance\n============================================================\nLeft: Tiny effect (0.02) but significant due to large sample\nRight: Large effect (8.7) but significant with small sample\n\n💡 Always consider BOTH statistical significance AND effect size!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#python-code-templates",
    "href": "files/lecture_notes/lecture13/lecture13.html#python-code-templates",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Python Code Templates 💻",
    "text": "Python Code Templates 💻\n\n# =============================================================================\n# COMPLETE HYPOTHESIS TESTING TOOLKIT\n# =============================================================================\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# -----------------------------------------------------------------------------\n# Template 1: One-Sample t-test\n# -----------------------------------------------------------------------------\ndef one_sample_ttest(data, null_value, alpha=0.05, alternative='two-sided'):\n    \"\"\"\n    Perform one-sample t-test with complete analysis\n    \n    Parameters:\n    -----------\n    data : array-like\n        Sample data\n    null_value : float\n        Hypothesized population mean\n    alpha : float\n        Significance level (default 0.05)\n    alternative : str\n        'two-sided', 'greater', or 'less'\n    \"\"\"\n    \n    # Calculate statistics\n    n = len(data)\n    x_bar = np.mean(data)\n    s = np.std(data, ddof=1)\n    se = s / np.sqrt(n)\n    \n    # Test statistic\n    t_stat = (x_bar - null_value) / se\n    df = n - 1\n    \n    # P-value calculation\n    if alternative == 'two-sided':\n        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    elif alternative == 'greater':\n        p_value = 1 - stats.t.cdf(t_stat, df)\n    elif alternative == 'less':\n        p_value = stats.t.cdf(t_stat, df)\n    \n    # Effect size (Cohen's d)\n    cohens_d = (x_bar - null_value) / s\n    \n    # Confidence interval\n    t_crit = stats.t.ppf(1 - alpha/2, df)\n    ci_lower = x_bar - t_crit * se\n    ci_upper = x_bar + t_crit * se\n    \n    # Results\n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'confidence_interval': (ci_lower, ci_upper),\n        'reject_null': p_value &lt;= alpha,\n        'sample_mean': x_bar,\n        'sample_std': s,\n        'sample_size': n\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 2: Two-Sample t-test\n# -----------------------------------------------------------------------------\ndef two_sample_ttest(group1, group2, alpha=0.05, equal_var=True):\n    \"\"\"\n    Perform two-sample t-test with complete analysis\n    \"\"\"\n    \n    # Calculate statistics\n    n1, n2 = len(group1), len(group2)\n    mean1, mean2 = np.mean(group1), np.mean(group2)\n    s1, s2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n    \n    if equal_var:\n        # Pooled variance\n        pooled_var = ((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2)\n        se = np.sqrt(pooled_var * (1/n1 + 1/n2))\n        df = n1 + n2 - 2\n    else:\n        # Welch's t-test\n        se = np.sqrt(s1**2/n1 + s2**2/n2)\n        df = (s1**2/n1 + s2**2/n2)**2 / ((s1**2/n1)**2/(n1-1) + (s2**2/n2)**2/(n2-1))\n    \n    # Test statistic\n    t_stat = (mean1 - mean2) / se\n    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    \n    # Effect size (Cohen's d)\n    if equal_var:\n        pooled_std = np.sqrt(pooled_var)\n    else:\n        pooled_std = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2))\n    \n    cohens_d = (mean1 - mean2) / pooled_std\n    \n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'reject_null': p_value &lt;= alpha,\n        'group1_stats': {'mean': mean1, 'std': s1, 'n': n1},\n        'group2_stats': {'mean': mean2, 'std': s2, 'n': n2}\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 3: Power Analysis\n# -----------------------------------------------------------------------------\ndef power_analysis(effect_size, alpha=0.05, power=0.8):\n    \"\"\"\n    Calculate required sample size for desired power\n    \"\"\"\n    from scipy.stats import norm\n    \n    z_alpha = norm.ppf(1 - alpha/2)\n    z_beta = norm.ppf(power)\n    \n    n = ((z_alpha + z_beta) / effect_size) ** 2\n    \n    return int(np.ceil(n))\n\n# -----------------------------------------------------------------------------\n# Example Usage\n# -----------------------------------------------------------------------------\n\n# Generate sample data\nnp.random.seed(42)\nsample_data = np.random.normal(105, 15, 25)\n\n# Perform one-sample t-test\nresults = one_sample_ttest(sample_data, null_value=100, alternative='greater')\n\nprint(\"One-Sample t-test Results:\")\nprint(f\"Test statistic: {results['test_statistic']:.3f}\")\nprint(f\"P-value: {results['p_value']:.4f}\")\nprint(f\"Effect size (d): {results['effect_size']:.3f}\")\nprint(f\"95% CI: ({results['confidence_interval'][0]:.2f}, {results['confidence_interval'][1]:.2f})\")\nprint(f\"Reject null: {results['reject_null']}\")\n\n# Power analysis\nrequired_n = power_analysis(effect_size=0.5, power=0.8)\nprint(f\"\\nRequired sample size for d=0.5, power=0.8: {required_n}\")"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#summary-key-takeaways",
    "href": "files/lecture_notes/lecture13/lecture13.html#summary-key-takeaways",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Summary: Key Takeaways 🎯",
    "text": "Summary: Key Takeaways 🎯\n\n\n🧠 Core Concepts\n\nHypothesis testing provides a framework for making decisions under uncertainty\nP-values quantify how surprising our data would be if H₀ were true\nStatistical significance ≠ practical importance - always consider effect size\nType I and II errors represent different kinds of mistakes with different costs\nPower is the ability to detect true effects when they exist\n\n\n🛠️ Practical Skills\n\nPlan before you analyze - specify hypotheses and α level in advance\nCheck assumptions and use appropriate tests\nReport effect sizes and confidence intervals, not just p-values\nConsider practical significance alongside statistical significance\nBe honest about limitations and acknowledge uncertainty"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#resources",
    "href": "files/lecture_notes/lecture13/lecture13.html#resources",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Resources",
    "text": "Resources\n\nOpenIntro Statistics, Ch. 7 – “Inference for Numerical Data” (Sections 7.1–7.5)\nKhan Academy - Hypothesis Testing\nSciPy Documentation - scipy.stats.ttest_1samp\nstatsmodels - Statistical Power & Sample‑Size Tools"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Download the full syllabus as a PDF\n\n\n\n\n\n📚 Overview\n\n\n👥 Logistics\n\n\n📊 Assessment\n\n\n🛡️ Policies\n\n\n🤝 Resources\n\n\n📅 Important Dates\n\n\n\n\n\n\nAll Info\n\n\nCourse Info\n\n\nDescription\n\n\nMaterials\n\n\n\n\n\n📚\n\n\nCourse Information\n\n\n\n\n\nLecture Time\n\n\nM/W/T/R 8:00 AM–9:30 AM\n\n\n\n\nLecture Hall\n\n\nHSSB 1173\n\n\n\n\nSections\n\n\nAs scheduled on GOLD (see Canvas for Zoom links)\n\n\n\n\nEmail\n\n\nnmathlouthi@ucsb.edu\n\n\n\n\nOffice\n\n\nEllison Hall 5829\n\n\n\n\nOffice Hours\n\n\nThursdays 11:00 AM–12:00 PM (via Zoom or by appointment)\n\n\n\n\n\nNote: Zoom links are posted on the Canvas page for the class.\n\n\n\n\n\n\n🎯\n\n\nCourse Description\n\n\nThis introductory course covers the foundations of statistical thinking, including data description, probability, and inference. Students will learn how to summarize data, compute basic probabilities, and make informed decisions using statistical tools.\n\nStudent Learning Objectives\nBy the end of this course, you will be able to:\n\nSummarize data using descriptive statistics\nUnderstand fundamental probability rules and distributions\nConduct basic inferential procedures (confidence intervals, hypothesis tests)\nInterpret results and communicate findings\n\n\n\n\n\n\n📖\n\n\nCourse Materials\n\n\n\n\n\nCanvas\n\n\nAnnouncements, Zoom links, and grades (canvas.ucsb.edu)\n\n\n\n\nCalculator\n\n\nScientific calculator for in-class and quiz work\n\n\n\n\nComputer\n\n\nUse our JupyterHub instance\n\n\n\n\nRecommended Texts\n\n\nOpenIntro Statistics (free online)\nThink Stats by Allen Downey (free online)\n\n\n\n\n\n\n\n📅\n\n\nClass Schedule\n\n\n\n\nNote: For the most up-to-date details, please visit the Class Schedule tab on our website: Class Schedule\n\n\n\n\n\n\n\n\nAll Staff\n\n\nInstructor\n\n\nTeaching Assistants\n\n\nSuccess Tips\n\n\n\n\n\n👩‍🏫\n\n\nInstructor Information\n\n\n\n\n\nNM\n\n\nNarjes Mathlouthi\n\n\nnmathlouthi@ucsb.edu\n\n\nOffice: Ellison Hall 5829\n\n\nOffice Hours: Thursdays 11:00 AM–12:00 PM\n\n\n\n\n\n\n\n👥\n\n\nTeaching Assistants\n\n\n\n\n\nSL\n\n\nSummer Le\n\n\nsle@ucsb.edu\n\n\n\n\nMH\n\n\nMingzhu He\n\n\nmingzhuhe@ucsb.edu\n\n\n\n\n\nEmail policy: Include [PSTAT 5A] in your subject. Allow 24–48 hours for a reply (avoid weekends).\n\n\n\n\n\n\n🎯\n\n\nHow to Succeed\n\n\n\nAttend lectures & sections\nEngage actively & ask questions\nUse office hours for help\n\n\nClassroom Expectations\nRespect peers & TAs. Stay engaged. Seek support if needed.\n\n\nCommunication Guidelines\n\nUse UCSB email with clear subject\nAllow 24–48 h for replies\nUse office hours or appointments\n\n\n\n\n\n\n\n\nAll Assessment Info\n\n\nGrade Breakdown\n\n\nQuiz Details\n\n\n\n\n\n📊\n\n\nGrading\n\n\n\n\nGrade Breakdown:\n\n\n\nLecture attendance: 5%\nSection attendance: 5%\nQuiz 1: 30%\nQuiz 2: 30%\nQuiz 3: 30%\n\n\n\nGrading Scale:\n\n\n\n\nA Grades\nB Grades\nC Grades\nD/F Grades\n\n\n\n\nA+: 97–100\nB+: 87–89\nC+: 77–79\nD+: 67–69\n\n\nA: 93–96\nB: 83–86\nC: 73–76\nD: 60–66\n\n\nA–: 90–92\nB–: 80–82\nC–: 70–72\nF: &lt; 60\n\n\n\n\n\n\nGrades round to the nearest whole number (e.g., 89.7 → 90).\n\n\n\n\n\n\n📝\n\n\nQuizzes\n\n\n\n\n\n1\n\n\n\nQuiz 1: Weeks 1–2\n\n\nJuly 11th\n\n\nCovers introduction, descriptive statistics and Intro to Probability\n\n\n\n\n\n2\n\n\n\nQuiz 2: Weeks 3–4\n\n\nJuly 25th\n\n\nCovers Conditional Probability, Counting & Random Variables (Discrete & Continuous)\n\n\n\n\n\n3\n\n\n\nQuiz 3: Weeks 5–6\n\n\nJuly 31st\n\n\nCovers Confidence Intervals & Hypothesis testing\n\n\n\n\n\n\nFormat: Multiple choice & short answer (open book)\nPlatform: Canvas or Gradescope\nAvailability: Fridays 7 AM–12 AM (1‑hour limit)\nMake‑up policy: Notify within 48 h; documentation required.\n\n\n\n\n\n\n\n\nAll Policies\n\n\nAcademic Integrity\n\n\nAttendance\n\n\n\n\n\n🛡️\n\n\nAcademic Integrity\n\n\nDo your own work. Cite sources properly. See:\n\nAcademic Integrity Policy\nStudent Conduct Code\n\n\n\nImportant: Violations of academic integrity will result in course failure and reporting to the Office of Student Conduct.\n\n\n\n\n\n\n📋\n\n\nAttendance Policy\n\n\n\n\n\nLecture Attendance\n\n\nWorth 5% of final grade. Regular attendance expected for success.\n\n\n\n\nSection Attendance\n\n\nWorth 5% of final grade. Participation in discussion sections is required.\n\n\n\n\nMake-up Policy\n\n\nContact instructor within 48 hours for excused absences with documentation.\n\n\n\n\n\n\n\n\n\nAll Resources\n\n\nAcademic Support\n\n\nHealth & Wellness\n\n\nBasic Needs\n\n\n\n\n\n🤝\n\n\nStudent Resources\n\n\n\n\n🦽 DSP & Accommodations Disability services and accommodations\n\n\n📚 CLAS Campus Learning Assistance Services\n\n\n🎓 EOP Educational Opportunity Program\n\n\n🔄 Transfer Center Transfer student support\n\n\n🏥 Student Health Health and wellness services\n\n\n💚 CAPS Counseling & Psychological Services\n\n\n🍎 Basic Needs Food security and basic needs support\n\n\n👥 ONDAS First-Generation Support\n\n\n📋 Undocumented Services Support for undocumented students\n\n\n\n\n\n\n\n\nAll Dates\n\n\nRegistration\n\n\nDeadlines\n\n\n\n\n\n📅\n\n\nImportant Dates\n\n\n\n\n\nAdd w/o Code\n\n\nJune 29\n\n\n\n\nDrop w/ Refund\n\n\nJune 29\n\n\n\n\nAdd w/ Code\n\n\nJuly 3\n\n\n\n\nDrop Course\n\n\nJuly 9\n\n\n\n\nChange Grade Option\n\n\nAugust 1\n\n\n\n\n\nNote: All dates are based on the UCSB Academic Calendar. Please verify important dates on your GOLD account."
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#the-six-steps-of-hypothesis-testing",
    "href": "files/lecture_notes/lecture13/lecture13.html#the-six-steps-of-hypothesis-testing",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "The Six Steps of Hypothesis Testing 📋",
    "text": "The Six Steps of Hypothesis Testing 📋"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#types-of-alternative-hypotheses",
    "href": "files/lecture_notes/lecture13/lecture13.html#types-of-alternative-hypotheses",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Types of Alternative Hypotheses 🎯",
    "text": "Types of Alternative Hypotheses 🎯"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#best-practices-summary",
    "href": "files/lecture_notes/lecture13/lecture13.html#best-practices-summary",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "Best Practices Summary 📋",
    "text": "Best Practices Summary 📋"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#important-announcements",
    "href": "files/lecture_notes/lecture11/lecture11.html#important-announcements",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "📢 Important Announcements",
    "text": "📢 Important Announcements\n\n\n📝 Quiz 2 Details\nWhen:\n- 📅 Date: Friday, July 25\n- ⏰ Window: 7 AM – 12 AM\n- ⏳ Duration: 1 hour once started\nWhere: 💻 Online via Canvas\nCovers: Material from Weeks 3-4\n\n📚 What to Expect\n\nDiscrete & continuous distributions\nProbability calculations\nExpected value & variance\nNormal distribution applications\nNote: Upload photos of written work for calculation problems"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#what-well-learn-today",
    "href": "files/lecture_notes/lecture11/lecture11.html#what-well-learn-today",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "What We’ll Learn Today 🎯",
    "text": "What We’ll Learn Today 🎯\n\n\nBig Ideas:\n\nHow sample means behave (they’re surprisingly predictable!)\nWhy we use intervals instead of single numbers\nHow confident we can be in our estimates\nPlanning studies for the right precision\n\n\nSkills You’ll Gain:\n\nBuild confidence intervals step-by-step\nInterpret what confidence really means\nChoose appropriate sample sizes\nAvoid common mistakes in interpretation"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#from-observation-experimentation-why-design-matters",
    "href": "files/lecture_notes/lecture11/lecture11.html#from-observation-experimentation-why-design-matters",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "From Observation ➡️ Experimentation: Why Design Matters",
    "text": "From Observation ➡️ Experimentation: Why Design Matters\n\nObservational Study: Passively record what already happens — good for spotting patterns, but hidden confounders can fool us.\nControlled Experiment: Actively assign treatments; randomization balances the lurking variables so we can talk about cause.\nRandomization & Replication: Twin shields that protect us from bias and one‑off flukes.\nProbability Framework: Sample space, events, and probabilities let us quantify uncertainty."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#the-big-picture-from-sample-to-population",
    "href": "files/lecture_notes/lecture11/lecture11.html#the-big-picture-from-sample-to-population",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "The Big Picture: From Sample to Population",
    "text": "The Big Picture: From Sample to Population\n\n\nThink of this like trying to understand a huge library by reading just a few books\n\n\n                            \n                                            \n\n\n\nKey Terms Made Simple:\n\nPopulation (\\mu): Everyone we care about (like all students at UCSB)\nSample (\\bar x): The people we actually measured (like 100 students we surveyed)\nParameter: The true answer we want (population mean)\nStatistic: Our best guess (sample mean)"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#why-point-estimates-arent-enough",
    "href": "files/lecture_notes/lecture11/lecture11.html#why-point-estimates-arent-enough",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Why Point Estimates Aren’t Enough",
    "text": "Why Point Estimates Aren’t Enough\n\n\nImagine asking: “What’s the average height of UCSB students?”\n\n\n                            \n                                            \n\n\n\nThe Problem: Each sample gives a slightly different answer!\n\nThe Solution: Use confidence intervals to show the range of reasonable values."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#sampling-distributions",
    "href": "files/lecture_notes/lecture11/lecture11.html#sampling-distributions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\n\n\nThink of sampling distributions like “What if we repeated our study 1000 times?”\n\n\n                            \n                                            \n\n\n\nKey Insights:\n\nPopulation can be any shape (skewed, normal, weird)\nOne sample might not look like the population\nSample means vary from sample to sample\nMany sample means form a beautiful normal distribution!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#the-central-limit-theorem-clt",
    "href": "files/lecture_notes/lecture11/lecture11.html#the-central-limit-theorem-clt",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "The Central Limit Theorem (CLT) 🎯",
    "text": "The Central Limit Theorem (CLT) 🎯\n\n\n\n\n                            \n                                            \nCentral Limit Theorem: Larger Samples → More Normal!\n\n\n\nThe Magic Rule: No matter what shape your population is, sample means will be approximately normal!\nThe Rule of Thumb: With n ≥ 30, sample means will be approximately normal, regardless of population shape!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#standard-error",
    "href": "files/lecture_notes/lecture11/lecture11.html#standard-error",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Standard Error",
    "text": "Standard Error\n\n\nWhat it measures\n\nStandard deviation (\\sigma or s): spread of individual data points\n\nStandard error (SE): spread of sample means\n\n\nSE = \\frac{\\sigma}{\\sqrt{n}}\n\\qquad(\\text{if } \\sigma \\text{ is known})\n\n\nSE = \\frac{s}{\\sqrt{n}}\n\\qquad(\\text{usual case, } \\sigma \\text{ unknown})\n\nKey facts\n\nSE shrinks at rate 1/\\sqrt{n} — every 4× more observations ⇒ ½ the SE\n\nSmaller SE ⇒ narrower confidence intervals and more powerful tests\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nImportant\n\n\nDoubling your sample size doesn’t halve the error - you need 4 times the sample for half the error!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-the-intuitive-idea",
    "href": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-the-intuitive-idea",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals: The Intuitive Idea",
    "text": "Confidence Intervals: The Intuitive Idea\n\n\nImagine you’re trying to guess someone’s height just by looking at their shadow…\n\n\n                            \n                                            \n\n\n\nSimple Interpretation: “We’re 95\\\\% confident the true average height is between 64.3 and 70.1 inches.”"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#what-exactly-is-a-confidence-interval",
    "href": "files/lecture_notes/lecture11/lecture11.html#what-exactly-is-a-confidence-interval",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "What Exactly Is a Confidence Interval? 🤓",
    "text": "What Exactly Is a Confidence Interval? 🤓\n\n\n\nA confidence interval (CI) is point estimate \\pm margin of error\n\n  \\text{CI} = \\text{statistic} \\;\\pm\\; \\bigl(\\text{critical value}\\bigr)\\times\\bigl(\\text{SE}\\bigr)\n\nThe “critical value” comes from a probability model (e.g., z^{\\star} or t^{\\star}).\nThe standard error (SE) captures sampling variation.\n\nFrequentist meaning\n\nIf we repeated the study infinitely many times and built a 95 \\% CI each time, about 95 \\% of those intervals would cover the true parameter.\n\n(For any one computed interval the parameter is fixed, the process has a 95 \\% success rate, not the individual interval.)\n\n\n\n\n\n\n\n\nWhat controls the width?\n\n\n\nVariability in the data: larger \\sigma or s ⇒ wider CI\nSample size n: width shrinks at rate 1/\\sqrt{n}\nConfidence level: 99 % CIs are wider than 90 % CIs\n\n\n\n\n\n\n\n\n\n\nCommon pitfalls\n\n\n\nSaying “there is a 95 \\% probability that \\mu lies in this interval” (wrong)\nInterpreting the CI as covering 95 \\% of future observations (it does not)\nIgnoring conditions (normality or CLT) before using the formulae"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#building-confidence-intervals-step-by-step",
    "href": "files/lecture_notes/lecture11/lecture11.html#building-confidence-intervals-step-by-step",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Building Confidence Intervals Step-by-Step",
    "text": "Building Confidence Intervals Step-by-Step\n\n\nFor Population Means (Most Common Case)\nWhen we DON’T know the population standard deviation (\\sigma):\n\n\n                            \n                                            \n\n\n\nThe Formula: \\bar{x} \\pm t^* \\cdot \\frac{s}{\\sqrt{n}}\nBreaking it down:\n\n\\bar{x} = our sample average (the center of our guess)\nt^* = critical value (how many standard errors to go out)\n\\frac{s}{\\sqrt{n}} = standard error (our uncertainty measure)"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#the-t-distribution-when-sigma-is-unknown",
    "href": "files/lecture_notes/lecture11/lecture11.html#the-t-distribution-when-sigma-is-unknown",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "The t-Distribution: When \\sigma is Unknown",
    "text": "The t-Distribution: When \\sigma is Unknown\n\n\nWhy not use the normal distribution? Because when we estimate \\sigma with s, we add extra uncertainty!\n\n\n                            \n                                            \n\n\n\nKey Points:\n\nSmall samples (n &lt; 30): Use t-distribution\nLarge samples (n ≥ 30): t ≈ normal\nDegrees of freedom (df)= n - 1"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-for-proportions",
    "href": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-for-proportions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals for Proportions",
    "text": "Confidence Intervals for Proportions\n\n\nFor Yes/No questions like: “What percentage of students prefer online classes?”\n\n\n                            \n                                            \n\n\n\nThe Formula: \\hat{p} \\pm z^* \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\nResults: Sample: 60% prefer online (120/200)\n95% CI: (53.2%, 66.8%) - We’re 95% confident the true percentage is in this range."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#what-does-95-confident-really-mean",
    "href": "files/lecture_notes/lecture11/lecture11.html#what-does-95-confident-really-mean",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "What Does “95% Confident” Really Mean? 🤔",
    "text": "What Does “95% Confident” Really Mean? 🤔\n\n\nThe Biggest Misconception: “There’s a 95% chance the true mean is in our interval”\nActually: “If we repeated this study 100 times, about 95 of our intervals would contain the true mean”\n\n\n                            \n                                            \n\n\n\nRemember: The interval either contains the true value or it doesn’t - there’s no probability involved for a single interval!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#sample-size-planning-getting-the-precision-you-want",
    "href": "files/lecture_notes/lecture11/lecture11.html#sample-size-planning-getting-the-precision-you-want",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Sample Size Planning: Getting the Precision You Want",
    "text": "Sample Size Planning: Getting the Precision You Want\n\n\nThe Question: “How many people do we need to survey?”\n\n\n                            \n                                            \n\n\n\nKey Formula for Means: n = \\left(\\frac{z^* \\sigma}{ME}\\right)^2\nTrade-offs:\n\nWant smaller margin of error? Need bigger sample\nWant higher confidence? Need bigger sample\nWant to save money? Accept wider intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#real-example-student-sleep-study",
    "href": "files/lecture_notes/lecture11/lecture11.html#real-example-student-sleep-study",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Real Example: Student Sleep Study 😴",
    "text": "Real Example: Student Sleep Study 😴\n\n\nResearch Question: How many hours do UCSB students sleep per night?\n\n\n                            \n                                            \n\n\n\nBottom Line: We’re 95% confident that UCSB students sleep between 6.73 and 7.47 hours per night on average."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/lecture11/lecture11.html#common-mistakes-to-avoid",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Common Mistakes to Avoid ⚠️",
    "text": "Common Mistakes to Avoid ⚠️\n\n\n❌ Wrong Interpretations\n“95% of students sleep in this range” - NO! This is about the population mean, not individual students\n“There’s a 95% chance μ is in our interval” - NO! \\mu is fixed; our interval varies\n“We can be 95% certain” - NO! Use “confident” not “certain”\n\n✅ Correct Approach\n“We are 95% confident the population mean is in this interval”\nKey Reminders:\n\nCheck conditions before using formulas\nUse t-distribution when \\sigma is unknown\nLarger samples give narrower intervals\nHigher confidence gives wider intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#problem-1-coffee-shop-revenue",
    "href": "files/lecture_notes/lecture11/lecture11.html#problem-1-coffee-shop-revenue",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Problem 1: Coffee Shop Revenue",
    "text": "Problem 1: Coffee Shop Revenue\nA coffee shop owner samples 36 days and finds average daily revenue of $850 with standard deviation $120.\nYour turn: Calculate a 90% confidence interval for the true average daily revenue.\n\n\nShow Solution\n\n\nGiven (from the prompt)\nn = 36,\\; \\bar{x} = \\$850,\\; s = \\$120,\\; \\text{confidence level} = 90\\%\n\nStep 1 – Conditions\n\nn \\ge 30 ⇒ a t‑interval is justified by the Central Limit Theorem.\n\nAssume daily revenues are independent.\n\nStep 2 – Critical value\n\\alpha = 1-0.90 = 0.10 \\;\\Rightarrow\\; \\alpha/2 = 0.05\nDegrees of freedom: df = n-1 = 35\n\\displaystyle t^{\\star}_{0.90,\\,35} \\approx 1.690\nStep 3 – Standard error\nSE = \\frac{s}{\\sqrt{n}}\n        = \\frac{120}{\\sqrt{36}}\n        = \\frac{120}{6}\n        = \\$20\nStep 4 – Margin of error\nME = t^{\\star}\\; SE\n       = 1.690 \\times \\$20\n       = \\$33.8\nStep 5 – Confidence interval\n\\bar{x} \\pm ME\n     = 850 \\pm 33.8\n     \\;\\Longrightarrow\\;\n     (\\$816.2,\\; \\$883.8)\nInterpretation – We are 90 % confident that the true mean daily revenue lies between $816.20 and $883.80."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#problem-2-student-survey",
    "href": "files/lecture_notes/lecture11/lecture11.html#problem-2-student-survey",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Problem 2: Student Survey",
    "text": "Problem 2: Student Survey\nIn a survey of 400 students, 280 say they would recommend their major to a friend.\nYour turn:\n\nCalculate the sample proportion\nBuild a 95\\% confidence interval\nCheck if conditions are met\n\n\n\nShow Solution\n\n\nGiven (from the survey)\nn = 400,\\; x = 280 “yes” responses\n\nStep 1 – Sample proportion\n\\hat{p} = \\frac{x}{n} = \\frac{280}{400} = 0.70\nStep 2 – Conditions for a z‑interval\nn\\hat{p} = 400(0.70)=280 \\ge 10\nn(1-\\hat{p}) = 400(0.30)=120 \\ge 10\nBoth counts ≥ 10, so the normal approximation is appropriate.\nStep 3 – Standard error\nSE = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n        = \\sqrt{\\frac{0.70(0.30)}{400}}\n        = \\sqrt{0.000525}\n        \\approx 0.0229\nStep 4 – Critical value & margin of error\nFor 95 % confidence, z^{\\star} = 1.96\nME = z^{\\star}\\; SE\n       = 1.96 \\times 0.0229\n       \\approx 0.045\nStep 5 – Confidence interval\n\\hat{p} \\pm ME\n     = 0.70 \\pm 0.045\n     \\;\\Longrightarrow\\;\n     (0.655,\\; 0.745)\nInterpretation – We are 95 % confident that between 65.5 % and 74.5 % of all students would recommend their major to a friend."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#looking-ahead-hypothesis-testing",
    "href": "files/lecture_notes/lecture11/lecture11.html#looking-ahead-hypothesis-testing",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Looking Ahead: Hypothesis Testing 🔮",
    "text": "Looking Ahead: Hypothesis Testing 🔮\n\n\nNext week we’ll learn:\n\nHow to test specific claims about populations\nWhen to reject or fail to reject hypotheses\nThe connection between confidence intervals and hypothesis tests"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#key-takeaways",
    "href": "files/lecture_notes/lecture11/lecture11.html#key-takeaways",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Key Takeaways 🎯",
    "text": "Key Takeaways 🎯\n\n\nBig Ideas:\n\nSamples vary - confidence intervals capture this uncertainty\nLarger samples give more precise estimates\nHigher confidence means wider intervals\nThe CLT makes normal-based inference possible\n\n\nPractical Skills:\n\nBuild CIs for means and proportions\nInterpret confidence correctly\nPlan sample sizes for desired precision\nAvoid common interpretation mistakes"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#comprehensive-resources",
    "href": "files/lecture_notes/lecture11/lecture11.html#comprehensive-resources",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Comprehensive Resources 📚",
    "text": "Comprehensive Resources 📚\n\n\n📖 Required Reading\n\nOpenIntro Statistics\n\nSection 1.3: Sampling principles and strategies\nSection 3.3: Confidence intervals for a mean\nSection 4.1: Central Limit Theorem\nSection 7.1.1 The distribution of \\bar x\nSection7.1.2 Evaluating the two conditions required for modeling \\bar x\nSection 7.1.3 Introducing the t-distribution\n\n\n🎥 Video Resources\n\nKhan Academy: Central Limit Theorem\nStatQuest: Confidence Intervals Explained\n3Blue1Brown: Central Limit Theorem Visualization\n\n\n💻 Interactive Tools\n\nSeeing Theory: Probability Visualizations\nRossman & Chance Applets: Sampling Distributions\nCentral Limit Theorem Simulator"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#questions",
    "href": "files/lecture_notes/lecture11/lecture11.html#questions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Questions? 🤔",
    "text": "Questions? 🤔\n\n\nOffice Hours: Thursday 11AM (link on Canvas)\nEmail: nmathlouthi@ucsb.edu\n“The goal is not to eliminate uncertainty, but to understand and work with it”\n\n\n\n\n🏠 Back to Main Page"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#important-announcements",
    "href": "files/lecture_notes/lecture10/lecture10.html#important-announcements",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "📢 Important Announcements",
    "text": "📢 Important Announcements\n\n\n📝 Quiz 2 Details\nWhen:\n- 📅 Date: Friday, July 25\n- ⏰ Window: 7 AM – 12 AM\n- ⏳ Duration: 1 hour once started\nWhere: 💻 Online via Canvas\nCovers: Material from Weeks 3-4\n\n📚 What to Expect\n\nDiscrete & continuous distributions\nProbability calculations\nExpected value & variance\nNormal distribution applications\nNote: Upload photos of written work for calculation problems"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#todays-learning-journey",
    "href": "files/lecture_notes/lecture10/lecture10.html#todays-learning-journey",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Today’s Learning Journey 🎯",
    "text": "Today’s Learning Journey 🎯\n\n\n🧠 Big Ideas We’ll Explore\n\nWhy sampling? The power and necessity of statistical inference\nSample behavior - How sample means form predictable patterns\nUncertainty quantification - From point estimates to intervals\nThe CLT magic - Why normal distributions appear everywhere\nConfidence intervals - Our bridge from samples to populations\n\n\n🛠️ Skills You’ll Master\n\nDesign effective sampling strategies\nCalculate and interpret standard errors\nApply the Central Limit Theorem\nConstruct and interpret confidence intervals\nChoose appropriate sample sizes for desired precision\nRecognize and avoid sampling bias"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#the-foundation-why-do-we-sample",
    "href": "files/lecture_notes/lecture10/lecture10.html#the-foundation-why-do-we-sample",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "The Foundation: Why Do We Sample? 🤔",
    "text": "The Foundation: Why Do We Sample? 🤔\n\n\n🌍 Real-World Constraints\nPopulation vs. Sample Realities:\n\nTime: Surveying 40,000 UCSB students takes months\nCost: Each measurement costs money and resources\nLogistics: Some populations are impossible to reach entirely\nFeasibility: Testing every light bulb would destroy the product\n\n💡 The Statistical Solution\nUse a representative sample to make valid inferences about the entire population"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#study-design-the-foundation-of-good-inference",
    "href": "files/lecture_notes/lecture10/lecture10.html#study-design-the-foundation-of-good-inference",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Study Design: The Foundation of Good Inference",
    "text": "Study Design: The Foundation of Good Inference\n\n\n                            \n                                            \n\n\n\n\n🔍 Observational Studies: - Observe what naturally occurs - Good for identifying associations - ⚠️ Cannot establish causation due to confounding\n\n🧪 Randomized Experiments: - Actively assign treatments randomly - Controls for confounding variables - ✅ Can establish causal relationships"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#types-of-sampling-methods",
    "href": "files/lecture_notes/lecture10/lecture10.html#types-of-sampling-methods",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Types of Sampling Methods 🎯",
    "text": "Types of Sampling Methods 🎯\n\n📋 Probability Sampling Methods\n\n1. Simple Random Sampling (SRS)\nEvery individual has equal chance of selection\nGold standard for inference\n2. Stratified Sampling\nDivide population into groups (strata)\nSample randomly within each group\nEnsures representation of subgroups\n\n3. Cluster Sampling\nDivide into clusters, randomly select clusters\nSample all/some individuals within chosen clusters\nCost-effective for large populations\n4. Systematic Sampling\nSelect every \\(kth\\) individual from ordered list\nSimple but can introduce bias if pattern exists"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#sampling-bias-what-can-go-wrong",
    "href": "files/lecture_notes/lecture10/lecture10.html#sampling-bias-what-can-go-wrong",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Sampling Bias: What Can Go Wrong? ⚠️",
    "text": "Sampling Bias: What Can Go Wrong? ⚠️\n\n\n🚨 Common Types of Bias\nSelection Bias - Systematic exclusion of certain groups - Example: Online surveys miss non-internet users\nResponse Bias\n- Who chooses to respond affects results - Example: Satisfaction surveys - unhappy customers more likely to respond\nNonresponse Bias - Missing data isn’t random - Example: Wealthy people less likely to disclose income\nConvenience Sampling - Sampling whoever is easiest to reach - Example: Surveying only students in your dorm\n\n\n\n                            \n                                            \n\n\n💡 Key Insight: Bias can’t be fixed by increasing sample size!"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#the-magic-of-sample-means-from-chaos-to-order",
    "href": "files/lecture_notes/lecture10/lecture10.html#the-magic-of-sample-means-from-chaos-to-order",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "The Magic of Sample Means: From Chaos to Order",
    "text": "The Magic of Sample Means: From Chaos to Order\n\n\n🎲 The Setup:\n\nTake many samples from the same population\nCalculate the mean of each sample\nPlot all these sample means\nObserve the magic!\n\n🎯 What We Discover:\n\nSample means cluster around the true population mean\nThey form a predictable pattern (normal distribution!)\nLarger samples give more consistent results"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#the-central-limit-theorem",
    "href": "files/lecture_notes/lecture10/lecture10.html#the-central-limit-theorem",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "The Central Limit Theorem 🌟",
    "text": "The Central Limit Theorem 🌟\n\n\n📐 The Statement\nFor a population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), when sample size \\(n\\) is large enough:\n\\[\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\]\nOr equivalently: \\[Z = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)\\]\n✨ The Magic Rules\n\nRule of Thumb: \\(n \\geq 30\\) usually works\nShape doesn’t matter: Works for ANY population distribution\n\nLarger \\(n\\) = Better approximation"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#standard-error-measuring-our-uncertainty",
    "href": "files/lecture_notes/lecture10/lecture10.html#standard-error-measuring-our-uncertainty",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Standard Error: Measuring Our Uncertainty 📏",
    "text": "Standard Error: Measuring Our Uncertainty 📏\n\n\n🎯 What is Standard Error?\nStandard Error (SE) measures how much sample means vary from sample to sample.\n\\[SE = \\frac{\\sigma}{\\sqrt{n}} \\text{ (when } \\sigma \\text{ is known)}\\]\n\\[SE = \\frac{s}{\\sqrt{n}} \\text{ (usual case, } \\sigma \\text{ unknown)}\\]\n🔍 Key Insights\n\nSmaller SE = More precise estimates\nSE decreases as sample size increases\nRate of decrease: \\(SE \\propto 1/\\sqrt{n}\\)\n4× larger sample = ½ the uncertainty!"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#confidence-intervals-our-bridge-to-the-population",
    "href": "files/lecture_notes/lecture10/lecture10.html#confidence-intervals-our-bridge-to-the-population",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Confidence Intervals: Our Bridge to the Population 🌉",
    "text": "Confidence Intervals: Our Bridge to the Population 🌉\n\n\n🎯 What Are Confidence Intervals?\nA confidence interval gives us a range of plausible values for the population parameter.\nFor a population mean: \\[\\bar{x} \\pm z^* \\cdot \\frac{s}{\\sqrt{n}}\\]\n🔢 Common Confidence Levels\n\n90% CI: \\(z^* = 1.645\\)\n95% CI: \\(z^* = 1.96\\)\n99% CI: \\(z^* = 2.576\\)\n\n💭 Correct Interpretation\n“We are 95% confident that the true population mean lies between [lower bound] and [upper bound]”"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#sample-size-planning-getting-it-right",
    "href": "files/lecture_notes/lecture10/lecture10.html#sample-size-planning-getting-it-right",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Sample Size Planning: Getting It Right 🎯",
    "text": "Sample Size Planning: Getting It Right 🎯\n\n\n📐 The Formula\nTo achieve margin of error \\(E\\) with confidence level \\((1-\\alpha)\\):\n\\[n = \\left(\\frac{z^*\\sigma}{E}\\right)^2\\]\n🎯 Key Considerations\nMargin of Error Trade-offs: - Smaller \\(E\\) requires larger \\(n\\) - Higher confidence requires larger \\(n\\)\n- More variable population requires larger \\(n\\)\nPractical Constraints: - Budget limitations - Time constraints\n- Availability of participants"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#putting-it-all-together-a-real-example",
    "href": "files/lecture_notes/lecture10/lecture10.html#putting-it-all-together-a-real-example",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Putting It All Together: A Real Example 📊",
    "text": "Putting It All Together: A Real Example 📊\n\n\n🎯 Research Question\n“What is the average height of UCSB students?”\nOur Approach:\n\nPopulation: All 26,000 UCSB students\nSample: Random sample of 100 students\nMeasurement: Height in inches\nGoal: 95% confidence interval for population mean\n\nResults:\n\nSample mean: \\(\\bar{x} = 68.2\\) inches\nSample std dev: \\(s = 4.1\\) inches\nSample size: \\(n = 100\\)\n\n\n\n\n                            \n                                            \n\n\n🎯 Interpretation: We are 95% confident that the true average height of UCSB students is between 67.40 and 69.00 inches."
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#key-takeaways-your-statistical-toolkit",
    "href": "files/lecture_notes/lecture10/lecture10.html#key-takeaways-your-statistical-toolkit",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Key Takeaways: Your Statistical Toolkit 🎯",
    "text": "Key Takeaways: Your Statistical Toolkit 🎯\n\n\n🧠 Fundamental Concepts\n1. Sampling Wisdom\n\nRepresentative samples beat large biased samples\nRandomization is your best friend\nBias can’t be fixed with larger samples\n\n2. The CLT Magic\n\nSample means are approximately normal (\\(n ≥ 30\\))\nWorks for ANY population distribution\nEnables powerful statistical inference\n\n3. Standard Error\n\nMeasures precision of our estimates\nDecreases with \\(\\sqrt{n}\\), not \\(n\\)\nKey ingredient in confidence intervals\n\n\n🛠️ Practical Skills\n4. Confidence Intervals\n\nQuantify uncertainty in our estimates\nCorrect interpretation is crucial\nWidth depends on confidence level and sample size\n\n5. Sample Size Planning\n\nBalance precision needs with resources\nConsider margin of error requirements\nAccount for practical constraints\n\n6. Quality Control\n\nAlways check for potential bias\nVerify assumptions (normality, independence)\nConsider the broader context"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#common-misconceptions-to-avoid",
    "href": "files/lecture_notes/lecture10/lecture10.html#common-misconceptions-to-avoid",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Common Misconceptions to Avoid ⚠️",
    "text": "Common Misconceptions to Avoid ⚠️"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#interactive-practice-test-your-understanding",
    "href": "files/lecture_notes/lecture10/lecture10.html#interactive-practice-test-your-understanding",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Interactive Practice: Test Your Understanding 🧪",
    "text": "Interactive Practice: Test Your Understanding 🧪\n\n\n🤔 Check Questions\n1. Sample Size Question: If we want to halve our margin of error, by what factor should we increase our sample size?\n2. CLT Application:\nA population has a right-skewed distribution. What can we say about the distribution of sample means when n = 50?\n3. CI Interpretation: We calculated a 95% CI as (45, 55). What does this mean?\n4. Bias Detection: An online survey about internet usage gets 10,000 responses. What type of bias might be present?\n\n✅ Answers\n1. Increase by factor of 4 (since \\(SE \\propto \\frac{1}{\\sqrt{n}}\\))\n2. Sample means will be approximately normal regardless of population shape\n3. We’re 95% confident the true population parameter is between 45 and 55\n4. Selection bias - excludes people without internet access"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#comprehensive-resources",
    "href": "files/lecture_notes/lecture10/lecture10.html#comprehensive-resources",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Comprehensive Resources 📚",
    "text": "Comprehensive Resources 📚\n\n\n📖 Required Reading\n\nOpenIntro Statistics\n\nSection 1.3: Sampling principles and strategies\nSection 3.3: Confidence intervals for a mean\nSection 4.1: Central Limit Theorem\n\n\n🎥 Video Resources\n\nKhan Academy: Central Limit Theorem\nStatQuest: Confidence Intervals Explained\n3Blue1Brown: Central Limit Theorem Visualization\n\n\n💻 Interactive Tools\n\nSeeing Theory: Probability Visualizations\nRossman & Chance Applets: Sampling Distributions\nCentral Limit Theorem Simulator\n\n🤝 Getting Help\n\nOffice Hours: Thursday 11 AM-12 PM (Zoom link on Canvas)\nEmail: nmathlouthi@ucsb.edu\n\n🎯 What’s Next?\nNext Lecture: Hypothesis Testing and p-values"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#questions-discussion",
    "href": "files/lecture_notes/lecture10/lecture10.html#questions-discussion",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Questions & Discussion 🤔",
    "text": "Questions & Discussion 🤔\n\n\n💭 Think About This…\n“The goal is not to eliminate uncertainty, but to understand and quantify it intelligently”\nKey Questions for Reflection:\n\nHow do we balance precision with practicality?\nWhen might a larger sample actually be worse?\nWhat makes a “good” confidence interval?\nHow do we communicate uncertainty to non-statisticians?\n\n\n🎯 Prepare for Next Class\nComing Up: Hypothesis Testing\n\nWhat are null and alternative hypotheses?\nHow do we make decisions with data?\nWhat does a p-value really mean?\n\nRecommended Prep:\n\nReview today’s confidence interval concepts\nThink about yes/no questions you’d test with data\nConsider what “statistical significance” means to you"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture9/lecture9.html#todays-learning-objectives",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Today’s Learning Objectives",
    "text": "Today’s Learning Objectives\nBy the end of this session, you will be able to:\n\nDefine what a random variable is\nDistinguish between different types of random variables\nIdentify examples of random variables in your field of study\nConnect probability concepts to real-world applications"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#what-is-a-random-variable",
    "href": "files/lecture_notes/lecture9/lecture9.html#what-is-a-random-variable",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "What is a Random Variable?",
    "text": "What is a Random Variable?\n\nA random variable (r.v.) is a function that assigns numerical values to the outcomes of a random experiment\nNotation: Usually denoted by capital letters (X, Y, Z)\nIt’s a bridge between the sample space and real numbers\nThink of it as a “rule” that translates outcomes into numbers\n\n\nKey Point: It’s not actually “random”, it’s a deterministic function applied to random outcomes!"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#real-world-connection",
    "href": "files/lecture_notes/lecture9/lecture9.html#real-world-connection",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Real-World Connection",
    "text": "Real-World Connection"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#activity-your-research-field",
    "href": "files/lecture_notes/lecture9/lecture9.html#activity-your-research-field",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Activity: Your Research Field",
    "text": "Activity: Your Research Field\n\n\n\n\n\n\n\n\nThink About Your Major/Research Area\n\n\nTake 2 minutes to brainstorm:\n\nWhat random phenomena occur in your field?\nHow might you assign numbers to these outcomes?\nWhat questions could you answer with this data?\n\n\n\n\n\n\n\n\n\n\n\n\nExamples by Field\n\n\n\nPsychology: Reaction times, survey responses\nBiology: Species counts, gene expression levels\nEconomics: Stock prices, unemployment rates\nEngineering: System failures, signal strength"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#discrete-random-variables",
    "href": "files/lecture_notes/lecture9/lecture9.html#discrete-random-variables",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Discrete Random Variables",
    "text": "Discrete Random Variables\n\nDefinition: Takes on countable values (finite or countably infinite)\nExamples:\n\nNumber of emails received per day\nNumber of defective products in a batch\nStudent enrollment in courses\nNumber of research papers published per year\n\n\n\nNote: If X is discrete, then X can take values x_1, x_2, x_3, \\cdot where we can list all possible values."
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#continuous-random-variables",
    "href": "files/lecture_notes/lecture9/lecture9.html#continuous-random-variables",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Continuous Random Variables",
    "text": "Continuous Random Variables\n\nDefinition: Takes on uncountably infinite values (any value in an interval)\nExamples:\n\nHeight of students\nTime until equipment failure\nTemperature measurements\nGPA (technically discrete, but often treated as continuous)\n\n\n\nNote: If X is continuous, then X can take any value in an interval [a,b] or (-\\infty, \\infty)."
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#sampling-and-random-variables",
    "href": "files/lecture_notes/lecture9/lecture9.html#sampling-and-random-variables",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Sampling and Random Variables",
    "text": "Sampling and Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#central-limit-theorem-connection",
    "href": "files/lecture_notes/lecture9/lecture9.html#central-limit-theorem-connection",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Central Limit Theorem Connection",
    "text": "Central Limit Theorem Connection\n\nWhen we repeatedly sample from a population, the sample mean becomes a random variable\nFormula: \\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i\nEach time we sample, we get a different \\bar{X}\nThe distribution of \\bar{X} has special properties!"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#central-limit-theorem-connection-1",
    "href": "files/lecture_notes/lecture9/lecture9.html#central-limit-theorem-connection-1",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Central Limit Theorem Connection",
    "text": "Central Limit Theorem Connection\n\n\nThese properties are :\n\nCenter (Unbiased): E[\\bar{X}] = \\mu.\nSpread Shrinks with n: \\mathrm{Var}(\\bar{X}) = \\sigma^2/n; \\mathrm{SE}(\\bar{X}) = \\sigma/\\sqrt{n} (estimate with s/\\sqrt{n}).\nShape:\n\nIf the population is Normal, then \\bar{X} \\sim \\text{Normal}(\\mu, \\sigma^2/n) exactly.\n\nOtherwise, CLT: for large n, \\bar{X} is approximately Normal even when the data aren’t.\n\n\n\n\nConsistency / Law of Large Numbers: \\bar{X} \\xrightarrow{P} \\mu as n \\to \\infty (estimates get closer to the truth with more data).\n(If sampling w/out replacement, pop size N): Apply finite population correction (FPC):\n\\mathrm{SE}(\\bar{X}) = \\dfrac{\\sigma}{\\sqrt{n}}\\sqrt{\\dfrac{N-n}{N-1}}."
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#common-discrete-distributions",
    "href": "files/lecture_notes/lecture9/lecture9.html#common-discrete-distributions",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Common Discrete Distributions",
    "text": "Common Discrete Distributions\nBinomial Distribution - Characteristics\n\n\n\n\nFixed number of trials (n)\nEach trial has two outcomes\nConstant probability of success\nTrials are independent\n\nExample: Number of successful research grants out of 10 applications"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#poisson-distribution---characteristics",
    "href": "files/lecture_notes/lecture9/lecture9.html#poisson-distribution---characteristics",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Poisson Distribution - Characteristics",
    "text": "Poisson Distribution - Characteristics\n\n\n\nModels rare events\nEvents occur independently\nConstant average rate\nUseful for counts over time/space\n\nExample: Number of emails received per hour, number of mutations in DNA sequences"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#common-continuous-distributions",
    "href": "files/lecture_notes/lecture9/lecture9.html#common-continuous-distributions",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Common Continuous Distributions",
    "text": "Common Continuous Distributions\nNormal Distribution - Characteristics\n\n\n\nBell-shaped curve\nSymmetric around mean\nParameters: \\mu (mean), \\sigma (standard deviation)\nMany natural phenomena follow this pattern\n\nExample: Heights, test scores, measurement errors"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#exponential-distribution---characteristics",
    "href": "files/lecture_notes/lecture9/lecture9.html#exponential-distribution---characteristics",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Exponential Distribution - Characteristics",
    "text": "Exponential Distribution - Characteristics\n\n\n\nModels waiting times\nMemoryless property\nParameter: \\lambda (rate)\nRight-skewed\n\nExample: Time between arrivals, equipment lifespan, time to next earthquake"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#interactive-activity-choose-your-distribution",
    "href": "files/lecture_notes/lecture9/lecture9.html#interactive-activity-choose-your-distribution",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Interactive Activity: Choose Your Distribution",
    "text": "Interactive Activity: Choose Your Distribution\n\n\n\n\n\n\nGroup Discussion (5 minutes)\n\n\nFor each scenario, identify: 1. Is the random variable discrete or continuous? 2. What distribution might it follow? 3. What are the parameters?\nScenarios: - Number of students attending office hours per week - Time spent studying for an exam - Number of typos in a research paper - Body temperature of patients in a hospital"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#application-research-design",
    "href": "files/lecture_notes/lecture9/lecture9.html#application-research-design",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Application: Research Design",
    "text": "Application: Research Design\nConsider your research question:\n\nIdentify your random variable(s)\n\nWhat are you measuring?\nWhat values can it take?\n\nChoose appropriate distribution\n\nBased on the nature of your data\nConsider the underlying process\n\nPlan your analysis\n\nHow will you collect data?\nWhat statistical tests are appropriate?"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#probability-mass-vs.-density-functions",
    "href": "files/lecture_notes/lecture9/lecture9.html#probability-mass-vs.-density-functions",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Probability Mass vs. Density Functions",
    "text": "Probability Mass vs. Density Functions\n\n\nDiscrete: Probability Mass Function (PMF)\n\nP(X = x) for specific values\nSums to 1 over all possible values\nCan find exact probabilities\n\nExample: P(X = 3) = 0.2\n\nContinuous: Probability Density Function (PDF)\n\nf(x) represents density\nArea under curve = 1\nP(X = x) = 0 for any specific value\nFind probabilities over intervals\n\nExample: P(a &lt; X &lt; b) =  \\int_{a}^{b} f(x)dx"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#comparing-distributions-side-by-side",
    "href": "files/lecture_notes/lecture9/lecture9.html#comparing-distributions-side-by-side",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Comparing Distributions Side-by-Side",
    "text": "Comparing Distributions Side-by-Side"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#confidence-intervals-for-means",
    "href": "files/lecture_notes/lecture9/lecture9.html#confidence-intervals-for-means",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Confidence Intervals for Means",
    "text": "Confidence Intervals for Means\n\nProblem: We have one sample mean, but want to estimate the population mean\nSolution: Use the sampling distribution to create a confidence interval\nKey Insight: If we know how \\bar{X} varies, we can make probabilistic statements about μ\n\n\n95% Confidence Interval Formula: \\bar{x} \\pm 1.96 \\times \\frac{\\sigma}{\\sqrt{n}}\nInterpretation: “We are 95% confident that the true population mean lies within this interval”"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#visualizing-confidence-intervals",
    "href": "files/lecture_notes/lecture9/lecture9.html#visualizing-confidence-intervals",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Visualizing Confidence Intervals",
    "text": "Visualizing Confidence Intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#confidence-interval-interpretation",
    "href": "files/lecture_notes/lecture9/lecture9.html#confidence-interval-interpretation",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Confidence Interval Interpretation",
    "text": "Confidence Interval Interpretation\n\n\n\n\n\n\nCommon Misconceptions\n\n\n❌ WRONG: “There’s a 95% probability that μ is in this specific interval”\n✅ CORRECT: “If we repeated this process many times, 95% of the intervals we construct would contain the true μ”\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe interval is random, not the population parameter\nBefore collecting data: 95% chance our method will work\nAfter collecting data: The interval either contains μ or it doesn’t\nConfidence level = Long-run success rate of the method"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#factors-affecting-confidence-interval-width",
    "href": "files/lecture_notes/lecture9/lecture9.html#factors-affecting-confidence-interval-width",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Factors Affecting Confidence Interval Width",
    "text": "Factors Affecting Confidence Interval Width"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#key-takeaways",
    "href": "files/lecture_notes/lecture9/lecture9.html#key-takeaways",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nRandom variables translate random outcomes into numbers\nDiscrete variables have countable values; continuous variables have uncountable values\nDistributions describe the probability patterns of random variables\nChoosing the right distribution depends on understanding your data’s nature\nReal applications exist in every field - think about your research!"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#next-steps",
    "href": "files/lecture_notes/lecture9/lecture9.html#next-steps",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Next Steps",
    "text": "Next Steps\n\n\n\n\n\n\nFor Your Research/Interests\n\n\n\nIdentify random variables in your field\nThink about appropriate distributions\nConsider data collection methods\nPlan statistical analyses\nConnect theory to practice"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#questions-and-discussion",
    "href": "files/lecture_notes/lecture9/lecture9.html#questions-and-discussion",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Questions and Discussion",
    "text": "Questions and Discussion\n\nShare with the class:\n\nWhat random variables are important in your field of study/major?\nWhich distributions might be most relevant?\nWhat challenges do you anticipate in data collection?\n\n\n\nThank you for your participation!"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#appendix-python-code-examples",
    "href": "files/lecture_notes/lecture9/lecture9.html#appendix-python-code-examples",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Appendix: Python Code Examples",
    "text": "Appendix: Python Code Examples\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport seaborn as sns\n\n# Generate random samples from different distributions\n\n# Binomial\nbinom_data = np.random.binomial(n=10, p=0.3, size=100)\n\n# Poisson  \npoisson_data = np.random.poisson(lam=3, size=100)\n\n# Normal\nnormal_data = np.random.normal(loc=0, scale=1, size=100)\n\n# Exponential\nexp_data = np.random.exponential(scale=1/1.5, size=100)\n\n# Create histograms\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\naxes[0,0].hist(binom_data, bins=11, alpha=0.7, color='steelblue')\naxes[0,0].set_title('Binomial Sample')\n\naxes[0,1].hist(poisson_data, bins=15, alpha=0.7, color='coral')\naxes[0,1].set_title('Poisson Sample')\n\naxes[1,0].hist(normal_data, bins=20, alpha=0.7, color='lightblue')\naxes[1,0].set_title('Normal Sample')\n\naxes[1,1].hist(exp_data, bins=20, alpha=0.7, color='lightgreen')\naxes[1,1].set_title('Exponential Sample')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#additional-resources",
    "href": "files/lecture_notes/lecture9/lecture9.html#additional-resources",
    "title": "From Random Variables to Sampling & Confidence Intervals",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n# Useful Python libraries for statistics and probability\nimport numpy as np           # Numerical computing\nimport scipy.stats as stats  # Statistical functions\nimport matplotlib.pyplot as plt  # Plotting\nimport seaborn as sns        # Statistical visualization\nimport pandas as pd          # Data manipulation\n\n# Quick reference for common distributions:\n# stats.binom.pmf(k, n, p)     # Binomial PMF\n# stats.poisson.pmf(k, lam)    # Poisson PMF  \n# stats.norm.pdf(x, mu, sigma) # Normal PDF\n# stats.expon.pdf(x, scale)    # Exponential PDF\n\n# Generate random samples:\n# np.random.binomial(n, p, size)\n# np.random.poisson(lam, size)\n# np.random.normal(mu, sigma, size)\n# np.random.exponential(scale, size)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#welcome-to-lecture-9",
    "href": "files/lecture_notes/lecture8/lecture8.html#welcome-to-lecture-9",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Welcome to Lecture 9",
    "text": "Welcome to Lecture 9\nContinuous Random Variables\nFrom discrete jumps to smooth curves: modeling the continuous world"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture8/lecture8.html#todays-learning-objectives",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Today’s Learning Objectives",
    "text": "Today’s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDistinguish between discrete and continuous random variables (Section 3)\nUnderstand probability density functions (PDFs) and their interpretation (Section 4)\nWork with cumulative distribution functions (CDFs) for continuous variables\nCalculate probabilities using areas under curves\nCompute expected values and variances for continuous distributions\nWork with common continuous distributions (Uniform, Normal, Exponential)\nApply the Central Limit Theorem\nUse python to work with continuous distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#sec-dis-cont-vars",
    "href": "files/lecture_notes/lecture8/lecture8.html#sec-dis-cont-vars",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Review: Discrete vs Continuous",
    "text": "Review: Discrete vs Continuous\n\n\n\n\nDiscrete Random Variables\n\n\n\nCountable values (can list them)\n\n\nGaps between possible values\n\n\nUses Probability Mass Function (PMF)\n\n\nP(X = x) makes sense\n\n\n\nExamples: Dice rolls, number of emails, quiz scores\n\n\n\n\n\n\n\n\n\nContinuous Random Variables\n\n\n\nUncountable values (infinite possibilities)\n\n\nNo gaps - any value in an interval\n\n\nUses Probability Density Function (PDF)\n\n\nP(X = x) = 0 for any specific value!\n\n\n\nExamples: Height, weight, time, temperature"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#sec-pdf",
    "href": "files/lecture_notes/lecture8/lecture8.html#sec-pdf",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Why P(X = x) = 0 for Continuous Variables?",
    "text": "Why P(X = x) = 0 for Continuous Variables?\n\n\nFor continuous random variables, the probability of any exact value is zero!\nThink about it: What’s the probability someone is exactly 5.7324681… feet tall?\n\n\n\n\nInstead, we ask:\n\nP(5.7 ≤ X ≤ 5.8)?\nP(X ≤ 6.0)?\nP(X &gt; 5.5)?\n\nKey insight: We calculate probabilities for intervals, not exact points.\n\n\n\n\n\nClick to see why P(X = exact value) = 0"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#probability-density-function-pdf",
    "href": "files/lecture_notes/lecture8/lecture8.html#probability-density-function-pdf",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Probability Density Function (PDF)",
    "text": "Probability Density Function (PDF)\n\n\n\n\n 🎯 Definition: The Probability Density Function (PDF) of a continuous random variable X is a function f(x) such that:\n\n\nP(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx\n\n\n\n\n\nProperties of PDF:\n\n\n\nf(x) \\geq 0 for all x\n\n\n\\int_{-\\infty}^{\\infty} f(x) \\, dx = 1\n\n\nf(x) is NOT a probability - it’s a density!\n\n\n\nKey Insight:\n\n\nThe area under the PDF curve between a and b gives the probability that X falls in that interval."
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#cumulative-distribution-function-cdf",
    "href": "files/lecture_notes/lecture8/lecture8.html#cumulative-distribution-function-cdf",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\n\n\n\nFor continuous random variables, the CDF is:\nF(x) = P(X \\leq x) = \\int_{-\\infty}^x f(t) \\, dt\nKey relationship: f(x) = \\frac{d}{dx}F(x)\nThe PDF is the derivative of the CDF!\n\n\n\n\n\nClick anywhere to see F(x) = P(X ≤ x) for that point"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#expected-value-and-variance",
    "href": "files/lecture_notes/lecture8/lecture8.html#expected-value-and-variance",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Expected Value and Variance",
    "text": "Expected Value and Variance\n\n\nExpected Value: E[X] = \\mu = \\int_{-\\infty}^{\\infty} x \\cdot f(x) \\, dx\nVariance:\n\\text{Var}(X) = \\sigma^2 = \\int_{-\\infty}^{\\infty} (x - \\mu)^2 f(x) \\, dx = E[X^2] - (E[X])^2\nWhere:\nE[X^2] = \\int_{-\\infty}^{\\infty} x^2 \\cdot f(x) \\, dx\n\n\n\n\n\n\n\nImportant\n\n\nNotice: Integrals replace sums when moving from discrete to continuous!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#common-continuous-distributions",
    "href": "files/lecture_notes/lecture8/lecture8.html#common-continuous-distributions",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Common Continuous Distributions",
    "text": "Common Continuous Distributions\n\nUniform Distribution\nAll values equally likely in an interval\nParameters: a (min), b (max)\nPDF: f(x) = \\frac{1}{b-a} for a \\leq x \\leq b\nMean: \\frac{a+b}{2}\nVariance: \\frac{(b-a)^2}{12}\nUse: Random numbers, waiting times\n\n\nNormal Distribution\nBell-shaped, symmetric\nParameters: \\mu (mean), \\sigma^2 (variance)\nPDF: f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\nMean: \\mu\nVariance: \\sigma^2\nUse: Heights, test scores, errors\n\n\nExponential Distribution\nModels waiting times\nParameters: \\lambda (rate)\nPDF: f(x) = \\lambda e^{-\\lambda x} for x \\geq 0\nMean: \\frac{1}{\\lambda}\nVariance: \\frac{1}{\\lambda^2}\nUse: Time between events, lifetimes"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#the-normal-distribution",
    "href": "files/lecture_notes/lecture8/lecture8.html#the-normal-distribution",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "The Normal Distribution",
    "text": "The Normal Distribution\n\n\n\nWhy Normal is Special\n\nCentral Limit Theorem: Sample means approach normal\n68-95-99.7 Rule:\n\n68% within 1 \\sigma of \\mu\n95% within 2 \\sigma of \\mu\n\n99.7% within 3 \\sigma of \\mu\n\nStandard Normal: \\mu = 0 , \\sigma = 1\n\nZ-Score Transformation\nZ = \\frac{X - \\mu}{\\sigma}"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-1-uniform-distribution",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-1-uniform-distribution",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Practice Problem 1: Uniform Distribution",
    "text": "Practice Problem 1: Uniform Distribution\n\nA bus arrives uniformly between 10:00 AM and 10:20 AM. Let X = arrival time in minutes after 10:00 AM.\n(a) What is the PDF of X?\n(b) What’s the probability the bus arrives between 10:05 and 10:12?\n(c) What’s the expected arrival time?\n\nShow Solution\n\n\nSolution. (a) X \\sim \\text{Uniform}(0, 20) f(x) = \\frac{1}{20-0} = \\frac{1}{20} \\text{ for } 0 \\leq x \\leq 20\n(b) P(5 \\leq X \\leq 12) = \\int_5^{12} \\frac{1}{20} dx = \\frac{1}{20} \\times (12-5) = \\frac{7}{20} = 0.35\n(c) E[X] = \\frac{a+b}{2} = \\frac{0+20}{2} = 10 minutes after 10:00 AM"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-2-normal-distribution",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-2-normal-distribution",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Practice Problem 2: Normal Distribution",
    "text": "Practice Problem 2: Normal Distribution\n\nHeights of adult women are normally distributed with μ = 64 inches and σ = 2.5 inches.\n(a) What’s the probability a woman is taller than 67 inches?\n(b) What height represents the 90th percentile?\n(c) What’s the probability a woman is between 62 and 66 inches tall?\n\nShow Solution\n\n\nSolution. (a) P(X &gt; 67) = P\\left(Z &gt; \\frac{67-64}{2.5}\\right) = P(Z &gt; 1.2) = 1 - 0.8849 = 0.1151\n(b) For 90th percentile: P(X \\leq x) = 0.90\nz_{0.90} = 1.28, so x = 64 + 1.28(2.5) = 67.2 inches\n(c) P(62 \\leq X \\leq 66) = P\\left(\\frac{62-64}{2.5} \\leq Z \\leq \\frac{66-64}{2.5}\\right)\n= P(-0.8 \\leq Z \\leq 0.8) = 0.7881 - 0.2119 = 0.5762"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-3-exponential-distribution",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-3-exponential-distribution",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Practice Problem 3: Exponential Distribution",
    "text": "Practice Problem 3: Exponential Distribution\n\nThe time between customer arrivals at a store follows an exponential distribution with an average of 5 minutes between arrivals.\n(a) What is the PDF?\n(b) What’s the probability the next customer arrives within 3 minutes?\n(c) What’s the probability no customer arrives in the next 10 minutes?\n\nShow Solution\n\n\nSolution. (a) Average = 5 minutes = \\frac{1}{\\lambda}, so \\lambda = 0.2\nf(x) = 0.2e^{-0.2x} \\text{ for } x \\geq 0\n(b) P(X \\leq 3) = \\int_0^3 0.2e^{-0.2x} dx = 1 - e^{-0.2 \\times 3} = 1 - e^{-0.6} = 0.4512\n(c) P(X &gt; 10) = e^{-0.2 \\times 10} = e^{-2} = 0.1353"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#central-limit-theorem",
    "href": "files/lecture_notes/lecture8/lecture8.html#central-limit-theorem",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nInteractive CLT Demo: Sample Means Approach Normal\n\n Uniform Population Exponential Population Bimodal Population  Sample Size:  Run Simulation\n\n\n\n\n\n\nPopulation Distribution\n\n\n\n\n\n\nSample Means Distribution\n\n\n\n\nCLT in Action: Run simulation to see the magic!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#transformations-of-random-variables",
    "href": "files/lecture_notes/lecture8/lecture8.html#transformations-of-random-variables",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Transformations of Random Variables",
    "text": "Transformations of Random Variables\n\n\nLinear Transformations\nIf Y = aX + b, then:\n\nE[Y] = aE[X] + b\n\\text{Var}(Y) = a^2\\text{Var}(X)\nIf X \\sim N(\\mu, \\sigma^2), then Y \\sim N(a\\mu + b, a^2\\sigma^2)\n\n\nStandardization\nZ = \\frac{X - \\mu}{\\sigma} \\sim N(0, 1)\n\nImportant: Normal distributions are closed under linear transformations!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#comparing-discrete-and-continuous",
    "href": "files/lecture_notes/lecture8/lecture8.html#comparing-discrete-and-continuous",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Comparing Discrete and Continuous",
    "text": "Comparing Discrete and Continuous\n\n\n\n\n\n\n\n\n\nProperty\nDiscrete\nContinuous\n\n\n\n\nProbability Function\nPMF: P(X = x)\nPDF: f(x)\n\n\nExact Value Probability\nP(X = x) &gt; 0 possible\nP(X = x) = 0 always\n\n\nInterval Probability\n\\sum P(X = x_i)\n\\int_a^b f(x) dx\n\n\nExpected Value\n\\sum x \\cdot P(X = x)\n\\int x \\cdot f(x) dx\n\n\nVariance\n\\sum (x-\\mu)^2 P(X = x)\n\\int (x-\\mu)^2 f(x) dx\n\n\nCDF\n\\sum_{x_i \\leq x} P(X = x_i)\n\\int_{-\\infty}^x f(t) dt"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#properties-of-continuous-distributions",
    "href": "files/lecture_notes/lecture8/lecture8.html#properties-of-continuous-distributions",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Properties of Continuous Distributions",
    "text": "Properties of Continuous Distributions\n\n\n\nKey Properties\n\nMemoryless Property (Exponential only):\nP(X &gt; s+t | X &gt; s) = P(X &gt; t)\nSymmetry (Normal):\nP(X \\leq \\mu - a) = P(X \\geq \\mu + a)\nScaling Invariance (Normal):\nLinear combinations of normals are normal\n\n\nUseful Relationships\n\nCDF to PDF: f(x) = F'(x)\nPDF to CDF: F(x) = \\int_{-\\infty}^x f(t) dt\nComplementary CDF: P(X &gt; x) = 1 - F(x)\n\n\nRemember: Area under PDF = 1, but PDF values can exceed 1!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#key-takeaways",
    "href": "files/lecture_notes/lecture8/lecture8.html#key-takeaways",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\n\n\nMain Concepts\n\nContinuous variables require PDFs, not PMFs\nProbabilities are areas under curves, not function values\nIntegration replaces summation for continuous distributions\nNormal distribution is central due to CLT\n\n\nDistribution Selection\nChoose distributions based on the data characteristics:\n\nUniform for equally likely intervals\nNormal for symmetric, bell-shaped data\n\nExponential for waiting times/lifetimes\nUse CLT when working with sample means\n\nKey Principle\n\nCentral Limit Theorem makes normal distributions ubiquitous in statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#looking-ahead",
    "href": "files/lecture_notes/lecture8/lecture8.html#looking-ahead",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\nNext Lecture: Statistical Inference\nTopics we’ll cover:\n\nSampling distributions\nConfidence intervals\nHypothesis testing\np-values and significance\n\n\nConnection: Continuous distributions (especially normal) form the foundation for statistical inference"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#questions",
    "href": "files/lecture_notes/lecture8/lecture8.html#questions",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: 11AM on Thursday (link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Statistical Inference and Hypothesis Testing"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#resources",
    "href": "files/lecture_notes/lecture8/lecture8.html#resources",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Resources",
    "text": "Resources\n\n\n\n Read OpenIntro Statistics Chapter 4 sections 4.1-4.3\n\n\n Khan Academy - Continuous Random Variables\n\n\n Seeing Theory - Probability Distributions\n\n\n Central Limit Theorem - Wikipedia\n\n\n Introduction to Probability - Continuous Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#back-to-main-page",
    "href": "files/lecture_notes/lecture8/lecture8.html#back-to-main-page",
    "title": "PSTAT 5A: Continuous Random Variables",
    "section": "Back to Main Page",
    "text": "Back to Main Page\n🏠 Back to Main Page"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#learning-objectives",
    "href": "files/lecture_notes/lecture3/lecture3.html#learning-objectives",
    "title": "Descriptive Statistics Part II",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture, you will be able to:\n\nCalculate and interpret measures of variability (range, variance, standard deviation)\nUnderstand and compute measures of position (percentiles, quartiles, z-scores)\nAssess distribution shape using skewness and kurtosis\nCreate and interpret histograms with appropriate bin widths\nConstruct and analyze boxplots for data exploration\nIdentify trends, patterns, and outliers in data visualizations\nApply Python for comprehensive descriptive analysis and visualization"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#lecture-outline",
    "href": "files/lecture_notes/lecture3/lecture3.html#lecture-outline",
    "title": "Descriptive Statistics Part II",
    "section": "Lecture Outline",
    "text": "Lecture Outline\n\n\nPart I: Measures of Variability (25 min)\n\nRange, Variance, Standard Deviation\nCoefficient of Variation\nPython Implementation\n\nPart II: Measures of Position (20 min)\n\nPercentiles and Quartiles\nZ-scores and Standardization\n\n\n\nPart III: Distribution Shape (10 min)\n\nSkewness and Kurtosis\n\nPart IV: Data Visualization (20 min)\n\nHistograms and Bin Width Selection\nBoxplots and Interpretation\n\nPart V: Identifying Patterns (5 min)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-is-variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-is-variability",
    "title": "Descriptive Statistics Part II",
    "section": "What is Variability?",
    "text": "What is Variability?\n\n🎯 Definition: Variability (or dispersion) measures how spread out or scattered the data points are around the center.\n\nWhy Variability Matters\n\nTwo datasets can have the same mean but very different spreads\nVariability indicates consistency and predictability\nEssential for risk assessment and quality control\nHelps determine confidence in our central tendency measures"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#range",
    "href": "files/lecture_notes/lecture3/lecture3.html#range",
    "title": "Descriptive Statistics Part II",
    "section": "Range",
    "text": "Range\n\nRange = Maximum value - Minimum value\n\nExample\nData: 12, 15, 18, 22, 25, 30, 35\n\nRange = 35 - 12 = 23"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#when-to-use-range",
    "href": "files/lecture_notes/lecture3/lecture3.html#when-to-use-range",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Range",
    "text": "When to Use Range\n✅ Use range when:\n\nNeed a quick, simple measure of spread\nWorking with small datasets\nCommunicating to non-technical audiences\n\n❌ Avoid range when:\n\nOutliers are present\nNeed detailed information about variability\nWorking with large datasets"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#variance-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#variance-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Variance Definition",
    "text": "Variance Definition\n\n🎯 Definition: Variance measures the average squared deviation from the mean."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#recall",
    "href": "files/lecture_notes/lecture3/lecture3.html#recall",
    "title": "Descriptive Statistics Part II",
    "section": "Recall",
    "text": "Recall"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#side-by-side-comparison",
    "href": "files/lecture_notes/lecture3/lecture3.html#side-by-side-comparison",
    "title": "Descriptive Statistics Part II",
    "section": "Side-by-Side Comparison",
    "text": "Side-by-Side Comparison\n\n\n\nPopulation Variance\n\n\n\\[\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\]\n\n\\(\\sigma^2\\) = population variance\n\\(x_i\\) = value of \\(i^{th}\\) element\n\\(\\mu\\) = population mean\n\\(N\\) = population size\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\]\n\n\\(s^2\\) = sample variance\n\\(x_i\\) = value of \\(i^{th}\\) element\n\\(\\bar{x}\\) = sample mean\n\\(n\\) = sample size"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#key-differences",
    "href": "files/lecture_notes/lecture3/lecture3.html#key-differences",
    "title": "Descriptive Statistics Part II",
    "section": "Key Differences",
    "text": "Key Differences\n\nKey Difference: Sample variance uses \\((n-1)\\) instead of \\(N\\) in the denominator\n\nWhy \\((n-1)\\)?\n\nWhen we use sample mean \\(\\bar{x}\\) to estimate population mean \\(\\mu\\)\nWe lose one degree of freedom\nCalled Bessel’s correction\nMakes sample variance an unbiased estimator"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#when-to-use-each-formula",
    "href": "files/lecture_notes/lecture3/lecture3.html#when-to-use-each-formula",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Each Formula",
    "text": "When to Use Each Formula\n\nPopulation Variance (\\(\\sigma^2\\))\n\nYou have data for the entire population\nYou know the true population mean \\(\\mu\\)\nExample: Test scores for all students in a small class\n\n\n\nSample Variance (\\(s^2\\))\n\nYou have data from a sample only\nWant to estimate population variance\nExample: Survey responses from 100 people out of 10,000"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#understanding-degrees-of-freedom",
    "href": "files/lecture_notes/lecture3/lecture3.html#understanding-degrees-of-freedom",
    "title": "Descriptive Statistics Part II",
    "section": "Understanding Degrees of Freedom",
    "text": "Understanding Degrees of Freedom\n\n\n📊 Population Case\nAll observations are independent\n\nWe know the true population mean \\(\\mu\\)\nEach of the \\(N\\) observations provides independent information\nNo constraints on the data\n\n\n\\[\\text{Degrees of Freedom} = N\\]\n\n\n\n📈 Sample Case\nConstraint introduced by sample mean\n\nWe must estimate \\(\\mu\\) using \\(\\bar{x}\\)\nOnce we know \\(\\bar{x}\\) and \\((n-1)\\) observations, the last one is determined\nWe “lose” one degree of freedom\n\n\n\\[\\text{Degrees of Freedom} = n-1\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#section",
    "href": "files/lecture_notes/lecture3/lecture3.html#section",
    "title": "Descriptive Statistics Part II",
    "section": "",
    "text": "Sample Mean Constraint\n\\[\\bar{x} = \\frac{x_1 + x_2 + \\cdots + x_n}{n}\\]\nRearranging: \\[x_n = n\\bar{x} - (x_1 + x_2 + \\cdots + x_{n-1})\\]\nOnce we know \\(\\bar{x}\\) and the first \\((n-1)\\) values, \\(x_n\\) is completely determined!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#example-calculation",
    "href": "files/lecture_notes/lecture3/lecture3.html#example-calculation",
    "title": "Descriptive Statistics Part II",
    "section": "Example Calculation",
    "text": "Example Calculation\nData: 3, 7, 2, 8, 5\nIf this is the entire population:\n\n\\(\\mu = \\frac{3+7+2+8+5}{5} = 5\\)\n\\(\\sigma^2 = \\frac{(3-5)^2+(7-5)^2+(2-5)^2+(8-5)^2+(5-5)^2}{5} = \\frac{22}{5} = 4.4\\)\n\nIf this is a sample:\n\n\\(\\bar{x} = 5\\) (same calculation)\n\\(s^2 = \\frac{22}{5-1} = \\frac{22}{4} = 5.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#variance-properties",
    "href": "files/lecture_notes/lecture3/lecture3.html#variance-properties",
    "title": "Descriptive Statistics Part II",
    "section": "Variance Properties",
    "text": "Variance Properties\nVariance measures:\n\nAverage squared deviation from the mean\nAlways non-negative: \\(\\sigma^2 \\geq 0\\), \\(s^2 \\geq 0\\)\nUnits: (original units)²\n\nStandard Deviation:\n\n\\(\\sigma = \\sqrt{\\sigma^2}\\) (population)\n\\(s = \\sqrt{s^2}\\) (sample)\nSame units as original data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#bias-and-unbiasedness",
    "href": "files/lecture_notes/lecture3/lecture3.html#bias-and-unbiasedness",
    "title": "Descriptive Statistics Part II",
    "section": "Bias and Unbiasedness",
    "text": "Bias and Unbiasedness\nPopulation variance:\n\nTrue parameter value\nNo estimation involved\n\nSample variance with \\((n-1)\\):\n\n\\(E[s^2] = \\sigma^2\\) (unbiased)\nOn average, equals population variance\n\nSample variance with \\(n\\):\n\n\\(E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n}\\right] = \\frac{n-1}{n}\\sigma^2\\) (biased)\nSystematically underestimates population variance"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#implementation",
    "href": "files/lecture_notes/lecture3/lecture3.html#implementation",
    "title": "Descriptive Statistics Part II",
    "section": "Implementation",
    "text": "Implementation\nCalculators:\n\nMost use \\((n-1)\\) by default for sample standard deviation\nCheck your calculator’s documentation\n\nSoftware:\n\nR: var() uses \\((n-1)\\), sd() uses \\((n-1)\\)\nExcel: VAR.S() uses \\((n-1)\\), VAR.P() uses \\(n\\)\nPython: np.var(ddof=1) uses \\((n-1)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practice-problem",
    "href": "files/lecture_notes/lecture3/lecture3.html#practice-problem",
    "title": "Descriptive Statistics Part II",
    "section": "Practice Problem",
    "text": "Practice Problem\nDataset: Number of hours studied by 6 students: 2, 4, 3, 5, 6, 4\nCalculate both:\n\nPopulation variance (assuming this is the entire population)\nSample variance (assuming this is a sample)\n\n\nSolution:\n\nMean: \\(\\bar{x} = \\frac{24}{6} = 4\\)\nPopulation variance: \\(\\sigma^2 = \\frac{10}{6} = 1.67\\)\nSample variance: \\(s^2 = \\frac{10}{5} = 2.0\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#summary",
    "href": "files/lecture_notes/lecture3/lecture3.html#summary",
    "title": "Descriptive Statistics Part II",
    "section": "Summary",
    "text": "Summary\n\nKey Takeaways\n\nPopulation variance uses \\(N\\) (entire population)\nSample variance uses \\((n-1)\\) (Bessel’s correction)\nSample variance is unbiased estimator of population variance\nDifference matters more for small samples\nAlways check which formula your software uses!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#example-1",
    "href": "files/lecture_notes/lecture3/lecture3.html#example-1",
    "title": "Descriptive Statistics Part II",
    "section": "Example",
    "text": "Example\n\n\n📊 Complete Population Data (Test Scores)\nWe have test scores from 100 students arranged in a grid:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nM\nN\nO\nP\nQ\nR\nS\nT\n\n\n\n\n1\n24\n96\n30\n69\n85\n60\n55\n18\n30\n66\n64\n99\n92\n95\n84\n55\n72\n38\n86\n32\n\n\n2\n53\n81\n30\n89\n42\n94\n31\n26\n53\n78\n38\n60\n93\n90\n82\n85\n89\n54\n30\n58\n\n\n3\n62\n67\n75\n47\n99\n25\n32\n63\n49\n45\n30\n97\n57\n32\n37\n62\n33\n16\n11\n41\n\n\n4\n95\n74\n28\n73\n82\n97\n65\n88\n56\n95\n85\n44\n70\n65\n34\n85\n58\n15\n64\n84\n\n\n5\n76\n46\n83\n56\n98\n16\n76\n77\n35\n19\n97\n42\n90\n79\n73\n28\n82\n92\n90\n22\n\n\n\n\n\n\n🎯 Random Sample Selection\nWe randomly select 5 scores from different positions in our population:\nOur Sample: 82, 95, 83, 60, 92"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#final-calculations",
    "href": "files/lecture_notes/lecture3/lecture3.html#final-calculations",
    "title": "Descriptive Statistics Part II",
    "section": "Final Calculations",
    "text": "Final Calculations\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum(x_i - \\bar{x})^2}{n-1}\\] \\[s^2 = \\frac{753.2}{5-1} = \\frac{753.2}{4} = 188.3\\]\n\n\n\n\nSample Standard Deviation\n\n\n\\[s = \\sqrt{s^2}\\] \\[s = \\sqrt{188.3} = 13.72\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#properties-of-standard-deviation",
    "href": "files/lecture_notes/lecture3/lecture3.html#properties-of-standard-deviation",
    "title": "Descriptive Statistics Part II",
    "section": "Properties of Standard Deviation",
    "text": "Properties of Standard Deviation\n\nSame units as the original data\nAlways non-negative\nZero only when all values are identical\nLarger values indicate more variability\nApproximately 68% of data within 1 SD of mean (for normal distributions)\nApproximately 95% of data within 2 SD of mean"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#empirical-rule-68-95-99.7-rule",
    "href": "files/lecture_notes/lecture3/lecture3.html#empirical-rule-68-95-99.7-rule",
    "title": "Descriptive Statistics Part II",
    "section": "Empirical Rule (68-95-99.7 Rule)",
    "text": "Empirical Rule (68-95-99.7 Rule)\nFor approximately normal distributions:\n\n68% of data falls within 1 standard deviation of the mean\n95% of data falls within 2 standard deviations of the mean\n99.7% of data falls within 3 standard deviations of the mean\n\nThis rule helps us understand what constitutes “typical” vs “unusual” values."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#definition-and-purpose",
    "href": "files/lecture_notes/lecture3/lecture3.html#definition-and-purpose",
    "title": "Descriptive Statistics Part II",
    "section": "Definition and Purpose",
    "text": "Definition and Purpose\n\n🎯 Definition: Coefficient of Variation (CV) = \\(\\frac{\\text{Standard Deviation}}{\\text{Mean}} \\times 100\\%\\)\n\n\nWhy Use CV?\n\nCompares variability across different units or scales\nRelative measure of variability\nUseful when means differ substantially"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-implementation---variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-implementation---variability",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Variability",
    "text": "Python Implementation - Variability\n\nCodeVisualization\n\n\n\nimport numpy as np\nimport pandas as pd\n\n# Sample data\ndata = [10, 12, 14, 16, 18, 22, 25]\n\n# Calculate measures of variability\nrange_val = np.max(data) - np.min(data)\nvariance_sample = np.var(data, ddof=1)  # Sample variance\nstd_sample = np.std(data, ddof=1)       # Sample standard deviation\ncv = (std_sample / np.mean(data)) * 100\n\nprint(f\"Range: {range_val}\")\nprint(f\"Variance: {variance_sample:.2f}\")\nprint(f\"Standard Deviation: {std_sample:.2f}\")\nprint(f\"Coefficient of Variation: {cv:.1f}%\")\n\nRange: 15\nVariance: 28.90\nStandard Deviation: 5.38\nCoefficient of Variation: 32.2%"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-are-measures-of-position",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-are-measures-of-position",
    "title": "Descriptive Statistics Part II",
    "section": "What are Measures of Position?",
    "text": "What are Measures of Position?\n\n\nMeasures of position tell us where a particular value stands relative to the rest of the data.\nThey answer questions like:\n\n“What percentage of students scored below 85?”\n“Is this value typical or unusual?”\n“How does this observation compare to others?”"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#percentiles-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#percentiles-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Percentiles Definition",
    "text": "Percentiles Definition\nThe k-th percentile is the value below which k% of the data falls.\nExamples:\n\n50th percentile = Median (50% of data below this value)\n90th percentile = 90% of data falls below this value\n25th percentile = 25% of data falls below this value"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#quartiles",
    "href": "files/lecture_notes/lecture3/lecture3.html#quartiles",
    "title": "Descriptive Statistics Part II",
    "section": "Quartiles",
    "text": "Quartiles\nQuartiles divide the data into four equal parts:\n\nQ1 (First Quartile) = 25th percentile\nQ2 (Second Quartile) = 50th percentile = Median\nQ3 (Third Quartile) = 75th percentile"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#interquartile-range-iqr",
    "href": "files/lecture_notes/lecture3/lecture3.html#interquartile-range-iqr",
    "title": "Descriptive Statistics Part II",
    "section": "Interquartile Range (IQR)",
    "text": "Interquartile Range (IQR)\nIQR = Q3 - Q1\n\n\n\n\nProperties of IQR:\n\nContains the middle 50% of the data\nResistant to outliers\nUsed in boxplot construction\nUseful for outlier detection"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#z-score-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#z-score-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Z-score Definition",
    "text": "Z-score Definition\n\n\n\n🎯 Definition\nZ-score tells us how many standard deviations a value is from the mean.\n\n\n\\[z = \\frac{x - \\mu}{\\sigma} \\text{ or } z = \\frac{x - \\bar{x}}{s}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#z-score-example",
    "href": "files/lecture_notes/lecture3/lecture3.html#z-score-example",
    "title": "Descriptive Statistics Part II",
    "section": "Z-score Example",
    "text": "Z-score Example\nStudent’s test score: 85 Class mean: 78, Class standard deviation: 6\n\n\\[z = \\frac{85 - 78}{6} = \\frac{7}{6} = 1.17\\]\n\nInterpretation: This student scored 1.17 standard deviations above the class average."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#benefits-of-standardization",
    "href": "files/lecture_notes/lecture3/lecture3.html#benefits-of-standardization",
    "title": "Descriptive Statistics Part II",
    "section": "Benefits of Standardization",
    "text": "Benefits of Standardization\n\nCompare across different scales (test scores vs income)\nIdentify outliers systematically\n\nCombine different variables meaningfully\nPrepare data for certain statistical methods"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#skewness",
    "href": "files/lecture_notes/lecture3/lecture3.html#skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Skewness",
    "text": "Skewness\nSkewness measures the asymmetry of a distribution.\nTypes of Skewness:\n\n\n\n\nSymmetric (Skewness ≈ 0): Mean ≈ Median ≈ Mode\nRight-skewed (Positive skewness): Mean &gt; Median, long tail to the right\nLeft-skewed (Negative skewness): Mean &lt; Median, long tail to the left"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#examples-of-skewness",
    "href": "files/lecture_notes/lecture3/lecture3.html#examples-of-skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Examples of Skewness",
    "text": "Examples of Skewness\nRight-skewed (Income data):\n\nMost people earn moderate amounts\nFew people earn very high amounts\nMean &gt; Median\n\nLeft-skewed (Test scores with ceiling effect):\n\nMost students score high\nFew students score very low\nMean &lt; Median"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#kurtosis",
    "href": "files/lecture_notes/lecture3/lecture3.html#kurtosis",
    "title": "Descriptive Statistics Part II",
    "section": "Kurtosis",
    "text": "Kurtosis\nKurtosis measures the “tailedness” of a distribution. It measures the degree of peaked Ness or flatness of a distribution compared to the normal distribution.\nTypes:\n\nMesokurtic (Normal-like): Kurtosis ≈ 3\nLeptokurtic (Heavy tails): Kurtosis &gt; 3, more peaked\nPlatykurtic (Light tails): Kurtosis &lt; 3, flatter\n\nExcess Kurtosis = Kurtosis - 3 (makes normal distributions have excess kurtosis of 0)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-implementation---position-shape",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-implementation---position-shape",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Position & Shape",
    "text": "Python Implementation - Position & Shape\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndata = [12, 15, 18, 22, 25, 28, 30, 35, 40, 45]\n\n# Percentiles and quartiles\nq1 = np.percentile(data, 25)\nmedian = np.percentile(data, 50)\nq3 = np.percentile(data, 75)\niqr = q3 - q1\n\n# Z-scores\nz_scores = stats.zscore(data)\n\n# Shape measures\nskewness = stats.skew(data)\nkurt = stats.kurtosis(data)\n\nprint(f\"Q1: {q1}, Median: {median}, Q3: {q3}\")\nprint(f\"IQR: {iqr}\")\nprint(f\"Skewness: {skewness:.3f}\")\nprint(f\"Kurtosis: {kurt:.3f}\")\n\nQ1: 19.0, Median: 26.5, Q3: 33.75\nIQR: 14.75\nSkewness: 0.243\nKurtosis: -1.023"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-is-a-histogram",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-is-a-histogram",
    "title": "Descriptive Statistics Part II",
    "section": "What is a Histogram?",
    "text": "What is a Histogram?\nA histogram displays the distribution of a continuous variable by dividing data into bins and showing the frequency of observations in each bin.\nKey Components:\n\nX-axis: Variable values (continuous)\nY-axis: Frequency or density\nBins: Intervals that group the data\nBars: Height represents frequency in each bin"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#choosing-bin-width-critical-decision",
    "href": "files/lecture_notes/lecture3/lecture3.html#choosing-bin-width-critical-decision",
    "title": "Descriptive Statistics Part II",
    "section": "Choosing Bin Width: Critical Decision",
    "text": "Choosing Bin Width: Critical Decision\nBin width dramatically affects histogram interpretation!\nToo Few Bins (Wide bins):\n\nOversmoothing - lose important details\nMay hide multimodality\nDistribution appears simpler than it is\n\nToo Many Bins (Narrow bins):\n\nUndersmoothing - too much noise\nMay create artificial gaps\nHard to see overall pattern"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#bin-width-guidelines",
    "href": "files/lecture_notes/lecture3/lecture3.html#bin-width-guidelines",
    "title": "Descriptive Statistics Part II",
    "section": "Bin Width Guidelines",
    "text": "Bin Width Guidelines\nRule of Thumb Methods:\n\nSquare Root Rule: Number of bins ≈ \\(\\sqrt{n}\\)\nSturges’ Rule: Number of bins = \\(1 + \\log_2(n)\\)\nScott’s Rule: Bin width = \\(\\frac{3.5 \\times \\text{SD}}{n^{1/3}}\\)\nFreedman-Diaconis Rule: Bin width = \\(\\frac{2 \\times \\text{IQR}}{n^{1/3}}\\)\n\nBest practice: Try multiple bin widths and choose based on the story your data tells!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-histogram-examples",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-histogram-examples",
    "title": "Descriptive Statistics Part II",
    "section": "Python Histogram Examples",
    "text": "Python Histogram Examples\n\nCodeVisualization\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate sample data\nnp.random.seed(42)\ndata = np.random.normal(100, 15, 1000)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#interpreting-histograms",
    "href": "files/lecture_notes/lecture3/lecture3.html#interpreting-histograms",
    "title": "Descriptive Statistics Part II",
    "section": "Interpreting Histograms",
    "text": "Interpreting Histograms\nWhat to Look For:\n\nShape: Normal, skewed, uniform, bimodal?\nCenter: Where is the “typical” value?\nSpread: How variable is the data?\nOutliers: Any unusual values?\nGaps: Are there missing values in certain ranges?\nMultiple peaks: Suggests multiple subgroups"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#anatomy-of-a-boxplot",
    "href": "files/lecture_notes/lecture3/lecture3.html#anatomy-of-a-boxplot",
    "title": "Descriptive Statistics Part II",
    "section": "Anatomy of a Boxplot",
    "text": "Anatomy of a Boxplot"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#boxplot-components-explained",
    "href": "files/lecture_notes/lecture3/lecture3.html#boxplot-components-explained",
    "title": "Descriptive Statistics Part II",
    "section": "Boxplot Components Explained",
    "text": "Boxplot Components Explained\nThe Box:\n\nLeft edge: Q1 (25th percentile)\nMiddle line: Median (Q2, 50th percentile)\n\nRight edge: Q3 (75th percentile)\nBox width: IQR (contains middle 50% of data)\n\nThe Whiskers:\n\nExtend to: Most extreme values within 1.5 × IQR from box edges\nLower whisker: Minimum value within Q1 - 1.5×IQR\nUpper whisker: Maximum value within Q3 + 1.5×IQR"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-boxplots-tell-us",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-boxplots-tell-us",
    "title": "Descriptive Statistics Part II",
    "section": "What Boxplots Tell Us",
    "text": "What Boxplots Tell Us\nDistribution Shape:\n\nSymmetric: Median in center of box, whiskers equal length\nRight-skewed: Median closer to Q1, longer upper whisker\nLeft-skewed: Median closer to Q3, longer lower whisker\n\nVariability:\n\nWide box: High variability in middle 50%\nLong whiskers: High overall variability\nMany outliers: Extreme variability"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#comparing-groups-with-boxplots",
    "href": "files/lecture_notes/lecture3/lecture3.html#comparing-groups-with-boxplots",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Groups with Boxplots",
    "text": "Comparing Groups with Boxplots"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#advanced-boxplot-interpretations",
    "href": "files/lecture_notes/lecture3/lecture3.html#advanced-boxplot-interpretations",
    "title": "Descriptive Statistics Part II",
    "section": "Advanced Boxplot Interpretations",
    "text": "Advanced Boxplot Interpretations"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#comparing-boxplots",
    "href": "files/lecture_notes/lecture3/lecture3.html#comparing-boxplots",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Boxplots:",
    "text": "Comparing Boxplots:\n\nMedian differences: Which group has higher typical values?\nIQR differences: Which group is more consistent?\nOutlier patterns: Which group has more extreme values?\nOverlap: Do the groups have similar ranges?"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#business-applications",
    "href": "files/lecture_notes/lecture3/lecture3.html#business-applications",
    "title": "Descriptive Statistics Part II",
    "section": "Business Applications:",
    "text": "Business Applications:\n\nQuality control: Compare product batches\nPerformance analysis: Compare team/department performance\n\nCustomer segmentation: Compare customer groups"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#common-patterns-in-data",
    "href": "files/lecture_notes/lecture3/lecture3.html#common-patterns-in-data",
    "title": "Descriptive Statistics Part II",
    "section": "Common Patterns in Data",
    "text": "Common Patterns in Data\nDistribution Patterns:\n\nNormal/Bell-shaped: Symmetric, single peak\nUniform: All values equally likely\nBimodal: Two distinct peaks (suggests subgroups)\nMultimodal: Multiple peaks\nU-shaped: High values at extremes, low in middle\n\nOutlier Patterns:\n\nIndividual outliers: Data entry errors, measurement errors\nClustered outliers: Distinct subpopulation\nSystematic outliers: May indicate process changes"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#red-flags-in-data-visualization",
    "href": "files/lecture_notes/lecture3/lecture3.html#red-flags-in-data-visualization",
    "title": "Descriptive Statistics Part II",
    "section": "Red Flags in Data Visualization",
    "text": "Red Flags in Data Visualization\nWarning Signs:\n\nGaps in histograms: Missing data or measurement limitations\nHeaping: Values cluster at round numbers (10, 50, 100)\nTruncation: Data cut off at certain values\nDigit preference: People prefer certain ending digits\nMultiple modes: Hidden subgroups in your data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#essential-concepts-to-remember",
    "href": "files/lecture_notes/lecture3/lecture3.html#essential-concepts-to-remember",
    "title": "Descriptive Statistics Part II",
    "section": "Essential Concepts to Remember",
    "text": "Essential Concepts to Remember\nVariability:\n\nStandard deviation is preferred over range for most analyses\nCV allows comparison across different scales\nIQR is resistant to outliers\n\nPosition:\n\nPercentiles and quartiles provide relative position\nZ-scores standardize across different distributions\nFive-number summary gives complete overview"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practical-guidelines",
    "href": "files/lecture_notes/lecture3/lecture3.html#practical-guidelines",
    "title": "Descriptive Statistics Part II",
    "section": "Practical Guidelines",
    "text": "Practical Guidelines\n\nAlways visualize before calculating statistics\nUse multiple measures - no single statistic tells the whole story\nConsider the context - what makes sense for your data?\nCheck for outliers - they can drastically affect your analysis\nCompare distributions using standardized measures when appropriate"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#try-these-exercises",
    "href": "files/lecture_notes/lecture3/lecture3.html#try-these-exercises",
    "title": "Descriptive Statistics Part II",
    "section": "Try These Exercises",
    "text": "Try These Exercises\n\nCalculate the five-number summary for: 12, 15, 18, 22, 25, 28, 30, 35, 40, 45\nCreate histograms with 5, 15, and 50 bins for the same dataset. What patterns do you observe?\nInterpret this scenario: Dataset A has mean=50, SD=5. Dataset B has mean=100, SD=10. Which is more variable?\nA student scores 85 on a test where the class mean is 78 and SD is 6. Calculate and interpret the z-score.\nDesign a boxplot comparison for three different customer segments in your business."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#additional-resources",
    "href": "files/lecture_notes/lecture3/lecture3.html#additional-resources",
    "title": "Descriptive Statistics Part II",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nMatplotlib Gallery: Histogram and Boxplot Examples\nExplore examples of histograms, boxplots, and other visualizations using Matplotlib.\nSeaborn Documentation: Statistical Visualizations\nFind examples and documentation for statistical visualizations, including distribution plots, categorical plots, and regression plots.\nNumPy Statistical Functions Reference\nOfficial reference for NumPy’s statistical functions such as mean, median, variance, and standard deviation.\nSciPy Statistical Functions Reference\nComprehensive documentation for statistical functions in scipy.stats, including probability distributions, hypothesis tests, and descriptive statistics.\nRecommended reading: Continue reading Chapter 2 in course textbook"
  },
  {
    "objectID": "files/labs/lab1/lab1.html",
    "href": "files/labs/lab1/lab1.html",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Welcome to the first PSTAT 5A Lab! As we will soon learn, computers play an integral part in effectively and efficiently performing statistical analyses. The primary goal of these Labs is to develop the skills to communicate with computers and learn the basic principles and language of programming.\nThis first lab will introduce you to the JupyterHub environment, Python as a programming language, and some basic concepts of programming. You will also complete a series of tasks to familiarize yourself with the tools and concepts we will use throughout the course.\nThis lab is designed to be completed during your first lab section of the week, and it will set the foundation for the rest of the course. Make sure to read through all the material carefully, as it will be essential for your success in PSTAT 5A."
  },
  {
    "objectID": "files/labs/lab1/lab1.html#structure-of-labs",
    "href": "files/labs/lab1/lab1.html#structure-of-labs",
    "title": "PSTAT 5A Lab 1",
    "section": "Structure of Labs",
    "text": "Structure of Labs\nEvery week we (the course staff) will publish a lab document, which is intended to be completed during your Lab Section (i.e., your first Section) of the week. Each lab document will consist of a combination of text, tips, and the occasional task for you to complete based on the text provided. Your TA will cover exactly what you need to turn in at the end of each lab in order to receive credit, but you should read all lab material carefully and thoroughly as content from labs will appear on quizzes and exams."
  },
  {
    "objectID": "files/labs/lab1/lab1.html#what-is-programming",
    "href": "files/labs/lab1/lab1.html#what-is-programming",
    "title": "PSTAT 5A Lab 1",
    "section": "What Is Programming?",
    "text": "What Is Programming?\nComputers, though incredibly useful, are fairly complex machines. To communicate with them, we need to use a specific language, known as a programming language. There are a number of programming languages currently in use—R, Julia, MatLab, and the language we will use for this course, Python.\nPython programs can be written in many environments (e.g., text editors like VS Code or in a Terminal window). For this class we will use Jupyter Notebook (pronounced “Jew-pi-ter”), an interactive environment that’s hosted online so you don’t have to install anything to run Python code!"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#getting-started",
    "href": "files/labs/lab1/lab1.html#getting-started",
    "title": "PSTAT 5A Lab 1",
    "section": "Getting Started",
    "text": "Getting Started\n\nNavigate to https://pstat5a.lsit.ucsb.edu\n\nIf you are using a personal computer, you may want to bookmark this page for easy access later.\n\nClick Sign in with your UCSB NetID, and sign in.\n\nNavigate to the Labs folder on the left-hand side of the JupyterHub interface. \nUnder Notebook, click Python 3 (ipykernel).\n\n\nCongratulations, you have just made your first Jupyter notebook! Now, it’s time for our first task:"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-1-rename-your-notebook",
    "href": "files/labs/lab1/lab1.html#task-1-rename-your-notebook",
    "title": "PSTAT 5A Lab 1",
    "section": "Task 1: Rename Your Notebook",
    "text": "Task 1: Rename Your Notebook\n\n\nFind your new notebook in the left-hand file browser (it will be named Untitled or Untitled1 by default).\n\nRight-click the notebook and select → Rename.\n\nRename it to Lab1 and hit Enter.\n\nWatch the title bar update to Lab1.ipynb."
  },
  {
    "objectID": "files/labs/lab1/lab1.html#the-jupyterhub-environment",
    "href": "files/labs/lab1/lab1.html#the-jupyterhub-environment",
    "title": "PSTAT 5A Lab 1",
    "section": "The JupyterHub Environment",
    "text": "The JupyterHub Environment\nJupyter notebooks are built from cells—the shaded boxes you see on screen. Here’s how to work with them:\n\nCell Activation\n\nInactive cell\n\nAppearance: light grey background\n\nAction: click anywhere inside the cell to activate\n\n\nActive cell\n\nAppearance: colored border (green or blue)\n\nYou can now type code or Markdown here.\n\n\n\n\n\n\n\n\nTip\n\n\n\nOnly the active cell runs when you press Run.\n\n\n\n\nRunning Cells\n\nClick the ▶️ Run button in the toolbar\n\nOr press Shift + Enter to run and advance to the next cell"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#cell-types",
    "href": "files/labs/lab1/lab1.html#cell-types",
    "title": "PSTAT 5A Lab 1",
    "section": "Cell Types",
    "text": "Cell Types\nYou can switch any cell between Code and Markdown:\n\nCode Cells\n\nPurpose: write and execute Python code\n\nSelect:\n\nClick the cell\n\nChoose Code from the toolbar dropdown\n\n\n\nRun: ▶️ Run button or Shift + Enter\n\n\n\nMarkdown Cells\n\nPurpose: write formatted text, headings, lists, math, and embed images\n\nSelect:\n\nClick the cell\n\nChoose Markdown from the toolbar dropdown\n\n\nRender: ▶️ Run button or Shift + Enter"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-2-markdown-and-code-cells",
    "href": "files/labs/lab1/lab1.html#task-2-markdown-and-code-cells",
    "title": "PSTAT 5A Lab 1",
    "section": "Task 2: Markdown and Code Cells",
    "text": "Task 2: Markdown and Code Cells\n\n\nClick into the initial cell (marked by [ ] on the left).\n\nIn the toolbar dropdown (that currently says Code), select Markdown.\n\nCopy-paste the following (including the #):\n# Task 2\nRun the cell. You should see a large heading that says “Task 2”.\nAdd a new cell below (use the + button or menu).\nMake sure the new cell is a Code cell.\nEnter the following code and run it:\n2 + 2\n\nExpected Output:\n4"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-3-understanding-errors",
    "href": "files/labs/lab1/lab1.html#task-3-understanding-errors",
    "title": "PSTAT 5A Lab 1",
    "section": "Task 3: Understanding Errors",
    "text": "Task 3: Understanding Errors\n\n\nAdd a new Markdown cell with the heading:\n# Task 3\nAdd a new Code cell and enter the following (intentional error):\n2 plus 2\nRun the cell. You should see an error message like:\n\n  Cell In[2], line 1\n    2 plus 2\n      ^^^^\nSyntaxError: invalid syntax\nExplanation: - Python doesn’t understand plus as an operator - The ^^^^ points to where Python detected the problem - The error message tells us it’s a SyntaxError meaning invalid Python syntax - In Python, we must use + for addition, not the word plus\n\nCorrect the code to:\n2 + 2  # This works correctly\nRun the corrected cell. You should see:\n\n4"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-4-math-in-python",
    "href": "files/labs/lab1/lab1.html#task-4-math-in-python",
    "title": "PSTAT 5A Lab 1",
    "section": "Task 4: Math in Python",
    "text": "Task 4: Math in Python\n\n\nIn a new Code cell, compute the following:\n\\(\\frac{2 + 3}{4 + 5^6}\\)\n(2 + 3) / (4 + 5**6)\nBreak it down step by step:\nnumerator = 2 + 3\nprint(f\"Numerator: {numerator}\")\n\ndenominator = 4 + 5**6\nprint(f\"Denominator: {denominator}\")\n\nresult = numerator / denominator\nprint(f\"Final result: {result}\")\n\nExpected Output:\nNumerator: 5\nDenominator: 15629\nFinal result: 0.00032002048131121975\n\nTry this one as well:\n\\((1 - 3 \\cdot 4^5)^6\\)\n(1 - 3 * 4**5)**6\nStep by step:\ninner_exponent = 4**5\nprint(f\"4^5 = {inner_exponent}\")\n\nmultiplication = 3 * inner_exponent\nprint(f\"3 * 4^5 = {multiplication}\")\n\nsubtraction = 1 - multiplication\nprint(f\"1 - 3 * 4^5 = {subtraction}\")\n\nfinal_result = subtraction**6\nprint(f\"(1 - 3 * 4^5)^6 = {final_result}\")\n\nExpected Output:\n4^5 = 1024\n3 * 4^5 = 3072\n1 - 3 * 4^5 = -3071\n(1 - 3 * 4^5)^6 = 729071973630476174071"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-5-importing-modules",
    "href": "files/labs/lab1/lab1.html#task-5-importing-modules",
    "title": "PSTAT 5A Lab 1",
    "section": "Task 5: Importing Modules",
    "text": "Task 5: Importing Modules\n\n\nIn a new Code cell, try running:\nsin(1)\nYou should see:\nNameError: name 'sin' is not defined\nTo fix this, import the math module:\nfrom math import *\nsin(1)\nExpected Output:\n0.8414709848078965\nAlternative ways to import and use sin:\n# Method 1: Import specific function\nfrom math import sin\nprint(sin(1))\n\n# Method 2: Import entire module\nimport math\nprint(math.sin(1))\n\n# Method 3: Import with alias\nimport math as m\nprint(m.sin(1))"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-6-case-sensitivity",
    "href": "files/labs/lab1/lab1.html#task-6-case-sensitivity",
    "title": "PSTAT 5A Lab 1",
    "section": "Task 6: Case Sensitivity",
    "text": "Task 6: Case Sensitivity\n\n\nAssign a value to a variable:\nmy_variable = 5\nTry printing with the wrong capitalization:\nprint(My_variable)\nYou should see:\nNameError: name 'My_variable' is not defined\nPrint with the correct capitalization:\nprint(my_variable)\nOutput:\n5\nTry these examples to see how Python treats variable names:\nmy_variable = 5\nMy_variable = 10\nMY_VARIABLE = 15\nmy_Variable = 20\n\nprint(f\"my_variable = {my_variable}\")\nprint(f\"My_variable = {My_variable}\")\nprint(f\"MY_VARIABLE = {MY_VARIABLE}\")\nprint(f\"my_Variable = {my_Variable}\")\nOutput:\nmy_variable = 5\nMy_variable = 10\nMY_VARIABLE = 15\nmy_Variable = 20"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-7-commenting-code",
    "href": "files/labs/lab1/lab1.html#task-7-commenting-code",
    "title": "PSTAT 5A Lab 1",
    "section": "Task 7: Commenting Code",
    "text": "Task 7: Commenting Code\n\nAdd comments to your code from previous tasks. For example:\n# Task 2: Basic arithmetic\n2 + 2  # Adding two integers\n\n# Task 4: Complex mathematical expression\n# Calculate (2 + 3) / (4 + 5^6)\nnumerator = 2 + 3  # Sum of 2 and 3\ndenominator = 4 + 5**6  # 4 plus 5 to the 6th power\nresult = numerator / denominator  # Final division\nprint(f\"Result: {result}\")\n\n# Task 5: Import math module and use sin function\nfrom math import *  # Import all math functions\nangle_in_radians = 1  # Input angle in radians\nsine_value = sin(angle_in_radians)  # Calculate sine\nprint(f\"sin(1) = {sine_value}\")\n\n# Task 6: Variable assignment with proper naming\nmy_variable = 5  # Store the value 5 in my_variable\nprint(my_variable)  # Display the value\n\n\"\"\"\nThis is a multi-line comment.\nIt can span multiple lines and is useful\nfor longer explanations or documentation.\n\"\"\"\nGood commenting practices: - Explain what the code does - Clarify complex calculations - Document variable purposes - Use both inline (#) and block (\"\"\") comments"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-8-data-types",
    "href": "files/labs/lab1/lab1.html#task-8-data-types",
    "title": "PSTAT 5A Lab 1",
    "section": "Task 8: Data Types",
    "text": "Task 8: Data Types\n\n\nUse the type() function to check data types:\nprint(type(1))           # Output: &lt;class 'int'&gt;\nprint(type(1.1))         # Output: &lt;class 'float'&gt;\nprint(type(\"hello\"))     # Output: &lt;class 'str'&gt;\nTry more examples:\nprint(\"Integer:\", type(42))\nprint(\"Float:\", type(3.14159))\nprint(\"String with single quotes:\", type('Python'))\nprint(\"String with double quotes:\", type(\"Programming\"))\nprint(\"Boolean True:\", type(True))\nprint(\"Boolean False:\", type(False))\nprint(\"List:\", type([1, 2, 3]))\nprint(\"Tuple:\", type((1, 2, 3)))\nprint(\"Dictionary:\", type({\"key\": \"value\"}))"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-9-variables-and-calculations",
    "href": "files/labs/lab1/lab1.html#task-9-variables-and-calculations",
    "title": "PSTAT 5A Lab 1",
    "section": "Task 9: Variables and Calculations",
    "text": "Task 9: Variables and Calculations\n\n\nAdd a Markdown cell:\n# Task 9\nAssign values to variables:\ncourse = \"PSTAT 5A\"\nnum_sections = 4\nsection_capacity = 25\nUpdate num_sections:\nnum_sections = num_sections + 1\nprint(f\"Updated number of sections: {num_sections}\")\n# Alternative: num_sections += 1\n# Alternative: num_sections = 4 + 1\nPredict and test expressions:\nprint(type(course))           # Expected: &lt;class 'str'&gt;\nprint(type(num_sections))     # Expected: &lt;class 'int'&gt;\nprint(num_sections * section_capacity) # Expected: 125\nCalculate course capacity:\ncourse_capacity = num_sections * section_capacity\nprint(f\"Course: {course}\")\nprint(f\"Number of sections: {num_sections}\")\nprint(f\"Capacity per section: {section_capacity}\")\nprint(f\"Total course capacity: {course_capacity}\")\nComplete solution with comments:\n# Step 2: Initial variable assignments\ncourse = \"PSTAT 5A\"          # Course name as string\nnum_sections = 4             # Initial number of sections\nsection_capacity = 25        # Maximum students per section\n\n# Step 3: A new section has been added\nnum_sections = num_sections + 1  # Increment by 1, now equals 5\n\n# Step 4: Testing expressions with predictions\nprint(\"Testing type() function:\")\nprint(f\"type(course) = {type(course)}\")  # Expected: &lt;class 'str'&gt;\nprint(f\"type(num_sections) = {type(num_sections)}\")  # Expected: &lt;class 'int'&gt;\nprint(f\"num_sections * section_capacity = {num_sections * section_capacity}\")  # Expected: 125\n\n# Step 5: Calculate total course capacity\ncourse_capacity = num_sections * section_capacity  # 5 × 25 = 125\nprint(f\"\\nFinal Results:\")\nprint(f\"Course: {course}\")\nprint(f\"Total sections: {num_sections}\")\nprint(f\"Capacity per section: {section_capacity}\")\nprint(f\"Total course capacity: {course_capacity} students\")"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#summary-of-key-concepts-learned",
    "href": "files/labs/lab1/lab1.html#summary-of-key-concepts-learned",
    "title": "PSTAT 5A Lab 1",
    "section": "Summary of Key Concepts Learned",
    "text": "Summary of Key Concepts Learned\n\nJupyterHub Environment: Creating and renaming notebooks, understanding cell types (Code vs Markdown), running cells, navigating the interface\nPython Basics: Arithmetic operations, order of operations, error reading\nVariables and Data Types: Assignment, case sensitivity, types, type()\nModules and Imports: Import syntax, using functions, math module\nComments and Documentation: Inline and block comments, purpose\nProgramming Best Practices: Descriptive variable names, comments, incremental testing, reading errors, using variables"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#next-steps",
    "href": "files/labs/lab1/lab1.html#next-steps",
    "title": "PSTAT 5A Lab 1",
    "section": "Next Steps",
    "text": "Next Steps\nIn Lab 2, you’ll learn about: - Python functions and how to create them - Data structures (lists, dictionaries) - Control flow (if statements, loops) - More advanced programming concepts\nGreat work completing Lab 1! You now have the foundation needed for statistical programming in Python."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSTAT 5A: Understanding Data",
    "section": "",
    "text": "Learn the fundamentals of data science and statistical thinking\n\n\nSummer Session A 2025 • Taught by Narjes Mathlouthi\n\n\n\n\n6\n\n\nWeeks\n\n\n\n\n20+\n\n\nTopics\n\n\n\n\n100+\n\n\nResources\n\n\n\nGet Started →"
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Course Overview",
    "text": "Course Overview\n\nTransform raw data into meaningful insights through hands-on learning and real-world applications"
  },
  {
    "objectID": "index.html#quick-navigation",
    "href": "index.html#quick-navigation",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Quick Navigation",
    "text": "Quick Navigation\n\nEverything you need for the course, organized and accessible"
  },
  {
    "objectID": "files/labs/lab1/lab1_sln.html#task-1-solution",
    "href": "files/labs/lab1/lab1_sln.html#task-1-solution",
    "title": "PSTAT 5A Lab 1 - SOLUTIONS",
    "section": "Task 1 Solution",
    "text": "Task 1 Solution\n\nObjective: Rename your notebook from Untitled to Lab1\nSteps:\n\nLocated the notebook in the file browser (appears as Untitled.ipynb)\nRight-clicked on the notebook name\nSelected “Rename” from the context menu\nChanged the name to Lab1\nPressed Enter to confirm\nVerified the title bar now shows Lab1.ipynb\n\nExpected Result:\nYour notebook should now be named Lab1.ipynb and this should be visible in both the file browser and the title bar."
  },
  {
    "objectID": "files/labs/lab1/lab1_sln.html#task-2-solution",
    "href": "files/labs/lab1/lab1_sln.html#task-2-solution",
    "title": "PSTAT 5A Lab 1 - SOLUTIONS",
    "section": "Task 2 Solution",
    "text": "Task 2 Solution\n\nObjective: Create a Markdown cell with heading and a Code cell with basic arithmetic\nMarkdown Cell:\n# Task 2\nCode Cell:\n\n2 + 2\n\n4\n\n\nExpected Result:\n\nThe code cell executes the arithmetic operation\nPython displays the result 4 below the cell\nA new empty code cell automatically appears below\nThe cell is marked as executed with a number like [1]"
  },
  {
    "objectID": "files/labs/lab1/lab1_sln.html#task-3-solution",
    "href": "files/labs/lab1/lab1_sln.html#task-3-solution",
    "title": "PSTAT 5A Lab 1 - SOLUTIONS",
    "section": "Task 3 Solution",
    "text": "Task 3 Solution\n\nObjective: Demonstrate syntax error and understand error messages\nMarkdown Cell:\n# Task 3\nCode Cell with Intentional Error:\n\n2 plus 2\n\nExpected Error Output:\n  Cell In[2], line 1\n    2 plus 2\n      ^^^^\nSyntaxError: invalid syntax\nExplanation:\n\nPython doesn’t understand plus as an operator\nThe ^^^^ points to where Python detected the problem\nThe error message tells us it’s a SyntaxError meaning invalid Python syntax\nIn Python, we must use + for addition, not the word plus\n\nCorrected Version:\n\n2 + 2  # This works correctly\n\n4"
  },
  {
    "objectID": "files/labs/lab1/lab1_sln.html#task-4-solution",
    "href": "files/labs/lab1/lab1_sln.html#task-4-solution",
    "title": "PSTAT 5A Lab 1 - SOLUTIONS",
    "section": "Task 4 Solution",
    "text": "Task 4 Solution\n\nObjective: Compute mathematical expressions using Python**\nProblem 1: \\(\\frac{2 + 3}{4 + 5^6}\\)\nPython Code:\n\n(2 + 3) / (4 + 5**6)\n\n0.0003199181009661527\n\n\nStep by Step:\n\nnumerator = 2 + 3\nprint(f\"Numerator: {numerator}\")\n\ndenominator = 4 + 5**6\nprint(f\"Denominator: {denominator}\")\n\nresult = numerator / denominator\nprint(f\"Final result: {result}\")\n\nNumerator: 5\nDenominator: 15629\nFinal result: 0.0003199181009661527\n\n\nProblem 2: \\((1 - 3 \\cdot 4^5)^6\\)\nPython Code:\n\n(1 - 3 * 4**5)**6\n\n838839550121163601921\n\n\nStep by Step:\n\ninner_exponent = 4**5\nprint(f\"4^5 = {inner_exponent}\")\n\nmultiplication = 3 * inner_exponent\nprint(f\"3 * 4^5 = {multiplication}\")\n\nsubtraction = 1 - multiplication\nprint(f\"1 - 3 * 4^5 = {subtraction}\")\n\nfinal_result = subtraction**6\nprint(f\"(1 - 3 * 4^5)^6 = {final_result}\")\n\n4^5 = 1024\n3 * 4^5 = 3072\n1 - 3 * 4^5 = -3071\n(1 - 3 * 4^5)^6 = 838839550121163601921"
  },
  {
    "objectID": "files/labs/lab1/lab1_sln.html#task-5-solution",
    "href": "files/labs/lab1/lab1_sln.html#task-5-solution",
    "title": "PSTAT 5A Lab 1 - SOLUTIONS",
    "section": "Task 5 Solution",
    "text": "Task 5 Solution\n\nObjective: Understand module importing and fix NameError\nStep 1: Code that produces error\n\nsin(1)\n\nExpected Error:\nNameError: name 'sin' is not defined\nExplanation: Python doesn’t recognize sin because the math functions aren’t loaded by default.\nStep 2: Import module and retry\n\nfrom math import *\nsin(1)\n\n0.8414709848078965\n\n\nAlternative Solutions:\n\n# Method 1: Import specific function\nfrom math import sin\nprint(sin(1))\n\n# Method 2: Import entire module\nimport math\nprint(math.sin(1))\n\n# Method 3: Import with alias\nimport math as m\nprint(m.sin(1))\n\n0.8414709848078965\n0.8414709848078965\n0.8414709848078965\n\n\nAll produce the same result: 0.8414709848078965"
  },
  {
    "objectID": "files/labs/lab1/lab1_sln.html#task-6-solution",
    "href": "files/labs/lab1/lab1_sln.html#task-6-solution",
    "title": "PSTAT 5A Lab 1 - SOLUTIONS",
    "section": "Task 6 Solution",
    "text": "Task 6 Solution\n\nObjective: Understand Python case sensitivity\nStep 1: Variable assignment\n\nmy_variable = 5\n\nStep 2: Wrong capitalization\n\nprint(My_variable)\n\nExpected Error:\nNameError: name 'My_variable' is not defined\nExplanation: Python is case-sensitive, so My_variable ≠ my_variable\nStep 3: Correct capitalization\n\nprint(my_variable)\n\n5\n\n\nAdditional Examples:\n\n# These are all different variables in Python\nmy_variable = 5\nMy_variable = 10\nMY_VARIABLE = 15\nmy_Variable = 20\n\nprint(f\"my_variable = {my_variable}\")\nprint(f\"My_variable = {My_variable}\")\nprint(f\"MY_VARIABLE = {MY_VARIABLE}\")\nprint(f\"my_Variable = {my_Variable}\")\n\nmy_variable = 5\nMy_variable = 10\nMY_VARIABLE = 15\nmy_Variable = 20"
  },
  {
    "objectID": "files/labs/lab1/lab1_sln.html#task-7-solution",
    "href": "files/labs/lab1/lab1_sln.html#task-7-solution",
    "title": "PSTAT 5A Lab 1 - SOLUTIONS",
    "section": "Task 7 Solution",
    "text": "Task 7 Solution\n\nObjective: Add descriptive comments to previous code\nExamples of well-commented code from previous tasks:\n\n# Task 2: Basic arithmetic\n2 + 2  # Adding two integers\n\n# Task 4: Complex mathematical expression\n# Calculate (2 + 3) / (4 + 5^6)\nnumerator = 2 + 3  # Sum of 2 and 3\ndenominator = 4 + 5**6  # 4 plus 5 to the 6th power\nresult = numerator / denominator  # Final division\nprint(f\"Result: {result}\")\n\n# Task 5: Import math module and use sin function\nfrom math import *  # Import all math functions\nangle_in_radians = 1  # Input angle in radians\nsine_value = sin(angle_in_radians)  # Calculate sine\nprint(f\"sin(1) = {sine_value}\")\n\n# Task 6: Variable assignment with proper naming\nmy_variable = 5  # Store the value 5 in my_variable\nprint(my_variable)  # Display the value\n\n\"\"\"\nThis is a multi-line comment.\nIt can span multiple lines and is useful\nfor longer explanations or documentation.\n\"\"\"\n\nGood commenting practices demonstrated:\n\nExplain what the code does\nClarify complex calculations\nDocument variable purposes\nUse both inline (#) and block (\"\"\") comments"
  },
  {
    "objectID": "files/labs/lab1/lab1_sln.html#task-8-solution",
    "href": "files/labs/lab1/lab1_sln.html#task-8-solution",
    "title": "PSTAT 5A Lab 1 - SOLUTIONS",
    "section": "Task 8 Solution",
    "text": "Task 8 Solution\n\nObjective: Explore Python data types using the type() function\nCode and Expected Outputs:\n\nprint(type(1))           # Output: &lt;class 'int'&gt;\nprint(type(1.1))         # Output: &lt;class 'float'&gt;\nprint(type(\"hello\"))     # Output: &lt;class 'str'&gt;\n\n&lt;class 'int'&gt;\n&lt;class 'float'&gt;\n&lt;class 'str'&gt;\n\n\nAdditional Examples:\n\n# More data type examples\nprint(\"Integer:\", type(42))\nprint(\"Float:\", type(3.14159))\nprint(\"String with single quotes:\", type('Python'))\nprint(\"String with double quotes:\", type(\"Programming\"))\nprint(\"Boolean True:\", type(True))\nprint(\"Boolean False:\", type(False))\nprint(\"List:\", type([1, 2, 3]))\nprint(\"Tuple:\", type((1, 2, 3)))\nprint(\"Dictionary:\", type({\"key\": \"value\"}))\n\nInteger: &lt;class 'int'&gt;\nFloat: &lt;class 'float'&gt;\nString with single quotes: &lt;class 'str'&gt;\nString with double quotes: &lt;class 'str'&gt;\nBoolean True: &lt;class 'bool'&gt;\nBoolean False: &lt;class 'bool'&gt;\nList: &lt;class 'list'&gt;\nTuple: &lt;class 'tuple'&gt;\nDictionary: &lt;class 'dict'&gt;"
  },
  {
    "objectID": "files/labs/lab1/lab1_sln.html#task-9-solution",
    "href": "files/labs/lab1/lab1_sln.html#task-9-solution",
    "title": "PSTAT 5A Lab 1 - SOLUTIONS",
    "section": "Task 9 Solution",
    "text": "Task 9 Solution\n\nObjective: Practice variable assignment, updating, and calculations\nMarkdown cell:\n# Task 9\nStep 2: Initial variable assignments\n\ncourse = \"PSTAT 5A\"\nnum_sections = 4\nsection_capacity = 25\n\nStep 3: Update num_sections (correct approach)\n\nnum_sections = num_sections + 1\nprint(f\"Updated number of sections: {num_sections}\")\n# Alternative: num_sections += 1\n# Alternative: num_sections = 4 + 1\n\nUpdated number of sections: 5\n\n\nStep 4: Predict and test expressions\n\nprint(type(course))           # Expected: &lt;class 'str'&gt;\nprint(type(num_sections))     # Expected: &lt;class 'int'&gt;\nprint(num_sections * section_capacity) # Expected: 125\n\n&lt;class 'str'&gt;\n&lt;class 'int'&gt;\n125\n\n\nStep 5: Calculate course capacity\n\ncourse_capacity = num_sections * section_capacity\nprint(f\"Course: {course}\")\nprint(f\"Number of sections: {num_sections}\")\nprint(f\"Capacity per section: {section_capacity}\")\nprint(f\"Total course capacity: {course_capacity}\")\n\nCourse: PSTAT 5A\nNumber of sections: 5\nCapacity per section: 25\nTotal course capacity: 125\n\n\nComplete Solution with Comments:\n\n# Step 2: Initial variable assignments\ncourse = \"PSTAT 5A\"          # Course name as string\nnum_sections = 4             # Initial number of sections\nsection_capacity = 25        # Maximum students per section\n\n# Step 3: A new section has been added\nnum_sections = num_sections + 1  # Increment by 1, now equals 5\n\n# Step 4: Testing expressions with predictions\nprint(\"Testing type() function:\")\nprint(f\"type(course) = {type(course)}\")  # Expected: &lt;class 'str'&gt;\nprint(f\"type(num_sections) = {type(num_sections)}\")  # Expected: &lt;class 'int'&gt;\nprint(f\"num_sections * section_capacity = {num_sections * section_capacity}\")  # Expected: 125\n\n# Step 5: Calculate total course capacity\ncourse_capacity = num_sections * section_capacity  # 5 × 25 = 125\nprint(f\"\\nFinal Results:\")\nprint(f\"Course: {course}\")\nprint(f\"Total sections: {num_sections}\")\nprint(f\"Capacity per section: {section_capacity}\")\nprint(f\"Total course capacity: {course_capacity} students\")\n\nTesting type() function:\ntype(course) = &lt;class 'str'&gt;\ntype(num_sections) = &lt;class 'int'&gt;\nnum_sections * section_capacity = 125\n\nFinal Results:\nCourse: PSTAT 5A\nTotal sections: 5\nCapacity per section: 25\nTotal course capacity: 125 students"
  },
  {
    "objectID": "files/labs/lab1/lab1_sln.html#summary-of-key-concepts-learned",
    "href": "files/labs/lab1/lab1_sln.html#summary-of-key-concepts-learned",
    "title": "PSTAT 5A Lab 1 - SOLUTIONS",
    "section": "Summary of Key Concepts Learned",
    "text": "Summary of Key Concepts Learned\n✅ JupyterHub Environment\n\nCreating and renaming notebooks\nUnderstanding cell types (Code vs Markdown)\nRunning cells with ▶️ button or Shift+Enter\nNavigating the interface\n\n✅ Python Basics\n\nArithmetic operations: +, -, *, /, **\nOrder of operations: Parentheses, Exponents, Multiplication/Division, Addition/Subtraction\nError reading: Understanding SyntaxError and NameError messages\n\n✅ Variables and Data Types\n\nVariable assignment: variable_name = value\nCase sensitivity: my_var ≠ My_var\nBasic types: int, float, str, bool\nType checking: type() function\n\n✅ Modules and Imports\n\nImport syntax: from module import * or import module\nUsing functions: After importing, functions become available\nMath module: Contains mathematical functions like sin(), cos(), etc.\n\n✅ Comments and Documentation\n\nInline comments: # This is a comment\nBlock comments: \"\"\"Multi-line comment\"\"\"\nPurpose: Document code for yourself and others\n\n✅ Programming Best Practices\n\nWrite descriptive variable names\nAdd comments to explain complex logic\nTest your code incrementally\nRead and understand error messages\nUse existing variables in calculations when possible"
  },
  {
    "objectID": "files/labs/lab1/lab1_sln.html#next-steps",
    "href": "files/labs/lab1/lab1_sln.html#next-steps",
    "title": "PSTAT 5A Lab 1 - SOLUTIONS",
    "section": "Next Steps",
    "text": "Next Steps\nIn Lab 2, you’ll learn about:\n\nPython functions and how to create them\nData structures (lists, dictionaries)\nControl flow (if statements, loops)\nMore advanced programming concepts\n\nGreat work completing Lab 1! You now have the foundation needed for statistical programming in Python."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Get in Touch\n\nWe’re here to help you succeed in PSTAT 5A\n\n\n\n\n\n\nNM\n\n\nCourse Instructor\n\n\nNarjes Mathlouthi\n\n\n\n\n📧\n\n\nnmathlouthi@ucsb.edu\n\n\n\n\n🏢\n\n\nEllison Hall 5829\n\n\n\n\n🕐\n\n\nThursdays 11:00 AM–12:00 PM\n\n\n\n\n💻\n\n\nVia Zoom or by appointment\n\n\n\n\n\n\nSL\n\n\nTeaching Assistant\n\n\nSummer Le\n\n\n\n\n📧\n\n\nsle@ucsb.edu\n\n\n\n\n🕐\n\n\nFriday 1:00 PM – 2:00 PM\n\n\n\n\n💻\n\n\nVia Zoom (links on Canvas)\n\n\n\n\n\n\n\nMH\n\n\nTeaching Assistant\n\n\nMingzhu He\n\n\n\n\n📧\n\n\nmingzhuhe@ucsb.edu\n\n\n\n\n🕐\n\n\nTuesday 11:00 AM – 12:00 PM\n\n\n\n\n💻\n\n\nVia Zoom (links on Canvas)\n\n\n\n\n\n\n\nInstructor Office Hours\n\n\nThursdays 11:00 AM – 12:00 PM\n\n\nAvailable via Zoom or by appointment  Zoom links posted on Canvas\n\n\n\n\n\nCommunication Guidelines\n\n\n\n1\n\n\nSubject Line: Always include [PSTAT 5A] in your email subject for faster response\n\n\n\n\n2\n\n\nResponse Time: Allow 24–48 hours for replies (avoid sending on weekends)\n\n\n\n\n3\n\n\nUse UCSB Email: Always email from your UCSB account for verification\n\n\n\n\n4\n\n\nOffice Hours: Use office hours for complex questions or detailed help\n\n\n\n\n5\n\n\nUrgent Matters: For time-sensitive issues, mention “URGENT” in the subject line\n\n\n\n\n\n\nEmergency Contacts\n\n\nFor campus emergencies: 911 • For student crisis support: CAPS 24/7 line (805) 893-4411"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#task-1-solutions",
    "href": "files/labs/lab3/lab3_sln.html#task-1-solutions",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Task 1 Solutions",
    "text": "Task 1 Solutions\n\nTask 1 Solutions:\n\nImport the numpy module as np, and check that np.sin(0) returns a value of 0.\nImport the datascience module as ds, and check the table creation works correctly.\n\n\n\n# Solution to Task 1\n\n# Part 1: Import numpy and test sin function\nimport numpy as np\nprint(\"np.sin(0) =\", np.sin(0))\n\n# Part 2: Import datascience and test table creation\nimport datascience as ds\n\ntable_result = ds.Table().with_columns(\n    \"Col1\", [1, 2, 3],\n    \"Col2\", [2, 3, 4]\n)\nprint(table_result)\n\nnp.sin(0) = 0.0\nCol1 | Col2\n1    | 2\n2    | 3\n3    | 4"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#task-2-solutions",
    "href": "files/labs/lab3/lab3_sln.html#task-2-solutions",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Task 2 Solutions",
    "text": "Task 2 Solutions\n\nTask 2 Solutions: Create x_list and x_array containing elements 1, 2, and 3, then compute mean and median.\n\n\n# Solution to Task 2\n\n# Create x_list as a regular Python list\nx_list = [1, 2, 3]\n\n# Create x_array as a numpy array\nx_array = np.array([1, 2, 3])\n\n# Compute mean and median for x_list\nprint(\"x_list mean:\", np.mean(x_list))\nprint(\"x_list median:\", np.median(x_list))\n\n# Compute mean and median for x_array\nprint(\"x_array mean:\", np.mean(x_array))\nprint(\"x_array median:\", np.median(x_array))\n\n# Verify they give the same results\nprint(\"\\nBoth give the same results!\")\n\nx_list mean: 2.0\nx_list median: 2.0\nx_array mean: 2.0\nx_array median: 2.0\n\nBoth give the same results!"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#task-3-solutions",
    "href": "files/labs/lab3/lab3_sln.html#task-3-solutions",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Task 3 Solutions",
    "text": "Task 3 Solutions\n\nTask 3 Solutions: Look up np.ptp() function and apply it to the data.\n\nAnswer: The np.ptp() function computes the range of values (maximum - minimum) along an axis. PTP stands for “Peak To Peak” - the difference between the maximum peak and minimum peak values.\n\n# Solution to Task 3\n\n# Apply np.ptp() to x_list and x_array from Task 2\nprint(\"Range of x_list using np.ptp():\", np.ptp(x_list))\nprint(\"Range of x_array using np.ptp():\", np.ptp(x_array))\n\n# Manual verification: max - min\nprint(\"Manual calculation: max - min =\", max(x_list) - min(x_list))\n\n# Both should give the same result: 3 - 1 = 2\n\nRange of x_list using np.ptp(): 2\nRange of x_array using np.ptp(): 2\nManual calculation: max - min = 2"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#task-4-solutions",
    "href": "files/labs/lab3/lab3_sln.html#task-4-solutions",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Task 4 Solutions",
    "text": "Task 4 Solutions\n\nTask 4 Solutions: Compute standard deviation by hand and compare with np.std() function.\n\n\n# Solution to Task 4\n\nx_list = [1, 2, 3]  # From Task 2\n\n# Part (a): Calculate sample standard deviation by hand (using n-1)\n# Mean = (1 + 2 + 3) / 3 = 2\nmean_x = 2\n\n# Sample variance = [(1-2)² + (2-2)² + (3-2)²] / (3-1)\n# = [1 + 0 + 1] / 2 = 2/2 = 1\nsample_variance = ((1-2)**2 + (2-2)**2 + (3-2)**2) / (3-1)\nsample_std = np.sqrt(sample_variance)\n\nprint(\"Sample standard deviation (by hand):\", sample_std)\nprint(\"Sample standard deviation (by hand):\", np.sqrt(1))  # Should be 1.0\n\n# Part (b): Compare with np.std(x_list)\nprint(\"np.std(x_list) default:\", np.std(x_list))\nprint(\"Does this match part (a)?\", np.isclose(sample_std, np.std(x_list)))\n\n# Part (c): Calculate population standard deviation by hand (using n)\n# Population variance = [(1-2)² + (2-2)² + (3-2)²] / 3\n# = [1 + 0 + 1] / 3 = 2/3\npopulation_variance = ((1-2)**2 + (2-2)**2 + (3-2)**2) / 3\npopulation_std = np.sqrt(population_variance)\n\nprint(\"Population standard deviation (by hand):\", population_std)\nprint(\"This matches np.std(x_list):\", np.isclose(population_std, np.std(x_list)))\n\n# Part (d): Use ddof=1 to get sample standard deviation\nprint(\"np.std(x_list, ddof=1):\", np.std(x_list, ddof=1))\nprint(\"This matches part (a):\", np.isclose(sample_std, np.std(x_list, ddof=1)))\n\nSample standard deviation (by hand): 1.0\nSample standard deviation (by hand): 1.0\nnp.std(x_list) default: 0.816496580928\nDoes this match part (a)? False\nPopulation standard deviation (by hand): 0.816496580928\nThis matches np.std(x_list): True\nnp.std(x_list, ddof=1): 1.0\nThis matches part (a): True"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#optional-task-solutions",
    "href": "files/labs/lab3/lab3_sln.html#optional-task-solutions",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Optional Task Solutions",
    "text": "Optional Task Solutions\n\nOptional Task Solutions: Create a custom IQR function.\n\n\n# Solution to Optional Task\n\ndef calculate_iqr(data):\n    \"\"\"\n    Calculate the Interquartile Range (IQR) of a dataset.\n    \n    Parameter:\n    data - a list or array of numbers\n    \n    Returns:\n    The IQR value (Q3 - Q1)\n    \"\"\"\n    # Calculate the IQR using the numpy method we learned\n    iqr_value = np.diff(np.percentile(data, [25, 75]))[0]\n    return iqr_value\n\n# Test the function\ntest_scores = [72, 85, 90, 78, 92, 88, 76, 94, 82, 89, 91, 77]\n\n# Use our custom function\nmy_iqr = calculate_iqr(test_scores)\nprint(f\"IQR using our function: {my_iqr}\")\n\n# Compare with the direct method\ndirect_iqr = np.diff(np.percentile(test_scores, [25, 75]))[0]\nprint(f\"IQR using direct method: {direct_iqr}\")\n\n# They should be the same!\nprint(f\"Results match: {np.isclose(my_iqr, direct_iqr)}\")\n\nIQR using our function: 12.5\nIQR using direct method: 12.5\nResults match: True"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#task-5-solutions",
    "href": "files/labs/lab3/lab3_sln.html#task-5-solutions",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Task 5 Solutions",
    "text": "Task 5 Solutions\n\nTask 5 Solutions: Create boxplots with various customizations.\n\n\n# Solution to Task 5\n\n# Import matplotlib for plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('seaborn-v0_8-whitegrid')\n\n# Step 1: Create the list y\ny = [1, 2, 3, 4, 5, 4, 3, 5, 4, 1, 2]\n\n# Step 2: Create basic vertical boxplot\nplt.figure(figsize=(8, 6))\nplt.subplot(2, 2, 1)\nplt.boxplot(y)\nplt.title(\"Basic Vertical Boxplot\")\n\n# Step 3: Create horizontal boxplot\nplt.subplot(2, 2, 2)\nplt.boxplot(y, orientation='horizontal')\nplt.title(\"Horizontal Boxplot\")\n\n# Step 4: Add color\nplt.subplot(2, 2, 3)\nplt.boxplot(y, orientation='horizontal', patch_artist=True, \n            boxprops=dict(facecolor=\"aquamarine\"))\nplt.title(\"Colored Horizontal Boxplot\")\n\n# Step 5: Final version with title\nplt.subplot(2, 2, 4)\nplt.boxplot(y, orientation='horizontal', patch_artist=True, \n            boxprops=dict(facecolor=\"aquamarine\"))\nplt.title(\"My First Python Boxplot\")\n\nplt.tight_layout()\nplt.show()\n\n# Answer the IQR question\nprint(\"\\nBased on the boxplot:\")\nprint(\"Q1 (25th percentile) appears to be around 2\")\nprint(\"Q3 (75th percentile) appears to be around 4.5\")\nprint(\"So IQR ≈ 4.5 - 2 = 2.5\")\n\n# Verify with Python calculation\niqr_calculated = np.diff(np.percentile(y, [25, 75]))[0]\nprint(f\"\\nActual IQR calculated by Python: {iqr_calculated}\")\n\n\n\n\n\n\n\n\n\nBased on the boxplot:\nQ1 (25th percentile) appears to be around 2\nQ3 (75th percentile) appears to be around 4.5\nSo IQR ≈ 4.5 - 2 = 2.5\n\nActual IQR calculated by Python: 2.0"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#task-6-solutions",
    "href": "files/labs/lab3/lab3_sln.html#task-6-solutions",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Task 6 Solutions",
    "text": "Task 6 Solutions\n\nTask 6 Solutions: Create a histogram with appropriate bins and labels.\n\n\n# Solution to Task 6\n\ny = [1, 2, 3, 4, 5, 4, 3, 5, 4, 1, 2]  # From Task 5\n\n# Create histogram with appropriate bins\nplt.figure(figsize=(10, 6))\n\n# Method 1: Using explicit bin edges\nplt.subplot(1, 2, 1)\nplt.hist(y, bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5], rwidth=0.9, edgecolor='black')\nplt.xlabel('Values')\nplt.ylabel('Frequency')\nplt.title('Histogram of y values (Method 1)')\n\n# Method 2: Using range and bins parameters\nplt.subplot(1, 2, 2)\nplt.hist(y, bins=5, range=(0.5, 5.5), rwidth=0.9, edgecolor='black')\nplt.xlabel('Values')\nplt.ylabel('Frequency')\nplt.title('Histogram of y values (Method 2)')\n\nplt.tight_layout()\nplt.show()\n\n# Show frequency count for verification\nunique, counts = np.unique(y, return_counts=True)\nprint(\"Value frequencies:\")\nfor value, count in zip(unique, counts):\n    print(f\"Value {value}: appears {count} times\")\n\n\n\n\n\n\n\n\nValue frequencies:\nValue 1: appears 2 times\nValue 2: appears 2 times\nValue 3: appears 2 times\nValue 4: appears 3 times\nValue 5: appears 2 times"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#task-7-solutions",
    "href": "files/labs/lab3/lab3_sln.html#task-7-solutions",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Task 7 Solutions",
    "text": "Task 7 Solutions\n\nTask 7 Solutions: Create a scatterplot with proper labels.\n\n\n# Solution to Task 7\n\n# Part 1: Copy and run the provided code\nnp.random.seed(5)\n\nx1 = np.random.normal(0, 1, 100)\nx2 = x1 + np.random.normal(0, 1, 100)\n\nplt.figure(figsize=(8, 6))\nplt.scatter(x1, x2)\n\n# Part 2: Add labels and title\nplt.xlabel('x1')\nplt.ylabel('x2')\nplt.title('My First Python Scatterplot')\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# Additional information about the plot\nprint(f\"Number of points plotted: {len(x1)}\")\nprint(f\"x1 range: {x1.min():.2f} to {x1.max():.2f}\")\nprint(f\"x2 range: {x2.min():.2f} to {x2.max():.2f}\")\n\n\n\n\n\n\n\n\nNumber of points plotted: 100\nx1 range: -2.86 to 2.43\nx2 range: -4.00 to 4.10"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#task-8-solutions",
    "href": "files/labs/lab3/lab3_sln.html#task-8-solutions",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Task 8 Solutions",
    "text": "Task 8 Solutions\n\nTask 8 Solutions: Plot the function f(x) = x - x²sin(x) between x = -10 and x = 10.\n\n\n# Solution to Task 8\n\n# Create x values using linspace for a smooth plot\nx = np.linspace(-10, 10, 1000)  # 1000 points for smoothness\n\n# Define the function f(x) = x - x²sin(x)\ny = x - x**2 * np.sin(x)\n\n# Create the plot with red color\nplt.figure(figsize=(12, 8))\nplt.plot(x, y, color='red', linewidth=2)\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.title('Plot of f(x) = x - x²sin(x)')\nplt.grid(True, alpha=0.3)  # Add a light grid for better readability\nplt.show()\n\n# Show what happens with fewer points for comparison\nplt.figure(figsize=(12, 4))\n\n# Fewer points - not smooth\nplt.subplot(1, 2, 1)\nx_few = np.linspace(-10, 10, 20)\ny_few = x_few - x_few**2 * np.sin(x_few)\nplt.plot(x_few, y_few, color='blue', linewidth=2, marker='o')\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.title('With 20 points (not smooth)')\nplt.grid(True, alpha=0.3)\n\n# Many points - smooth\nplt.subplot(1, 2, 2)\nplt.plot(x, y, color='red', linewidth=2)\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.title('With 1000 points (smooth)')\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Notice how more points create a smoother curve!\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice how more points create a smoother curve!"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#summary-of-key-learning-points",
    "href": "files/labs/lab3/lab3_sln.html#summary-of-key-learning-points",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Summary of Key Learning Points",
    "text": "Summary of Key Learning Points\n\nKey Functions Learned:\n\nnp.mean() - Calculate mean\nnp.median() - Calculate median\nnp.std() - Calculate standard deviation (use ddof=1 for sample std)\nnp.ptp() - Calculate range (peak-to-peak)\nnp.percentile() - Calculate percentiles\nnp.diff(np.percentile(data, [25,75]))[0] - Calculate IQR"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#key-plotting-functions",
    "href": "files/labs/lab3/lab3_sln.html#key-plotting-functions",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Key Plotting Functions:",
    "text": "Key Plotting Functions:\n\nplt.boxplot() - Create boxplots\nplt.hist() - Create histograms\nplt.scatter() - Create scatterplots\nplt.plot() - Create line plots\nplt.xlabel(), plt.ylabel(), plt.title() - Add labels"
  },
  {
    "objectID": "files/labs/lab3/lab3_sln.html#important-concepts",
    "href": "files/labs/lab3/lab3_sln.html#important-concepts",
    "title": "Lab 3: Descriptive Statistics - SOLUTIONS",
    "section": "Important Concepts:",
    "text": "Important Concepts:\n\nSample vs Population Standard Deviation: Use ddof=1 for sample statistics\nFunction Parameters: Many plotting functions accept optional parameters for customization\nSmooth Plotting: Use more points in np.linspace() for smoother function plots\nModule Importing: import module as abbreviation saves typing\n\nThis concludes Lab 3 Solutions!"
  },
  {
    "objectID": "resources.html#week-1-foundations-of-data-science",
    "href": "resources.html#week-1-foundations-of-data-science",
    "title": "Course Resources",
    "section": "Week 1: Foundations of Data Science",
    "text": "Week 1: Foundations of Data Science\nGetting Started with Data - Data types, basic statistics, and Python tools"
  },
  {
    "objectID": "resources.html#week-2-introduction-to-probability",
    "href": "resources.html#week-2-introduction-to-probability",
    "title": "Course Resources",
    "section": "Week 2: Introduction to Probability",
    "text": "Week 2: Introduction to Probability\nUnderstanding Uncertainty - Sample spaces, conditional probability, and Bayes’ theorem"
  },
  {
    "objectID": "resources.html#week-3-conditional-probability-counting-discrete-random-variables",
    "href": "resources.html#week-3-conditional-probability-counting-discrete-random-variables",
    "title": "Course Resources",
    "section": "Week 3: Conditional Probability, Counting & Discrete Random Variables",
    "text": "Week 3: Conditional Probability, Counting & Discrete Random Variables\nAdvanced Probability & Discrete Distributions"
  },
  {
    "objectID": "resources.html#week-4-continuous-random-variables-intro-to-confidence-intervals",
    "href": "resources.html#week-4-continuous-random-variables-intro-to-confidence-intervals",
    "title": "Course Resources",
    "section": "Week 4: Continuous Random Variables & Intro to Confidence Intervals",
    "text": "Week 4: Continuous Random Variables & Intro to Confidence Intervals\nFrom Discrete to Continuous: Understanding Density and Intervals"
  },
  {
    "objectID": "resources.html#week-5-statistical-methods-testing",
    "href": "resources.html#week-5-statistical-methods-testing",
    "title": "Course Resources",
    "section": "Week 5: Statistical Methods & Testing",
    "text": "Week 5: Statistical Methods & Testing\nConfidence Intervals, Hypothesis Testing, and Statistical Inference"
  },
  {
    "objectID": "resources.html#week-6-linear-regression-basics",
    "href": "resources.html#week-6-linear-regression-basics",
    "title": "Course Resources",
    "section": "Week 6: Linear Regression Basics",
    "text": "Week 6: Linear Regression Basics\nStatistical Modeling and Relationship Analysis"
  },
  {
    "objectID": "index.html#what-makes-this-course-special",
    "href": "index.html#what-makes-this-course-special",
    "title": "PSTAT 5A: Understanding Data",
    "section": "What Makes This Course Special",
    "text": "What Makes This Course Special\n\nModern pedagogy meets practical application in statistical education"
  },
  {
    "objectID": "index.html#course-highlights",
    "href": "index.html#course-highlights",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Course Highlights",
    "text": "Course Highlights\n\nModern pedagogy meets practical application in statistical education"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#course-overview",
    "href": "files/lecture_notes/wrap_up.html#course-overview",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Course Overview 📊",
    "text": "Course Overview 📊\nWhat We’ve Learned\n\nUnderstanding Data: Types, visualization, summary statistics\nSampling & Distributions: How samples represent populations\nStatistical Inference: Confidence intervals and hypothesis testing\nRelationships: Correlation and linear regression\nReal-world Applications: Making data-driven decisions"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#section-1-understanding-data",
    "href": "files/lecture_notes/wrap_up.html#section-1-understanding-data",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Section 1: Understanding Data 📈",
    "text": "Section 1: Understanding Data 📈\nTypes of Data\n\n\nQuantitative\n\nNumerical values\nCan perform arithmetic\nExamples: height, income, test scores\n\nContinuous vs Discrete\n\nContinuous: can take any value in range\nDiscrete: countable values\n\n\nQualitative (Categorical)\n\nNon-numerical categories\nExamples: color, major, satisfaction level\n\nNominal vs Ordinal\n\nNominal: no natural order\nOrdinal: natural ordering exists"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#descriptive-statistics",
    "href": "files/lecture_notes/wrap_up.html#descriptive-statistics",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\n\n\nMeasures of Center\n\nMean: \\(\\bar{x} = \\frac{\\sum x_i}{n}\\)\nMedian: Middle value when ordered\nMode: Most frequent value\n\n\nMeasures of Spread\n\nRange: Max - Min\nStandard Deviation: \\(s = \\sqrt{\\frac{\\sum(x_i - \\bar{x})^2}{n-1}}\\)\nIQR: Q3 - Q1\n\nShape\n\nSkewness: Left, right, or symmetric\nOutliers: Values far from typical"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#data-visualization",
    "href": "files/lecture_notes/wrap_up.html#data-visualization",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Data Visualization",
    "text": "Data Visualization\n\n\nCommon Plots\n\nHistogram: Distribution of quantitative data\nBoxplot: Five-number summary, outliers\nScatterplot: Relationship between two quantitative variables\nBar chart: Frequency of categorical data\n\n\nKey Principles\n\nChoose appropriate plot for data type\nClear labels and titles\nAvoid misleading scales\nHighlight important patterns"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#section-2-sampling-sampling-distributions",
    "href": "files/lecture_notes/wrap_up.html#section-2-sampling-sampling-distributions",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Section 2: Sampling & Sampling Distributions 🎯",
    "text": "Section 2: Sampling & Sampling Distributions 🎯\n\n\nWhy Sample?\n\nPopulations often too large/expensive to study completely\nGood samples can represent populations well\nRandom sampling reduces bias\n\n\nSampling Methods\n\nSimple Random: Every individual has equal chance\nStratified: Divide into groups, sample from each\nCluster: Sample entire groups\nSystematic: Every nth individual"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#central-limit-theorem",
    "href": "files/lecture_notes/wrap_up.html#central-limit-theorem",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\nThe Magic of Averages ✨\n\nFor large samples (n ≥ 30), the sampling distribution of \\(\\bar{X}\\) is approximately normal, regardless of the population distribution\n\n\n\nKey Results\n\n\\(E[\\bar{X}] = \\mu\\) (unbiased)\n\\(SD[\\bar{X}] = \\frac{\\sigma}{\\sqrt{n}}\\) (standard error)\n\\(\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\) for large n\n\n\nImplications\n\nLarger samples → more precise estimates\nCan make probability statements about sample means"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#standard-error",
    "href": "files/lecture_notes/wrap_up.html#standard-error",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Standard Error",
    "text": "Standard Error\n\nFormula and Interpretation \\[SE_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}} \\text{ or } \\frac{s}{\\sqrt{n}}\\]\nFor Proportions \\[SE_{\\hat{p}} = \\sqrt{\\frac{p(1-p)}{n}}\\]\n\n\n\n\n\n\n\nKey Points\n\n\n\nMeasures variability of sample statistic\nDecreases as sample size increases\nFoundation for confidence intervals and hypothesis tests"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#section-3-confidence-intervals",
    "href": "files/lecture_notes/wrap_up.html#section-3-confidence-intervals",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Section 3: Confidence Intervals 🎯",
    "text": "Section 3: Confidence Intervals 🎯\nThe Big Idea\n\n“We are X% confident that the true parameter lies between [lower bound, upper bound]”\n\nGeneral Form\n\\[\\text{Estimate} \\pm \\text{(Critical Value)} \\times \\text{(Standard Error)}\\]"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#ci-for-population-mean",
    "href": "files/lecture_notes/wrap_up.html#ci-for-population-mean",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "CI for Population Mean",
    "text": "CI for Population Mean\n\n\nWhen σ is Known (Z-interval) - \\[\\bar{x} \\pm z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\\]\nWhen σ is Unknown (t-interval) - \\[\\bar{x} \\pm t_{\\alpha/2,df} \\cdot \\frac{s}{\\sqrt{n}}\\]\nwhere \\(df = n - 1\\)\n\nCommon Critical Values\n\n90% CI: \\(z_{0.05} = 1.645\\), \\(t_{0.05}\\) (depends on df)\n95% CI: \\(z_{0.025} = 1.96\\), \\(t_{0.025}\\) (depends on df)\n99% CI: \\(z_{0.005} = 2.576\\), \\(t_{0.005}\\) (depends on df)"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#ci-for-population-proportion",
    "href": "files/lecture_notes/wrap_up.html#ci-for-population-proportion",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "CI for Population Proportion",
    "text": "CI for Population Proportion\nFormula\n\\[\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\]\n\n\nConditions\n\n\\(n\\hat{p} \\geq 10\\) and \\(n(1-\\hat{p}) \\geq 10\\)\nRandom sample\nIndependent observations\n\n\nInterpretation\n\nSame logic as mean: we’re confident the true proportion lies in this interval"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#sample-size-determination",
    "href": "files/lecture_notes/wrap_up.html#sample-size-determination",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Sample Size Determination",
    "text": "Sample Size Determination\nFor Means \\[n = \\left(\\frac{z_{\\alpha/2} \\cdot \\sigma}{ME}\\right)^2\\]\nFor Proportions \\[n = \\left(\\frac{z_{\\alpha/2}}{ME}\\right)^2 \\cdot \\hat{p}(1-\\hat{p})\\]\nKey Trade-offs\n\nHigher confidence → larger sample needed\nSmaller margin of error → larger sample needed\nUse \\(\\hat{p} = 0.5\\) for most conservative estimate"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#section-4-hypothesis-testing",
    "href": "files/lecture_notes/wrap_up.html#section-4-hypothesis-testing",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Section 4: Hypothesis Testing ⚖️",
    "text": "Section 4: Hypothesis Testing ⚖️\nThe Scientific Method in Statistics\n\nFormulate hypotheses\nCollect data\nCalculate test statistic\nFind p-value\nMake decision\nState conclusion in context"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#setting-up-hypotheses",
    "href": "files/lecture_notes/wrap_up.html#setting-up-hypotheses",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Setting Up Hypotheses",
    "text": "Setting Up Hypotheses\n\n\nNull Hypothesis (\\(H_0\\))\n\nStatus quo, no effect, no difference\nContains equality (=, ≤, ≥)\nWhat we assume is true\n\nAlternative Hypothesis (\\(H_a\\) or \\(H_1\\))\n\nWhat we want to prove\nContains inequality (&lt;, &gt;, ≠)\nRepresents change or difference\n\n\nExample\n\n\\(H_0: \\mu = 100\\) vs \\(H_a: \\mu \\neq 100\\) (two-tailed)\n\\(H_0: p \\leq 0.5\\) vs \\(H_a: p &gt; 0.5\\) (one-tailed)"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#test-statistics",
    "href": "files/lecture_notes/wrap_up.html#test-statistics",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Test Statistics",
    "text": "Test Statistics\n\n\n\n\n\n\nFor Population Mean\n\n\n\nWhen \\(\\sigma\\) known: \\(z = (\\bar x - \\mu_0)/(\\sigma/\\sqrt{n})\\)\nWhen \\(\\sigma\\) unknown: \\(t = (\\bar x - \\mu_0)/(s/\\sqrt{n})\\), \\(df = n-1\\)\n\n\n\n\n\n\n\n\n\n\nFor Population Proportion\n\n\n\n\\(z = (\\hat p - p_0)/\\sqrt{[p_0(1-p_0)/n]}\\)"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#p-values-and-decision-making",
    "href": "files/lecture_notes/wrap_up.html#p-values-and-decision-making",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "P-values and Decision Making",
    "text": "P-values and Decision Making\nP-value Definition\n\nThe probability of observing a test statistic as extreme or more extreme than what we observed, assuming \\(H_0\\) is true\n\n\n\nDecision Rules\n\nIf p-value ≤ \\(\\alpha\\): Reject \\(H_0\\) (statistically significant)\nIf p-value &gt; \\(\\alpha\\): Fail to reject \\(H_0\\) (not statistically significant)\n\n\nCommon Significance Levels\n\n\\(\\alpha\\) = \\(0.05\\) (most common)\n\\(\\alpha\\) = \\(0.01\\) (more stringent)\n\\(\\alpha\\) = \\(0.10\\) (less stringent)"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#types-of-errors",
    "href": "files/lecture_notes/wrap_up.html#types-of-errors",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Types of Errors",
    "text": "Types of Errors\n\n\nType I Error\n\nRejecting true \\(H_0\\)\nProbability = \\(\\alpha\\) (significance level)\n“False positive”\n\n\nType II Error\n\nFailing to reject false \\(H_0\\)\nProbability = \\(\\beta\\)\n“False negative”\nPower = \\(1 - \\beta\\)\n\nTrade-off\n\nDecreasing \\(\\alpha\\) increases \\(\\beta\\)\nNeed larger samples to decrease both"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#section-5-linear-regression",
    "href": "files/lecture_notes/wrap_up.html#section-5-linear-regression",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Section 5: Linear Regression 📈",
    "text": "Section 5: Linear Regression 📈\n\nCorrelation Coefficient (r) \\[r = \\frac{\\sum(x-\\bar{x})(y-\\bar{y})}{\\sqrt{\\sum(x-\\bar{x})^2 \\sum(y-\\bar{y})^2}}\\]\n\nRanges from -1 to +1\nMeasures strength and direction of linear relationship\nr = 0: no linear relationship\n|r| close to 1: strong linear relationship"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#regression-line",
    "href": "files/lecture_notes/wrap_up.html#regression-line",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Regression Line",
    "text": "Regression Line\n\n\nEquation\n\\[\\hat{y} = a + bx\\]\nSlope (b)\n\\[b = \\frac{\\sum(x-\\bar{x})(y-\\bar{y})}{\\sum(x-\\bar{x})^2}\\]\n\nIntercept (a)\n\\[a = \\bar{y} - b\\bar{x}\\]\nInterpretation\n\nSlope: Change in y for 1-unit increase in x\nIntercept: Value of y when x = 0"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#coefficient-of-determination",
    "href": "files/lecture_notes/wrap_up.html#coefficient-of-determination",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Coefficient of Determination",
    "text": "Coefficient of Determination\n\n\nR-squared (\\(r^2\\))\n\nProportion of variance in y explained by x\nRanges from 0 to 1\nHigher values indicate better fit\n\n\nResiduals\n\n\\(e_i = y_i - \\hat{y}_i\\)\nVertical distance from point to line\nUsed to assess model fit\n\nStandard Error of Regression\n\n\\[s_e = \\sqrt{\\frac{\\sum(y-\\hat{y})^2}{n-2}}\\]"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#inference-for-regression",
    "href": "files/lecture_notes/wrap_up.html#inference-for-regression",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Inference for Regression",
    "text": "Inference for Regression\n\n\nTesting Slope Significance\n\n\\(H_0: \\beta = 0\\) vs \\(H_a: \\beta \\neq 0\\)\nTest statistic: \\(t = \\frac{b}{SE_b}\\)\nIf significant: x is useful for predicting y\n\n\nConditions for Regression Inference\n\nLinear relationship\nIndependent observations\nNormal residuals\nEqual variance (homoscedasticity)"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#section-6-quiz-review-strategy",
    "href": "files/lecture_notes/wrap_up.html#section-6-quiz-review-strategy",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Section 6: Quiz Review Strategy 🎯",
    "text": "Section 6: Quiz Review Strategy 🎯\nWhat to Focus On\n\nKnow your formulas (but understand when to use them)\nPractice identifying appropriate procedures\nCheck conditions before applying methods\nInterpret results in context\nShow your work clearly"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/wrap_up.html#common-mistakes-to-avoid",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Common Mistakes to Avoid ⚠️",
    "text": "Common Mistakes to Avoid ⚠️\n\n\nConfidence Intervals\n\nSaying “probability the parameter is in interval”\nConfusing confidence level with confidence\nWrong critical values (z vs t)\n\n\nHypothesis Testing\n\nConfusing “fail to reject” with “accept”\nWrong tail for p-value calculation\nNot stating conclusions in context\n\nRegression\n\nClaiming causation from correlation\nExtrapolating beyond data range\nIgnoring model assumptions"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#problem-solving-approach",
    "href": "files/lecture_notes/wrap_up.html#problem-solving-approach",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Problem-Solving Approach 🧠",
    "text": "Problem-Solving Approach 🧠\nStep-by-Step Method\n\nIdentify what type of problem\nCheck conditions/assumptions\nState hypotheses (if testing)\nCalculate test statistic or interval\nFind p-value or interpret interval\nMake decision (if testing)\nConclude in context of problem"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#key-formulas-summary",
    "href": "files/lecture_notes/wrap_up.html#key-formulas-summary",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\nStandard Errors\n\n\\(SE_{\\bar x} = \\sigma/\\sqrt{n}\\) or \\(s/\\sqrt{n}\\)\n\\(SE_{\\hat p}= \\sqrt{[p(1-p)/n]}\\)\n\nConfidence Intervals\n\nMean: \\(\\bar x ± t_{(\\alpha/2)} \\times (s/\\sqrt{n})\\)\nProportion: \\(\\hat p ± z_(\\alpha/2) \\times \\sqrt{[\\hat p(1-\\hat p)/n]}\\)\n\n\nTest Statistics\n\n\\(t = (\\bar x - \\mu_{0})/(s/\\sqrt{n})\\)\n\\(z = (\\hat p - p_{0})/\\sqrt{[p_0(1-p_0)/n]}\\)"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#calculatorsoftware-tips",
    "href": "files/lecture_notes/wrap_up.html#calculatorsoftware-tips",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Calculator/Software Tips 💻",
    "text": "Calculator/Software Tips 💻\n\n\nKnow How To:\n\nCalculate descriptive statistics\nFind normal/t probabilities\nPerform hypothesis tests\nCreate confidence intervals\nDo regression analysis\n\n\nDouble-Check:\n\nInput values correctly\nChoose right test/interval\nInterpret output properly"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#final-tips-for-success",
    "href": "files/lecture_notes/wrap_up.html#final-tips-for-success",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Final Tips for Success 🌟",
    "text": "Final Tips for Success 🌟\n\n\nBefore the Quiz\n\nReview worksheet problems\nPractice with different scenarios\nMake a cheat sheet of key formulas\nUnderstand when to use each method\n\n\nDuring the Quiz\n\nRead problems carefully\nShow all work\nCheck your answers make sense\nManage your time wisely\n\n\n\n\n\n\n\nNote\n\n\n\nStatistics is about making decisions with uncertainty\nContext matters as much as calculations\nPractice makes perfect!"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#questions",
    "href": "files/lecture_notes/wrap_up.html#questions",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Questions? 🤔",
    "text": "Questions? 🤔\nRemember:\n\nConfidence intervals: estimate unknown parameters\nHypothesis tests: make decisions about claims\nRegression: model relationships between variables\nSampling: connect samples to populations\n\nGood luck on Quiz 3! 🍀"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#extra-practice-resources",
    "href": "files/lecture_notes/wrap_up.html#extra-practice-resources",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "Extra Practice Resources",
    "text": "Extra Practice Resources\nRecommended Review\n\nWork through textbook examples\nRedo homework problems\nCreate your own formula sheet\nPractice explaining concepts to others\nUse online resources (Khan Academy, etc.)\n\nCommon Quiz Topics\n\nInterpreting confidence intervals\nSetting up hypothesis tests\nCalculating and interpreting correlation\nChoosing appropriate statistical methods"
  },
  {
    "objectID": "files/lecture_notes/wrap_up.html#section",
    "href": "files/lecture_notes/wrap_up.html#section",
    "title": "PSTAT 5A: Course Wrap-Up and Quiz Review",
    "section": "",
    "text": "🏠 Back to Main Page"
  }
]