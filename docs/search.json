[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Class Schedule",
    "section": "",
    "text": "⚠️\n\nImportant: This schedule is subject to change. Please check back regularly for updates and announcements.\n\n\n\n\n\n\nLabs & Worksheets\n\n\n\n\n\nQuizzes & Exams\n\n\n\n\n\nLecture Materials\n\n\n\n\n\nWeek 1: Introduction & Descriptive Statistics\n\n\n\n\n1\n\n\n6/23\n\n\nIntroduction\n\n\nLab 1\n\n\nWorksheet 1\n\n\n\n\n\n\n\n6/24\n\n\nNo class (lecture canceled)\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n6/25\n\n\nDescriptive Statistics I\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n6/26\n\n\nDescriptive Statistics II\n\n\n\n\n\n\n\n—\n\n\n\n\n\n\nWeek 2: Probability Foundations\n\n\n\n\n2\n\n\n6/30\n\n\nIntro to Probability\n\n\nLab2 Lab2 Notebook\n\n\nWorksheet 2\n\n\n\n\n\n\n\n7/01\n\n\nCounting\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/02\n\n\nConditional Probability\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/03\n\n\nDiscrete Random Variables\n\n\n—\n\n\n—\n\n\n\n\n\n\nWeek 3: Random Variables & Inference\n\n\n\n\n3\n\n\n7/07\n\n\nContinuous Random Variables\n\n\nLab 3\n\n\nWorksheet 3\n\n\n\n\n\n\n\n7/08\n\n\nIntroduction to Inference\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/09\n\n\nConfidence Intervals (Proportions)\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/10\n\n\nConfidence Intervals (Means)\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/11\n\n\nQuiz 1 (Weeks 1–2)\n\n\n—\n\n\n—\n\n\n\n\n\n\nWeek 4: Hypothesis Testing\n\n\n\n\n4\n\n\n7/14\n\n\nHypothesis Testing I\n\n\nLab 4\n\n\nWorksheet 4\n\n\n\n\n\n\n\n7/15\n\n\nHypothesis Testing II\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/16\n\n\nTwo–Sample t-Tests\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/17\n\n\nTwo–Sample t-Tests Continued\n\n\n—\n\n\n—\n\n\n\n\n\n\nWeek 5: ANOVA & Statistical Modeling\n\n\n\n\n5\n\n\n7/21\n\n\nANOVA\n\n\nLab 5\n\n\nWorksheet 5\n\n\n\n\n\n\n\n7/22\n\n\nIntro to Statistical Modeling\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/23\n\n\nIntro to Statistical Modeling & Correlation\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/24\n\n\nQuiz 2 (Weeks 3–4)\n\n\n—\n\n\n—\n\n\n\n\n\n\nWeek 6: Regression & Course Wrap-Up\n\n\n\n\n6\n\n\n7/28\n\n\nRegression Analysis\n\n\nLab 6\n\n\nWorksheet 6\n\n\n\n\n\n\n\n7/29\n\n\nRegression Diagnostics, Sampling\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/30\n\n\nWrap-Up\n\n\n—\n\n\n—\n\n\n\n\n\n\n\n7/31\n\n\nQuiz 3 (Weeks 5–6)\n\n\n—\n\n\n—"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Download the full syllabus as a PDF\n\n\n\n\n📚\n\n\nCourse Information\n\n\n\n\n\nLecture Time\n\n\nM/W/T/R 8:00 AM–9:30 AM\n\n\n\n\nLecture Hall\n\n\nHSSB 1173\n\n\n\n\nSections\n\n\nAs scheduled on GOLD (see Canvas for Zoom links)\n\n\n\n\nEmail\n\n\nnmathlouthi@ucsb.edu\n\n\n\n\nOffice\n\n\nEllison Hall 5829\n\n\n\n\nOffice Hours\n\n\nThursdays 11:00 AM–12:00 PM (via Zoom or by appointment)\n\n\n\n\n\nNote: Zoom links are posted on the Canvas page for the class.\n\n\n\n\n\n\n👥\n\n\nTeaching Assistants\n\n\n\n\n\nSL\n\n\nSummer Le\n\n\nsle@ucsb.edu\n\n\n\n\nMH\n\n\nMingzhu He\n\n\nmingzhuhe@ucsb.edu\n\n\n\n\n\nEmail policy: Include [PSTAT 5A] in your subject. Allow 24–48 hours for a reply (avoid weekends).\n\n\n\n\n\n\n🎯\n\n\nCourse Description\n\n\nThis introductory course covers the foundations of statistical thinking, including data description, probability, and inference. Students will learn how to summarize data, compute basic probabilities, and make informed decisions using statistical tools.\n\nStudent Learning Objectives\nBy the end of this course, you will be able to:\n\nSummarize data using descriptive statistics\nUnderstand fundamental probability rules and distributions\nConduct basic inferential procedures (confidence intervals, hypothesis tests)\nInterpret results and communicate findings\n\n\n\n\n\n\n📖\n\n\nCourse Materials\n\n\n\n\n\nCanvas\n\n\nAnnouncements, Zoom links, and grades (canvas.ucsb.edu)\n\n\n\n\nCalculator\n\n\nScientific calculator for in-class and quiz work\n\n\n\n\nComputer\n\n\nUse our JupyterHub instance\n\n\n\n\nRecommended Texts\n\n\nOpenIntro Statistics (free online)\nThink Stats by Allen Downey (free online)\n\n\n\n\n\n\n\n📅\n\n\nClass Schedule\n\n\n\n\nNote: For the most up-to-date details, please visit the Class Schedule tab on our website: Class Schedule\n\n\n\n\n\n\n📊\n\n\nGrading\n\n\n\n\nGrade Breakdown:\n\n\n\nLecture attendance: 5%\nSection attendance: 5%\nQuiz 1: 30%\nQuiz 2: 30%\nQuiz 3: 30%\n\n\n\nGrading Scale:\n\n\n\n\nA Grades\nB Grades\nC Grades\nD/F Grades\n\n\n\n\nA+: 97–100\nB+: 87–89\nC+: 77–79\nD+: 67–69\n\n\nA: 93–96\nB: 83–86\nC: 73–76\nD: 60–66\n\n\nA–: 90–92\nB–: 80–82\nC–: 70–72\nF: &lt; 60\n\n\n\n\n\n\nGrades round to the nearest whole number (e.g., 89.7 → 90).\n\n\n\n\n\n\n📝\n\n\nQuizzes\n\n\n\n\n\n1\n\n\n\nQuiz 1: Weeks 1–2\n\n\nJuly 10th\n\n\nCovers introduction and descriptive statistics\n\n\n\n\n\n2\n\n\n\nQuiz 2: Weeks 3–4\n\n\nJuly 24th\n\n\nCovers probability and hypothesis testing\n\n\n\n\n\n3\n\n\n\nQuiz 3: Weeks 5–6\n\n\nJuly 31st\n\n\nCovers ANOVA and regression analysis\n\n\n\n\n\n\nFormat: Multiple choice & short answer (open book)\nPlatform: Gradescope\nAvailability: Fridays 7 AM–12 AM (1‑hour limit)\nMake‑up policy: Notify within 48 h; documentation required.\n\n\n\n\n\n\n🎯\n\n\nHow to Succeed\n\n\n\nAttend lectures & sections\nEngage actively & ask questions\nUse office hours for help\n\n\nClassroom Expectations\nRespect peers & TAs. Stay engaged. Seek support if needed.\n\n\nCommunication Guidelines\n\nUse UCSB email with clear subject\nAllow 24–48 h for replies\nUse office hours or appointments\n\n\n\n\n\n\n🛡️\n\n\nAcademic Integrity\n\n\nDo your own work. Cite sources properly. See:\n\nAcademic Integrity Policy\nStudent Conduct Code\n\n\n\n\n\n🤝\n\n\nStudent Resources\n\n\n\n\n🦽 DSP & Accommodations Disability services and accommodations\n\n\n📚 CLAS Campus Learning Assistance Services\n\n\n🏥 Student Health Health and wellness services\n\n\n🍎 Basic Needs Food security and basic needs support\n\n\n💚 CAPS Counseling & Psychological Services\n\n\n🎓 EOP Educational Opportunity Program\n\n\n👥 ONDAS First-Generation Support\n\n\n📋 Undocumented Services Support for undocumented students\n\n\n🔄 Transfer Center Transfer student support\n\n\n\n\n\n\n📅\n\n\nImportant Dates\n\n\n\n\n\nAdd w/o Code\n\n\nJune 29\n\n\n\n\nDrop w/ Refund\n\n\nJune 29\n\n\n\n\nAdd w/ Code\n\n\nJuly 3\n\n\n\n\nDrop Course\n\n\nJuly 9\n\n\n\n\nChange Grade Option\n\n\nAugust 1"
  },
  {
    "objectID": "syllabus.html#dsp-accommodations",
    "href": "syllabus.html#dsp-accommodations",
    "title": "Syllabus",
    "section": "DSP & Accommodations",
    "text": "DSP & Accommodations\n\nDSP & Accommodations or call (805) 893-2668"
  },
  {
    "objectID": "syllabus.html#other-services",
    "href": "syllabus.html#other-services",
    "title": "Syllabus",
    "section": "Other Services",
    "text": "Other Services\n\nCLAS\n\nStudent Health\n\nBasic Needs\n\nCAPS\n\nEqual Opportunity Program (EOP)\n\nONDAS First-Gen Support\n\nUndocumented Student Services\n\nTransfer Student Center"
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Course Overview",
    "text": "Course Overview\n\nTransform raw data into meaningful insights through hands-on learning and real-world applications"
  },
  {
    "objectID": "index.html#quick-links",
    "href": "index.html#quick-links",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Quick Links",
    "text": "Quick Links\n\n\n\nIcon\nSection\nLink\n\n\n\n\n📘\nSyllabus\nView Syllabus\n\n\n🗓️\nSchedule\nClass Schedule\n\n\n🎥\nLectures\nLecture Notes\n\n\n💻\nLabs\nComputing Labs\n\n\n📂\nResources\nData & Code\n\n\n🕑\nOffice Hours\nOffice Hours\n\n\n📬\nContact\nGet in Touch\n\n\n\n\n\nNote: This schedule and all deadlines are subject to change. Check this site regularly for updates.\n\nFeel free to explore via the navigation bar above or through these quick‐link buttons. If you have any questions, use the Contact page or drop by office hours. Let’s have a great quarter!"
  },
  {
    "objectID": "files/labs/lab1/lab1.html",
    "href": "files/labs/lab1/lab1.html",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Welcome to the first PSTAT 5A Lab! As we will soon learn, computers play an integral part in effectively and efficiently performing statistical analyses. The primary goal of these Labs is to develop the skills to communicate with computers and learn the basic principles and language of programming.\nThis first lab will introduce you to the JupyterHub environment, Python as a programming language, and some basic concepts of programming. You will also complete a series of tasks to familiarize yourself with the tools and concepts we will use throughout the course.\nThis lab is designed to be completed during your first lab section of the week, and it will set the foundation for the rest of the course. Make sure to read through all the material carefully, as it will be essential for your success in PSTAT 5A.\n\n\n\nEvery week we (the course staff) will publish a lab document, which is intended to be completed during your Lab Section (i.e., your first Section) of the week. Each lab document will consist of a combination of text, tips, and the occasional task for you to complete based on the text provided. Your TA will cover exactly what you need to turn in at the end of each lab in order to receive credit, but you should read all lab material carefully and thoroughly as content from labs will appear on quizzes and exams.\n\n\n\n\nComputers, though incredibly useful, are fairly complex machines. To communicate with them, we need to use a specific language, known as a programming language. There are a number of programming languages currently in use—R, Julia, MatLab, and the language we will use for this course, Python.\nPython programs can be written in many environments (e.g., text editors like VS Code or in a Terminal window). For this class we will use Jupyter Notebook (pronounced “Jew-pi-ter”), an interactive environment that’s hosted online so you don’t have to install anything to run Python code!\n\n\n\n\n\nNavigate to (https://pstat5a.lsit.ucsb.edu)\n\nIf you are using a personal computer, you may want to bookmark this page for easy access later.\n\nClick Sign in with your UCSB NetID, and sign in.\n\nNavigate to the Labs folder on the left-hand side of the JupyterHub interface. \nUnder Notebook, click Python 3 (ipykernel).\n\n\nCongratulations, you have just made your first Jupyter notebook! Now, it’s time for our first task:\n\n\n\n\n\nFind your new notebook in the left-hand file browser (it will be named Untitled or Untitled1 by default).\n\nRight-click the notebook and select → Rename.\n\nRename it to Lab1 and hit Enter.\n\nWatch the title bar update to Lab1.ipynb.\n\n\n\n\n\nJupyter notebooks are built from cells—the shaded boxes you see on screen. Here’s how to work with them:\n\n\n\nInactive cell\n\nAppearance: light grey background\n\nAction: click anywhere inside the cell to activate\n\n\nActive cell\n\nAppearance: colored border (green or blue)\n\nYou can now type code or Markdown here.\n\n\n\nTip: Only the active cell runs when you press Run.\n\n\n\n\n\nClick the ▶️ Run button in the toolbar\n\nOr press Shift + Enter to run and advance to the next cell\n\n\n\n\n\n\n\nYou can switch any cell between Code and Markdown:\n\n\n\nPurpose: write and execute Python code\n\nSelect:\n\nClick the cell\n\nChoose Code from the toolbar dropdown\n\n\n\nRun: ▶️ Run button or Shift + Enter\n\n\n\n\n\nPurpose: write formatted text, headings, lists, math, and embed images\n\nSelect:\n\nClick the cell\n\nChoose Markdown from the toolbar dropdown\n\n\nRender: ▶️ Run button or Shift + Enter\n\n\n\n\n\n\nClick into the initial cell ( marked by [ ] on the left).\n\nIn the toolbar dropdown (that currently says Code), select Markdown.\n\nCopy-paste the following (including the #):\n# Task 2\nRun the cell (▶️).\nCreate a new code cell by clicking the + button in the toolbar.\n\n\nAlternatively, you can press B to add a cell below the current one or A to add one above it.\n\nThis option preserves the previous cell type (Code or Markdown).\n\nYou can also right-click the cell and select Insert Cell Below or Insert Cell Above.\nYou can also use the Insert menu at the top of the page. &gt; Tip: Press Shift + Enter to run a cell and move to (or create) the next one.\n\nEnter and run:\n2 + 2\nObserve that a new cell appears under it automatically.\n\n\nTip: Press Shift + Enter to run a cell and move to (or create) the next one.\n\n\n\n\n\nCreate a new Markdown cell labeled:\n# Task 3\nCreate a new code cell and run:\n2 plus 2\nObserve the SyntaxError and note how Python points to the problem.\n\n\nNote: Always read error messages, they tell you what went wrong!\n\n\n\n\n\nPython follows the usual order of operations:\n\nParentheses\n\nExponents\n\nMultiplication / Division\n\nAddition / Subtraction\n\n\n\n\nOperation\nPython Syntax\nExample\nResult\n\n\n\n\nAddition\n+\n2 + 2\n4\n\n\nSubtraction\n-\n2 - 2\n0\n\n\nMultiplication\n*\n2 * 2\n4\n\n\nDivision\n/\n2 / 2\n1.0\n\n\nExponentiation\n**\n2 ** 2\n4\n\n\n\n\n\n\nCompute the following in separate code cells:\n\n\\[\\frac{2 + 3}{4 + 5^6}\\]\n\\[(1 - 3 \\cdot 4^5)^6\\]\n\n\n\n\n\nIn Python, a module is simply a file (with a .py extension) that contains related code, functions, classes, and variables—that you can reuse in other programs. Modules help you organize your code, avoid naming conflicts, and leverage functionality written by others.\n\n\n\nReusability: Write a function once, then import it wherever you need it.\n\nOrganization: Group related functionality into logical units (e.g., math operations).\n\nNamespace Management: Keep your global namespace clean by accessing code through the module’s name.\n\n\n\n\nThere are several ways to bring module code into your current script or notebook:\n\nImport the entire module\nimport math\nprint(math.sin(1))\nImport specific names\nfrom math import sin, pi\nprint(sin(pi/2))\nImport with an alias\nimport numpy as np\narr = np.array([1, 2, 3])\n\n\nTip: Use specific imports (from module import name) to keep your namespace tidy, or aliases (import module as m) for brevity.\n\n\n\n\n\n\nStandard library: Modules like math, random, and datetime come with Python.\n\nThird-party: Install via pip install package_name (e.g. pip install pandas).\n\nYour own: Create my_utils.py and then import my_utils in your project.\n\nModules are the building blocks of larger Python applications; get comfortable importing and exploring them!\n\n\n\n\n\n\nIn a code cell, type:\nsin(1)\nObserve the NameError.\n\nIn the same (or a new) cell, load the module and retry:\nfrom math import *\nsin(1)\n\n\n\n\n\nVariables in Python are used to store data values. You can think of them as labels for data that you want to use later in your program.\n\nAssignment:\nx = 2\nPrinting:\nprint(x)\n\nPython is case-sensitive: my_variable ≠ My_variable.\n\nBehind the scenes, print() is a function that takes one or more values and displays them on the screen. We’ll learn what functions are and how to create our own functions soon.\n\n\n\n\n\n\nAssign:\nmy_variable = 5\nIn a new cell, run:\nprint(My_variable)\n– observe the NameError due to wrong capitalization.\nNameError: name 'My_variable' is not defined\nIn the same cell, run:\nprint(my_variable)\nNow you should see 5 printed without any errors.\n\n\n\n\n\nComments are notes in your code that Python ignores when running the program. They help you and others understand what your code does. Comments are essential for documenting your code, explaining complex logic, or leaving reminders for yourself or others. They do not affect the execution of your program.\nYou can add comments anywhere in your code, and they can be on their own line or at the end of a line of code.\nIn Python, comments start with a # symbol. Everything after the # on that line is considered a comment and will not be executed by Python. You can also use multi-line comments with triple quotes (\"\"\" or '''), which allows you to write longer explanations or block comments that span multiple lines. These are often used for documentation strings (docstrings) to describe functions, classes, or modules.\nYou can add comments in two ways:\n\nInline comment: Use # to comment out a single line.\nExample:\n# This is an inline comment\nx = 5  # Assign 5 to x\nBlock comment: Use triple quotes \"\"\" or ''' to comment out multiple lines.\n\nExample:\n\"\"\"\nMultiple lines\nof comment here\n\"\"\"\n\n\n\n\n\nGo back and add descriptive comments to some of your previous code cells.\n\n\n\n\nPython has several basic data types, which are the building blocks for more complex data structures. The most common ones are: - bool — boolean (e.g. True, False)\n\nNoneType — represents the absence of a value (e.g. None)\nlist — ordered collection (e.g. [1, 2, 3])\ntuple — immutable ordered collection (e.g. (1, 2, 3))\ndict — key-value pairs (e.g. `{“key”: “value”})\nset — unordered collection of unique items (e.g. {1, 2, 3})\n\nThe most basic data types you will use in this course are:\n\nint — integer (e.g. 1, 42)\nfloat — real number (e.g. 1.0, 3.14)\n\nstr — string/text (e.g. \"hello\", 'abc')\n\n\n\n\n\nRun each in its own cell:\ntype(1)\ntype(1.1)\ntype(\"hello\")\n\n\n\n\nYou can assign values to variables and use them in expressions. Here’s an example:\n\n\n\n\n\nCreate a new Markdown cell labeled:\n# Task 9\nIn a new code cell, perform the following variable assignments:\ncourse = \"PSTAT 5A\"\nnum_sections = 4\nsection_capacity = 25\nA new section has been added! Update the variable num_sections to be one more than when you initially defined it above. (Don’t just use num_sections = 5- think about our discussion on updating variables above!)\nUsing comments, write down what you think the output of each of the following expressions will be:\ntype(course)\ntype(num_sections)\nnum_sections * section_capacity\nThen, run each expression in a separate code chunk and comment on the results.\nCreate a new variable called course_capacity and assign it the value of the maximum capacity of the course. (Hint: there are only 5 sections, and each section has a maximum capacity of 25. Try to use your already-defined variables as much as possible!)\n\n\n\n\n\nThat wraps up Lab 1! You’ve successfully navigated the JupyterHub environment, learned how to switch between and run Code and Markdown cells, experimented with basic Python expressions, and practiced variable assignment. In Lab 2, we’ll dive deeper into Python functions, data structures, and more advanced programming concepts. Great work, see you next time!\n\n\n\n\n\n\n🔖 Table of Contents\n- PSTAT 5A Lab 1  - Structure of Labs  - What Is Programming?  - Getting Started  - Task 1  - The JupyterHub Environment  - 1. Cell Activation  - 2. Running Cells  - Cell Types  - Code Cells  - Markdown Cells  - Task 2  - Task 3  - Python as a Calculator  - Task 4  - Python Modules  - Why Use Modules?  - Importing Modules  - Finding and Installing Modules  - Task 5  - Variable Assignment  - Task 6  - Comments  - Task 7  - Basic Data Types  - Task 8  - Using Variables and Data Types  - Task 9  - Conclusion"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#structure-of-labs",
    "href": "files/labs/lab1/lab1.html#structure-of-labs",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Every week we (the course staff) will publish a lab document, which is intended to be completed during your Lab Section (i.e., your first Section) of the week. Each lab document will consist of a combination of text, tips, and the occasional task for you to complete based on the text provided. Your TA will cover exactly what you need to turn in at the end of each lab in order to receive credit, but you should read all lab material carefully and thoroughly as content from labs will appear on quizzes and exams."
  },
  {
    "objectID": "files/labs/lab1/lab1.html#what-is-programming",
    "href": "files/labs/lab1/lab1.html#what-is-programming",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Computers, though incredibly useful, are fairly complex machines. To communicate with them, we need to use a specific language, known as a programming language. There are a number of programming languages currently in use—R, Julia, MatLab, and the language we will use for this course, Python.\nPython programs can be written in many environments (e.g., text editors like VS Code or in a Terminal window). For this class we will use Jupyter Notebook (pronounced “Jew-pi-ter”), an interactive environment that’s hosted online so you don’t have to install anything to run Python code!"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#getting-started",
    "href": "files/labs/lab1/lab1.html#getting-started",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Navigate to (https://pstat5a.lsit.ucsb.edu)\n\nIf you are using a personal computer, you may want to bookmark this page for easy access later.\n\nClick Sign in with your UCSB NetID, and sign in.\n\nNavigate to the Labs folder on the left-hand side of the JupyterHub interface. \nUnder Notebook, click Python 3 (ipykernel).\n\n\nCongratulations, you have just made your first Jupyter notebook! Now, it’s time for our first task:"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-1",
    "href": "files/labs/lab1/lab1.html#task-1",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Find your new notebook in the left-hand file browser (it will be named Untitled or Untitled1 by default).\n\nRight-click the notebook and select → Rename.\n\nRename it to Lab1 and hit Enter.\n\nWatch the title bar update to Lab1.ipynb."
  },
  {
    "objectID": "files/labs/lab1/lab1.html#the-jupyterhub-environment",
    "href": "files/labs/lab1/lab1.html#the-jupyterhub-environment",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Jupyter notebooks are built from cells—the shaded boxes you see on screen. Here’s how to work with them:\n\n\n\nInactive cell\n\nAppearance: light grey background\n\nAction: click anywhere inside the cell to activate\n\n\nActive cell\n\nAppearance: colored border (green or blue)\n\nYou can now type code or Markdown here.\n\n\n\nTip: Only the active cell runs when you press Run.\n\n\n\n\n\nClick the ▶️ Run button in the toolbar\n\nOr press Shift + Enter to run and advance to the next cell"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#cell-types",
    "href": "files/labs/lab1/lab1.html#cell-types",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "You can switch any cell between Code and Markdown:\n\n\n\nPurpose: write and execute Python code\n\nSelect:\n\nClick the cell\n\nChoose Code from the toolbar dropdown\n\n\n\nRun: ▶️ Run button or Shift + Enter\n\n\n\n\n\nPurpose: write formatted text, headings, lists, math, and embed images\n\nSelect:\n\nClick the cell\n\nChoose Markdown from the toolbar dropdown\n\n\nRender: ▶️ Run button or Shift + Enter"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-2",
    "href": "files/labs/lab1/lab1.html#task-2",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Click into the initial cell ( marked by [ ] on the left).\n\nIn the toolbar dropdown (that currently says Code), select Markdown.\n\nCopy-paste the following (including the #):\n# Task 2\nRun the cell (▶️).\nCreate a new code cell by clicking the + button in the toolbar.\n\n\nAlternatively, you can press B to add a cell below the current one or A to add one above it.\n\nThis option preserves the previous cell type (Code or Markdown).\n\nYou can also right-click the cell and select Insert Cell Below or Insert Cell Above.\nYou can also use the Insert menu at the top of the page. &gt; Tip: Press Shift + Enter to run a cell and move to (or create) the next one.\n\nEnter and run:\n2 + 2\nObserve that a new cell appears under it automatically.\n\n\nTip: Press Shift + Enter to run a cell and move to (or create) the next one."
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-3",
    "href": "files/labs/lab1/lab1.html#task-3",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Create a new Markdown cell labeled:\n# Task 3\nCreate a new code cell and run:\n2 plus 2\nObserve the SyntaxError and note how Python points to the problem.\n\n\nNote: Always read error messages, they tell you what went wrong!"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#python-as-a-calculator",
    "href": "files/labs/lab1/lab1.html#python-as-a-calculator",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Python follows the usual order of operations:\n\nParentheses\n\nExponents\n\nMultiplication / Division\n\nAddition / Subtraction\n\n\n\n\nOperation\nPython Syntax\nExample\nResult\n\n\n\n\nAddition\n+\n2 + 2\n4\n\n\nSubtraction\n-\n2 - 2\n0\n\n\nMultiplication\n*\n2 * 2\n4\n\n\nDivision\n/\n2 / 2\n1.0\n\n\nExponentiation\n**\n2 ** 2\n4"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-4",
    "href": "files/labs/lab1/lab1.html#task-4",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Compute the following in separate code cells:\n\n\\[\\frac{2 + 3}{4 + 5^6}\\]\n\\[(1 - 3 \\cdot 4^5)^6\\]"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#python-modules",
    "href": "files/labs/lab1/lab1.html#python-modules",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "In Python, a module is simply a file (with a .py extension) that contains related code, functions, classes, and variables—that you can reuse in other programs. Modules help you organize your code, avoid naming conflicts, and leverage functionality written by others.\n\n\n\nReusability: Write a function once, then import it wherever you need it.\n\nOrganization: Group related functionality into logical units (e.g., math operations).\n\nNamespace Management: Keep your global namespace clean by accessing code through the module’s name.\n\n\n\n\nThere are several ways to bring module code into your current script or notebook:\n\nImport the entire module\nimport math\nprint(math.sin(1))\nImport specific names\nfrom math import sin, pi\nprint(sin(pi/2))\nImport with an alias\nimport numpy as np\narr = np.array([1, 2, 3])\n\n\nTip: Use specific imports (from module import name) to keep your namespace tidy, or aliases (import module as m) for brevity.\n\n\n\n\n\n\nStandard library: Modules like math, random, and datetime come with Python.\n\nThird-party: Install via pip install package_name (e.g. pip install pandas).\n\nYour own: Create my_utils.py and then import my_utils in your project.\n\nModules are the building blocks of larger Python applications; get comfortable importing and exploring them!"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-5",
    "href": "files/labs/lab1/lab1.html#task-5",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "In a code cell, type:\nsin(1)\nObserve the NameError.\n\nIn the same (or a new) cell, load the module and retry:\nfrom math import *\nsin(1)"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#variable-assignment",
    "href": "files/labs/lab1/lab1.html#variable-assignment",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Variables in Python are used to store data values. You can think of them as labels for data that you want to use later in your program.\n\nAssignment:\nx = 2\nPrinting:\nprint(x)\n\nPython is case-sensitive: my_variable ≠ My_variable.\n\nBehind the scenes, print() is a function that takes one or more values and displays them on the screen. We’ll learn what functions are and how to create our own functions soon."
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-6",
    "href": "files/labs/lab1/lab1.html#task-6",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Assign:\nmy_variable = 5\nIn a new cell, run:\nprint(My_variable)\n– observe the NameError due to wrong capitalization.\nNameError: name 'My_variable' is not defined\nIn the same cell, run:\nprint(my_variable)\nNow you should see 5 printed without any errors."
  },
  {
    "objectID": "files/labs/lab1/lab1.html#comments",
    "href": "files/labs/lab1/lab1.html#comments",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Comments are notes in your code that Python ignores when running the program. They help you and others understand what your code does. Comments are essential for documenting your code, explaining complex logic, or leaving reminders for yourself or others. They do not affect the execution of your program.\nYou can add comments anywhere in your code, and they can be on their own line or at the end of a line of code.\nIn Python, comments start with a # symbol. Everything after the # on that line is considered a comment and will not be executed by Python. You can also use multi-line comments with triple quotes (\"\"\" or '''), which allows you to write longer explanations or block comments that span multiple lines. These are often used for documentation strings (docstrings) to describe functions, classes, or modules.\nYou can add comments in two ways:\n\nInline comment: Use # to comment out a single line.\nExample:\n# This is an inline comment\nx = 5  # Assign 5 to x\nBlock comment: Use triple quotes \"\"\" or ''' to comment out multiple lines.\n\nExample:\n\"\"\"\nMultiple lines\nof comment here\n\"\"\""
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-7",
    "href": "files/labs/lab1/lab1.html#task-7",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Go back and add descriptive comments to some of your previous code cells."
  },
  {
    "objectID": "files/labs/lab1/lab1.html#basic-data-types",
    "href": "files/labs/lab1/lab1.html#basic-data-types",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Python has several basic data types, which are the building blocks for more complex data structures. The most common ones are: - bool — boolean (e.g. True, False)\n\nNoneType — represents the absence of a value (e.g. None)\nlist — ordered collection (e.g. [1, 2, 3])\ntuple — immutable ordered collection (e.g. (1, 2, 3))\ndict — key-value pairs (e.g. `{“key”: “value”})\nset — unordered collection of unique items (e.g. {1, 2, 3})\n\nThe most basic data types you will use in this course are:\n\nint — integer (e.g. 1, 42)\nfloat — real number (e.g. 1.0, 3.14)\n\nstr — string/text (e.g. \"hello\", 'abc')"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-8",
    "href": "files/labs/lab1/lab1.html#task-8",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Run each in its own cell:\ntype(1)\ntype(1.1)\ntype(\"hello\")"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#using-variables-and-data-types",
    "href": "files/labs/lab1/lab1.html#using-variables-and-data-types",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "You can assign values to variables and use them in expressions. Here’s an example:"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#task-9",
    "href": "files/labs/lab1/lab1.html#task-9",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "Create a new Markdown cell labeled:\n# Task 9\nIn a new code cell, perform the following variable assignments:\ncourse = \"PSTAT 5A\"\nnum_sections = 4\nsection_capacity = 25\nA new section has been added! Update the variable num_sections to be one more than when you initially defined it above. (Don’t just use num_sections = 5- think about our discussion on updating variables above!)\nUsing comments, write down what you think the output of each of the following expressions will be:\ntype(course)\ntype(num_sections)\nnum_sections * section_capacity\nThen, run each expression in a separate code chunk and comment on the results.\nCreate a new variable called course_capacity and assign it the value of the maximum capacity of the course. (Hint: there are only 5 sections, and each section has a maximum capacity of 25. Try to use your already-defined variables as much as possible!)"
  },
  {
    "objectID": "files/labs/lab1/lab1.html#conclusion",
    "href": "files/labs/lab1/lab1.html#conclusion",
    "title": "PSTAT 5A Lab 1",
    "section": "",
    "text": "That wraps up Lab 1! You’ve successfully navigated the JupyterHub environment, learned how to switch between and run Code and Markdown cells, experimented with basic Python expressions, and practiced variable assignment. In Lab 2, we’ll dive deeper into Python functions, data structures, and more advanced programming concepts. Great work, see you next time!"
  },
  {
    "objectID": "files/lecture_notes/Lecture_1/lecture1.html#course-resources",
    "href": "files/lecture_notes/Lecture_1/lecture1.html#course-resources",
    "title": "Lecture 1: Introduction to Data Science",
    "section": "Course Resources",
    "text": "Course Resources\n\nCanvas: for grades\n\nGradescope: for quizzes & labs\n\nEntry code: WJ4XR7\n\n\nCourse Website: bit.ly/3Ga8CSK\n\n\nAll relevant course material will be posted on the website. quizzes are the only exception and will be administered via Gradescope.\n\n\nPlease read the syllabus fully and carefully!"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#welcome-agenda",
    "href": "files/lecture_notes/lecture2/lecture2.html#welcome-agenda",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Welcome & Agenda",
    "text": "Welcome & Agenda\n\nWhat is descriptive statistics?\nWhy it matters before any modeling\nToday’s roadmap: data types → center → spread → shape → visual summaries\n\n\nQuick ice-breaker: ask students for one dataset they’ve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "href": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Learning Objectives (LOs)",
    "text": "Learning Objectives (LOs)\nBy the end of this lecture you should be able to:\n\nDefine descriptive statistics and explain its importance in data analysis (Section 1)\nDistinguish between different types of data and measurement scales (Section 2)\nCalculate and interpret measures of central tendency (mean, median, mode)(Section 3)\nUnderstand when to use each measure of central tendency\nApply Python to compute descriptive statistics(Section 9)\nInterpret basic descriptive statistics in real-world contexts(Section 10)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Data",
    "text": "Types of Data\n\n\n\n\n\ngraph TD\n    A[Variable Types]\n    A --&gt; B[Categorical]\n    A --&gt; C[Numerical]\n    B --&gt; B1[\"Nominal&lt;br/&gt;e.g., gender, major\"]\n    B --&gt; B2[\"Ordinal&lt;br/&gt;e.g., rating, education level\"]\n    C --&gt; C1[\"Discrete&lt;br/&gt;e.g., count (# of students)\"]\n    C --&gt; C2[\"Continuous&lt;br/&gt;e.g., measurements like height, weight\"]\n    \n    classDef root fill:#e1f5fe,stroke:#01579b,stroke-width:3px\n    classDef categorical fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef numerical fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px\n    classDef nominal fill:#fce4ec,stroke:#880e4f,stroke-width:2px\n    classDef ordinal fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef discrete fill:#e0f2f1,stroke:#00695c,stroke-width:2px\n    classDef continuous fill:#f1f8e9,stroke:#33691e,stroke-width:2px\n    \n    class A root\n    class B categorical\n    class C numerical\n    class B1 nominal\n    class B2 ordinal\n    class C1 discrete\n    class C2 continuous\n\n\n\n\n\n\n\nPrompt: Which summary stat would you pick for “major”? For “gpa”?"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#introducing-pandas-dataframes",
    "href": "files/lecture_notes/lecture2/lecture2.html#introducing-pandas-dataframes",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "2️⃣ Introducing pandas DataFrames",
    "text": "2️⃣ Introducing pandas DataFrames\n\nRows = observations (students)\nColumns = variables (age, major, …)\ndtype drives what Pandas methods you can call"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#center-mean-vs.-median-vs.-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#center-mean-vs.-median-vs.-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "3️⃣ Center: Mean vs. Median vs. Mode",
    "text": "3️⃣ Center: Mean vs. Median vs. Mode\n\n\n\n\n\n\n\n\nMeasure\nFormula\nWhen to prefer\n\n\n\n\nMean\n\\(\\bar x = \\frac{1}{n}\\sum x_i\\)\nSymmetric, no extreme outliers\n\n\nMedian\n50th percentile\nSkewed distributions\n\n\nMode\nMost frequent\nCategorical or multimodal"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#live-coding-break-5-min",
    "href": "files/lecture_notes/lecture2/lecture2.html#live-coding-break-5-min",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "⚡ Live Coding Break (5 min)",
    "text": "⚡ Live Coding Break (5 min)\n\nTask: Compute the average steps per day from fitbit_week.csv.\nStretch: How many students are above the mean?\n\n??? Give them 3 minutes solo → 2 minutes pair-share. Then demo solution."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#spread-range-iqr-variance-sd",
    "href": "files/lecture_notes/lecture2/lecture2.html#spread-range-iqr-variance-sd",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "4️⃣ Spread: Range, IQR, Variance, SD",
    "text": "4️⃣ Spread: Range, IQR, Variance, SD\n\nRange = max − min (sensitive to outliers)\nIQR = Q3 − Q1 (middle 50 %)\nVariance \\(s^2\\) & SD \\(s\\): average squared / root → keeps units"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#visualization-histogram-boxplot",
    "href": "files/lecture_notes/lecture2/lecture2.html#visualization-histogram-boxplot",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Visualization: Histogram & Boxplot",
    "text": "Visualization: Histogram & Boxplot\n\nHist = shape & modality\nBox = center, IQR, outliers (1.5×IQR rule)\n\n??? Ask: What can you say about skewness? Any potential data quality issues?"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#shape-skewness-kurtosis-brief",
    "href": "files/lecture_notes/lecture2/lecture2.html#shape-skewness-kurtosis-brief",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "5️⃣ Shape: Skewness & Kurtosis (brief)",
    "text": "5️⃣ Shape: Skewness & Kurtosis (brief)\n\nSkewness: direction & degree of asymmetry\nKurtosis: tailedness vs. normal (peaked vs. flat)\nPython: scipy.stats.skew, scipy.stats.kurtosis"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#frequency-tables-for-categorical-data",
    "href": "files/lecture_notes/lecture2/lecture2.html#frequency-tables-for-categorical-data",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Frequency Tables for Categorical Data",
    "text": "Frequency Tables for Categorical Data\n\nBar chart & pie chart caveats (use sparingly!)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#common-pitfalls",
    "href": "files/lecture_notes/lecture2/lecture2.html#common-pitfalls",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Common Pitfalls",
    "text": "Common Pitfalls\n\nIgnoring data types (e.g., averaging ZIP codes 🔥)\nReporting mean on skewed salary data\nForgetting units/scale transformations (log, %)\nOver-plotting 2D histograms vs. scatter"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#quick-recap",
    "href": "files/lecture_notes/lecture2/lecture2.html#quick-recap",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Quick Recap",
    "text": "Quick Recap\n\nDescriptive stats = center + spread + shape + visuals\nPython toolbox: pandas, numpy, matplotlib, scipy\nNext lecture: Descriptive Stats Part II – association (covariance, correlation) & grouped summaries\n\n??? Use a minute for questions; assign short exercise notebook for practice."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#exit-ticket",
    "href": "files/lecture_notes/lecture2/lecture2.html#exit-ticket",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Exit Ticket ✏️",
    "text": "Exit Ticket ✏️\n\nIn one sentence, describe what the IQR tells you that the range does not."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#appendix-extra-code-snippets",
    "href": "files/lecture_notes/lecture2/lecture2.html#appendix-extra-code-snippets",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Appendix: Extra Code Snippets",
    "text": "Appendix: Extra Code Snippets"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "href": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Today’s Agenda",
    "text": "Today’s Agenda\n\nIntroduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\n\nWhy it matters before any modeling\n\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset they’ve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What are Descriptive Statistics?",
    "text": "What are Descriptive Statistics?\n\nDescriptive statistics are numerical and graphical methods used to summarize, organize, and describe data in a meaningful way.\n\nPurpose of Descriptive Statistics\n\nSummarize large datasets into manageable information\nIdentify patterns and trends in data\nCommunicate findings clearly to others\nPrepare data for further analysis\nMake initial assessments about data quality"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Statistics",
    "text": "Statistics\n\nFacts are stubborn, but statistics are more pliable.\nMark Twain\n\nStatistics refers to the mathematics and techniques with which we understand data. 1\n\n\n\n(source)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs. Inferential Statistics",
    "text": "Descriptive vs. Inferential Statistics\n\n\n\n\n\n\n\nDescriptive Statistics\nInferential Statistics\n\n\n\n\nDescribes what the data shows\nMakes predictions about populations\n\n\nSummarizes sample data\nUses sample data to make generalizations\n\n\nNo conclusions beyond the data\nDraws conclusions beyond the immediate data\n\n\nExamples: mean, median, graphs\nExamples: hypothesis testing, confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs. Inferential Statistics",
    "text": "Descriptive vs. Inferential Statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "href": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Why Data Types Matter",
    "text": "Why Data Types Matter\nUnderstanding data types is crucial because:\n\n\nDifferent statistics are appropriate for different data types\nStatistical methods depend on the level of measurement\nMisapplying statistics can lead to incorrect conclusions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Categorical Data (Qualitative)",
    "text": "Categorical Data (Qualitative)\n\n\nNominal Data\n\nCategories with no natural order\nExamples: gender, color, brand names, marital status\nAppropriate statistics: mode, frequency counts, proportions\n\n\nOrdinal Data\n\nCategories with a natural order or ranking\nExamples: education level, satisfaction ratings, letter grades\nAppropriate statistics: mode, median, percentiles"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Numerical Data (Quantitative)",
    "text": "Numerical Data (Quantitative)\n\nDiscrete Data\n\nCountable values, often integers\nExamples: number of children, cars sold, defective items\nCan take on finite or countably infinite values\n\n\n\nContinuous Data\n\nCan take any value within a range\nExamples: height, weight, temperature, time\nMeasured rather than counted"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "href": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Measurement Scales Summary",
    "text": "Measurement Scales Summary\n\n\n\n\n\n\n\n\n\n\nScale\nType\nProperties\nExamples\nAppropriate Statistics\n\n\n\n\nNominal\nCategorical\nCategories only\nGender, Color\nMode, Frequency\n\n\nOrdinal\nCategorical\nOrder matters\nRankings, Grades\nMode, Median\n\n\nInterval\nNumerical\nEqual intervals, no true zero\nTemperature (°C)\nMean, Median, Mode\n\n\nRatio\nNumerical\nEqual intervals, true zero\nHeight, Weight, Income\nAll statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What is Central Tendency?",
    "text": "What is Central Tendency?\nCentral tendency describes the center or typical value of a dataset.\nIt answers the question: “What is a representative value for this data?”"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition and Formula",
    "text": "Definition and Formula\nThe mean is the sum of all values divided by the number of values.\n\nFormula\n\nFor a sample: \\(\\bar{x} = \\frac{\\sum x}{n}\\)\nFor a population: \\(\\mu = \\frac{\\sum x}{N}\\)\n\nWhere:\n\n\\(\\bar{x}\\) (x-bar) = sample mean\n\\(\\mu\\) (mu) = population mean\n\\(\\sum x\\) = sum of all values\n\\(n\\) = sample size, \\(N\\) = population size"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example Calculation",
    "text": "Example Calculation\nStudent test scores: 85, 90, 78, 92, 88\n\nMean = \\(\\frac{85 + 90 + 78 + 92 + 88}{5} = \\frac{433}{5} = 86.6\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mean",
    "text": "Properties of the Mean\n\nUses all data points - every value affects the mean\nSensitive to outliers - extreme values can distort the mean\nUnique - there is only one mean for a dataset\nCan be calculated for interval and ratio data\nBalancing point - sum of deviations from mean equals zero"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mean",
    "text": "When to Use the Mean\n✅ Use the mean when:\n\nData is approximately symmetric\nNo extreme outliers present\nWorking with interval or ratio data\nNeed to use the value in further calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "href": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Advantages and Disadvantages",
    "text": "Advantages and Disadvantages\n\n\nAdvantages\n\nUses all information in the dataset\nAlgebraically defined and mathematically tractable\nWidely understood and accepted\n\n\nDisadvantages\n\nAffected by outliers and skewed distributions\nMay not represent a typical value in skewed data\nCannot be used with nominal or ordinal data"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\nThe median is the middle value when data is arranged in ascending or descending order."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "href": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Calculation Steps",
    "text": "Calculation Steps\n\nArrange data in ascending order\nFind the middle position:\n\nIf n is odd: position = \\(\\frac{n + 1}{2}\\)\nIf n is even: average of positions \\(\\frac{n}{2}\\) and \\(\\frac{n}{2} + 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#examples",
    "href": "files/lecture_notes/lecture2/lecture2.html#examples",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Examples",
    "text": "Examples\n\nOdd number of values:\n\n\nData: 12, 15, 18, 20, 25\nWhat is the median here ?\nMedian = 18 (middle value)\n\n\n\n\nEven number of values:\n\n\nData: 10, 15, 20, 25, 30, 35\nWhat is the median here ?\nMedian = \\(\\frac{20 + 25}{2} = 22.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Median",
    "text": "Properties of the Median\n\n\nNot affected by outliers - resistant measure\nRepresents the 50th percentile\nMay not be an actual data value (when n is even)\nAppropriate for ordinal, interval, and ratio data\nDivides data into two equal halves"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Median",
    "text": "When to Use the Median\n✅ Use the median when:\n\nData is skewed (not symmetric)\nOutliers are present\nWorking with ordinal data\nWant a robust measure of central tendency\nData represents income, housing prices, or similar distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "href": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Median vs Mean with Outliers",
    "text": "Median vs Mean with Outliers\nConsider household incomes: $30,000, $32,000, $35,000, $38,000, $2,000,000\n\n\nMean = $427,000 (not representative of typical household)\nMedian = $35,000 (better represents typical household)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\nThe mode is the value that appears most frequently in a dataset.\n\n\n\n\n\n%%{init: {'flowchart': {'nodeSpacing': 100, 'rankSpacing': 100}, 'width': 600, 'height': 400}}%%\ngraph TD\n    A[\"Mode Types\"]\n    A --&gt; B[\"Unimodal&lt;br/&gt;One peak\"]\n    A --&gt; C[\"Bimodal&lt;br/&gt;Two peaks\"]\n    A --&gt; D[\"Multimodal&lt;br/&gt;Multiple peaks\"]\n    A --&gt; E[\"No Mode&lt;br/&gt;No repeated values\"]\n    \n    classDef main fill:#e1f5fe,stroke:#01579b,stroke-width:3px,font-size:16px\n    classDef types fill:#f5f5f5,stroke:#424242,stroke-width:2px,font-size:14px\n    \n    class A main\n    class B,C,D,E types"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Distributions by Mode",
    "text": "Types of Distributions by Mode\n\nUnimodal: One mode\nBimodal: Two modes\n\nMultimodal: More than two modes\nNo mode: All values appear with equal frequency"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#examples-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#examples-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Examples",
    "text": "Examples\n\n\n\nEx1:\n\n\nData: 2, 3, 3, 4, 5, 5, 5, 6, 7\nWhat is the mode here ?\nMode = 5 (appears 3 times)\nWhat type of mode is it?\nUnimodal\n\n\n\nEx2\n\n\nData: 1, 2, 2, 3, 4, 4, 5\nWhat is the mode here ?\nModes = 2 and 4 (both appear twice)\nWhat type of mode is it?\nBimodal\n\n\n\nEx3\n\n\nData: 1, 2, 3, 4, 5\nWhat is the mode here ?\nNo mode (all appear once)\n\n\n\n\n}"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "href": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mode for Different Data Types",
    "text": "Mode for Different Data Types\nCategorical Data:\nFavorite colors: Red, Blue, Blue, Green, Blue, Red, Blue Mode = Blue\nContinuous Data:\nOften requires grouping into intervals or bins Example: Heights grouped into ranges"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mode",
    "text": "Properties of the Mode\n\nCan be used with any type of data (nominal, ordinal, interval, ratio)\nNot affected by outliers\nMay not exist or may not be unique\nRepresents the most common value\nEasy to identify in frequency distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mode",
    "text": "When to Use the Mode\n✅ Use the mode when:\n\nWorking with categorical (nominal) data\nWant to identify the most popular or common choice\nData has clear peaks in frequency\nQuality control applications (most common defect type)\nBusiness applications (best-selling product, most common customer complaint)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Comparing Measures of Central Tendency",
    "text": "Comparing Measures of Central Tendency\n\n\n\n\n\n\n\n\n\n\nMeasure\nBest for Data Type\nStrengths\nWeaknesses\nAffected by Outliers?\n\n\n\n\nMean\nInterval, Ratio\nUses all data, mathematically tractable\nSensitive to outliers\nYes\n\n\nMedian\nOrdinal, Interval, Ratio\nRobust to outliers, represents middle\nIgnores extreme values\nNo\n\n\nMode\nAll types\nWorks with categorical, identifies most common\nMay not exist/be unique\nNo"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "href": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Shape of Distribution Effects",
    "text": "Shape of Distribution Effects\n\nSymmetric distribution: Mean ≈ Median ≈ Mode\nRight-skewed (positively skewed): Mean &gt; Median &gt; Mode\n\nLeft-skewed (negatively skewed): Mode &gt; Median &gt; Mean"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#essential-libraries",
    "href": "files/lecture_notes/lecture2/lecture2.html#essential-libraries",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Essential Libraries",
    "text": "Essential Libraries\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#calculating-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#calculating-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Calculating the Mean",
    "text": "Calculating the Mean\n\n# Sample data\ndata = [85, 90, 78, 92, 88]\n\n# Using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np}\")\n\n# Using Pandas\ndf = pd.DataFrame({'scores': data})\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd}\")\n\nOutput:\nMean (NumPy): 86.6\nMean (Pandas): 86.6"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#calculating-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#calculating-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Calculating the Median",
    "text": "Calculating the Median\n\n# Using NumPy\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np}\")\n\n# Using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd}\")\n\nOutput:\nMedian (NumPy): 88.0\nMedian (Pandas): 88.0"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#calculating-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#calculating-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Calculating the Mode",
    "text": "Calculating the Mode\n\n# Using SciPy\nfrom scipy import stats\nmode_result = stats.mode(data)\nprint(f\"Mode: {mode_result.mode}, Count: {mode_result.count}\")\n\n# Using Pandas\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#comprehensive-analysis-function",
    "href": "files/lecture_notes/lecture2/lecture2.html#comprehensive-analysis-function",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Comprehensive Analysis Function",
    "text": "Comprehensive Analysis Function\n\ndef descriptive_summary(data, column_name=\"Data\"):\n    \"\"\"Calculate comprehensive descriptive statistics\"\"\"\n    df = pd.DataFrame({column_name: data})\n    \n    print(f\"Descriptive Statistics for {column_name}\")\n    print(\"=\" * 40)\n    print(f\"Count: {len(data)}\")\n    print(f\"Mean: {np.mean(data):.2f}\")\n    print(f\"Median: {np.median(data):.2f}\")\n    \n    try:\n        mode_result = stats.mode(data)\n        print(f\"Mode: {mode_result.mode[0]} (appears {mode_result.count[0]} times)\")\n    except:\n        print(\"Mode: No unique mode\")\n    \n    return df.describe()\n\n# Example usage\ntest_scores = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\nsummary = descriptive_summary(test_scores, \"Test Scores\")"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#handling-categorical-data",
    "href": "files/lecture_notes/lecture2/lecture2.html#handling-categorical-data",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Handling Categorical Data",
    "text": "Handling Categorical Data\n\n# Categorical data example\ncategories = ['A', 'B', 'B', 'C', 'A', 'B', 'A', 'C', 'B', 'B']\ncat_series = pd.Series(categories)\n\nprint(\"Categorical Data Analysis:\")\nprint(f\"Mode: {cat_series.mode().values[0]}\")\nprint(\"\\nValue Counts:\")\nprint(cat_series.value_counts())\n\nOutput:\nCategorical Data Analysis:\nMode: B\n\nValue Counts:\nB    5\nA    3\nC    2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Business Applications",
    "text": "Business Applications\n\nCustomer Satisfaction: Mean rating shows overall satisfaction, median shows typical experience\nSales Data: Mode identifies best-selling products, median shows typical sale amount\n\nEmployee Performance: Mean for overall team performance, median for typical employee"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Educational Applications",
    "text": "Educational Applications\n\nTest Scores: Mean for class average, median for typical student performance\nGrade Distribution: Mode shows most common grade\nAttendance: Mean for overall attendance rate"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Healthcare Applications",
    "text": "Healthcare Applications\n\nPatient Wait Times: Median often preferred due to skewed distributions\nTreatment Outcomes: Mean for overall effectiveness, mode for most common result\nVital Signs: All three measures provide different insights"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "href": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Interpretation Guidelines",
    "text": "Interpretation Guidelines\n\nAlways consider the context of your data\nReport multiple measures when appropriate\n\nBe aware of data distribution shape\nConsider the presence of outliers\nChoose the most appropriate measure for your specific question"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "href": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Remember These Points",
    "text": "Remember These Points\n\nData type determines which statistics are appropriate\nMean uses all data but is sensitive to outliers\nMedian is robust and represents the middle value\nMode identifies the most common value and works with all data types\nContext matters when choosing and interpreting measures\nPython provides powerful tools for calculating descriptive statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "href": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Next Lecture Preview",
    "text": "Next Lecture Preview\nDescriptive Statistics Part II will cover:\n\nMeasures of variability (range, variance, standard deviation)\nMeasures of position (percentiles, quartiles, z-scores)\nShape of distributions (skewness and kurtosis)\nAdvanced Python visualization techniques"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "href": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Try These Problems",
    "text": "Try These Problems\n\nCalculate mean, median, and mode for: 12, 15, 18, 12, 20, 25, 12, 30\nA dataset has mean = 50 and median = 45. What does this tell you about the distribution?\nWhy might median be preferred over mean for reporting household income?\nCreate a Python function to identify the most appropriate measure of central tendency for a given dataset."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#additional-resources",
    "href": "files/lecture_notes/lecture2/lecture2.html#additional-resources",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nPython documentation: pandas.DataFrame.describe()\nNumPy statistical functions documentation\n\nSciPy.stats module reference\nRecommended reading: Chapter 3 in course textbook"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-1-unimodal",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-1-unimodal",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 1: Unimodal",
    "text": "Example 1: Unimodal\nData: 2, 3, 3, 4, 5, 5, 5, 6, 7\n\nAnalysis:\n\n\nCount each value: 2(1), 3(2), 4(1), 5(3), 6(1), 7(1)\nMost frequent value: 5 appears 3 times\nMode = 5\nType: Unimodal (one mode)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-2-bimodal",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-2-bimodal",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 2: Bimodal",
    "text": "Example 2: Bimodal\nData: 1, 2, 2, 3, 4, 4, 5\nAnalysis: - Count each value: 1(1), 2(2), 3(1), 4(2), 5(1) - Most frequent values: 2 and 4 both appear twice - Modes = 2 and 4 - Type: Bimodal (two modes)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-3-no-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-3-no-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 3: No Mode",
    "text": "Example 3: No Mode\nData: 1, 2, 3, 4, 5\nAnalysis: - Count each value: 1(1), 2(1), 3(1), 4(1), 5(1) - All values appear exactly once - No mode (no value repeats) - Type: No mode"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 1:",
    "text": "Example 1:\nData: 2, 3, 3, 4, 5, 5, 5, 6, 7\n\nAnalysis:\n\n\nCount each value: 2(1), 3(2), 4(1), 5(3), 6(1), 7(1)\nMost frequent value: 5 appears 3 times\nMode = 5\nType: Unimodal (one mode)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 2:",
    "text": "Example 2:\nData: 1, 2, 2, 3, 4, 4, 5\n\nAnalysis:\n\n\nCount each value: 1(1), 2(2), 3(1), 4(2), 5(1)\nMost frequent values: 2 and 4 both appear twice\nModes = 2 and 4\nType: Bimodal (two modes)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 3:",
    "text": "Example 3:\nData: 1, 2, 3, 4, 5\n\nAnalysis:\n\n\nCount each value: 1(1), 2(1), 3(1), 4(1), 5(1)\nAll values appear exactly once\nNo mode (no value repeats)\nType: No mode"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics-sec-descriptive",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics-sec-descriptive",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What are Descriptive Statistics? {sec-descriptive}",
    "text": "What are Descriptive Statistics? {sec-descriptive}\n\nDescriptive statistics are numerical and graphical methods used to summarize, organize, and describe data in a meaningful way.\n\nPurpose of Descriptive Statistics\n\nSummarize large datasets into manageable information\nIdentify patterns and trends in data\nCommunicate findings clearly to others\nPrepare data for further analysis\nMake initial assessments about data quality"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#sec-descriptive",
    "href": "files/lecture_notes/lecture2/lecture2.html#sec-descriptive",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What are Descriptive Statistics?",
    "text": "What are Descriptive Statistics?\n\nDescriptive statistics are numerical and graphical methods used to summarize, organize, and describe data in a meaningful way.\n\nPurpose of Descriptive Statistics\n\nSummarize large datasets into manageable information\nIdentify patterns and trends in data\nCommunicate findings clearly to others\nPrepare data for further analysis\nMake initial assessments about data quality"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#plot",
    "href": "files/lecture_notes/lecture2/lecture2.html#plot",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Plot",
    "text": "Plot\n\nPlot.rectY(data, \n  Plot.stackY(\n    Plot.binX( \n      {y: \"count\"}, \n      {x: \"body_mass_g\", fill: \"species\", thresholds: 20})\n    )\n  ).plot({\n    facet: {\n      data,\n      x: \"sex\"\n    },\n    marks: [Plot.frame()]\n  })\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#todays-agenda",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#todays-agenda",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Today’s Agenda",
    "text": "Today’s Agenda\n\nIntroduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\n\nWhy it matters before any modeling\n\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset they’ve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#learning-objectives-los",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#learning-objectives-los",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Learning Objectives (LOs)",
    "text": "Learning Objectives (LOs)\nBy the end of this lecture you should be able to:\n\nDefine descriptive statistics and explain its importance in data analysis (Section 1)\nDistinguish between different types of data and measurement scales (Section 2)\nCalculate and interpret measures of central tendency (mean, median, mode)(Section 3)\nUnderstand when to use each measure of central tendency\nApply Python to compute descriptive statistics(Section 9)\nInterpret basic descriptive statistics in real-world contexts(Section 10)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#statistics",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#statistics",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Statistics",
    "text": "Statistics\n\nFacts are stubborn, but statistics are more pliable.\nMark Twain\n\nStatistics refers to the mathematics and techniques with which we understand data. 1\n\n\n\n(source)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#what-are-descriptive-statistics",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#what-are-descriptive-statistics",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "What are Descriptive Statistics?",
    "text": "What are Descriptive Statistics?\n\nDescriptive statistics are numerical and graphical methods used to summarize, organize, and describe data in a meaningful way.\n\nPurpose of Descriptive Statistics\n\nSummarize large datasets into manageable information\nIdentify patterns and trends in data\nCommunicate findings clearly to others\nPrepare data for further analysis\nMake initial assessments about data quality"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#descriptive-vs.-inferential-statistics",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#descriptive-vs.-inferential-statistics",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Descriptive vs. Inferential Statistics",
    "text": "Descriptive vs. Inferential Statistics\n\n\n\n\n\n\n\nDescriptive Statistics\nInferential Statistics\n\n\n\n\nDescribes what the data shows\nMakes predictions about populations\n\n\nSummarizes sample data\nUses sample data to make generalizations\n\n\nNo conclusions beyond the data\nDraws conclusions beyond the immediate data\n\n\nExamples: mean, median, graphs\nExamples: hypothesis testing, confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#descriptive-vs.-inferential-statistics-1",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#descriptive-vs.-inferential-statistics-1",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Descriptive vs. Inferential Statistics",
    "text": "Descriptive vs. Inferential Statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#why-data-types-matter",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#why-data-types-matter",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Why Data Types Matter",
    "text": "Why Data Types Matter\nUnderstanding data types is crucial because:\n\n\nDifferent statistics are appropriate for different data types\nStatistical methods depend on the level of measurement\nMisapplying statistics can lead to incorrect conclusions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#types-of-data",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#types-of-data",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Types of Data",
    "text": "Types of Data\n\n\n\n\n\ngraph TD\n    A[Variable Types]\n    A --&gt; B[Categorical]\n    A --&gt; C[Numerical]\n    B --&gt; B1[\"Nominal&lt;br/&gt;e.g., gender, major\"]\n    B --&gt; B2[\"Ordinal&lt;br/&gt;e.g., rating, education level\"]\n    C --&gt; C1[\"Discrete&lt;br/&gt;e.g., count (# of students)\"]\n    C --&gt; C2[\"Continuous&lt;br/&gt;e.g., measurements like height, weight\"]\n    \n    classDef root fill:#e1f5fe,stroke:#01579b,stroke-width:3px\n    classDef categorical fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef numerical fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px\n    classDef nominal fill:#fce4ec,stroke:#880e4f,stroke-width:2px\n    classDef ordinal fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef discrete fill:#e0f2f1,stroke:#00695c,stroke-width:2px\n    classDef continuous fill:#f1f8e9,stroke:#33691e,stroke-width:2px\n    \n    class A root\n    class B categorical\n    class C numerical\n    class B1 nominal\n    class B2 ordinal\n    class C1 discrete\n    class C2 continuous\n\n\n\n\n\n\n\nPrompt: Which summary stat would you pick for “major”? For “gpa”?"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#categorical-data-qualitative",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#categorical-data-qualitative",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Categorical Data (Qualitative)",
    "text": "Categorical Data (Qualitative)\n\n\nNominal Data\n\nCategories with no natural order\nExamples: gender, color, brand names, marital status\nAppropriate statistics: mode, frequency counts, proportions\n\n\nOrdinal Data\n\nCategories with a natural order or ranking\nExamples: education level, satisfaction ratings, letter grades\nAppropriate statistics: mode, median, percentiles"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#numerical-data-quantitative",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#numerical-data-quantitative",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Numerical Data (Quantitative)",
    "text": "Numerical Data (Quantitative)\n\nDiscrete Data\n\nCountable values, often integers\nExamples: number of children, cars sold, defective items\nCan take on finite or countably infinite values\n\n\n\nContinuous Data\n\nCan take any value within a range\nExamples: height, weight, temperature, time\nMeasured rather than counted"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#measurement-scales-summary",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#measurement-scales-summary",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Measurement Scales Summary",
    "text": "Measurement Scales Summary\n\n\n\n\n\n\n\n\n\n\nScale\nType\nProperties\nExamples\nAppropriate Statistics\n\n\n\n\nNominal\nCategorical\nCategories only\nGender, Color\nMode, Frequency\n\n\nOrdinal\nCategorical\nOrder matters\nRankings, Grades\nMode, Median\n\n\nInterval\nNumerical\nEqual intervals, no true zero\nTemperature (°C)\nMean, Median, Mode\n\n\nRatio\nNumerical\nEqual intervals, true zero\nHeight, Weight, Income\nAll statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#what-is-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#what-is-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "What is Central Tendency?",
    "text": "What is Central Tendency?\nCentral tendency describes the center or typical value of a dataset.\nIt answers the question: “What is a representative value for this data?”"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#definition-and-formula",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#definition-and-formula",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Definition and Formula",
    "text": "Definition and Formula\nThe mean is the sum of all values divided by the number of values.\n\nFormula\n\nFor a sample: \\(\\bar{x} = \\frac{\\sum x}{n}\\)\nFor a population: \\(\\mu = \\frac{\\sum x}{N}\\)\n\nWhere:\n\n\\(\\bar{x}\\) (x-bar) = sample mean\n\\(\\mu\\) (mu) = population mean\n\\(\\sum x\\) = sum of all values\n\\(n\\) = sample size, \\(N\\) = population size"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#example-calculation",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#example-calculation",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Example Calculation",
    "text": "Example Calculation\nStudent test scores: 85, 90, 78, 92, 88\n\nMean = \\(\\frac{85 + 90 + 78 + 92 + 88}{5} = \\frac{433}{5} = 86.6\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#properties-of-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#properties-of-the-mean",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Properties of the Mean",
    "text": "Properties of the Mean\n\nUses all data points - every value affects the mean\nSensitive to outliers - extreme values can distort the mean\nUnique - there is only one mean for a dataset\nCan be calculated for interval and ratio data\nBalancing point - sum of deviations from mean equals zero"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#when-to-use-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#when-to-use-the-mean",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "When to Use the Mean",
    "text": "When to Use the Mean\n✅ Use the mean when:\n\nData is approximately symmetric\nNo extreme outliers present\nWorking with interval or ratio data\nNeed to use the value in further calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#advantages-and-disadvantages",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#advantages-and-disadvantages",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Advantages and Disadvantages",
    "text": "Advantages and Disadvantages\n\n\nAdvantages\n\nUses all information in the dataset\nAlgebraically defined and mathematically tractable\nWidely understood and accepted\n\n\nDisadvantages\n\nAffected by outliers and skewed distributions\nMay not represent a typical value in skewed data\nCannot be used with nominal or ordinal data"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#definition",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#definition",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Definition",
    "text": "Definition\nThe median is the middle value when data is arranged in ascending or descending order."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#calculation-steps",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#calculation-steps",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Calculation Steps",
    "text": "Calculation Steps\n\nArrange data in ascending order\nFind the middle position:\n\nIf n is odd: position = \\(\\frac{n + 1}{2}\\)\nIf n is even: average of positions \\(\\frac{n}{2}\\) and \\(\\frac{n}{2} + 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#examples",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#examples",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Examples",
    "text": "Examples\n\nOdd number of values:\n\n\nData: 12, 15, 18, 20, 25\nWhat is the median here ?\nMedian = 18 (middle value)\n\n\n\n\nEven number of values:\n\n\nData: 10, 15, 20, 25, 30, 35\nWhat is the median here ?\nMedian = \\(\\frac{20 + 25}{2} = 22.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#properties-of-the-median",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#properties-of-the-median",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Properties of the Median",
    "text": "Properties of the Median\n\n\nNot affected by outliers - resistant measure\nRepresents the 50th percentile\nMay not be an actual data value (when n is even)\nAppropriate for ordinal, interval, and ratio data\nDivides data into two equal halves"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#when-to-use-the-median",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#when-to-use-the-median",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "When to Use the Median",
    "text": "When to Use the Median\n✅ Use the median when:\n\nData is skewed (not symmetric)\nOutliers are present\nWorking with ordinal data\nWant a robust measure of central tendency\nData represents income, housing prices, or similar distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#median-vs-mean-with-outliers",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#median-vs-mean-with-outliers",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Median vs Mean with Outliers",
    "text": "Median vs Mean with Outliers\nConsider household incomes: $30,000, $32,000, $35,000, $38,000, $2,000,000\n\n\nMean = $427,000 (not representative of typical household)\nMedian = $35,000 (better represents typical household)"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Course Resources",
    "section": "",
    "text": "🔍"
  },
  {
    "objectID": "resources.html#textbook-readings",
    "href": "resources.html#textbook-readings",
    "title": "Week 1 Resources",
    "section": "",
    "text": "OpenIntro Statistics, Chapters 1 & 2\nFoundations of data, variables, and basic descriptive statistics\n/files/Book/os4_for_screen_reader.pdf\nPython for Data Analysis (McKinney), Chapter 5\nSummary and aggregation functions in pandas (describe(), groupby)\nhttps://learning.oreilly.com/library/view/data-science-from/9781491901410/ch05.html#idp14953264"
  },
  {
    "objectID": "resources.html#interactive-tutorials",
    "href": "resources.html#interactive-tutorials",
    "title": "Week 1 Resources",
    "section": "2. Interactive Tutorials",
    "text": "2. Interactive Tutorials\n\nUCSB Library Data Lab: “Data Types and Format”\nHands-on lesson covering Python data types, pandas DataFrame structures, and I/O\nhttps://carpentry.library.ucsb.edu/2025-01-14-python-ecology-lesson/04-data-types-and-format.html"
  },
  {
    "objectID": "resources.html#api-documentation",
    "href": "resources.html#api-documentation",
    "title": "Week 1 Resources",
    "section": "3. API Documentation",
    "text": "3. API Documentation\n\npandas — DataFrame.describe()\nQuick overview of central tendency, dispersion, and shape of your DataFrame\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\nNumPy — Statistical functions (mean, median, std, percentile, …)\nhttps://numpy.org/doc/2.1/reference/routines.statistics.html\nSciPy — scipy.stats module (distributions, tests, descriptive stats)\nhttps://docs.scipy.org/doc/scipy/reference/stats.html"
  },
  {
    "objectID": "resources.html#live-demos-with-observable",
    "href": "resources.html#live-demos-with-observable",
    "title": "Week 1 Resources",
    "section": "4. Live Demos with Observable",
    "text": "4. Live Demos with Observable\n\n4.1 pandas.DataFrame.describe() demo"
  },
  {
    "objectID": "resources.html#course-resources",
    "href": "resources.html#course-resources",
    "title": "Resources",
    "section": "",
    "text": "OpenIntro Statistics, Chapters 1 & 2\nFoundations of data, variables, and basic descriptive statistics\nPython for Data Analysis (McKinney), Ch. 5\nSummary and aggregation functions in pandas (describe(), groupby)\n\n\n\n\n\nUCSB Library Data Lab: “Data Types and Format”\nHands-on lesson covering Python data types, pandas DataFrame structures, and I/O\n\n\n\n\n\npandas.DataFrame.describe()\nCentral tendency, dispersion, and shape of your DataFrame\nNumPy statistical functions\nmean, median, std, percentile, and more\nSciPy stats module\nProbability distributions, statistical tests, and descriptive statistics\n\n\n\n\n\n(Resources coming soon!)"
  },
  {
    "objectID": "resources.html#week-1-foundations-of-data-science",
    "href": "resources.html#week-1-foundations-of-data-science",
    "title": "Course Resources",
    "section": "Week 1: Foundations of Data Science",
    "text": "Week 1: Foundations of Data Science"
  },
  {
    "objectID": "resources.html#getting-started-with-data",
    "href": "resources.html#getting-started-with-data",
    "title": "Course Resources",
    "section": "Getting Started with Data",
    "text": "Getting Started with Data\nThis week introduces fundamental concepts in data science, including data types, basic statistics, and essential Python tools for data manipulation and analysis."
  },
  {
    "objectID": "resources.html#week-2-data-visualization",
    "href": "resources.html#week-2-data-visualization",
    "title": "Course Resources",
    "section": "Week 2: Data Visualization",
    "text": "Week 2: Data Visualization\n\n\n🚧\n\n\nResources Coming Soon!\nWeek 2 materials focusing on matplotlib, seaborn, and plotly will be available next week. Check back soon for visualization tutorials and interactive exercises."
  },
  {
    "objectID": "resources.html#week-3-statistical-analysis",
    "href": "resources.html#week-3-statistical-analysis",
    "title": "Course Resources",
    "section": "Week 3: Statistical Analysis",
    "text": "Week 3: Statistical Analysis\n\n\n📊\n\n\nStatistical Inference & Confidence Intervals (CI’s)\nWeek 3 will cover statistical inference,and confidence intervals. Materials will be posted by week 3."
  },
  {
    "objectID": "resources.html#week-4-advanced-topics",
    "href": "resources.html#week-4-advanced-topics",
    "title": "",
    "section": "Week 4: Advanced Topics",
    "text": "Week 4: Advanced Topics\n\n\n🔬\n\n\nMachine Learning Fundamentals\nWeek 4 introduces supervised learning, model evaluation, and scikit-learn basics. Resources will be available by [DATE].\n\n\n\n\nCode\nviewof searchTerm = html`&lt;div&gt;&lt;/div&gt;`\n\n// Get search input and add event listener\ndocument.getElementById('searchInput').addEventListener('input', function() {\n  const searchTerm = this.value.toLowerCase();\n  const resourceCards = document.querySelectorAll('.resource-card');\n  \n  resourceCards.forEach(card =&gt; {\n    const title = card.querySelector('.resource-title').textContent.toLowerCase();\n    const description = card.querySelector('.resource-description').textContent.toLowerCase();\n    const type = card.querySelector('.resource-type').textContent.toLowerCase();\n    \n    if (title.includes(searchTerm) || description.includes(searchTerm) || type.includes(searchTerm)) {\n      card.style.display = 'block';\n      card.style.opacity = '1';\n      card.style.transform = 'scale(1)';\n    } else if (searchTerm !== '') {\n      card.style.opacity = '0.3';\n      card.style.transform = 'scale(0.95)';\n    } else {\n      card.style.opacity = '1';\n      card.style.transform = 'scale(1)';\n    }\n  });\n});"
  },
  {
    "objectID": "resources.html#week-4-statistical-methods-testing",
    "href": "resources.html#week-4-statistical-methods-testing",
    "title": "Course Resources",
    "section": "Week 4: Statistical Methods & Testing",
    "text": "Week 4: Statistical Methods & Testing\n\n\n🔬\n\n\nHypothesis Testing Fundamentals\nWeek 4 will cover hypothesis testing, and two sample t-Tests. Materials will be posted by week 4."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSTAT 5A: Understanding Data",
    "section": "",
    "text": "Learn the fundamentals of data science and statistical thinking\n\n\nSummer Session A 2025 • Taught by Narjes Mathlouthi\n\nGet Started →"
  },
  {
    "objectID": "index.html#quick-navigation",
    "href": "index.html#quick-navigation",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Quick Navigation",
    "text": "Quick Navigation\n\nEverything you need for the course, organized and accessible"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Get in Touch\n\nWe’re here to help you succeed in PSTAT 5A\n\n\n\n\n\n\nNM\n\n\nCourse Instructor\n\n\nNarjes Mathlouthi\n\n\n\n\n📧\n\n\nnmathlouthi@ucsb.edu\n\n\n\n\n🏢\n\n\nEllison Hall 5829\n\n\n\n\n🕐\n\n\nThursdays 11:00 AM–12:00 PM\n\n\n\n\n💻\n\n\nVia Zoom or by appointment\n\n\n\n\n\n\nSL\n\n\nTeaching Assistant\n\n\nSummer Le\n\n\n\n\n📧\n\n\nsle@ucsb.edu\n\n\n\n\n🕐\n\n\nFriday 1:00 PM – 2:00 PM\n\n\n\n\n💻\n\n\nVia Zoom (links on Canvas)\n\n\n\n\n\n\n\nMH\n\n\nTeaching Assistant\n\n\nMingzhu He\n\n\n\n\n📧\n\n\nmingzhuhe@ucsb.edu\n\n\n\n\n🕐\n\n\nTuesday 11:00 AM – 12:00 PM\n\n\n\n\n💻\n\n\nVia Zoom (links on Canvas)\n\n\n\n\n\n\n\nInstructor Office Hours\n\n\nThursdays 11:00 AM – 12:00 PM\n\n\nAvailable via Zoom or by appointment  Zoom links posted on Canvas\n\n\n\n\n\nCommunication Guidelines\n\n\n\n1\n\n\nSubject Line: Always include [PSTAT 5A] in your email subject for faster response\n\n\n\n\n2\n\n\nResponse Time: Allow 24–48 hours for replies (avoid sending on weekends)\n\n\n\n\n3\n\n\nUse UCSB Email: Always email from your UCSB account for verification\n\n\n\n\n4\n\n\nOffice Hours: Use office hours for complex questions or detailed help\n\n\n\n\n5\n\n\nUrgent Matters: For time-sensitive issues, mention “URGENT” in the subject line\n\n\n\n\n\n\nEmergency Contacts\n\n\nFor campus emergencies: 911 • For student crisis support: CAPS 24/7 line (805) 893-4411"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "",
    "text": "Introduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\n\nWhy it matters before any modeling\n\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset they’ve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#footnotes",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#footnotes",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(source)↩︎"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html",
    "title": "Lecture 2: Descriptive Statistics I - Part II",
    "section": "",
    "text": "Introduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\n\nWhy it matters before any modeling\n\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset they’ve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#todays-agenda",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#todays-agenda",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Today’s Agenda",
    "text": "Today’s Agenda\n\nIntroduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\n\nWhy it matters before any modeling\n\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset they’ve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#learning-objectives-los",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#learning-objectives-los",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Learning Objectives (LOs)",
    "text": "Learning Objectives (LOs)\nBy the end of this lecture you should be able to:\n\nDefine descriptive statistics and explain its importance in data analysis (Section 1)\nDistinguish between different types of data and measurement scales (Section 2)\nCalculate and interpret measures of central tendency (mean, median, mode)(Section 3)\nUnderstand when to use each measure of central tendency\nApply Python to compute descriptive statistics(Section 9)\nInterpret basic descriptive statistics in real-world contexts(Section 10)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#statistics",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#statistics",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Statistics",
    "text": "Statistics\n\nFacts are stubborn, but statistics are more pliable.\nMark Twain\n\nStatistics refers to the mathematics and techniques with which we understand data. 1\n\n\n\n(source)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#what-are-descriptive-statistics",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#what-are-descriptive-statistics",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "What are Descriptive Statistics?",
    "text": "What are Descriptive Statistics?\n\nDescriptive statistics are numerical and graphical methods used to summarize, organize, and describe data in a meaningful way.\n\nPurpose of Descriptive Statistics\n\nSummarize large datasets into manageable information\nIdentify patterns and trends in data\nCommunicate findings clearly to others\nPrepare data for further analysis\nMake initial assessments about data quality"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#descriptive-vs.-inferential-statistics",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#descriptive-vs.-inferential-statistics",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Descriptive vs. Inferential Statistics",
    "text": "Descriptive vs. Inferential Statistics\n\n\n\n\n\n\n\nDescriptive Statistics\nInferential Statistics\n\n\n\n\nDescribes what the data shows\nMakes predictions about populations\n\n\nSummarizes sample data\nUses sample data to make generalizations\n\n\nNo conclusions beyond the data\nDraws conclusions beyond the immediate data\n\n\nExamples: mean, median, graphs\nExamples: hypothesis testing, confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#descriptive-vs.-inferential-statistics-1",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#descriptive-vs.-inferential-statistics-1",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Descriptive vs. Inferential Statistics",
    "text": "Descriptive vs. Inferential Statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#why-data-types-matter",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#why-data-types-matter",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Why Data Types Matter",
    "text": "Why Data Types Matter\nUnderstanding data types is crucial because:\n\n\nDifferent statistics are appropriate for different data types\nStatistical methods depend on the level of measurement\nMisapplying statistics can lead to incorrect conclusions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#types-of-data",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#types-of-data",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Types of Data",
    "text": "Types of Data\n\ngraph TD\n    A[Variable Types]\n    A --&gt; B[Categorical]\n    A --&gt; C[Numerical]\n    B --&gt; B1[\"Nominal&lt;br/&gt;e.g., gender, major\"]\n    B --&gt; B2[\"Ordinal&lt;br/&gt;e.g., rating, education level\"]\n    C --&gt; C1[\"Discrete&lt;br/&gt;e.g., count (# of students)\"]\n    C --&gt; C2[\"Continuous&lt;br/&gt;e.g., measurements like height, weight\"]\n    \n    classDef root fill:#e1f5fe,stroke:#01579b,stroke-width:3px\n    classDef categorical fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef numerical fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px\n    classDef nominal fill:#fce4ec,stroke:#880e4f,stroke-width:2px\n    classDef ordinal fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef discrete fill:#e0f2f1,stroke:#00695c,stroke-width:2px\n    classDef continuous fill:#f1f8e9,stroke:#33691e,stroke-width:2px\n    \n    class A root\n    class B categorical\n    class C numerical\n    class B1 nominal\n    class B2 ordinal\n    class C1 discrete\n    class C2 continuous\n\n\n\n\ngraph TD\n    A[Variable Types]\n    A --&gt; B[Categorical]\n    A --&gt; C[Numerical]\n    B --&gt; B1[\"Nominal&lt;br/&gt;e.g., gender, major\"]\n    B --&gt; B2[\"Ordinal&lt;br/&gt;e.g., rating, education level\"]\n    C --&gt; C1[\"Discrete&lt;br/&gt;e.g., count (# of students)\"]\n    C --&gt; C2[\"Continuous&lt;br/&gt;e.g., measurements like height, weight\"]\n    \n    classDef root fill:#e1f5fe,stroke:#01579b,stroke-width:3px\n    classDef categorical fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef numerical fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px\n    classDef nominal fill:#fce4ec,stroke:#880e4f,stroke-width:2px\n    classDef ordinal fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef discrete fill:#e0f2f1,stroke:#00695c,stroke-width:2px\n    classDef continuous fill:#f1f8e9,stroke:#33691e,stroke-width:2px\n    \n    class A root\n    class B categorical\n    class C numerical\n    class B1 nominal\n    class B2 ordinal\n    class C1 discrete\n    class C2 continuous\n\n\n\n\n\n\n\nPrompt: Which summary stat would you pick for “major”? For “gpa”?"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#categorical-data-qualitative",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#categorical-data-qualitative",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Categorical Data (Qualitative)",
    "text": "Categorical Data (Qualitative)\n\n\nNominal Data\n\nCategories with no natural order\nExamples: gender, color, brand names, marital status\nAppropriate statistics: mode, frequency counts, proportions\n\n\nOrdinal Data\n\nCategories with a natural order or ranking\nExamples: education level, satisfaction ratings, letter grades\nAppropriate statistics: mode, median, percentiles"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#numerical-data-quantitative",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#numerical-data-quantitative",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Numerical Data (Quantitative)",
    "text": "Numerical Data (Quantitative)\n\nDiscrete Data\n\nCountable values, often integers\nExamples: number of children, cars sold, defective items\nCan take on finite or countably infinite values\n\n\n\nContinuous Data\n\nCan take any value within a range\nExamples: height, weight, temperature, time\nMeasured rather than counted"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#measurement-scales-summary",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#measurement-scales-summary",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Measurement Scales Summary",
    "text": "Measurement Scales Summary\n\n\n\n\n\n\n\n\n\n\nScale\nType\nProperties\nExamples\nAppropriate Statistics\n\n\n\n\nNominal\nCategorical\nCategories only\nGender, Color\nMode, Frequency\n\n\nOrdinal\nCategorical\nOrder matters\nRankings, Grades\nMode, Median\n\n\nInterval\nNumerical\nEqual intervals, no true zero\nTemperature (°C)\nMean, Median, Mode\n\n\nRatio\nNumerical\nEqual intervals, true zero\nHeight, Weight, Income\nAll statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#what-is-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#what-is-central-tendency",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "What is Central Tendency?",
    "text": "What is Central Tendency?\nCentral tendency describes the center or typical value of a dataset.\nIt answers the question: “What is a representative value for this data?”"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#definition-and-formula",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#definition-and-formula",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Definition and Formula",
    "text": "Definition and Formula\nThe mean is the sum of all values divided by the number of values.\n\nFormula\n\nFor a sample: \\(\\bar{x} = \\frac{\\sum x}{n}\\)\nFor a population: \\(\\mu = \\frac{\\sum x}{N}\\)\n\nWhere:\n\n\\(\\bar{x}\\) (x-bar) = sample mean\n\\(\\mu\\) (mu) = population mean\n\\(\\sum x\\) = sum of all values\n\\(n\\) = sample size, \\(N\\) = population size"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#example-calculation",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#example-calculation",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Example Calculation",
    "text": "Example Calculation\nStudent test scores: 85, 90, 78, 92, 88\n\nMean = \\(\\frac{85 + 90 + 78 + 92 + 88}{5} = \\frac{433}{5} = 86.6\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#properties-of-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#properties-of-the-mean",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Properties of the Mean",
    "text": "Properties of the Mean\n\nUses all data points - every value affects the mean\nSensitive to outliers - extreme values can distort the mean\nUnique - there is only one mean for a dataset\nCan be calculated for interval and ratio data\nBalancing point - sum of deviations from mean equals zero"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#when-to-use-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#when-to-use-the-mean",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "When to Use the Mean",
    "text": "When to Use the Mean\n✅ Use the mean when:\n\nData is approximately symmetric\nNo extreme outliers present\nWorking with interval or ratio data\nNeed to use the value in further calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#advantages-and-disadvantages",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#advantages-and-disadvantages",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Advantages and Disadvantages",
    "text": "Advantages and Disadvantages\n\n\nAdvantages\n\nUses all information in the dataset\nAlgebraically defined and mathematically tractable\nWidely understood and accepted\n\n\nDisadvantages\n\nAffected by outliers and skewed distributions\nMay not represent a typical value in skewed data\nCannot be used with nominal or ordinal data"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#definition",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#definition",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Definition",
    "text": "Definition\nThe median is the middle value when data is arranged in ascending or descending order."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#calculation-steps",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#calculation-steps",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Calculation Steps",
    "text": "Calculation Steps\n\nArrange data in ascending order\nFind the middle position:\n\nIf n is odd: position = \\(\\frac{n + 1}{2}\\)\nIf n is even: average of positions \\(\\frac{n}{2}\\) and \\(\\frac{n}{2} + 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#examples",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#examples",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Examples",
    "text": "Examples\n\nOdd number of values:\n\n\nData: 12, 15, 18, 20, 25\nWhat is the median here ?\nMedian = 18 (middle value)\n\n\n\n\nEven number of values:\n\n\nData: 10, 15, 20, 25, 30, 35\nWhat is the median here ?\nMedian = \\(\\frac{20 + 25}{2} = 22.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#properties-of-the-median",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#properties-of-the-median",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Properties of the Median",
    "text": "Properties of the Median\n\n\nNot affected by outliers - resistant measure\nRepresents the 50th percentile\nMay not be an actual data value (when n is even)\nAppropriate for ordinal, interval, and ratio data\nDivides data into two equal halves"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#when-to-use-the-median",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#when-to-use-the-median",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "When to Use the Median",
    "text": "When to Use the Median\n✅ Use the median when:\n\nData is skewed (not symmetric)\nOutliers are present\nWorking with ordinal data\nWant a robust measure of central tendency\nData represents income, housing prices, or similar distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#median-vs-mean-with-outliers",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#median-vs-mean-with-outliers",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Median vs Mean with Outliers",
    "text": "Median vs Mean with Outliers\nConsider household incomes: $30,000, $32,000, $35,000, $38,000, $2,000,000\n\n\nMean = $427,000 (not representative of typical household)\nMedian = $35,000 (better represents typical household)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#definition-1",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#definition-1",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Definition",
    "text": "Definition\nThe mode is the value that appears most frequently in a dataset."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#types-of-distributions-by-mode",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#types-of-distributions-by-mode",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Types of Distributions by Mode",
    "text": "Types of Distributions by Mode\n\nUnimodal: One mode\nBimodal: Two modes\n\nMultimodal: More than two modes\nNo mode: All values appear with equal frequency"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#example-1",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#example-1",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Example 1:",
    "text": "Example 1:\nData: 2, 3, 3, 4, 5, 5, 5, 6, 7\n\nAnalysis:\n\n\nCount each value: 2(1), 3(2), 4(1), 5(3), 6(1), 7(1)\nMost frequent value: 5 appears 3 times\nMode = 5\nType: Unimodal (one mode)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#example-2",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#example-2",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Example 2:",
    "text": "Example 2:\nData: 1, 2, 2, 3, 4, 4, 5\n\nAnalysis:\n\n\nCount each value: 1(1), 2(2), 3(1), 4(2), 5(1)\nMost frequent values: 2 and 4 both appear twice\nModes = 2 and 4\nType: Bimodal (two modes)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#example-3",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#example-3",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Example 3:",
    "text": "Example 3:\nData: 1, 2, 3, 4, 5\n\nAnalysis:\n\n\nCount each value: 1(1), 2(1), 3(1), 4(1), 5(1)\nAll values appear exactly once\nNo mode (no value repeats)\nType: No mode"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#mode-for-different-data-types",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#mode-for-different-data-types",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Mode for Different Data Types",
    "text": "Mode for Different Data Types\nCategorical Data:\nFavorite colors: Red, Blue, Blue, Green, Blue, Red, Blue Mode = Blue\nContinuous Data:\nOften requires grouping into intervals or bins Example: Heights grouped into ranges"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#properties-of-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#properties-of-the-mode",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Properties of the Mode",
    "text": "Properties of the Mode\n\nCan be used with any type of data (nominal, ordinal, interval, ratio)\nNot affected by outliers\nMay not exist or may not be unique\nRepresents the most common value\nEasy to identify in frequency distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#when-to-use-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#when-to-use-the-mode",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "When to Use the Mode",
    "text": "When to Use the Mode\n✅ Use the mode when:\n\nWorking with categorical (nominal) data\nWant to identify the most popular or common choice\nData has clear peaks in frequency\nQuality control applications (most common defect type)\nBusiness applications (best-selling product, most common customer complaint)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#comparing-measures-of-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#comparing-measures-of-central-tendency",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Comparing Measures of Central Tendency",
    "text": "Comparing Measures of Central Tendency\n\n\n\n\n\n\n\n\n\n\nMeasure\nBest for Data Type\nStrengths\nWeaknesses\nAffected by Outliers?\n\n\n\n\nMean\nInterval, Ratio\nUses all data, mathematically tractable\nSensitive to outliers\nYes\n\n\nMedian\nOrdinal, Interval, Ratio\nRobust to outliers, represents middle\nIgnores extreme values\nNo\n\n\nMode\nAll types\nWorks with categorical, identifies most common\nMay not exist/be unique\nNo"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#shape-of-distribution-effects",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#shape-of-distribution-effects",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Shape of Distribution Effects",
    "text": "Shape of Distribution Effects\n\nSymmetric distribution: Mean ≈ Median ≈ Mode\nRight-skewed (positively skewed): Mean &gt; Median &gt; Mode\n\nLeft-skewed (negatively skewed): Mode &gt; Median &gt; Mean"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#essential-libraries",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#essential-libraries",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Essential Libraries",
    "text": "Essential Libraries\n\nImport LibrariesLibrary OverviewReferences & Further Reading\n\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set styling for better plots\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n\n\n\n\n\n\n\n\n\n\n\n\nLibrary\nPurpose\nKey Functions\n\n\n\n\nNumPy\nNumerical computing\nnp.mean(), np.median(), np.std()\n\n\nPandas\nData manipulation\ndf.describe(), df.mean(), df.median()\n\n\nSciPy\nScientific computing\nstats.describe()\n\n\nMatplotlib\nBasic plotting\nplt.plot(), plt.hist(), plt.boxplot()\n\n\nSeaborn\nStatistical visualization\nsns.histplot(), sns.boxplot()\n\n\n\n\n\nCalculating the Mean\n\n# Sample data\ndata = [85, 90, 78, 92, 88]\n\n# Using NumPy\nimport numpy as np\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np}\")\n\n# Using Pandas\ndf = pd.DataFrame({'scores': data})\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd}\")\n\nMean (NumPy): 86.6\nMean (Pandas): 86.6\n\n\nOutput:\nMean (NumPy): 86.6\nMean (Pandas): 86.6\n\n\nCalculating the Median\n\n# Using NumPy\nimport numpy as np\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np}\")\n\n# Using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd}\")\n\nMedian (NumPy): 88.0\nMedian (Pandas): 88.0\n\n\nOutput:\nMedian (NumPy): 88.0\nMedian (Pandas): 88.0\n\n\nCalculating the Mode\n\n# Using SciPy\nfrom scipy import stats\nmode_result = stats.mode(data)\nprint(f\"Mode: {mode_result.mode}, Count: {mode_result.count}\")\n\n# Using Pandas\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\nMode: 78, Count: 1\nMode (Pandas): [78 85 88 90 92]\n\n\n\n\nComprehensive Analysis Function\n\nimport pandas as pd\nimport numpy as np\ndef descriptive_summary(data, column_name=\"Data\"):\n    \"\"\"Calculate comprehensive descriptive statistics\"\"\"\n    df = pd.DataFrame({column_name: data})\n    \n    print(f\"Descriptive Statistics for {column_name}\")\n    print(\"=\" * 40)\n    print(f\"Count: {len(data)}\")\n    print(f\"Mean: {np.mean(data):.2f}\")\n    print(f\"Median: {np.median(data):.2f}\")\n    \n    try:\n        mode_result = stats.mode(data)\n        print(f\"Mode: {mode_result.mode[0]} (appears {mode_result.count[0]} times)\")\n    except:\n        print(\"Mode: No unique mode\")\n    \n    return df.describe()\n\n# Example usage\ntest_scores = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\nsummary = descriptive_summary(test_scores, \"Test Scores\")\n\nDescriptive Statistics for Test Scores\n========================================\nCount: 10\nMean: 87.10\nMedian: 87.50\nMode: No unique mode\n\n\n\n\nHandling Categorical Data\n\n# Categorical data example\ncategories = ['A', 'B', 'B', 'C', 'A', 'B', 'A', 'C', 'B', 'B']\ncat_series = pd.Series(categories)\n\nprint(\"Categorical Data Analysis:\")\nprint(f\"Mode: {cat_series.mode().values[0]}\")\nprint(\"\\nValue Counts:\")\nprint(cat_series.value_counts())\n\nCategorical Data Analysis:\nMode: B\n\nValue Counts:\nB    5\nA    3\nC    2\nName: count, dtype: int64\n\n\nOutput:\nCategorical Data Analysis:\nMode: B\n\nValue Counts:\nB    5\nA    3\nC    2\n\n\nReal-world Applications\n5 minutes\n\n\nBusiness Applications\n\nCustomer Satisfaction: Mean rating shows overall satisfaction, median shows typical experience\nSales Data: Mode identifies best-selling products, median shows typical sale amount\n\nEmployee Performance: Mean for overall team performance, median for typical employee\n\n\n\nEducational Applications\n\nTest Scores: Mean for class average, median for typical student performance\nGrade Distribution: Mode shows most common grade\nAttendance: Mean for overall attendance rate\n\n\n\nHealthcare Applications\n\nPatient Wait Times: Median often preferred due to skewed distributions\nTreatment Outcomes: Mean for overall effectiveness, mode for most common result\nVital Signs: All three measures provide different insights\n\n\n\nInterpretation Guidelines\n\nAlways consider the context of your data\nReport multiple measures when appropriate\n\nBe aware of data distribution shape\nConsider the presence of outliers\nChoose the most appropriate measure for your specific question\n\n\n\n\nKey Takeaways\n\n\n\nRemember These Points\n\nData type determines which statistics are appropriate\nMean uses all data but is sensitive to outliers\nMedian is robust and represents the middle value\nMode identifies the most common value and works with all data types\nContext matters when choosing and interpreting measures\nPython provides powerful tools for calculating descriptive statistics\n\n\n\nNext Lecture Preview\nDescriptive Statistics Part II will cover:\n\nMeasures of variability (range, variance, standard deviation)\nMeasures of position (percentiles, quartiles, z-scores)\nShape of distributions (skewness and kurtosis)\nAdvanced Python visualization techniques\n\n\n\n\nPractice Problems\n\n\n\nTry These Problems\n\nCalculate mean, median, and mode for: 12, 15, 18, 12, 20, 25, 12, 30\nA dataset has mean = 50 and median = 45. What does this tell you about the distribution?\nWhy might median be preferred over mean for reporting household income?\nCreate a Python function to identify the most appropriate measure of central tendency for a given dataset.\n\n\n\n\nQuestions?\nThank you for your attention!\n\n\n\n\n\n\nOpenIntro Statistics, Ch. 1 & 2\nPython for Data Analysis (McKinney), Ch. 5\nUCSB Library Data Lab workshops\npandas DataFrame.describe() ￼\nNumPy statistical functions ￼\nSciPy stats module reference"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#calculating-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#calculating-the-mean",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Calculating the Mean",
    "text": "Calculating the Mean\n\n# Sample data\ndata = [85, 90, 78, 92, 88]\n\n# Using NumPy\nimport numpy as np\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np}\")\n\n# Using Pandas\ndf = pd.DataFrame({'scores': data})\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd}\")\n\nMean (NumPy): 86.6\nMean (Pandas): 86.6\n\n\nOutput:\nMean (NumPy): 86.6\nMean (Pandas): 86.6"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#calculating-the-median",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#calculating-the-median",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Calculating the Median",
    "text": "Calculating the Median\n\n# Using NumPy\nimport numpy as np\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np}\")\n\n# Using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd}\")\n\nMedian (NumPy): 88.0\nMedian (Pandas): 88.0\n\n\nOutput:\nMedian (NumPy): 88.0\nMedian (Pandas): 88.0"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#calculating-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#calculating-the-mode",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Calculating the Mode",
    "text": "Calculating the Mode\n\n# Using SciPy\nfrom scipy import stats\nmode_result = stats.mode(data)\nprint(f\"Mode: {mode_result.mode}, Count: {mode_result.count}\")\n\n# Using Pandas\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\nMode: 78, Count: 1\nMode (Pandas): [78 85 88 90 92]"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#comprehensive-analysis-function",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#comprehensive-analysis-function",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Comprehensive Analysis Function",
    "text": "Comprehensive Analysis Function\n\nimport pandas as pd\nimport numpy as np\ndef descriptive_summary(data, column_name=\"Data\"):\n    \"\"\"Calculate comprehensive descriptive statistics\"\"\"\n    df = pd.DataFrame({column_name: data})\n    \n    print(f\"Descriptive Statistics for {column_name}\")\n    print(\"=\" * 40)\n    print(f\"Count: {len(data)}\")\n    print(f\"Mean: {np.mean(data):.2f}\")\n    print(f\"Median: {np.median(data):.2f}\")\n    \n    try:\n        mode_result = stats.mode(data)\n        print(f\"Mode: {mode_result.mode[0]} (appears {mode_result.count[0]} times)\")\n    except:\n        print(\"Mode: No unique mode\")\n    \n    return df.describe()\n\n# Example usage\ntest_scores = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\nsummary = descriptive_summary(test_scores, \"Test Scores\")\n\nDescriptive Statistics for Test Scores\n========================================\nCount: 10\nMean: 87.10\nMedian: 87.50\nMode: No unique mode"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#handling-categorical-data",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#handling-categorical-data",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Handling Categorical Data",
    "text": "Handling Categorical Data\n\n# Categorical data example\ncategories = ['A', 'B', 'B', 'C', 'A', 'B', 'A', 'C', 'B', 'B']\ncat_series = pd.Series(categories)\n\nprint(\"Categorical Data Analysis:\")\nprint(f\"Mode: {cat_series.mode().values[0]}\")\nprint(\"\\nValue Counts:\")\nprint(cat_series.value_counts())\n\nCategorical Data Analysis:\nMode: B\n\nValue Counts:\nB    5\nA    3\nC    2\nName: count, dtype: int64\n\n\nOutput:\nCategorical Data Analysis:\nMode: B\n\nValue Counts:\nB    5\nA    3\nC    2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#business-applications",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#business-applications",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Business Applications",
    "text": "Business Applications\n\nCustomer Satisfaction: Mean rating shows overall satisfaction, median shows typical experience\nSales Data: Mode identifies best-selling products, median shows typical sale amount\n\nEmployee Performance: Mean for overall team performance, median for typical employee"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#educational-applications",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#educational-applications",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Educational Applications",
    "text": "Educational Applications\n\nTest Scores: Mean for class average, median for typical student performance\nGrade Distribution: Mode shows most common grade\nAttendance: Mean for overall attendance rate"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#healthcare-applications",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#healthcare-applications",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Healthcare Applications",
    "text": "Healthcare Applications\n\nPatient Wait Times: Median often preferred due to skewed distributions\nTreatment Outcomes: Mean for overall effectiveness, mode for most common result\nVital Signs: All three measures provide different insights"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#interpretation-guidelines",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#interpretation-guidelines",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Interpretation Guidelines",
    "text": "Interpretation Guidelines\n\nAlways consider the context of your data\nReport multiple measures when appropriate\n\nBe aware of data distribution shape\nConsider the presence of outliers\nChoose the most appropriate measure for your specific question"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#remember-these-points",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#remember-these-points",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Remember These Points",
    "text": "Remember These Points\n\nData type determines which statistics are appropriate\nMean uses all data but is sensitive to outliers\nMedian is robust and represents the middle value\nMode identifies the most common value and works with all data types\nContext matters when choosing and interpreting measures\nPython provides powerful tools for calculating descriptive statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#next-lecture-preview",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#next-lecture-preview",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Next Lecture Preview",
    "text": "Next Lecture Preview\nDescriptive Statistics Part II will cover:\n\nMeasures of variability (range, variance, standard deviation)\nMeasures of position (percentiles, quartiles, z-scores)\nShape of distributions (skewness and kurtosis)\nAdvanced Python visualization techniques"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#try-these-problems",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#try-these-problems",
    "title": "Lecture 2: Descriptive Statistics II",
    "section": "Try These Problems",
    "text": "Try These Problems\n\nCalculate mean, median, and mode for: 12, 15, 18, 12, 20, 25, 12, 30\nA dataset has mean = 50 and median = 45. What does this tell you about the distribution?\nWhy might median be preferred over mean for reporting household income?\nCreate a Python function to identify the most appropriate measure of central tendency for a given dataset."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part2.html#footnotes",
    "href": "files/lecture_notes/lecture2/lecture2_part2.html#footnotes",
    "title": "Lecture 2: Descriptive Statistics I - Part II",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(source)↩︎"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#learning-objectives",
    "href": "files/lecture_notes/lecture3/lecture3.html#learning-objectives",
    "title": "Descriptive Statistics Part II",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture, you will be able to:\n\nCalculate and interpret measures of variability (range, variance, standard deviation)\nUnderstand and compute measures of position (percentiles, quartiles, z-scores)\nAssess distribution shape using skewness and kurtosis\nCreate and interpret histograms with appropriate bin widths\nConstruct and analyze boxplots for data exploration\nIdentify trends, patterns, and outliers in data visualizations\nApply Python for comprehensive descriptive analysis and visualization"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#lecture-outline-80-minutes",
    "href": "files/lecture_notes/lecture3/lecture3.html#lecture-outline-80-minutes",
    "title": "Descriptive Statistics Part II",
    "section": "Lecture Outline (80 minutes)",
    "text": "Lecture Outline (80 minutes)\n\nMeasures of Variability (25 minutes)\n\nRange, Variance, Standard Deviation (15 min)\nCoefficient of Variation (5 min)\nPython Implementation (5 min)\n\nMeasures of Position (20 minutes)\n\nPercentiles and Quartiles (10 min)\nZ-scores and Standardization (10 min)\n\nDistribution Shape (10 minutes)\n\nSkewness and Kurtosis (10 min)\n\nData Visualization (20 minutes)\n\nHistograms and Bin Width Selection (10 min)\nBoxplots and Interpretation (10 min)\n\nIdentifying Trends and Patterns (5 minutes)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-is-variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-is-variability",
    "title": "Descriptive Statistics Part II",
    "section": "What is Variability?",
    "text": "What is Variability?\n\n🎯 Definition\nVariability (or dispersion) measures how spread out or scattered the data points are around the center.\n\nWhy Variability Matters\n\nTwo datasets can have the same mean but very different spreads\nVariability indicates consistency and predictability\nEssential for risk assessment and quality control\nHelps determine confidence in our central tendency measures"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#comparing-datasets-with-same-mean",
    "href": "files/lecture_notes/lecture3/lecture3.html#comparing-datasets-with-same-mean",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Datasets with Same Mean",
    "text": "Comparing Datasets with Same Mean\n\nDataset A: 98, 99, 100, 101, 102 (Mean = 100)\nDataset B: 80, 90, 100, 110, 120 (Mean = 100)\n\n\n\nBoth have the same mean (100), but Dataset B is much more variable!\nThis is why we need measures of variability."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#definition-and-calculation",
    "href": "files/lecture_notes/lecture3/lecture3.html#definition-and-calculation",
    "title": "Descriptive Statistics Part II",
    "section": "Definition and Calculation",
    "text": "Definition and Calculation\nRange = Maximum value - Minimum value\n\nExample\n\nData: 12, 15, 18, 22, 25, 30, 35\n\n\n\nRange = 35 - 12 = 23"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#when-to-use-range",
    "href": "files/lecture_notes/lecture3/lecture3.html#when-to-use-range",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Range",
    "text": "When to Use Range\n✅ Use range when:\n\nNeed a quick, simple measure of spread\nWorking with small datasets\nCommunicating to non-technical audiences\n\n❌ Avoid range when:\n\nOutliers are present\nNeed detailed information about variability\nWorking with large datasets"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#variance-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#variance-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Variance Definition",
    "text": "Variance Definition\n\n🎯 Definition\nVariance measures the average squared deviation from the mean."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#standard-deviation-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#standard-deviation-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Standard Deviation Definition",
    "text": "Standard Deviation Definition\n\n🎯 Definition\nStandard Deviation is the square root of variance.\n\n\n\nSample Standard Deviation\n\\[s = \\sqrt{s^2} = \\sqrt{\\frac{\\sum(x_i - \\bar{x})^2}{n-1}}\\]\n\n\nPopulation Standard Deviation\n\\[\\sigma = \\sqrt{\\sigma^2} = \\sqrt{\\frac{\\sum(x_i - \\mu)^2}{N}}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#step-by-step-calculation-example",
    "href": "files/lecture_notes/lecture3/lecture3.html#step-by-step-calculation-example",
    "title": "Descriptive Statistics Part II",
    "section": "Step-by-Step Calculation Example",
    "text": "Step-by-Step Calculation Example\nData: 10, 12, 14, 16, 18 (Mean = 14)\n\n\n\n\\(x_i\\)\n\\(x_i - \\bar{x}\\)\n\\((x_i - \\bar{x})^2\\)\n\n\n\n\n10\n-4\n16\n\n\n12\n-2\n4\n\n\n14\n0\n0\n\n\n16\n2\n4\n\n\n18\n4\n16\n\n\nSum\n\n40"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#completing-the-calculation",
    "href": "files/lecture_notes/lecture3/lecture3.html#completing-the-calculation",
    "title": "Descriptive Statistics Part II",
    "section": "Completing the Calculation",
    "text": "Completing the Calculation\n\\[s^2 = \\frac{40}{5-1} = \\frac{40}{4} = 10\\]\n\\[s = \\sqrt{10} = 3.16\\]\n\nInterpretation: On average, data points deviate from the mean by about 3.16 units."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#properties-of-standard-deviation",
    "href": "files/lecture_notes/lecture3/lecture3.html#properties-of-standard-deviation",
    "title": "Descriptive Statistics Part II",
    "section": "Properties of Standard Deviation",
    "text": "Properties of Standard Deviation\n\nSame units as the original data\nAlways non-negative\nZero only when all values are identical\nLarger values indicate more variability\nApproximately 68% of data within 1 SD of mean (for normal distributions)\nApproximately 95% of data within 2 SD of mean"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#empirical-rule-68-95-99.7-rule",
    "href": "files/lecture_notes/lecture3/lecture3.html#empirical-rule-68-95-99.7-rule",
    "title": "Descriptive Statistics Part II",
    "section": "Empirical Rule (68-95-99.7 Rule)",
    "text": "Empirical Rule (68-95-99.7 Rule)\nFor approximately normal distributions:\n\n68% of data falls within 1 standard deviation of the mean\n95% of data falls within 2 standard deviations of the mean\n99.7% of data falls within 3 standard deviations of the mean\n\nThis rule helps us understand what constitutes “typical” vs “unusual” values."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#definition-and-purpose",
    "href": "files/lecture_notes/lecture3/lecture3.html#definition-and-purpose",
    "title": "Descriptive Statistics Part II",
    "section": "Definition and Purpose",
    "text": "Definition and Purpose\n\n🎯 Definition\nCoefficient of Variation (CV) = \\(\\frac{\\text{Standard Deviation}}{\\text{Mean}} \\times 100\\%\\)\n\n\nWhy Use CV?\n\nCompares variability across different units or scales\nRelative measure of variability\nUseful when means differ substantially"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#example-comparing-variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#example-comparing-variability",
    "title": "Descriptive Statistics Part II",
    "section": "Example: Comparing Variability",
    "text": "Example: Comparing Variability\nStock A: Mean return = $50, SD = $10, CV = 20%\nStock B: Mean return = $500, SD = $50, CV = 10%\n\n\n\n\n\n\n\nImportant\n\n\nStock B has higher absolute variability ($50 vs $10) but lower relative variability (10% vs 20%)\nStock B is relatively less risky per dollar invested."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-implementation---variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-implementation---variability",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Variability",
    "text": "Python Implementation - Variability\n\nCodeVisualization\n\n\n\nimport numpy as np\nimport pandas as pd\n\n# Sample data\ndata = [10, 12, 14, 16, 18, 22, 25]\n\n# Calculate measures of variability\nrange_val = np.max(data) - np.min(data)\nvariance_sample = np.var(data, ddof=1)  # Sample variance\nstd_sample = np.std(data, ddof=1)       # Sample standard deviation\ncv = (std_sample / np.mean(data)) * 100\n\nprint(f\"Range: {range_val}\")\nprint(f\"Variance: {variance_sample:.2f}\")\nprint(f\"Standard Deviation: {std_sample:.2f}\")\nprint(f\"Coefficient of Variation: {cv:.1f}%\")\n\nRange: 15\nVariance: 28.90\nStandard Deviation: 5.38\nCoefficient of Variation: 32.2%"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-are-measures-of-position",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-are-measures-of-position",
    "title": "Descriptive Statistics Part II",
    "section": "What are Measures of Position?",
    "text": "What are Measures of Position?\n\n\nMeasures of position tell us where a particular value stands relative to the rest of the data.\nThey answer questions like:\n\n“What percentage of students scored below 85?”\n“Is this value typical or unusual?”\n“How does this observation compare to others?”"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#percentiles-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#percentiles-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Percentiles Definition",
    "text": "Percentiles Definition\nThe k-th percentile is the value below which k% of the data falls.\nExamples:\n\n50th percentile = Median (50% of data below this value)\n90th percentile = 90% of data falls below this value\n25th percentile = 25% of data falls below this value"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#quartiles",
    "href": "files/lecture_notes/lecture3/lecture3.html#quartiles",
    "title": "Descriptive Statistics Part II",
    "section": "Quartiles",
    "text": "Quartiles\nQuartiles divide the data into four equal parts:\n\nQ1 (First Quartile) = 25th percentile\nQ2 (Second Quartile) = 50th percentile = Median\nQ3 (Third Quartile) = 75th percentile"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#interquartile-range-iqr",
    "href": "files/lecture_notes/lecture3/lecture3.html#interquartile-range-iqr",
    "title": "Descriptive Statistics Part II",
    "section": "Interquartile Range (IQR)",
    "text": "Interquartile Range (IQR)\nIQR = Q3 - Q1\n\n\n\n\nProperties of IQR:\n\nContains the middle 50% of the data\nResistant to outliers\nUsed in boxplot construction\nUseful for outlier detection"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#five-number-summary",
    "href": "files/lecture_notes/lecture3/lecture3.html#five-number-summary",
    "title": "Descriptive Statistics Part II",
    "section": "Five-Number Summary",
    "text": "Five-Number Summary\nThe five-number summary provides a complete picture of data distribution:\n\nMinimum\nQ1 (25th percentile)\nMedian (50th percentile)\nQ3 (75th percentile)\nMaximum\n\nThis forms the basis for boxplots!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#z-score-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#z-score-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Z-score Definition",
    "text": "Z-score Definition\n\n\n\n🎯 Definition\nZ-score tells us how many standard deviations a value is from the mean.\n\n\n\\[z = \\frac{x - \\mu}{\\sigma} \\text{ or } z = \\frac{x - \\bar{x}}{s}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#interpreting-z-scores",
    "href": "files/lecture_notes/lecture3/lecture3.html#interpreting-z-scores",
    "title": "Descriptive Statistics Part II",
    "section": "Interpreting Z-scores",
    "text": "Interpreting Z-scores\n\nz = 0: Value equals the mean\nz = 1: Value is 1 standard deviation above the mean\nz = -2: Value is 2 standard deviations below the mean\n|z| &gt; 2: Often considered “unusual” (beyond 95% of data)\n|z| &gt; 3: Very unusual (beyond 99.7% of data)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#z-score-example",
    "href": "files/lecture_notes/lecture3/lecture3.html#z-score-example",
    "title": "Descriptive Statistics Part II",
    "section": "Z-score Example",
    "text": "Z-score Example\nStudent’s test score: 85 Class mean: 78, Class standard deviation: 6\n\n\\[z = \\frac{85 - 78}{6} = \\frac{7}{6} = 1.17\\]\n\nInterpretation: This student scored 1.17 standard deviations above the class average."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#benefits-of-standardization",
    "href": "files/lecture_notes/lecture3/lecture3.html#benefits-of-standardization",
    "title": "Descriptive Statistics Part II",
    "section": "Benefits of Standardization",
    "text": "Benefits of Standardization\n\nCompare across different scales (test scores vs income)\nIdentify outliers systematically\n\nCombine different variables meaningfully\nPrepare data for certain statistical methods"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#skewness",
    "href": "files/lecture_notes/lecture3/lecture3.html#skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Skewness",
    "text": "Skewness\nSkewness measures the asymmetry of a distribution.\nTypes of Skewness:\n\n\n\n\nSymmetric (Skewness ≈ 0): Mean ≈ Median ≈ Mode\nRight-skewed (Positive skewness): Mean &gt; Median, long tail to the right\nLeft-skewed (Negative skewness): Mean &lt; Median, long tail to the left"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#visual-examples-of-skewness",
    "href": "files/lecture_notes/lecture3/lecture3.html#visual-examples-of-skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Visual Examples of Skewness",
    "text": "Visual Examples of Skewness\nRight-skewed (Income data):\n\nMost people earn moderate amounts\nFew people earn very high amounts\nMean &gt; Median\n\nLeft-skewed (Test scores with ceiling effect):\n\nMost students score high\nFew students score very low\nMean &lt; Median"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#kurtosis",
    "href": "files/lecture_notes/lecture3/lecture3.html#kurtosis",
    "title": "Descriptive Statistics Part II",
    "section": "Kurtosis",
    "text": "Kurtosis\nKurtosis measures the “tailedness” of a distribution. It measures the degree of peaked Ness or flatness of a distribution compared to the normal distribution.\nTypes:\n\nMesokurtic (Normal-like): Kurtosis ≈ 3\nLeptokurtic (Heavy tails): Kurtosis &gt; 3, more peaked\nPlatykurtic (Light tails): Kurtosis &lt; 3, flatter\n\nExcess Kurtosis = Kurtosis - 3 (makes normal distributions have excess kurtosis of 0)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-implementation---position-shape",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-implementation---position-shape",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Position & Shape",
    "text": "Python Implementation - Position & Shape\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndata = [12, 15, 18, 22, 25, 28, 30, 35, 40, 45]\n\n# Percentiles and quartiles\nq1 = np.percentile(data, 25)\nmedian = np.percentile(data, 50)\nq3 = np.percentile(data, 75)\niqr = q3 - q1\n\n# Z-scores\nz_scores = stats.zscore(data)\n\n# Shape measures\nskewness = stats.skew(data)\nkurt = stats.kurtosis(data)\n\nprint(f\"Q1: {q1}, Median: {median}, Q3: {q3}\")\nprint(f\"IQR: {iqr}\")\nprint(f\"Skewness: {skewness:.3f}\")\nprint(f\"Kurtosis: {kurt:.3f}\")\n\nQ1: 19.0, Median: 26.5, Q3: 33.75\nIQR: 14.75\nSkewness: 0.243\nKurtosis: -1.023"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-is-a-histogram",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-is-a-histogram",
    "title": "Descriptive Statistics Part II",
    "section": "What is a Histogram?",
    "text": "What is a Histogram?\nA histogram displays the distribution of a continuous variable by dividing data into bins and showing the frequency of observations in each bin.\nKey Components:\n\nX-axis: Variable values (continuous)\nY-axis: Frequency or density\nBins: Intervals that group the data\nBars: Height represents frequency in each bin"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#choosing-bin-width-critical-decision",
    "href": "files/lecture_notes/lecture3/lecture3.html#choosing-bin-width-critical-decision",
    "title": "Descriptive Statistics Part II",
    "section": "Choosing Bin Width: Critical Decision",
    "text": "Choosing Bin Width: Critical Decision\nBin width dramatically affects histogram interpretation!\nToo Few Bins (Wide bins):\n\nOversmoothing - lose important details\nMay hide multimodality\nDistribution appears simpler than it is\n\nToo Many Bins (Narrow bins):\n\nUndersmoothing - too much noise\nMay create artificial gaps\nHard to see overall pattern"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#bin-width-guidelines",
    "href": "files/lecture_notes/lecture3/lecture3.html#bin-width-guidelines",
    "title": "Descriptive Statistics Part II",
    "section": "Bin Width Guidelines",
    "text": "Bin Width Guidelines\nRule of Thumb Methods:\n\nSquare Root Rule: Number of bins ≈ \\(\\sqrt{n}\\)\nSturges’ Rule: Number of bins = \\(1 + \\log_2(n)\\)\nScott’s Rule: Bin width = \\(\\frac{3.5 \\times \\text{SD}}{n^{1/3}}\\)\nFreedman-Diaconis Rule: Bin width = \\(\\frac{2 \\times \\text{IQR}}{n^{1/3}}\\)\n\nBest practice: Try multiple bin widths and choose based on the story your data tells!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-histogram-examples",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-histogram-examples",
    "title": "Descriptive Statistics Part II",
    "section": "Python Histogram Examples",
    "text": "Python Histogram Examples\n\nCodeVisualization\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate sample data\nnp.random.seed(42)\ndata = np.random.normal(100, 15, 1000)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#interpreting-histograms",
    "href": "files/lecture_notes/lecture3/lecture3.html#interpreting-histograms",
    "title": "Descriptive Statistics Part II",
    "section": "Interpreting Histograms",
    "text": "Interpreting Histograms\nWhat to Look For:\n\nShape: Normal, skewed, uniform, bimodal?\nCenter: Where is the “typical” value?\nSpread: How variable is the data?\nOutliers: Any unusual values?\nGaps: Are there missing values in certain ranges?\nMultiple peaks: Suggests multiple subgroups"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#anatomy-of-a-boxplot",
    "href": "files/lecture_notes/lecture3/lecture3.html#anatomy-of-a-boxplot",
    "title": "Descriptive Statistics Part II",
    "section": "Anatomy of a Boxplot",
    "text": "Anatomy of a Boxplot"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#boxplot-components-explained",
    "href": "files/lecture_notes/lecture3/lecture3.html#boxplot-components-explained",
    "title": "Descriptive Statistics Part II",
    "section": "Boxplot Components Explained",
    "text": "Boxplot Components Explained\nThe Box:\n\nLeft edge: Q1 (25th percentile)\nMiddle line: Median (Q2, 50th percentile)\n\nRight edge: Q3 (75th percentile)\nBox width: IQR (contains middle 50% of data)\n\nThe Whiskers:\n\nExtend to: Most extreme values within 1.5 × IQR from box edges\nLower whisker: Minimum value within Q1 - 1.5×IQR\nUpper whisker: Maximum value within Q3 + 1.5×IQR\n\nOutliers:\n\nPoints beyond whiskers: Values &gt; Q3 + 1.5×IQR or &lt; Q1 - 1.5×IQR"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-boxplots-tell-us",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-boxplots-tell-us",
    "title": "Descriptive Statistics Part II",
    "section": "What Boxplots Tell Us",
    "text": "What Boxplots Tell Us\nDistribution Shape:\n\nSymmetric: Median in center of box, whiskers equal length\nRight-skewed: Median closer to Q1, longer upper whisker\nLeft-skewed: Median closer to Q3, longer lower whisker\n\nVariability:\n\nWide box: High variability in middle 50%\nLong whiskers: High overall variability\nMany outliers: Extreme variability"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#comparing-groups-with-boxplots",
    "href": "files/lecture_notes/lecture3/lecture3.html#comparing-groups-with-boxplots",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Groups with Boxplots",
    "text": "Comparing Groups with Boxplots"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#advanced-boxplot-interpretations",
    "href": "files/lecture_notes/lecture3/lecture3.html#advanced-boxplot-interpretations",
    "title": "Descriptive Statistics Part II",
    "section": "Advanced Boxplot Interpretations",
    "text": "Advanced Boxplot Interpretations"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#common-patterns-in-data",
    "href": "files/lecture_notes/lecture3/lecture3.html#common-patterns-in-data",
    "title": "Descriptive Statistics Part II",
    "section": "Common Patterns in Data",
    "text": "Common Patterns in Data\nDistribution Patterns:\n\nNormal/Bell-shaped: Symmetric, single peak\nUniform: All values equally likely\nBimodal: Two distinct peaks (suggests subgroups)\nMultimodal: Multiple peaks\nU-shaped: High values at extremes, low in middle\n\nOutlier Patterns:\n\nIndividual outliers: Data entry errors, measurement errors\nClustered outliers: Distinct subpopulation\nSystematic outliers: May indicate process changes"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#red-flags-in-data-visualization",
    "href": "files/lecture_notes/lecture3/lecture3.html#red-flags-in-data-visualization",
    "title": "Descriptive Statistics Part II",
    "section": "Red Flags in Data Visualization",
    "text": "Red Flags in Data Visualization\nWarning Signs:\n\nGaps in histograms: Missing data or measurement limitations\nHeaping: Values cluster at round numbers (10, 50, 100)\nTruncation: Data cut off at certain values\nDigit preference: People prefer certain ending digits\nMultiple modes: Hidden subgroups in your data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-comprehensive-data-exploration",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-comprehensive-data-exploration",
    "title": "Descriptive Statistics Part II",
    "section": "Python: Comprehensive Data Exploration",
    "text": "Python: Comprehensive Data Exploration"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#essential-concepts-to-remember",
    "href": "files/lecture_notes/lecture3/lecture3.html#essential-concepts-to-remember",
    "title": "Descriptive Statistics Part II",
    "section": "Essential Concepts to Remember",
    "text": "Essential Concepts to Remember\nVariability:\n\nStandard deviation is preferred over range for most analyses\nCV allows comparison across different scales\nIQR is resistant to outliers\n\nPosition:\n\nPercentiles and quartiles provide relative position\nZ-scores standardize across different distributions\nFive-number summary gives complete overview\n\nVisualization:\n\nBin width choice is critical for histogram interpretation\nBoxplots excel at comparing groups and identifying outliers\nMultiple visualizations provide different insights"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practical-guidelines",
    "href": "files/lecture_notes/lecture3/lecture3.html#practical-guidelines",
    "title": "Descriptive Statistics Part II",
    "section": "Practical Guidelines",
    "text": "Practical Guidelines\n\nAlways visualize before calculating statistics\nUse multiple measures - no single statistic tells the whole story\nConsider the context - what makes sense for your data?\nCheck for outliers - they can drastically affect your analysis\nCompare distributions using standardized measures when appropriate"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#next-steps-in-your-data-journey",
    "href": "files/lecture_notes/lecture3/lecture3.html#next-steps-in-your-data-journey",
    "title": "Descriptive Statistics Part II",
    "section": "Next Steps in Your Data Journey",
    "text": "Next Steps in Your Data Journey\nAdvanced Topics to Explore:\n\nCorrelation and association between variables\nTime series analysis for temporal patterns\nMultivariate descriptive statistics\nInteractive visualizations with plotly\nStatistical inference based on descriptive findings"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#try-these-exercises",
    "href": "files/lecture_notes/lecture3/lecture3.html#try-these-exercises",
    "title": "Descriptive Statistics Part II",
    "section": "Try These Exercises",
    "text": "Try These Exercises\n\nCalculate the five-number summary for: 12, 15, 18, 22, 25, 28, 30, 35, 40, 45\nCreate histograms with 5, 15, and 50 bins for the same dataset. What patterns do you observe?\nInterpret this scenario: Dataset A has mean=50, SD=5. Dataset B has mean=100, SD=10. Which is more variable?\nA student scores 85 on a test where the class mean is 78 and SD is 6. Calculate and interpret the z-score.\nDesign a boxplot comparison for three different customer segments in your business."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#additional-resources",
    "href": "files/lecture_notes/lecture3/lecture3.html#additional-resources",
    "title": "Descriptive Statistics Part II",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nMatplotlib gallery: Histogram and boxplot examples\nSeaborn documentation: Statistical visualizations\nNumPy/SciPy: Statistical functions reference\nRecommended reading: Chapter 4-5 in course textbook"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#lecture-outline",
    "href": "files/lecture_notes/lecture3/lecture3.html#lecture-outline",
    "title": "Descriptive Statistics Part II",
    "section": "Lecture Outline",
    "text": "Lecture Outline\n\n\nPart I: Measures of Variability (25 min)\n\nRange, Variance, Standard Deviation\nCoefficient of Variation\nPython Implementation\n\nPart II: Measures of Position (20 min)\n\nPercentiles and Quartiles\nZ-scores and Standardization\n\n\n\nPart III: Distribution Shape (10 min)\n\nSkewness and Kurtosis\n\nPart IV: Data Visualization (20 min)\n\nHistograms and Bin Width Selection\nBoxplots and Interpretation\n\nPart V: Identifying Patterns (5 min)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#properties-of-range",
    "href": "files/lecture_notes/lecture3/lecture3.html#properties-of-range",
    "title": "Descriptive Statistics Part II",
    "section": "Properties of Range",
    "text": "Properties of Range\n\n\n✅ Advantages\n\nSimple to calculate and understand\nQuick measure of spread\nEasy to communicate\n\n\n\n❌ Disadvantages\n\nUses only two values (ignores all others)\nSensitive to outliers\nLimited information about distribution"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#comparing-boxplots",
    "href": "files/lecture_notes/lecture3/lecture3.html#comparing-boxplots",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Boxplots:",
    "text": "Comparing Boxplots:\n\nMedian differences: Which group has higher typical values?\nIQR differences: Which group is more consistent?\nOutlier patterns: Which group has more extreme values?\nOverlap: Do the groups have similar ranges?"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#business-applications",
    "href": "files/lecture_notes/lecture3/lecture3.html#business-applications",
    "title": "Descriptive Statistics Part II",
    "section": "Business Applications:",
    "text": "Business Applications:\n\nQuality control: Compare product batches\nPerformance analysis: Compare team/department performance\n\nCustomer segmentation: Compare customer groups"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#visual-comparison-same-mean-different-spreads",
    "href": "files/lecture_notes/lecture3/lecture3.html#visual-comparison-same-mean-different-spreads",
    "title": "Descriptive Statistics Part II",
    "section": "📈 Visual Comparison: Same Mean, Different Spreads",
    "text": "📈 Visual Comparison: Same Mean, Different Spreads"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test.html",
    "href": "files/lecture_notes/lecture3/test.html",
    "title": "Python Implementation of Descriptive Statistics",
    "section": "",
    "text": "Import LibrariesLibrary Overview\n\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set styling for better plots\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n\n\n\n\n\n\n\n\n\n\n\nLibrary\nPurpose\nKey Functions\n\n\n\n\nNumPy\nNumerical computing\nnp.mean(), np.median(), np.std()\n\n\nPandas\nData manipulation\ndf.describe(), df.mean(), df.median()\n\n\nSciPy\nScientific computing\nstats.mode(), stats.describe()\n\n\nMatplotlib\nBasic plotting\nplt.plot(), plt.hist(), plt.boxplot()\n\n\nSeaborn\nStatistical visualization\nsns.histplot(), sns.boxplot()"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test.html#sec-libraries",
    "href": "files/lecture_notes/lecture3/test.html#sec-libraries",
    "title": "Python Implementation of Descriptive Statistics",
    "section": "",
    "text": "Import LibrariesLibrary Overview\n\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set styling for better plots\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n\n\n\n\n\n\n\n\n\n\n\nLibrary\nPurpose\nKey Functions\n\n\n\n\nNumPy\nNumerical computing\nnp.mean(), np.median(), np.std()\n\n\nPandas\nData manipulation\ndf.describe(), df.mean(), df.median()\n\n\nSciPy\nScientific computing\nstats.mode(), stats.describe()\n\n\nMatplotlib\nBasic plotting\nplt.plot(), plt.hist(), plt.boxplot()\n\n\nSeaborn\nStatistical visualization\nsns.histplot(), sns.boxplot()"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test.html#sec-central-tendency",
    "href": "files/lecture_notes/lecture3/test.html#sec-central-tendency",
    "title": "Python Implementation of Descriptive Statistics",
    "section": "Central Tendency Measures",
    "text": "Central Tendency Measures\n\nMean CalculationMedian CalculationMode CalculationVisualization\n\n\n\n# Sample data\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\n\n# Using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np:.2f}\")\n\n# Using Pandas\ndf = pd.DataFrame({'scores': data})\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd:.2f}\")\n\n# Manual calculation for understanding\nmanual_mean = sum(data) / len(data)\nprint(f\"Mean (Manual): {manual_mean:.2f}\")\n\nMean (NumPy): 87.10\nMean (Pandas): 87.10\nMean (Manual): 87.10\n\n\n\n\n\n# Using NumPy\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np:.2f}\")\n\n# Using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd:.2f}\")\n\n# Manual calculation\nsorted_data = sorted(data)\nn = len(sorted_data)\nif n % 2 == 0:\n    manual_median = (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2\nelse:\n    manual_median = sorted_data[n//2]\nprint(f\"Median (Manual): {manual_median:.2f}\")\n\nMedian (NumPy): 87.50\nMedian (Pandas): 87.50\nMedian (Manual): 87.50\n\n\n\n\n\n# Using SciPy\nmode_result = stats.mode(data, keepdims=True)\nprint(f\"Mode (SciPy): {mode_result.mode[0]}, Count: {mode_result.count[0]}\")\n\n# Using Pandas\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\n# Manual calculation using Counter\nfrom collections import Counter\ncounter = Counter(data)\nmax_count = max(counter.values())\nmodes = [k for k, v in counter.items() if v == max_count]\nprint(f\"Mode (Manual): {modes}, Count: {max_count}\")\n\nMode (SciPy): 85, Count: 2\nMode (Pandas): [85]\nMode (Manual): [85], Count: 2\n\n\n\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# Histogram with central tendency lines\nax1.hist(data, bins=8, alpha=0.7, color='skyblue', edgecolor='black')\nax1.axvline(mean_np, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_np:.1f}')\nax1.axvline(median_np, color='green', linestyle='--', linewidth=2, label=f'Median: {median_np:.1f}')\nax1.axvline(mode_result.mode[0], color='orange', linestyle='--', linewidth=2, label=f'Mode: {mode_result.mode[0]}')\nax1.set_xlabel('Test Scores')\nax1.set_ylabel('Frequency')\nax1.set_title('Distribution with Central Tendency')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Box plot\nax2.boxplot(data, patch_artist=True, \n            boxprops=dict(facecolor='lightblue', alpha=0.7),\n            medianprops=dict(color='red', linewidth=2))\nax2.set_ylabel('Test Scores')\nax2.set_title('Box Plot of Test Scores')\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nDistribution of Test Scores with Central Tendency Measures"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test.html#sec-comprehensive",
    "href": "files/lecture_notes/lecture3/test.html#sec-comprehensive",
    "title": "Python Implementation of Descriptive Statistics",
    "section": "Comprehensive Analysis Function",
    "text": "Comprehensive Analysis Function\n\nFunction DefinitionExample UsageDetailed Summary Table\n\n\n\ndef descriptive_summary(data, column_name=\"Data\", create_plots=True):\n    \"\"\"\n    Calculate comprehensive descriptive statistics with optional visualizations\n    \n    Parameters:\n    -----------\n    data : list or array-like\n        The data to analyze\n    column_name : str\n        Name for the data column\n    create_plots : bool\n        Whether to create visualizations\n    \n    Returns:\n    --------\n    pandas.DataFrame\n        Descriptive statistics summary\n    \"\"\"\n    \n    # Convert to DataFrame\n    df = pd.DataFrame({column_name: data})\n    \n    # Basic statistics\n    print(f\"📊 Descriptive Statistics for {column_name}\")\n    print(\"=\" * 50)\n    print(f\"Count: {len(data)}\")\n    print(f\"Mean: {np.mean(data):.3f}\")\n    print(f\"Median: {np.median(data):.3f}\")\n    print(f\"Standard Deviation: {np.std(data, ddof=1):.3f}\")\n    print(f\"Variance: {np.var(data, ddof=1):.3f}\")\n    print(f\"Range: {np.max(data) - np.min(data):.3f}\")\n    print(f\"Min: {np.min(data):.3f}\")\n    print(f\"Max: {np.max(data):.3f}\")\n    \n    # Mode calculation\n    try:\n        mode_result = stats.mode(data, keepdims=True)\n        print(f\"Mode: {mode_result.mode[0]} (appears {mode_result.count[0]} times)\")\n    except:\n        print(\"Mode: No unique mode\")\n    \n    # Quartiles\n    q1, q2, q3 = np.percentile(data, [25, 50, 75])\n    print(f\"Q1 (25th percentile): {q1:.3f}\")\n    print(f\"Q2 (50th percentile): {q2:.3f}\")\n    print(f\"Q3 (75th percentile): {q3:.3f}\")\n    print(f\"IQR: {q3 - q1:.3f}\")\n    \n    if create_plots:\n        # Create comprehensive visualization\n        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n        \n        # Histogram\n        ax1.hist(data, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n        ax1.axvline(np.mean(data), color='red', linestyle='--', label=f'Mean: {np.mean(data):.2f}')\n        ax1.axvline(np.median(data), color='green', linestyle='--', label=f'Median: {np.median(data):.2f}')\n        ax1.set_xlabel(column_name)\n        ax1.set_ylabel('Frequency')\n        ax1.set_title('Histogram')\n        ax1.legend()\n        ax1.grid(True, alpha=0.3)\n        \n        # Box plot\n        ax2.boxplot(data, patch_artist=True, \n                   boxprops=dict(facecolor='lightgreen', alpha=0.7))\n        ax2.set_ylabel(column_name)\n        ax2.set_title('Box Plot')\n        ax2.grid(True, alpha=0.3)\n        \n        # Q-Q plot\n        stats.probplot(data, dist=\"norm\", plot=ax3)\n        ax3.set_title('Q-Q Plot (Normal Distribution)')\n        ax3.grid(True, alpha=0.3)\n        \n        # Violin plot\n        parts = ax4.violinplot([data], positions=[1], showmeans=True, showmedians=True)\n        ax4.set_xticks([1])\n        ax4.set_xticklabels([column_name])\n        ax4.set_ylabel('Values')\n        ax4.set_title('Violin Plot')\n        ax4.grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.show()\n    \n    return df.describe()\n\n\n\n\n# Example with test scores\ntest_scores = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86, 94, 82, 88, 90, 87]\nsummary = descriptive_summary(test_scores, \"Test Scores\", create_plots=True)\n\n📊 Descriptive Statistics for Test Scores\n==================================================\nCount: 15\nMean: 87.467\nMedian: 88.000\nStandard Deviation: 4.015\nVariance: 16.124\nRange: 16.000\nMin: 78.000\nMax: 94.000\nMode: 85 (appears 2 times)\nQ1 (25th percentile): 85.500\nQ2 (50th percentile): 88.000\nQ3 (75th percentile): 90.000\nIQR: 4.500\n\n\n\n\n\n\n\n\n\n\n\n\n# Display the detailed summary\nprint(\"\\n📋 Pandas Describe Output:\")\nprint(summary)\n\n# Additional statistics\nprint(f\"\\n🔍 Additional Insights:\")\nprint(f\"Coefficient of Variation: {(np.std(test_scores, ddof=1) / np.mean(test_scores)) * 100:.2f}%\")\nprint(f\"Skewness: {stats.skew(test_scores):.3f}\")\nprint(f\"Kurtosis: {stats.kurtosis(test_scores):.3f}\")\n\n\n📋 Pandas Describe Output:\n       Test Scores\ncount    15.000000\nmean     87.466667\nstd       4.015446\nmin      78.000000\n25%      85.500000\n50%      88.000000\n75%      90.000000\nmax      94.000000\n\n🔍 Additional Insights:\nCoefficient of Variation: 4.59%\nSkewness: -0.677\nKurtosis: 0.383"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test.html#sec-categorical",
    "href": "files/lecture_notes/lecture3/test.html#sec-categorical",
    "title": "Python Implementation of Descriptive Statistics",
    "section": "Categorical Data Analysis",
    "text": "Categorical Data Analysis\n\nBasic AnalysisVisualizationAdvanced Categorical Analysis\n\n\n\n# Categorical data example\ncategories = ['A', 'B', 'B', 'C', 'A', 'B', 'A', 'C', 'B', 'B', 'A', 'C', 'B']\ncat_series = pd.Series(categories, name='Grades')\n\nprint(\"📊 Categorical Data Analysis:\")\nprint(f\"Mode: {cat_series.mode().values[0]}\")\nprint(f\"Total Count: {len(cat_series)}\")\n\nprint(\"\\n📈 Value Counts:\")\nvalue_counts = cat_series.value_counts()\nprint(value_counts)\n\nprint(\"\\n📊 Proportions:\")\nproportions = cat_series.value_counts(normalize=True)\nprint(proportions.round(3))\n\n📊 Categorical Data Analysis:\nMode: B\nTotal Count: 13\n\n📈 Value Counts:\nGrades\nB    6\nA    4\nC    3\nName: count, dtype: int64\n\n📊 Proportions:\nGrades\nB    0.462\nA    0.308\nC    0.231\nName: proportion, dtype: float64\n\n\n\n\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n\n# Bar chart\nvalue_counts.plot(kind='bar', ax=ax1, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\nax1.set_title('Grade Distribution (Bar Chart)')\nax1.set_xlabel('Grade')\nax1.set_ylabel('Count')\nax1.tick_params(axis='x', rotation=0)\nax1.grid(True, alpha=0.3)\n\n# Pie chart\nax2.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%', \n        colors=['#FF6B6B', '#4ECDC4', '#45B7D1'], startangle=90)\nax2.set_title('Grade Distribution (Pie Chart)')\n\n# Horizontal bar chart\nvalue_counts.plot(kind='barh', ax=ax3, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\nax3.set_title('Grade Distribution (Horizontal)')\nax3.set_xlabel('Count')\nax3.set_ylabel('Grade')\nax3.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCategorical Data Visualization\n\n\n\n\n\n\n\n# Create a more complex categorical dataset\nnp.random.seed(42)\ndepartments = ['Engineering', 'Marketing', 'Sales', 'HR', 'Finance']\nperformance = ['Excellent', 'Good', 'Average', 'Below Average']\n\n# Generate sample data\ndata_complex = pd.DataFrame({\n    'Department': np.random.choice(departments, 100),\n    'Performance': np.random.choice(performance, 100, p=[0.2, 0.4, 0.3, 0.1]),\n    'Salary': np.random.normal(60000, 15000, 100)\n})\n\nprint(\"🏢 Advanced Categorical Analysis:\")\nprint(\"\\nCross-tabulation of Department vs Performance:\")\ncrosstab = pd.crosstab(data_complex['Department'], data_complex['Performance'])\nprint(crosstab)\n\nprint(\"\\nProportions within each department:\")\nproportions = pd.crosstab(data_complex['Department'], data_complex['Performance'], normalize='index')\nprint(proportions.round(3))\n\n🏢 Advanced Categorical Analysis:\n\nCross-tabulation of Department vs Performance:\nPerformance  Average  Below Average  Excellent  Good\nDepartment                                          \nEngineering        6              0          4     8\nFinance            8              2          2     7\nHR                 4              3          4    15\nMarketing          4              2          3    12\nSales              5              1          2     8\n\nProportions within each department:\nPerformance  Average  Below Average  Excellent   Good\nDepartment                                           \nEngineering    0.333          0.000      0.222  0.444\nFinance        0.421          0.105      0.105  0.368\nHR             0.154          0.115      0.154  0.577\nMarketing      0.190          0.095      0.143  0.571\nSales          0.312          0.062      0.125  0.500\n\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n\n# Stacked bar chart\ncrosstab.plot(kind='bar', stacked=True, ax=ax1, \n              colormap='viridis', alpha=0.8)\nax1.set_title('Performance by Department (Stacked)')\nax1.set_xlabel('Department')\nax1.set_ylabel('Count')\nax1.tick_params(axis='x', rotation=45)\nax1.legend(title='Performance', bbox_to_anchor=(1.05, 1), loc='upper left')\nax1.grid(True, alpha=0.3)\n\n# Grouped bar chart\ncrosstab.plot(kind='bar', ax=ax2, \n              colormap='Set3', alpha=0.8)\nax2.set_title('Performance by Department (Grouped)')\nax2.set_xlabel('Department')\nax2.set_ylabel('Count')\nax2.tick_params(axis='x', rotation=45)\nax2.legend(title='Performance', bbox_to_anchor=(1.05, 1), loc='upper left')\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nAdvanced Categorical Analysis Visualization"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test.html#sec-dashboard",
    "href": "files/lecture_notes/lecture3/test.html#sec-dashboard",
    "title": "Python Implementation of Descriptive Statistics",
    "section": "Interactive Summary Dashboard",
    "text": "Interactive Summary Dashboard\n\nStatistical SummaryKey TakeawaysBest Practices\n\n\n\n# Create a comprehensive summary of all our analyses\ndef create_summary_dashboard():\n    print(\"🎯 PYTHON STATISTICS IMPLEMENTATION SUMMARY\")\n    print(\"=\" * 60)\n    \n    # Test scores summary\n    test_scores = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86, 94, 82, 88, 90, 87]\n    \n    print(f\"📊 NUMERICAL DATA ANALYSIS\")\n    print(f\"Sample Size: {len(test_scores)}\")\n    print(f\"Mean: {np.mean(test_scores):.2f}\")\n    print(f\"Median: {np.median(test_scores):.2f}\")\n    print(f\"Mode: {stats.mode(test_scores, keepdims=True).mode[0]}\")\n    print(f\"Standard Deviation: {np.std(test_scores, ddof=1):.2f}\")\n    print(f\"Range: {np.max(test_scores) - np.min(test_scores)}\")\n    \n    print(f\"\\n📈 CATEGORICAL DATA ANALYSIS\")\n    categories = ['A', 'B', 'B', 'C', 'A', 'B', 'A', 'C', 'B', 'B', 'A', 'C', 'B']\n    cat_counts = pd.Series(categories).value_counts()\n    print(f\"Most Frequent Category: {cat_counts.index[0]} ({cat_counts.iloc[0]} occurrences)\")\n    print(f\"Categories: {list(cat_counts.index)}\")\n    print(f\"Distribution: {dict(cat_counts)}\")\n    \n    print(f\"\\n🔧 LIBRARIES USED\")\n    print(\"✓ NumPy - Numerical operations\")\n    print(\"✓ Pandas - Data manipulation\")\n    print(\"✓ SciPy - Statistical functions\")\n    print(\"✓ Matplotlib - Basic plotting\")\n    print(\"✓ Seaborn - Statistical visualization\")\n\ncreate_summary_dashboard()\n\n🎯 PYTHON STATISTICS IMPLEMENTATION SUMMARY\n============================================================\n📊 NUMERICAL DATA ANALYSIS\nSample Size: 15\nMean: 87.47\nMedian: 88.00\nMode: 85\nStandard Deviation: 4.02\nRange: 16\n\n📈 CATEGORICAL DATA ANALYSIS\nMost Frequent Category: B (6 occurrences)\nCategories: ['B', 'A', 'C']\nDistribution: {'B': np.int64(6), 'A': np.int64(4), 'C': np.int64(3)}\n\n🔧 LIBRARIES USED\n✓ NumPy - Numerical operations\n✓ Pandas - Data manipulation\n✓ SciPy - Statistical functions\n✓ Matplotlib - Basic plotting\n✓ Seaborn - Statistical visualization\n\n\n\n\n\n\n\n\n\n\n🎯 Key Learning Points\n\n\n\n\nMultiple Ways to Calculate: NumPy, Pandas, and manual methods all provide ways to calculate statistical measures\nVisualization is Essential: Plots help understand data distribution and identify patterns\nLibrary Specialization: Each library has its strengths - NumPy for speed, Pandas for data manipulation, SciPy for advanced statistics\nCategorical vs Numerical: Different approaches needed for different data types\nComprehensive Analysis: Combining multiple statistical measures provides better insights\n\n\n\n\n\n\n\n\n\n\n\n🚀 Implementation Best Practices\n\n\n\n\nAlways explore your data first with basic statistics and visualizations\nUse appropriate libraries for specific tasks (e.g., SciPy for advanced statistics)\nHandle missing data appropriately before analysis\nValidate results by cross-checking with multiple methods\nDocument your analysis with clear explanations and interpretations\nConsider the context of your data when interpreting results"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test.html#sec-code",
    "href": "files/lecture_notes/lecture3/test.html#sec-code",
    "title": "Python Implementation of Descriptive Statistics",
    "section": "Code Repository",
    "text": "Code Repository\n\nComplete Example ScriptExport Functions\n\n\n\n# Complete example script combining all concepts\ndef complete_analysis_example():\n    \"\"\"\n    Complete example demonstrating all statistical concepts covered\n    \"\"\"\n    print(\"🚀 COMPLETE STATISTICAL ANALYSIS EXAMPLE\")\n    print(\"=\" * 50)\n    \n    # Generate sample data\n    np.random.seed(42)\n    sample_data = np.random.normal(85, 10, 50).round().astype(int)\n    sample_data = np.clip(sample_data, 0, 100)  # Ensure scores are 0-100\n    \n    # Basic statistics\n    print(\"📊 Basic Statistics:\")\n    print(f\"Mean: {np.mean(sample_data):.2f}\")\n    print(f\"Median: {np.median(sample_data):.2f}\")\n    print(f\"Mode: {stats.mode(sample_data, keepdims=True).mode[0]}\")\n    print(f\"Std Dev: {np.std(sample_data, ddof=1):.2f}\")\n    \n    # Create visualization\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n    \n    # Histogram\n    ax1.hist(sample_data, bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n    ax1.axvline(np.mean(sample_data), color='red', linestyle='--', \n                label=f'Mean: {np.mean(sample_data):.1f}')\n    ax1.set_title('Distribution of Scores')\n    ax1.set_xlabel('Score')\n    ax1.set_ylabel('Frequency')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # Box plot\n    ax2.boxplot(sample_data, patch_artist=True, \n                boxprops=dict(facecolor='lightgreen', alpha=0.7))\n    ax2.set_title('Box Plot')\n    ax2.set_ylabel('Score')\n    ax2.grid(True, alpha=0.3)\n    \n    # Q-Q plot\n    stats.probplot(sample_data, dist=\"norm\", plot=ax3)\n    ax3.set_title('Q-Q Plot')\n    ax3.grid(True, alpha=0.3)\n    \n    # Cumulative distribution\n    sorted_data = np.sort(sample_data)\n    cumulative = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n    ax4.plot(sorted_data, cumulative, marker='o', markersize=3)\n    ax4.set_title('Cumulative Distribution')\n    ax4.set_xlabel('Score')\n    ax4.set_ylabel('Cumulative Probability')\n    ax4.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return sample_data\n\n# Run the complete example\nexample_data = complete_analysis_example()\n\n🚀 COMPLETE STATISTICAL ANALYSIS EXAMPLE\n==================================================\n📊 Basic Statistics:\nMean: 82.64\nMedian: 83.00\nMode: 80\nStd Dev: 9.17\n\n\n\n\n\n\n\n\n\n\n\n\n# Functions to export for reuse\ndef export_statistical_functions():\n    \"\"\"\n    Export key functions for external use\n    \"\"\"\n    functions = {\n        'descriptive_summary': descriptive_summary,\n        'np_mean': np.mean,\n        'np_median': np.median,\n        'np_std': lambda x: np.std(x, ddof=1),\n        'scipy_mode': lambda x: stats.mode(x, keepdims=True),\n        'pandas_describe': lambda x: pd.DataFrame({'data': x}).describe()\n    }\n    \n    print(\"📦 Exported Functions:\")\n    for name, func in functions.items():\n        print(f\"✓ {name}\")\n    \n    return functions\n\nexported_functions = export_statistical_functions()\n\n📦 Exported Functions:\n✓ descriptive_summary\n✓ np_mean\n✓ np_median\n✓ np_std\n✓ scipy_mode\n✓ pandas_describe\n\n\n\n\n\n\nThis presentation demonstrates comprehensive Python implementation of descriptive statistics using essential scientific libraries. The tabbed format makes it easy to navigate between different concepts and implementations."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#definition-1",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#definition-1",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Definition",
    "text": "Definition\nThe mode is the value that appears most frequently in a dataset.\n\n\n\n\n\n%%{init: {'flowchart': {'nodeSpacing': 100, 'rankSpacing': 100}, 'width': 600, 'height': 400}}%%\ngraph TD\n    A[\"Mode Types\"]\n    A --&gt; B[\"Unimodal&lt;br/&gt;One peak\"]\n    A --&gt; C[\"Bimodal&lt;br/&gt;Two peaks\"]\n    A --&gt; D[\"Multimodal&lt;br/&gt;Multiple peaks\"]\n    A --&gt; E[\"No Mode&lt;br/&gt;No repeated values\"]\n    \n    classDef main fill:#e1f5fe,stroke:#01579b,stroke-width:3px,font-size:16px\n    classDef types fill:#f5f5f5,stroke:#424242,stroke-width:2px,font-size:14px\n    \n    class A main\n    class B,C,D,E types"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#types-of-distributions-by-mode",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#types-of-distributions-by-mode",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Types of Distributions by Mode",
    "text": "Types of Distributions by Mode\n\nUnimodal: One mode\nBimodal: Two modes\n\nMultimodal: More than two modes\nNo mode: All values appear with equal frequency"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#example-1",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#example-1",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Example 1:",
    "text": "Example 1:\nData: 2, 3, 3, 4, 5, 5, 5, 6, 7\n\nAnalysis:\n\n\nCount each value: 2(1), 3(2), 4(1), 5(3), 6(1), 7(1)\nMost frequent value: 5 appears 3 times\nMode = 5\nType: Unimodal (one mode)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#example-2",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#example-2",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Example 2:",
    "text": "Example 2:\nData: 1, 2, 2, 3, 4, 4, 5\n\nAnalysis:\n\n\nCount each value: 1(1), 2(2), 3(1), 4(2), 5(1)\nMost frequent values: 2 and 4 both appear twice\nModes = 2 and 4\nType: Bimodal (two modes)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#example-3",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#example-3",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Example 3:",
    "text": "Example 3:\nData: 1, 2, 3, 4, 5\n\nAnalysis:\n\n\nCount each value: 1(1), 2(1), 3(1), 4(1), 5(1)\nAll values appear exactly once\nNo mode (no value repeats)\nType: No mode"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#mode-for-different-data-types",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#mode-for-different-data-types",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Mode for Different Data Types",
    "text": "Mode for Different Data Types\nCategorical Data:\nFavorite colors: Red, Blue, Blue, Green, Blue, Red, Blue Mode = Blue\nContinuous Data:\nOften requires grouping into intervals or bins Example: Heights grouped into ranges"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#properties-of-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#properties-of-the-mode",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Properties of the Mode",
    "text": "Properties of the Mode\n\nCan be used with any type of data (nominal, ordinal, interval, ratio)\nNot affected by outliers\nMay not exist or may not be unique\nRepresents the most common value\nEasy to identify in frequency distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#when-to-use-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#when-to-use-the-mode",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "When to Use the Mode",
    "text": "When to Use the Mode\n✅ Use the mode when:\n\nWorking with categorical (nominal) data\nWant to identify the most popular or common choice\nData has clear peaks in frequency\nQuality control applications (most common defect type)\nBusiness applications (best-selling product, most common customer complaint)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#comparing-measures-of-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#comparing-measures-of-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Comparing Measures of Central Tendency",
    "text": "Comparing Measures of Central Tendency\n\n\n\n\n\n\n\n\n\n\nMeasure\nBest for Data Type\nStrengths\nWeaknesses\nAffected by Outliers?\n\n\n\n\nMean\nInterval, Ratio\nUses all data, mathematically tractable\nSensitive to outliers\nYes\n\n\nMedian\nOrdinal, Interval, Ratio\nRobust to outliers, represents middle\nIgnores extreme values\nNo\n\n\nMode\nAll types\nWorks with categorical, identifies most common\nMay not exist/be unique\nNo"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#shape-of-distribution-effects",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#shape-of-distribution-effects",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Shape of Distribution Effects",
    "text": "Shape of Distribution Effects\n\nSymmetric distribution: Mean ≈ Median ≈ Mode\nRight-skewed (positively skewed): Mean &gt; Median &gt; Mode\n\nLeft-skewed (negatively skewed): Mode &gt; Median &gt; Mean"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#business-applications",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#business-applications",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Business Applications",
    "text": "Business Applications\n\nCustomer Satisfaction: Mean rating shows overall satisfaction, median shows typical experience\nSales Data: Mode identifies best-selling products, median shows typical sale amount\n\nEmployee Performance: Mean for overall team performance, median for typical employee"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#educational-applications",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#educational-applications",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Educational Applications",
    "text": "Educational Applications\n\nTest Scores: Mean for class average, median for typical student performance\nGrade Distribution: Mode shows most common grade\nAttendance: Mean for overall attendance rate"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#healthcare-applications",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#healthcare-applications",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Healthcare Applications",
    "text": "Healthcare Applications\n\nPatient Wait Times: Median often preferred due to skewed distributions\nTreatment Outcomes: Mean for overall effectiveness, mode for most common result\nVital Signs: All three measures provide different insights"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#interpretation-guidelines",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#interpretation-guidelines",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Interpretation Guidelines",
    "text": "Interpretation Guidelines\n\nAlways consider the context of your data\nReport multiple measures when appropriate\n\nBe aware of data distribution shape\nConsider the presence of outliers\nChoose the most appropriate measure for your specific question"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#remember-these-points",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#remember-these-points",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Remember These Points",
    "text": "Remember These Points\n\nData type determines which statistics are appropriate\nMean uses all data but is sensitive to outliers\nMedian is robust and represents the middle value\nMode identifies the most common value and works with all data types\nContext matters when choosing and interpreting measures\nPython provides powerful tools for calculating descriptive statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#next-lecture-preview",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#next-lecture-preview",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Next Lecture Preview",
    "text": "Next Lecture Preview\nDescriptive Statistics Part II will cover:\n\nMeasures of variability (range, variance, standard deviation)\nMeasures of position (percentiles, quartiles, z-scores)\nShape of distributions (skewness and kurtosis)\nAdvanced Python visualization techniques"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#try-these-problems",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#try-these-problems",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Try These Problems",
    "text": "Try These Problems\n\nCalculate mean, median, and mode for: 12, 15, 18, 12, 20, 25, 12, 30\nA dataset has mean = 50 and median = 45. What does this tell you about the distribution?\nWhy might median be preferred over mean for reporting household income?\nCreate a Python function to identify the most appropriate measure of central tendency for a given dataset."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#thank-you-for-your-attention",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#thank-you-for-your-attention",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Thank you for your attention!",
    "text": "Thank you for your attention!\nReferences & Further Reading\n\nOpenIntro Statistics, Ch. 1 & 2\nPython for Data Analysis (McKinney), Ch. 5\nUCSB Library Data Lab workshops\npandas DataFrame.describe() ￼\nNumPy statistical functions ￼\nSciPy stats module reference"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#thank-you-for-your-attention-1",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#thank-you-for-your-attention-1",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Thank you for your attention!",
    "text": "Thank you for your attention!\nReferences & Further Reading\n\nOpenIntro Statistics, Ch. 1 & 2\nPython for Data Analysis (McKinney), Ch. 5\nUCSB Library Data Lab workshops\npandas DataFrame.describe() ￼\nNumPy statistical functions ￼\nSciPy stats module reference"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#sec-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#sec-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Central Tendency Measures",
    "text": "Central Tendency Measures\n\nMean CalculationMedian CalculationMode Calculation\n\n\n\n# Sample data\nimport numpy as np \nimport pandas as pd\n\n# generate data\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\n\n# Using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np:.2f}\")\n\n# Using Pandas\ndf = pd.DataFrame({'scores': data})\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd:.2f}\")\n\n# Manual calculation for understanding\nmanual_mean = sum(data) / len(data)\nprint(f\"Mean (Manual): {manual_mean:.2f}\")\n\nMean (NumPy): 87.10\nMean (Pandas): 87.10\nMean (Manual): 87.10\n\n\n\n\n\n# Using NumPy\n\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np:.2f}\")\n\n# Using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd:.2f}\")\n\n# Manual calculation\nsorted_data = sorted(data)\nn = len(sorted_data)\nif n % 2 == 0:\n    manual_median = (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2\nelse:\n    manual_median = sorted_data[n//2]\nprint(f\"Median (Manual): {manual_median:.2f}\")\n\nMedian (NumPy): 87.50\nMedian (Pandas): 87.50\nMedian (Manual): 87.50\n\n\n\n\n\n# Using SciPy\nfrom scipy import stats\nmode_result = stats.mode(data, keepdims=True)\nprint(f\"Mode (SciPy): {mode_result.mode[0]}, Count: {mode_result.count[0]}\")\n\n# Using Pandas\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\n# Manual calculation using Counter\nfrom collections import Counter\ncounter = Counter(data)\nmax_count = max(counter.values())\nmodes = [k for k, v in counter.items() if v == max_count]\nprint(f\"Mode (Manual): {modes}, Count: {max_count}\")\n\nMode (SciPy): 85, Count: 2\nMode (Pandas): [85]\nMode (Manual): [85], Count: 2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#mean-mode-and-median",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#mean-mode-and-median",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Mean, Mode and Median",
    "text": "Mean, Mode and Median\n\nMean CalculationMedian CalculationMode Calculation\n\n\n\n# Sample data\nimport numpy as np \nimport pandas as pd\n\n# generate data\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\n\n# Using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np:.2f}\")\n\n# Using Pandas\ndf = pd.DataFrame({'scores': data})\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd:.2f}\")\n\n# Manual calculation for understanding\nmanual_mean = sum(data) / len(data)\nprint(f\"Mean (Manual): {manual_mean:.2f}\")\n\nMean (NumPy): 87.10\nMean (Pandas): 87.10\nMean (Manual): 87.10\n\n\n\n\n\n# Using NumPy\n\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np:.2f}\")\n\n# Using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd:.2f}\")\n\n# Manual calculation\nsorted_data = sorted(data)\nn = len(sorted_data)\nif n % 2 == 0:\n    manual_median = (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2\nelse:\n    manual_median = sorted_data[n//2]\nprint(f\"Median (Manual): {manual_median:.2f}\")\n\nMedian (NumPy): 87.50\nMedian (Pandas): 87.50\nMedian (Manual): 87.50\n\n\n\n\n\n# Using SciPy\nfrom scipy import stats\nmode_result = stats.mode(data, keepdims=True)\nprint(f\"Mode (SciPy): {mode_result.mode[0]}, Count: {mode_result.count[0]}\")\n\n# Using Pandas\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\n# Manual calculation using Counter\nfrom collections import Counter\ncounter = Counter(data)\nmax_count = max(counter.values())\nmodes = [k for k, v in counter.items() if v == max_count]\nprint(f\"Mode (Manual): {modes}, Count: {max_count}\")\n\nMode (SciPy): 85, Count: 2\nMode (Pandas): [85]\nMode (Manual): [85], Count: 2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#mean-mode-and-median-python-examples",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#mean-mode-and-median-python-examples",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Mean, Mode and Median Python Examples",
    "text": "Mean, Mode and Median Python Examples\n\nMean CalculationMedian CalculationMode Calculation\n\n\n\n# Sample data\nimport numpy as np \nimport pandas as pd\n\n# generate data\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\n\n# Using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np:.2f}\")\n\n# Using Pandas\ndf = pd.DataFrame({'scores': data})\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd:.2f}\")\n\n# Manual calculation for understanding\nmanual_mean = sum(data) / len(data)\nprint(f\"Mean (Manual): {manual_mean:.2f}\")\n\nMean (NumPy): 87.10\nMean (Pandas): 87.10\nMean (Manual): 87.10\n\n\n\n\n\n# Using NumPy\n\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np:.2f}\")\n\n# Using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd:.2f}\")\n\n# Manual calculation\nsorted_data = sorted(data)\nn = len(sorted_data)\nif n % 2 == 0:\n    manual_median = (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2\nelse:\n    manual_median = sorted_data[n//2]\nprint(f\"Median (Manual): {manual_median:.2f}\")\n\nMedian (NumPy): 87.50\nMedian (Pandas): 87.50\nMedian (Manual): 87.50\n\n\n\n\n\n# Using SciPy\nfrom scipy import stats\nmode_result = stats.mode(data, keepdims=True)\nprint(f\"Mode (SciPy): {mode_result.mode[0]}, Count: {mode_result.count[0]}\")\n\n# Using Pandas\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\n# Manual calculation using Counter\nfrom collections import Counter\ncounter = Counter(data)\nmax_count = max(counter.values())\nmodes = [k for k, v in counter.items() if v == max_count]\nprint(f\"Mode (Manual): {modes}, Count: {max_count}\")\n\nMode (SciPy): 85, Count: 2\nMode (Pandas): [85]\nMode (Manual): [85], Count: 2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#mean-mode-and-median-visualization",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#mean-mode-and-median-visualization",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Mean, Mode and Median Visualization",
    "text": "Mean, Mode and Median Visualization\n\nCodeVisualization\n\n\n\n# import libraries\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n# define your data and compute statistics here\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\nmean_np   = np.mean(data)\nmedian_np = np.median(data)\n# for mode, use Counter\ncounter   = Counter(data)\nmax_count = max(counter.values())\nmodes     = [k for k,v in counter.items() if v==max_count]\nmode_val  = modes[0]\n\n\n\n\n\n\n\n\nDistribution of Test Scores with Central Tendency Measures"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2_part1.html#central-measures",
    "href": "files/lecture_notes/lecture2/lecture2_part1.html#central-measures",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Central Measures",
    "text": "Central Measures\n\n\n\nMean CalculationMedian CalculationMode Calculation\n\n\n\n# Import numpy library for numeric operations\nimport numpy as np \n\n# Import pandas library for data structures\nimport pandas as pd\n\n# Define sample data as a list of test scores\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\n\n# Compute the arithmetic mean using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np:.2f}\")\n\n# Convert the data list into a pandas DataFrame\ndf = pd.DataFrame({'scores': data})\n\n# Compute the arithmetic mean using Pandas\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd:.2f}\")\n\n# Manually sum all scores and divide by count\nmanual_mean = sum(data) / len(data)\nprint(f\"Mean (Manual): {manual_mean:.2f}\")\n\nMean (NumPy): 87.10\nMean (Pandas): 87.10\nMean (Manual): 87.10\n\n\n\n\n\n# Compute the median value using NumPy\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np:.2f}\")\n\n# Compute the median value using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd:.2f}\")\n\n# Sort the data list in ascending order\nsorted_data = sorted(data)\n\n# Determine the number of elements\nn = len(sorted_data)\n\n# If even count, average the two middle elements; else take middle element\nif n % 2 == 0:\n    manual_median = (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2\nelse:\n    manual_median = sorted_data[n//2]\n\nprint(f\"Median (Manual): {manual_median:.2f}\")\n\nMedian (NumPy): 87.50\nMedian (Pandas): 87.50\nMedian (Manual): 87.50\n\n\n\n\n\n# Import SciPy stats module to compute mode\nfrom scipy import stats\n\n# Use SciPy to find the most common value and its count\nmode_result = stats.mode(data, keepdims=True)\nprint(f\"Mode (SciPy): {mode_result.mode[0]}, Count: {mode_result.count[0]}\")\n\n# Use Pandas to get mode(s) from the DataFrame\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\n# Import Counter for manual frequency counting\nfrom collections import Counter\n\n# Count occurrences of each score\ncounter = Counter(data)\n\n# Find the highest frequency\nmax_count = max(counter.values())\n\n# Identify all values that appear with that frequency\nmodes = [k for k, v in counter.items() if v == max_count]\n\nprint(f\"Mode (Manual): {modes}, Count: {max_count}\")\n\nMode (SciPy): 85, Count: 2\nMode (Pandas): [85]\nMode (Manual): [85], Count: 2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html",
    "href": "files/lecture_notes/lecture2/lecture2.html",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "",
    "text": "Introduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\n\nWhy it matters before any modeling\n\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset they’ve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "href": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Central Measures",
    "text": "Central Measures\n\n\n\nMean CalculationMedian CalculationMode Calculation\n\n\n\n# Import numpy library for numeric operations\nimport numpy as np \n\n# Import pandas library for data structures\nimport pandas as pd\n\n# Define sample data as a list of test scores\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\n\n# Compute the arithmetic mean using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np:.2f}\")\n\n# Convert the data list into a pandas DataFrame\ndf = pd.DataFrame({'scores': data})\n\n# Compute the arithmetic mean using Pandas\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd:.2f}\")\n\n# Manually sum all scores and divide by count\nmanual_mean = sum(data) / len(data)\nprint(f\"Mean (Manual): {manual_mean:.2f}\")\n\nMean (NumPy): 87.10\nMean (Pandas): 87.10\nMean (Manual): 87.10\n\n\n\n\n\n# Compute the median value using NumPy\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np:.2f}\")\n\n# Compute the median value using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd:.2f}\")\n\n# Sort the data list in ascending order\nsorted_data = sorted(data)\n\n# Determine the number of elements\nn = len(sorted_data)\n\n# If even count, average the two middle elements; else take middle element\nif n % 2 == 0:\n    manual_median = (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2\nelse:\n    manual_median = sorted_data[n//2]\n\nprint(f\"Median (Manual): {manual_median:.2f}\")\n\nMedian (NumPy): 87.50\nMedian (Pandas): 87.50\nMedian (Manual): 87.50\n\n\n\n\n\n# Import SciPy stats module to compute mode\nfrom scipy import stats\n\n# Use SciPy to find the most common value and its count\nmode_result = stats.mode(data, keepdims=True)\nprint(f\"Mode (SciPy): {mode_result.mode[0]}, Count: {mode_result.count[0]}\")\n\n# Use Pandas to get mode(s) from the DataFrame\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\n# Import Counter for manual frequency counting\nfrom collections import Counter\n\n# Count occurrences of each score\ncounter = Counter(data)\n\n# Find the highest frequency\nmax_count = max(counter.values())\n\n# Identify all values that appear with that frequency\nmodes = [k for k, v in counter.items() if v == max_count]\n\nprint(f\"Mode (Manual): {modes}, Count: {max_count}\")\n\nMode (SciPy): 85, Count: 2\nMode (Pandas): [85]\nMode (Manual): [85], Count: 2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "href": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mean, Mode and Median Visualization",
    "text": "Mean, Mode and Median Visualization\n\nCodeVisualization\n\n\n\n# import libraries\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n# define your data and compute statistics here\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\nmean_np   = np.mean(data)\nmedian_np = np.median(data)\n# for mode, use Counter\ncounter   = Counter(data)\nmax_count = max(counter.values())\nmodes     = [k for k,v in counter.items() if v==max_count]\nmode_val  = modes[0]\n\n\n\n\n\n\n\n\nDistribution of Test Scores with Central Tendency Measures"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#footnotes",
    "href": "files/lecture_notes/lecture2/lecture2.html#footnotes",
    "title": "Lecture 2: Descriptive Statistics I - Part I",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(source)↩︎"
  },
  {
    "objectID": "files/labs/lab2/lab2.html",
    "href": "files/labs/lab2/lab2.html",
    "title": "Lab 2: Data Classes and Programming Fundamentals",
    "section": "",
    "text": "Last week, we were introduced to the notion of data types. Recall that “data type” can be thought of as the category (or type) of data i.e. integer, float, character, etc.\nIn Python, however, we often need to aggregate data into larger structures, often referred to as data classes."
  },
  {
    "objectID": "files/labs/lab2/lab2.html#introduction",
    "href": "files/labs/lab2/lab2.html#introduction",
    "title": "Lab 2: Data Classes and Programming Fundamentals",
    "section": "1 Introduction",
    "text": "1 Introduction\nLast week, we were introduced to the notion of data types. Recall that “data type” can be thought of as the category (or type) of data i.e. integer, float, character, etc.\nIn Python, however, we often need to aggregate data into larger structures, often referred to as data classes."
  },
  {
    "objectID": "files/labs/lab2/lab2.html#lists",
    "href": "files/labs/lab2/lab2.html#lists",
    "title": "Lab 2: Data Classes and Programming Fundamentals",
    "section": "2 Lists",
    "text": "2 Lists\nPerhaps the most fundamental data structure in Python is that of a list. Just like lists in real life or in mathematics, Python lists are just collections of items enclosed in square brackets:\n[&lt;item 1&gt;, &lt;item 2&gt;, ..., &lt;item n&gt;]\nAgain, the items in a list can be of any data type; we can even mix and match data types!\n\n2.1 Task 1\nCreate a list containing the elements 1, \"hi\", 3.4, and \"PSTAT 5A\". Assign this list to a variable called list1.\n\n# Your code here\n\nJust as we were able to use a Python function (type()) to check the type of a particular piece of data, we can also use Python to check the structure or class of a piece of data. It turns out that we use the same function as before- namely, type()!\n\n\n2.2 Task 1 (cont’d)\nRun the code type(list1).\n\n# Your code here"
  },
  {
    "objectID": "files/labs/lab2/lab2.html#indexing",
    "href": "files/labs/lab2/lab2.html#indexing",
    "title": "Lab 2: Data Classes and Programming Fundamentals",
    "section": "3 Indexing",
    "text": "3 Indexing\nAlright, now that we can store data in lists, how can we access elements in a list? The answer is to use what is known as indexing.\nGiven a list x, we access the ith element using the code:\nx[i]\nThe reason we call this “indexing” is because the number that goes between the brackets is the index of the element that we want.\n\n\n\n\n\n\nCaution\n\n\n\nPython begins indexing at 0.\n\n\nWhat does this mean? Well, let’s see by way of an example.\n\n3.1 Task 2\nCreate a list with the numbers 1 through 10, inclusive, and assign this to a variable called x.\n\n# Your code here\n\nRun the code x[1].\n\n# Your code here\n\nRun the code x[0].\n\n# Your code here\n\nSo, what we would colloquially call the first element of a list, Python calls the zeroeth element.\n\n\n3.2 Task 3\nCreate a list called x that contains the elements 1, \"two\", 3.5, \"four\", and \"five five\". Answer the following questions WITHOUT running any code, writing your answers as a comment in a code cell:\n\nWhat would be the output of type(x)?\nWhat would be the output of type(x[1])?\nWhat would be the output of x[0]?\n\n\n# Create the list\nx = [1, \"two\", 3.5, \"four\", \"five five\"]\n\n# Your predictions as comments:\n# 1. type(x) would output: \n# 2. type(x[1]) would output: \n# 3. x[0] would output: \n\nNow, run code to verify your answers to the above three questions.\n\n# Verify your answers here"
  },
  {
    "objectID": "files/labs/lab2/lab2.html#tables",
    "href": "files/labs/lab2/lab2.html#tables",
    "title": "Lab 2: Data Classes and Programming Fundamentals",
    "section": "4 Tables",
    "text": "4 Tables\nAnother very useful data structure in Python is that of a table. Python tables behave pretty much the same as the tables we’ve used in, say, math- they are a grid of values arranged sequentially.\nTables can be created using the Table() function in Python, which itself comes from the datascience module. The general syntax of creating a table with the Table() function is:\nTable().with_columns(\n  \"\", [, , ... ],\n  \"\", [, , ... ],\n  ...\n)\nFor example:\n\n# Install datascience if needed (uncomment if necessary)\n# !pip install datascience\nfrom datascience import *\n\nTable().with_columns(\n  \"Course\", [\"PSTAT 5A\", \"PSTAT 120A\", \"PSTAT 130\"],\n  \"Units\", [4, 4, 4],\n  \"Quarter\", [\"Summer\", \"Fall\", \"Winter\"]\n)\n\n/Users/narjesmathlouthi/Desktop/PSTAT5A/web/PSTAT5A/.venv/lib/python3.13/site-packages/datascience/maps.py:13: UserWarning:\n\npkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n\n\n\n\n\n\nCourse\nUnits\nQuarter\n\n\n\n\nPSTAT 5A\n4\nSummer\n\n\nPSTAT 120A\n4\nFall\n\n\nPSTAT 130\n4\nWinter\n\n\n\n\n\nThere is nothing stopping us from assigning a table to a variable! For example, after running:\n\ntable1 = Table().with_columns(\n  \"Course\", [\"PSTAT 5A\", \"PSTAT 120A\", \"PSTAT 130\"],\n  \"Units\", [4, 4, 4],\n  \"Instructor\", [\"Mathlouthi\", \"Johnson\", \"Smith\"]\n)\n\ntable1\n\n\n\n\nCourse\nUnits\nInstructor\n\n\n\n\nPSTAT 5A\n4\nMathlouthi\n\n\nPSTAT 120A\n4\nJohnson\n\n\nPSTAT 130\n4\nSmith\n\n\n\n\n\n\n4.1 Terminology\nSometimes in Python we will encounter expressions of the form:\n&lt;object type&gt;.&lt;function name&gt;()\nIn this syntax, the function &lt;function name&gt; is said to be a method. For example, the function with_columns() is a method for the Table object.\nThe datascience module contains a plethora of methods we can use to manage tables. For example, the select() method can be used to select columns by name:\n\ntable1.select(\"Units\")\n\n\n\n\nUnits\n\n\n\n\n4\n\n\n4\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\nSyntax\n\n\n\nMethods are always appended to either a function that creates a blank object type (like Table()) or a variable of the correct type.\n\n\n\n\n4.2 Task 4\nRead the list of methods for Table objects at http://data8.org/datascience/tables.html, and write down (in a code cell, using comments) at least three different methods, including a short description of what each method does. For example:\n\n# .with_columns(): adds specified columns to a table.\n# Your three methods here:\n\n\n\n4.3 Task 5\nCreate the following table, and assign it to a variable called profs:\n\n\n\nProfessor\nOffice\nCourse\n\n\n\n\nDr. Swenson\nSouth Hall\nPSTAT 130\n\n\nDr. Wainwright\nOld Gym\nPSTAT 120A\n\n\nDr. Mouti\nOld Gym\nPSTAT 126\n\n\n\n\n# Your code here\n\nRun a cell containing only the code profs to make sure (visually) that your table looks correct.\n\n# Your code here\n\nSelect the column called Course from profs.\n\n# Your code here\n\nCreate a new table called profs_new that contains the same rows as the profs table, but with the following additional row:\n\n\n\nProfessor\nOffice\nCourse\n\n\n\n\nDr. Ravat\nSouth Hall\nPSTAT 120B\n\n\n\n\n# Your code here\n\nRun a cell containing only the code profs_new to make sure (visually) that the appending was successful.\n\n\n\n\n\n\nTip\n\n\n\nThink about how you can use our discussion on updating variable values from last lab. Also, the method .with_row() may be useful; see the help file at http://data8.org/datascience/tables.html for more information.\n\n\n\n# Your code here\n\n\n\n4.4 Filtering Tables\nSuppose we want to select rows of a table that satisfy a given condition. For example, if we wanted to find the information of only courses taught by Mathlouthi in the table1 table above, we would call:\n\ntable1.where(\"Instructor\", \"Mathlouthi\")\n\n\n\n\nCourse\nUnits\nInstructor\n\n\n\n\nPSTAT 5A\n4\nMathlouthi\n\n\n\n\n\nWhat would happen if we tried to select the rows of table1 with “Wilson” in the Instructor column? Well, since there is nobody in table1 named Wilson, we should hope that Python returns an empty table.\n\ntable1.where(\"Instructor\", \"Wilson\")\n\n\n\n\nCourse\nUnits\nInstructor\n\n\n\n\n\n\n\nSure enough, Python has returned an empty table!"
  },
  {
    "objectID": "files/labs/lab2/lab2.html#arrays",
    "href": "files/labs/lab2/lab2.html#arrays",
    "title": "Lab 2: Data Classes and Programming Fundamentals",
    "section": "5 Arrays",
    "text": "5 Arrays\nThe final Data Structure we will examine in this class is that of an array. Arrays behave very similarly to Tables, with a few differences. For one, the syntax used to create an array is slightly different:\nmake_array(&lt;item 1&gt;, &lt;item 2&gt;, &lt;item 3&gt;, ...)\nFor example:\n\nmake_array(\"Spring\", \"Summer\", \"Autumn\", \"Winter\")\n\narray(['Spring', 'Summer', 'Autumn', 'Winter'],\n      dtype='&lt;U6')\n\n\nYou may ask- what’s that dtype='&lt;U6' symbol at the end of the output? For now, don’t worry about it, as we will revisit this later.\n\n5.1 Lists vs. Arrays\nSo, we now know about three different data classes in Python: lists, tables, and arrays. At first glance, lists and arrays may seem somewhat similar. However, there are a few key differences between them:\n\n\n5.2 Task 6\nMake a list called my_list containing the elements 1, 2, and 3, and make an array called my_array also containing the elements 1, 2, and 3. Run the following commands in separate code cells:\n\n# Create list and array\nmy_list = [1, 2, 3]\nmy_array = make_array(1, 2, 3)\n\n\nsum(my_list)\n\n6\n\n\n\nsum(my_array)\n\n6\n\n\n\n# my_list + 2  # This will cause an error\n\n\nmy_array + 2\n\narray([3, 4, 5])\n\n\nWhat the previous Task illustrates is the fact that arrays lend themselves to element-wise operations, whereas lists do not. One important limitation about arrays, though, is that the elements in an array must all be of the same data type. If you try to make an array consisting of elements that are different data types Python will still run, however it will not run in the way you expect it to!"
  },
  {
    "objectID": "files/labs/lab2/lab2.html#comparisons",
    "href": "files/labs/lab2/lab2.html#comparisons",
    "title": "Lab 2: Data Classes and Programming Fundamentals",
    "section": "6 Comparisons",
    "text": "6 Comparisons\nHere’s a question: is 2 less than 3? Well, yes it is! If we wanted to confirm this, we could simply ask Python whether 2 is less than 3 by running:\n\n2 &lt; 3\n\nTrue\n\n\nNotice, however, how Python answered this question: it simply returned True. Let’s see what the data type of True is:\n\ntype(True)\n\nbool\n\n\nTrue is of the type bool, which is short for boolean. There are only two boolean quantities in Python: True and False. Let’s see how we can generate a False value:\n\n3 &lt; 2\n\nFalse\n\n\nHere is a list of comparison operators, taken from the Inferential Thinking textbook:\n\n\n\nComparison\nOperator\nTrue Example\nFalse Example\n\n\n\n\nLess than\n&lt;\n2 &lt; 3\n2 &lt; 2\n\n\nGreater than\n&gt;\n3 &gt; 2\n3 &gt; 3\n\n\nLess than or equal\n&lt;=\n2 &lt;= 2\n3 &lt;= 2\n\n\nGreater than or equal\n&gt;=\n3 &gt;= 3\n2 &gt;= 3\n\n\nEqual\n==\n3 == 3\n3 == 2\n\n\nNot equal\n!=\n3 != 2\n2 != 2\n\n\n\nOne nice thing about Python is that it allows for multiple simultaneous comparisons. For example:\n\n2 &lt; 3 &lt; 4\n\nTrue\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn a multiple comparison, Python will only return True when all of the included comparisons are true.\n\n\nFor instance, 2 &lt; 3 &lt; 1 would return False, because even though 2 is less than 3 it is not true that 3 is less than 1.\nBelieve it or not, you can compare strings as well! Python compares strings alphabetically; that is, letters at the beginning of the alphabet are considered to have smaller ordinal value than letters at the end of the alphabet. For example:\n\n\"apple\" &lt; \"banana\"\n\nTrue\n\n\n\n\"zebra\" &lt; \"zanzibar\"\n\nFalse\n\n\n\n\"cat\" &lt;= \"catenary\"\n\nTrue\n\n\n\n6.1 Task 7\nCheck how \"statistics\" and \"Statistics\" (note the capitalization!) compare. Use this to answer the question: when Python is comparing strings, does it give precedence to capital letters or not? If so, which (lowercase or capital) is given a “higher” value?\n\n# Your code here\n\n\n\n6.2 Comparing Lists and Arrays\nFinally, we discuss how comparisons work in the context of lists and arrays. The way Python compares lists is by what is known as lexicographical order. From the official Python help documentation, this means:\n\nfirst the first two items are compared, and if they differ this determines the outcome of the comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted.\n\nFor instance, [1, 2, 3] &lt; [2, 1, 1] would return True since 1 (the first element of the first list) is less than 2 (the first element of the second list).\nThe comparison of arrays is a little more straightforward, except:\n\n\n\n\n\n\nImportant\n\n\n\nWhen comparing two arrays, the arrays must be of the same length.\n\n\nTo see exactly how comparison of arrays works, let’s work through a Task:\n\n\n6.3 Task 8\nMake an array with the elements 1, 2, and 3, and call this x. Make another array with the elements 2, 3, 1, and call this y. Run x &lt; y, and comment on the result.\n\n# Your code here\n\nWhat the previous task illustrates is that Python compares arrays element-wise."
  },
  {
    "objectID": "files/labs/lab2/lab2.html#conditionals",
    "href": "files/labs/lab2/lab2.html#conditionals",
    "title": "Lab 2: Data Classes and Programming Fundamentals",
    "section": "7 Conditionals",
    "text": "7 Conditionals\nNow, we can use comparisons for much more than verifying simple arithmetic relationships. One of the main areas in which comparisons arise is the area of conditional expressions.\nSimply put, conditional expressions are how we can convey a set of choices to Python. As an example, let’s consider finding someone’s city based on their zip code. To simplify, let’s assume the only zip codes we consider are 93117, 93120, and 93150. From postal data, we know that:\n\na zip code of 93117 corresponds to Goleta\na zip code of 93120 corresponds to Santa Barbara\n\na zip code of 93150 corresponds to Montecito\n\nWe can rephrase this information in terms of “if” statements:\n\nIf a person has a zip code of 93117, then they are in Goleta\nOtherwise, if they have a zip code of 93120, then they are in Santa Barbara\nOtherwise, if they have a zip code of 93150, then they are in Montecito\n\nThis is precisely the syntax we would use when translating this experiment into Python syntax:\n\n# Example of conditional statements with zip codes\n# First, we need to define a zip_code variable\nzip_code = 93117  # Example zip code\n\nif zip_code == 93117:\n    location = \"Goleta\"\nelif zip_code == 93120:\n    location = \"Santa Barbara\"\nelif zip_code == 93150:\n    location = \"Montecito\"\nelse:\n    location = \"Unknown location\"\n\nprint(f\"Zip code {zip_code} corresponds to: {location}\")\n\n# Test with different zip codes\nfor test_zip in [93117, 93120, 93150, 99999]:\n    if test_zip == 93117:\n        loc = \"Goleta\"\n    elif test_zip == 93120:\n        loc = \"Santa Barbara\"\n    elif test_zip == 93150:\n        loc = \"Montecito\"\n    else:\n        loc = \"Unknown location\"\n    print(f\"Zip code {test_zip}: {loc}\")\n\nZip code 93117 corresponds to: Goleta\nZip code 93117: Goleta\nZip code 93120: Santa Barbara\nZip code 93150: Montecito\nZip code 99999: Unknown location\n\n\nBy the way: elif is an abbreviation for else if, which itself can be thought of as equivalent to otherwise, if.\nHere’s the general syntax of a conditional expression in Python:\n\nif &lt;condition 1&gt;:\n    &lt;task 1&gt;\nelif &lt;condition 2&gt;:\n    &lt;task 2&gt;\n...\nelse:\n    &lt;final task&gt;\n\nWhen executing the above conditional statement, Python first checks whether &lt;condition 1&gt; returns a value of True or False. If it returns a value of True, then &lt;task 1&gt; is executed and the statement ends. Otherwise, Python checks whether &lt;condition 2&gt; is True or False; if it is True then &lt;task 2&gt; is executed, etc.\n\n\n\n\n\n\nImportant\n\n\n\nIn the example code above: if &lt;condition 1&gt; is True, then no tasks beyond &lt;task 1&gt; are evaluated. If &lt;condition 2&gt; is True, then no tasks beyond &lt;task 2&gt; are evaluated. And so on and so forth.\n\n\n\n7.1 Task 9\nConsider the code:\n\nx = 2\n\nif x &lt; 2:\n    x = \"hello\"\nelif x &lt; 3:\n    x = \"goodbye\"\nelse:\n    x = \"take care\"\n\nBefore running any code, write down what you think the result of executing x would be. Then, run the loop, execute x, and check whether your answer was correct or not.\n\n# Your prediction: \n\n# Now run the code:\nx = 2\n\nif x &lt; 2:\n    x = \"hello\"\nelif x &lt; 3:\n    x = \"goodbye\"\nelse:\n    x = \"take care\"\n\nprint(x)\n\ngoodbye\n\n\n\n\n\n\n\n\nCaution\n\n\n\nIndentation is very important in Python.\n\n\nFor example, if instead of the conditional expression in Task 9 we had instead put:\nx = 2\n\nif x &lt; 2:\nx = \"hello\"\nelif x &lt; 3:\nx = \"goodbye\"\nelse:\nx = \"take care\"\nthen we would have received an error!"
  },
  {
    "objectID": "files/labs/lab2/lab2.html#functions",
    "href": "files/labs/lab2/lab2.html#functions",
    "title": "Lab 2: Data Classes and Programming Fundamentals",
    "section": "8 Functions",
    "text": "8 Functions\nFinally, let’s quickly discuss Python functions. We’ve already been using quite a few functions:\n\n8.1 Task 10\nIn a Markdown cell, write down three functions we’ve used in this Lab thus far.\nYour answer here:\nIf you recall, the general syntax for calling a function is:\n&lt;function name&gt;(&lt;arg1&gt;, &lt;arg2&gt;, ... )\nwhere &lt;function name&gt; denotes the function name and &lt;arg1&gt;, &lt;arg2&gt;, etc. denote the arguments of the function.\nCreating your own function in Python is actually fairly simple! Here is the syntax we use:\n\ndef &lt;function name&gt;(&lt;list out the argument names&gt;):\n    \"\"\"include a 'docstring' here\"\"\"\n    &lt;body of the function&gt;\n    return &lt;what you want the function to output&gt;\n\nFor example:\n\ndef f(x, y):\n    \"\"\"returns x^2 + y^2\"\"\"\n    return x**2 + y**2\n\ncreates a function f that can be called on two arguments, x and y, and returns the sum of squares of the arguments; e.g.\n\nf(3, 4)  # should return 3^2 + 4^2 = 25\n\n25\n\n\nBy the way, the docstring referenced above is a verbal description of what the function does. (Recall from Lab1 that it is just a multi-line comment, since it is enclosed in triple quotation marks!). All functions should include a docstring to convey to the user what the function does.\n\n\n\n\n\n\nImportant\n\n\n\nIf you don’t include a return statement in the definition of a function, then your function will never return anything.\n\n\nFor instance:\n\ndef g(x, y):\n    \"\"\"should return x^2 + y^2\"\"\"\n    x**2 + y**2\n\nprint(g(3, 4))  # This will print None!\n\nNone\n\n\n\n\n8.2 Task 11\nWrite a function called cent_to_far() which takes in a single temperature c as measured in degrees Celsius and returns the corresponding temperature in degrees Fahrenheit. Check that cent_to_far(0) correctly returns 32 and cent_to_far(20) correctly returns 68.\nAs a reminder, the conversion formula is: F = (9/5) × C + 32\n\n# Your code here\ndef cent_to_far(c):\n    \"\"\"Convert Celsius to Fahrenheit\"\"\"\n    # Your implementation here\n    pass\n\n# Test your function\nprint(cent_to_far(0))   # Should return 32\nprint(cent_to_far(20))  # Should return 68\n\nFinally, let’s combine some things by way of a concluding Task:\n\n\n8.3 Task 12\nWrite a function called parity() that returns the parity (i.e. whether a number is even or odd) of an input x. Call your parity() function on 2 and then 3 to make sure your function behaves as expected. Some hints:\n\nRecall that % is the modulus operator in Python. Specifically, x % y returns the remainder of performing x divided by y.\nRecall that even numbers are divisible by 2 (so what does this mean about the remainder of dividing x by 2 if x is even?)\n\n\n# Your code here\ndef parity(x):\n    \"\"\"Returns 'even' if x is even, 'odd' if x is odd\"\"\"\n    # Your implementation here\n    pass\n\n# Test your function\nprint(parity(2))  # Should return 'even'\nprint(parity(3))  # Should return 'odd'"
  },
  {
    "objectID": "files/labs/lab2/lab2.html#summary",
    "href": "files/labs/lab2/lab2.html#summary",
    "title": "Lab 2: Data Classes and Programming Fundamentals",
    "section": "9 Summary",
    "text": "9 Summary\nIn this lab, you’ve learned about:\n\nLists: Ordered collections that can contain mixed data types\nIndexing: Accessing elements using zero-based indexing\nTables: Structured data with named columns using the datascience module\nArrays: Homogeneous collections that support element-wise operations\nComparisons: Boolean operations and comparison operators\nConditionals: if/elif/else statements for decision making\nFunctions: Creating reusable code blocks with def statements\n\nThese are fundamental building blocks that will be essential for the rest of the course!"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#introduction",
    "href": "files/labs/lab2/lab2_sln.html#introduction",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis document contains the complete solutions to Lab 2: Data Classes and Programming Fundamentals. Each task is solved with explanations to help you understand the concepts."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#lists",
    "href": "files/labs/lab2/lab2_sln.html#lists",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "2 Lists",
    "text": "2 Lists\n\n2.1 Task 1 Solution\nCreate a list containing the elements 1, \"hi\", 3.4, and \"PSTAT 5A\". Assign this list to a variable called list1.\n\n# Solution\nlist1 = [1, \"hi\", 3.4, \"PSTAT 5A\"]\nprint(list1)\n\n[1, 'hi', 3.4, 'PSTAT 5A']\n\n\n\n\n2.2 Task 1 (cont’d) Solution\nRun the code type(list1).\n\n# Solution\nprint(type(list1))\n\n&lt;class 'list'&gt;\n\n\nExplanation: The output shows &lt;class 'list'&gt;, confirming that list1 is indeed a list object."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#indexing",
    "href": "files/labs/lab2/lab2_sln.html#indexing",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "3 Indexing",
    "text": "3 Indexing\n\n3.1 Task 2 Solution\nCreate a list with the numbers 1 through 10, inclusive, and assign this to a variable called x.\n\n# Solution\nx = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n# Alternative using range:\n# x = list(range(1, 11))\nprint(x)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nRun the code x[1].\n\n# Solution\nprint(x[1])\n\n2\n\n\nRun the code x[0].\n\n# Solution\nprint(x[0])\n\n1\n\n\nExplanation: - x[1] returns 2 (the second element, since indexing starts at 0) - x[0] returns 1 (the first element)\n\n\n3.2 Task 3 Solution\nCreate a list called x that contains the elements 1, \"two\", 3.5, \"four\", and \"five five\". Answer the questions and verify.\n\n# Create the list\nx = [1, \"two\", 3.5, \"four\", \"five five\"]\n\n# Predictions as comments:\n# 1. type(x) would output: &lt;class 'list'&gt;\n# 2. type(x[1]) would output: &lt;class 'str'&gt;\n# 3. x[0] would output: 1\n\nNow verify the answers:\n\n# Verify answers\nprint(\"1. type(x):\", type(x))\nprint(\"2. type(x[1]):\", type(x[1]))\nprint(\"3. x[0]:\", x[0])\n\n1. type(x): &lt;class 'list'&gt;\n2. type(x[1]): &lt;class 'str'&gt;\n3. x[0]: 1\n\n\nExplanation: 1. type(x) returns &lt;class 'list'&gt; because x is a list 2. type(x[1]) returns &lt;class 'str'&gt; because x[1] is “two”, which is a string 3. x[0] returns 1, the first element of the list"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#tables",
    "href": "files/labs/lab2/lab2_sln.html#tables",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "4 Tables",
    "text": "4 Tables\nFirst, let’s install and import the datascience module:\n\n# Install datascience if needed (uncomment if necessary)\n# !pip install datascience\nfrom datascience import *\n\n/Users/narjesmathlouthi/Desktop/PSTAT5A/web/PSTAT5A/.venv/lib/python3.13/site-packages/datascience/maps.py:13: UserWarning:\n\npkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n\n\n\n\n4.1 Task 4 Solution\nRead the list of methods for Table objects and write down three different methods:\n\n# Three Table methods with descriptions:\n# .with_columns(): adds specified columns to a table\n# .select(): selects specific columns from a table and returns a new table\n# .where(): filters rows based on a condition and returns a new table with matching rows\n# .num_rows: returns the number of rows in the table\n# .num_columns: returns the number of columns in the table\n\n\n\n4.2 Task 5 Solution\nCreate the professor table:\n\n# Solution\nprofs = Table().with_columns(\n    \"Professor\", [\"Dr. Swenson\", \"Dr. Wainwright\", \"Dr. Mouti\"],\n    \"Office\", [\"South Hall\", \"Old Gym\", \"Old Gym\"],\n    \"Course\", [\"PSTAT 130\", \"PSTAT 120A\", \"PSTAT 126\"]\n)\n\nprofs\n\n\n\n\nProfessor\nOffice\nCourse\n\n\n\n\nDr. Swenson\nSouth Hall\nPSTAT 130\n\n\nDr. Wainwright\nOld Gym\nPSTAT 120A\n\n\nDr. Mouti\nOld Gym\nPSTAT 126\n\n\n\n\n\nSelect the column called Course from profs:\n\n# Solution\nprofs.select(\"Course\")\n\n\n\n\nCourse\n\n\n\n\nPSTAT 130\n\n\nPSTAT 120A\n\n\nPSTAT 126\n\n\n\n\n\nCreate a new table called profs_new with an additional row:\n\n# Solution\nprofs_new = profs.with_row([\"Dr. Ravat\", \"South Hall\", \"PSTAT 120B\"])\nprofs_new\n\n\n\n\nProfessor\nOffice\nCourse\n\n\n\n\nDr. Swenson\nSouth Hall\nPSTAT 130\n\n\nDr. Wainwright\nOld Gym\nPSTAT 120A\n\n\nDr. Mouti\nOld Gym\nPSTAT 126\n\n\nDr. Ravat\nSouth Hall\nPSTAT 120B\n\n\n\n\n\nExplanation: The .with_row() method adds a new row to the existing table. We provide the values in the same order as the columns.\n\n\n4.3 Filtering Tables Example\n\n# Create example table for filtering\ntable1 = Table().with_columns(\n    \"Course\", [\"PSTAT 5A\", \"PSTAT 120A\", \"PSTAT 130\"],\n    \"Units\", [4, 4, 4],\n    \"Instructor\", [\"Mathlouthi\", \"Johnson\", \"Smith\"]\n)\n\n# Filter for courses taught by Mathlouthi\ntable1.where(\"Instructor\", \"Mathlouthi\")\n\n\n\n\nCourse\nUnits\nInstructor\n\n\n\n\nPSTAT 5A\n4\nMathlouthi\n\n\n\n\n\n\n# Try filtering for an instructor that doesn't exist\ntable1.where(\"Instructor\", \"Wilson\")\n\n\n\n\nCourse\nUnits\nInstructor"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#arrays",
    "href": "files/labs/lab2/lab2_sln.html#arrays",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "5 Arrays",
    "text": "5 Arrays\n\n5.1 Task 6 Solution\nMake a list and array with the same elements and compare operations:\n\n# Create list and array\nmy_list = [1, 2, 3]\nmy_array = make_array(1, 2, 3)\n\nprint(\"List:\", my_list)\nprint(\"Array:\", my_array)\n\nList: [1, 2, 3]\nArray: [1 2 3]\n\n\n\n# Sum operations\nprint(\"sum(my_list):\", sum(my_list))\nprint(\"sum(my_array):\", sum(my_array))\n\nsum(my_list): 6\nsum(my_array): 6\n\n\n\n# Addition with scalar - this will cause an error for lists\ntry:\n    result = my_list + 2\n    print(\"my_list + 2:\", result)\nexcept TypeError as e:\n    print(\"Error with my_list + 2:\", e)\n\nError with my_list + 2: can only concatenate list (not \"int\") to list\n\n\n\n# Addition with scalar works for arrays\nprint(\"my_array + 2:\", my_array + 2)\n\nmy_array + 2: [3 4 5]\n\n\nExplanation: Arrays support element-wise operations (like adding 2 to each element), while lists do not. Lists use + for concatenation, not arithmetic."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#comparisons",
    "href": "files/labs/lab2/lab2_sln.html#comparisons",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "6 Comparisons",
    "text": "6 Comparisons\n\n6.1 Task 7 Solution\nCompare \"statistics\" and \"Statistics\":\n\n# Solution\nprint('\"statistics\" &lt; \"Statistics\":', \"statistics\" &lt; \"Statistics\")\nprint('\"Statistics\" &lt; \"statistics\":', \"Statistics\" &lt; \"statistics\")\n\n# Additional comparisons to understand the pattern\nprint('ord(\"S\"):', ord(\"S\"))\nprint('ord(\"s\"):', ord(\"s\"))\n\n\"statistics\" &lt; \"Statistics\": False\n\"Statistics\" &lt; \"statistics\": True\nord(\"S\"): 83\nord(\"s\"): 115\n\n\nAnswer: When Python compares strings, capital letters are given precedence (they have “lower” ASCII values). Capital letters come before lowercase letters in ASCII ordering, so \"Statistics\" &lt; \"statistics\" returns True.\n\n\n6.2 Task 8 Solution\nCreate arrays and compare element-wise:\n\n# Solution\nx = make_array(1, 2, 3)\ny = make_array(2, 3, 1)\n\nprint(\"x:\", x)\nprint(\"y:\", y)\nprint(\"x &lt; y:\", x &lt; y)\n\nx: [1 2 3]\ny: [2 3 1]\nx &lt; y: [ True  True False]\n\n\nExplanation: Python compares arrays element-wise, returning an array of boolean values: - 1 &lt; 2 → True - 2 &lt; 3 → True\n- 3 &lt; 1 → False"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#conditionals",
    "href": "files/labs/lab2/lab2_sln.html#conditionals",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "7 Conditionals",
    "text": "7 Conditionals\n\n7.1 Task 9 Solution\nPredict and verify the conditional statement:\n\n# Prediction: x will be \"goodbye\"\n# Reasoning: x = 2, so x &lt; 2 is False, but x &lt; 3 is True\n\n# Run the code:\nx = 2\n\nif x &lt; 2:\n    x = \"hello\"\nelif x &lt; 3:\n    x = \"goodbye\"\nelse:\n    x = \"take care\"\n\nprint(\"Result:\", x)\n\nResult: goodbye\n\n\nExplanation: Since x = 2: - x &lt; 2 is False (2 is not less than 2) - x &lt; 3 is True (2 is less than 3) - So the elif condition executes, setting x = \"goodbye\""
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#functions",
    "href": "files/labs/lab2/lab2_sln.html#functions",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "8 Functions",
    "text": "8 Functions\n\n8.1 Task 10 Solution\nThree functions we’ve used in this Lab:\n# Three functions used in this lab:\n# 1. type() - returns the data type of an object\n# 2. print() - displays output to the screen\n# 3. make_array() - creates an array from the given elements\n# Additional: sum(), len(), range()\n\n\n8.2 Task 11 Solution\nWrite a Celsius to Fahrenheit conversion function:\n\n# Solution\ndef cent_to_far(c):\n    \"\"\"Convert Celsius to Fahrenheit using the formula F = (9/5) * C + 32\"\"\"\n    fahrenheit = (9/5) * c + 32\n    return fahrenheit\n\n# Test the function\nprint(\"cent_to_far(0):\", cent_to_far(0))    # Should return 32\nprint(\"cent_to_far(20):\", cent_to_far(20))  # Should return 68\n\ncent_to_far(0): 32.0\ncent_to_far(20): 68.0\n\n\nExplanation: The conversion formula is F = (9/5) × C + 32. Our function correctly implements this formula.\n\n\n8.3 Task 12 Solution\nWrite a parity function to determine if a number is even or odd:\n\n# Solution\ndef parity(x):\n    \"\"\"Returns 'even' if x is even, 'odd' if x is odd\"\"\"\n    if x % 2 == 0:\n        return \"even\"\n    else:\n        return \"odd\"\n\n# Test the function\nprint(\"parity(2):\", parity(2))  # Should return 'even'\nprint(\"parity(3):\", parity(3))  # Should return 'odd'\n\n# Additional tests\nprint(\"parity(10):\", parity(10))\nprint(\"parity(15):\", parity(15))\n\nparity(2): even\nparity(3): odd\nparity(10): even\nparity(15): odd\n\n\nExplanation: The modulus operator % returns the remainder of division. If x % 2 == 0, then x is divisible by 2 (even). Otherwise, it’s odd."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#complete-examples-and-additional-practice",
    "href": "files/labs/lab2/lab2_sln.html#complete-examples-and-additional-practice",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "9 Complete Examples and Additional Practice",
    "text": "9 Complete Examples and Additional Practice\nHere are some additional examples that demonstrate the concepts:\n\n9.1 Advanced List Operations\n\n# List slicing examples\nnumbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nprint(\"First 5 elements:\", numbers[:5])\nprint(\"Last 3 elements:\", numbers[-3:])\nprint(\"Every other element:\", numbers[::2])\n\nFirst 5 elements: [0, 1, 2, 3, 4]\nLast 3 elements: [7, 8, 9]\nEvery other element: [0, 2, 4, 6, 8]\n\n\n\n\n9.2 Table Operations\n\n# More complex table operations\nstudents = Table().with_columns(\n    \"Name\", [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"],\n    \"Grade\", [85, 92, 78, 96],\n    \"Year\", [\"Sophomore\", \"Junior\", \"Freshman\", \"Senior\"]\n)\n\n# Multiple operations\nhigh_performers = students.where(\"Grade\", are.above(90))\nprint(\"High performers:\")\nhigh_performers.show()\n\n# Sort by grade\nsorted_students = students.sort(\"Grade\", descending=True)\nprint(\"\\nStudents sorted by grade:\")\nsorted_students.show()\n\nHigh performers:\n\n\n\n\n\nName\nGrade\nYear\n\n\n\n\nBob\n92\nJunior\n\n\nDiana\n96\nSenior\n\n\n\n\n\n\nStudents sorted by grade:\n\n\n\n\n\nName\nGrade\nYear\n\n\n\n\nDiana\n96\nSenior\n\n\nBob\n92\nJunior\n\n\nAlice\n85\nSophomore\n\n\nCharlie\n78\nFreshman\n\n\n\n\n\n\n\n9.3 Array Operations\n\nimport numpy as np\n\n# Array mathematical operations\nscores = make_array(85, 92, 78, 96, 89)\nprint(\"Original scores:\", scores)\nprint(\"Curved scores (+5):\", scores + 5)\nprint(\"Squared scores:\", scores ** 2)\nprint(\"Average score:\", np.mean(scores))\n\nOriginal scores: [85 92 78 96 89]\nCurved scores (+5): [ 90  97  83 101  94]\nSquared scores: [7225 8464 6084 9216 7921]\nAverage score: 88.0"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#summary",
    "href": "files/labs/lab2/lab2_sln.html#summary",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "10 Summary",
    "text": "10 Summary\nThis lab covered fundamental Python data structures and programming concepts:\n\nLists: Mutable, mixed-type collections with zero-based indexing\nTables: Structured data with named columns for data analysis\nArrays: Homogeneous collections supporting element-wise operations\nComparisons: Boolean logic and various comparison operators\nConditionals: Decision-making with if/elif/else statements\nFunctions: Creating reusable code blocks with proper documentation\n\nThese concepts form the foundation for data analysis and programming in Python!"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#welcome-to-lecture-3",
    "href": "files/lecture_notes/lecture4/lecture4.html#welcome-to-lecture-3",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Welcome to Lecture 3",
    "text": "Welcome to Lecture 3\nIntroduction to Probability\nUnderstanding the mathematics of uncertainty"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture4/lecture4.html#todays-learning-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Today’s Learning Objectives",
    "text": "Today’s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities\nDetermine when events are independent\nUse Bayes’ theorem in simple applications"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#what-is-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#what-is-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is Probability?",
    "text": "What is Probability?\nProbability is a measure of the likelihood that an event will occur\n\nRanges from 0 to 1 (or 0% to 100%)\n0: Event will never occur\n1: Event will certainly occur\n0.5: Event has equal chance of occurring or not\n\n\nExample: The probability of getting heads when flipping a fair coin is 0.5"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#why-study-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#why-study-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Why Study Probability?",
    "text": "Why Study Probability?\nProbability helps us:\n\nMake decisions under uncertainty\nUnderstand random processes\nAnalyze data and draw conclusions\nModel real-world phenomena\nAssess risk and likelihood\n\n\nApplications: Weather forecasting, medical diagnosis, finance, quality control, gaming, insurance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#random-experiments",
    "href": "files/lecture_notes/lecture4/lecture4.html#random-experiments",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Random Experiments",
    "text": "Random Experiments\nA random experiment is a process that:\n\nCan be repeated under similar conditions\nHas multiple possible outcomes\nThe outcome cannot be predicted with certainty\n\n\nExamples: - Flipping a coin - Rolling a die - Drawing a card from a deck - Measuring the lifetime of a light bulb"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sample-space",
    "href": "files/lecture_notes/lecture4/lecture4.html#sample-space",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space",
    "text": "Sample Space\nThe sample space (denoted \\(S\\) or \\(\\Omega\\)) is the set of all possible outcomes of a random experiment\n\nExamples:\n\nCoin flip: \\(S = \\{H, T\\}\\)\nDie roll: \\(S = \\{1, 2, 3, 4, 5, 6\\}\\)\nTwo coin flips: \\(S = \\{HH, HT, TH, TT\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#types-of-sample-spaces",
    "href": "files/lecture_notes/lecture4/lecture4.html#types-of-sample-spaces",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Types of Sample Spaces",
    "text": "Types of Sample Spaces\n\nFinite Sample Space\n\nLimited number of outcomes\n\n\nExample: Rolling a die\n\nInfinite Sample Space\n\nUnlimited outcomes (countable or uncountable)\n\n\nExample: Measuring exact height of students"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#events",
    "href": "files/lecture_notes/lecture4/lecture4.html#events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Events",
    "text": "Events\nAn event is a subset of the sample space\n\nSimple event: Contains exactly one outcome\nCompound event: Contains multiple outcomes\n\n\nExample (rolling a die): - Simple event: \\(A = \\{3\\}\\) (rolling a 3) - Compound event: \\(B = \\{2, 4, 6\\}\\) (rolling an even number)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#event-notation",
    "href": "files/lecture_notes/lecture4/lecture4.html#event-notation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Event Notation",
    "text": "Event Notation\nFor a die roll with \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (rolling an odd number)\n\\(B = \\{4, 5, 6\\}\\) (rolling 4 or higher)\n\\(C = \\{6\\}\\) (rolling a six)\n\n\nWe can describe events in words or using set notation"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#set-operations-with-events",
    "href": "files/lecture_notes/lecture4/lecture4.html#set-operations-with-events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Set Operations with Events",
    "text": "Set Operations with Events\nUnion (\\(A \\cup B\\)): Event that \\(A\\) OR \\(B\\) occurs\nIntersection (\\(A \\cap B\\)): Event that \\(A\\) AND \\(B\\) occurs\nComplement (\\(A^c\\) or \\(\\bar{A}\\)): Event that \\(A\\) does NOT occur"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#visual-representation-venn-diagrams",
    "href": "files/lecture_notes/lecture4/lecture4.html#visual-representation-venn-diagrams",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Visual Representation: Venn Diagrams",
    "text": "Visual Representation: Venn Diagrams\n\n\n\n\n\ngraph LR\n    subgraph S [\"Sample Space S\"]\n        subgraph A [\"Event A\"]\n            a1[\" \"]\n        end\n        subgraph B [\"Event B\"]\n            b1[\" \"]\n        end\n        s1[\" \"]\n        s2[\" \"]\n    end\n\n\n\n\n\n\nUnion, intersection, and complement can be visualized using Venn diagrams"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#example-set-operations",
    "href": "files/lecture_notes/lecture4/lecture4.html#example-set-operations",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example: Set Operations",
    "text": "Example: Set Operations\nFor die roll \\(S = \\{1, 2, 3, 4, 5, 6\\}\\): - \\(A = \\{1, 3, 5\\}\\) (odd numbers) - \\(B = \\{4, 5, 6\\}\\) (4 or higher)\n\nFind: - \\(A \\cup B = \\{1, 3, 4, 5, 6\\}\\) - \\(A \\cap B = \\{5\\}\\) - \\(A^c = \\{2, 4, 6\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-events",
    "href": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive Events",
    "text": "Mutually Exclusive Events\nEvents \\(A\\) and \\(B\\) are mutually exclusive (or disjoint) if they cannot occur simultaneously\n\\[A \\cap B = \\emptyset\\]\n\nExample: When rolling a die - \\(A = \\{1, 3, 5\\}\\) (odd) - \\(B = \\{2, 4, 6\\}\\) (even)\n\\(A\\) and \\(B\\) are mutually exclusive"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-classical-definition-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-classical-definition-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Classical Definition of Probability",
    "text": "The Classical Definition of Probability\nFor equally likely outcomes:\n\\[P(A) = \\frac{\\text{Number of outcomes in } A}{\\text{Total number of outcomes in } S}\\]\n\nExample: Probability of rolling an even number on a fair die\n\\[P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#properties-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#properties-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Properties of Probability",
    "text": "Properties of Probability\n\nNon-negativity: \\(P(A) \\geq 0\\) for any event \\(A\\)\nNormalization: \\(P(S) = 1\\)\nAdditivity: If \\(A\\) and \\(B\\) are mutually exclusive, then \\[P(A \\cup B) = P(A) + P(B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-complement-rule",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-complement-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Complement Rule",
    "text": "The Complement Rule\n\\[P(A^c) = 1 - P(A)\\]\n\nExample: If the probability of rain is 0.3, what’s the probability of no rain?\n\\[P(\\text{no rain}) = 1 - P(\\text{rain}) = 1 - 0.3 = 0.7\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-problem-1",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-problem-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\nA standard deck has 52 cards. What is the probability of drawing:\n\nA heart?\nA face card (Jack, Queen, King)?\nThe ace of spades?\n\n\nSolutions: a) \\(P(\\text{heart}) = \\frac{13}{52} = \\frac{1}{4}\\) b) \\(P(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\\) c) \\(P(\\text{ace of spades}) = \\frac{1}{52}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-addition-rule",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-addition-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Addition Rule",
    "text": "The Addition Rule\nFor any two events \\(A\\) and \\(B\\):\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\nWhy subtract \\(P(A \\cap B)\\)?\nWe don’t want to double-count outcomes that are in both events"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#addition-rule-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#addition-rule-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Addition Rule Example",
    "text": "Addition Rule Example\nDrawing from a standard deck: - \\(A\\): Drawing a heart (\\(P(A) = \\frac{13}{52}\\)) - \\(B\\): Drawing a face card (\\(P(B) = \\frac{12}{52}\\))\nWhat’s \\(P(A \\cup B)\\) (heart OR face card)?\n\n\\(P(A \\cap B) = \\frac{3}{52}\\) (face cards that are hearts)\n\\(P(A \\cup B) = \\frac{13}{52} + \\frac{12}{52} - \\frac{3}{52} = \\frac{22}{52} = \\frac{11}{26}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#conditional-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#conditional-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\nConditional probability is the probability of event \\(A\\) given that event \\(B\\) has occurred\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nprovided \\(P(B) &gt; 0\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#conditional-probability-interpretation",
    "href": "files/lecture_notes/lecture4/lecture4.html#conditional-probability-interpretation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Interpretation",
    "text": "Conditional Probability Interpretation\n\\(P(A|B)\\) means: - We know event \\(B\\) has occurred - What’s the probability that \\(A\\) also occurred? - We “restrict” our sample space to only outcomes in \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#conditional-probability-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#conditional-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Example",
    "text": "Conditional Probability Example\nDrawing a card from a standard deck: - \\(A\\): Card is a heart - \\(B\\): Card is red\nFind \\(P(A|B)\\)\n\n\\(P(A \\cap B) = P(\\text{heart}) = \\frac{13}{52}\\)\n\\(P(B) = P(\\text{red}) = \\frac{26}{52}\\)\n\\(P(A|B) = \\frac{13/52}{26/52} = \\frac{13}{26} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#independence",
    "href": "files/lecture_notes/lecture4/lecture4.html#independence",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence",
    "text": "Independence\nEvents \\(A\\) and \\(B\\) are independent if:\n\\[P(A|B) = P(A)\\]\nor equivalently:\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\n\nKnowing that \\(B\\) occurred doesn’t change the probability of \\(A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#independence-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#independence-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence Example",
    "text": "Independence Example\nTwo coin flips: - \\(A\\): First flip is heads - \\(B\\): Second flip is heads\nAre \\(A\\) and \\(B\\) independent?\n\n\\(P(A) = \\frac{1}{2}\\), \\(P(B) = \\frac{1}{2}\\)\n\\(P(A \\cap B) = P(\\text{HH}) = \\frac{1}{4}\\)\n\\(P(A) \\times P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\)\nYes, they are independent!"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#multiplication-rule",
    "href": "files/lecture_notes/lecture4/lecture4.html#multiplication-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Multiplication Rule",
    "text": "Multiplication Rule\nGeneral case: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nIndependent events: \\(P(A \\cap B) = P(A) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-problem-2",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-problem-2",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement.\n\nWhat’s the probability both balls are red?\nWhat’s the probability the first is red and second is blue?\n\n\n\n\\(P(\\text{both red}) = \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)\n\\(P(\\text{red then blue}) = \\frac{5}{8} \\times \\frac{3}{7} = \\frac{15}{56}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#law-of-total-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#law-of-total-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space, then:\n\\[P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \\cdots + P(A|B_n)P(B_n)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#law-of-total-probability-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\nA factory has two machines: - Machine 1: Produces 60% of items, 5% defective - Machine 2: Produces 40% of items, 3% defective\nWhat’s the overall probability an item is defective?\n\n\\(P(\\text{defective}) = P(D|M_1)P(M_1) + P(D|M_2)P(M_2)\\)\n\\(= 0.05 \\times 0.6 + 0.03 \\times 0.4 = 0.03 + 0.012 = 0.042\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem",
    "href": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes’ Theorem",
    "text": "Bayes’ Theorem\n\\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\nThis allows us to “reverse” conditional probabilities\n\nNamed after Thomas Bayes (1701-1761)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-components",
    "href": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-components",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes’ Theorem Components",
    "text": "Bayes’ Theorem Components\n\n\\(P(A|B)\\): Posterior probability - what we want to find\n\\(P(B|A)\\): Likelihood - given \\(A\\), probability of observing \\(B\\)\n\\(P(A)\\): Prior probability - initial probability of \\(A\\)\n\\(P(B)\\): Marginal probability - total probability of \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes’ Theorem Example",
    "text": "Bayes’ Theorem Example\nMedical test for a disease: - Disease affects 1% of population - Test is 95% accurate for sick people - Test is 90% accurate for healthy people\nIf someone tests positive, what’s the probability they have the disease?"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-solution",
    "href": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-solution",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes’ Theorem Solution",
    "text": "Bayes’ Theorem Solution\nLet: - \\(D\\): Person has disease - \\(T^+\\): Test is positive\nGiven: - \\(P(D) = 0.01\\) - \\(P(T^+|D) = 0.95\\) - \\(P(T^-|D^c) = 0.90\\), so \\(P(T^+|D^c) = 0.10\\)\n\n\\(P(T^+) = P(T^+|D)P(D) + P(T^+|D^c)P(D^c)\\) \\(= 0.95 \\times 0.01 + 0.10 \\times 0.99 = 0.1085\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-solution-cont.",
    "href": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-solution-cont.",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes’ Theorem Solution (cont.)",
    "text": "Bayes’ Theorem Solution (cont.)\n\\[P(D|T^+) = \\frac{P(T^+|D) \\times P(D)}{P(T^+)} = \\frac{0.95 \\times 0.01}{0.1085} \\approx 0.088\\]\n\nSurprising result: Even with a positive test, there’s only an 8.8% chance of having the disease!\nThis is due to the low base rate of the disease"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#common-probability-mistakes",
    "href": "files/lecture_notes/lecture4/lecture4.html#common-probability-mistakes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nConfusing \\(P(A|B)\\) with \\(P(B|A)\\)\n\nProsecutor’s fallacy\n\nAssuming independence when events are dependent\nIgnoring base rates (as in the medical test example)\nDouble counting in union calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#tree-diagrams",
    "href": "files/lecture_notes/lecture4/lecture4.html#tree-diagrams",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\nTree diagrams help visualize sequential events and calculate probabilities\n                    0.6   Red\n            0.7 ──┐\n                    0.4   Blue\n    \n                    0.3   Red  \n            0.3 ──┐\n                    0.7   Blue\nExample: Drawing from different urns"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-problem-3",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-problem-3",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\nTwo fair dice are rolled. Find:\n\n\\(P(\\text{sum} = 7)\\)\n\\(P(\\text{sum} = 7 | \\text{first die shows 3})\\)\nAre these events independent?\n\n\n\n6 ways out of 36: \\(P(\\text{sum} = 7) = \\frac{6}{36} = \\frac{1}{6}\\)\nGiven first die is 3, need second die to be 4: \\(P(\\text{sum} = 7 | \\text{first} = 3) = \\frac{1}{6}\\)\nYes, they’re independent since \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#counting-and-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#counting-and-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Counting and Probability",
    "text": "Counting and Probability\nSometimes we need to count outcomes:\nMultiplication Principle: If task 1 can be done in \\(m\\) ways and task 2 in \\(n\\) ways, both can be done in \\(m \\times n\\) ways\nPermutations: Arrangements where order matters \\[P(n,r) = \\frac{n!}{(n-r)!}\\]\nCombinations: Selections where order doesn’t matter \\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#counting-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#counting-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Counting Example",
    "text": "Counting Example\nHow many ways can you arrange 5 people in a row?\n\nThis is a permutation: \\(P(5,5) = 5! = 120\\) ways\n\n\nHow many ways can you choose 3 people from 5 for a committee?\nThis is a combination: \\(C(5,3) = \\binom{5}{3} = \\frac{5!}{3!2!} = 10\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-with-counting",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-with-counting",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability with Counting",
    "text": "Probability with Counting\nExample: A committee of 3 people is chosen from 8 people (5 women, 3 men). What’s the probability all 3 are women?\n\nTotal ways to choose 3 from 8: \\(\\binom{8}{3} = 56\\)\nWays to choose 3 women from 5: \\(\\binom{5}{3} = 10\\)\nProbability: \\(\\frac{10}{56} = \\frac{5}{28}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-distributions-preview",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-distributions-preview",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Distributions Preview",
    "text": "Probability Distributions Preview\nA probability distribution assigns probabilities to all possible outcomes\nFor discrete random variables: - Probability mass function (PMF) - Cumulative distribution function (CDF)\nWe’ll explore this more in future lectures"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#common-discrete-distributions",
    "href": "files/lecture_notes/lecture4/lecture4.html#common-discrete-distributions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Discrete Distributions",
    "text": "Common Discrete Distributions\nUniform Distribution: All outcomes equally likely\nBinomial Distribution: Number of successes in fixed trials\nGeometric Distribution: Number of trials until first success\nExamples and details coming in later lectures"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#real-world-applications",
    "href": "files/lecture_notes/lecture4/lecture4.html#real-world-applications",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Diagnosis: Using Bayes’ theorem for test interpretation\nQuality Control: Probability of defective items\nFinance: Risk assessment and portfolio theory\nSports: Probability of wins, fantasy sports\nInsurance: Calculating premiums based on risk"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture4/lecture4.html#key-formulas-summary",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\nBasic probability: \\(P(A) = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\\)\nComplement: \\(P(A^c) = 1 - P(A)\\)\nAddition: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nConditional: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nIndependence: \\(P(A \\cap B) = P(A) \\times P(B)\\)\nBayes’: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture4/lecture4.html#problem-solving-strategy",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\nIdentify the sample space and events\nDetermine if events are independent or mutually exclusive\nChoose the appropriate rule or formula\nCalculate step by step\nCheck if your answer makes sense"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-problem-4",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-problem-4",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\nA bag contains 4 red, 3 blue, and 2 green marbles. Three marbles are drawn without replacement.\nFind the probability that: a) All three are red b) No two are the same color c) At least one is blue"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-problem-4-solutions",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-problem-4-solutions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 4 Solutions",
    "text": "Practice Problem 4 Solutions\n\nAll red: \\(\\frac{4}{9} \\times \\frac{3}{8} \\times \\frac{2}{7} = \\frac{24}{504} = \\frac{1}{21}\\)\nDifferent colors: \\(\\frac{4 \\times 3 \\times 2}{9 \\times 8 \\times 7} \\times 3! = \\frac{24 \\times 6}{504} = \\frac{144}{504} = \\frac{2}{7}\\)\nAt least one blue: \\(1 - P(\\text{no blue}) = 1 - \\frac{6 \\times 5 \\times 4}{9 \\times 8 \\times 7} = 1 - \\frac{120}{504} = \\frac{384}{504} = \\frac{16}{21}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#common-student-questions",
    "href": "files/lecture_notes/lecture4/lecture4.html#common-student-questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: “Why isn’t \\(P(A \\cup B) = P(A) + P(B)\\) always?” A: We’d double-count outcomes in both events\nQ: “How do I know if events are independent?” A: Check if \\(P(A|B) = P(A)\\) or if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nQ: “When do I use Bayes’ theorem?” A: When you want to “reverse” a conditional probability"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#looking-ahead",
    "href": "files/lecture_notes/lecture4/lecture4.html#looking-ahead",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture: Random Variables and Probability Distributions - Discrete vs. continuous random variables - Expected value and variance - Binomial and normal distributions\nHomework: Problems on basic probability, conditional probability, and independence"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#final-thoughts",
    "href": "files/lecture_notes/lecture4/lecture4.html#final-thoughts",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nProbability is the foundation of statistics: - Helps us quantify uncertainty - Provides tools for making decisions with incomplete information - Essential for understanding statistical inference\n\nPractice: The key to mastering probability is working through many problems!"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#questions",
    "href": "files/lecture_notes/lecture4/lecture4.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: [Your office hours] Email: [Your email] Next Class: Random Variables and Distributions\nRemember: Homework due [date]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bonus-probability-paradoxes",
    "href": "files/lecture_notes/lecture4/lecture4.html#bonus-probability-paradoxes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bonus: Probability Paradoxes",
    "text": "Bonus: Probability Paradoxes\nMonty Hall Problem: Should you switch doors?\nBirthday Paradox: How many people needed for 50% chance of shared birthday?\nSimpson’s Paradox: When aggregate data reverses subgroup trends\nExplore these to deepen your probability intuition!"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#welcome-to-lecture-5",
    "href": "files/lecture_notes/lecture5/lecture5.html#welcome-to-lecture-5",
    "title": "PSTAT 5A: Counting",
    "section": "Welcome to Lecture 5",
    "text": "Welcome to Lecture 5\nCounting\nThe art and science of systematic enumeration"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture5/lecture5.html#todays-learning-objectives",
    "title": "PSTAT 5A: Counting",
    "section": "Today’s Learning Objectives",
    "text": "Today’s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nApply the fundamental counting principles\nCalculate permutations with and without repetition\nCalculate combinations and understand when to use them\nDistinguish between permutations and combinations\nUse counting techniques to solve probability problems\nApply the inclusion-exclusion principle\nSolve complex counting problems systematically"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#why-study-counting",
    "href": "files/lecture_notes/lecture5/lecture5.html#why-study-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Why Study Counting?",
    "text": "Why Study Counting?\nCounting helps us:\n\nCalculate probabilities for complex events\nSolve optimization problems\nUnderstand combinations in genetics, computer science\nAnalyze algorithms and data structures\nMake decisions involving arrangements and selections\n\n\nApplications: Cryptography, genetics, tournament brackets, lottery odds, password security"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#the-fundamental-counting-principle",
    "href": "files/lecture_notes/lecture5/lecture5.html#the-fundamental-counting-principle",
    "title": "PSTAT 5A: Counting",
    "section": "The Fundamental Counting Principle",
    "text": "The Fundamental Counting Principle\nMultiplication Rule: If a procedure consists of \\(k\\) separate tasks where: - Task 1 can be performed in \\(n_1\\) ways - Task 2 can be performed in \\(n_2\\) ways - … - Task \\(k\\) can be performed in \\(n_k\\) ways\nThen the entire procedure can be performed in \\(n_1 \\times n_2 \\times \\cdots \\times n_k\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#simple-counting-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#simple-counting-example",
    "title": "PSTAT 5A: Counting",
    "section": "Simple Counting Example",
    "text": "Simple Counting Example\nLicense Plates: Format ABC-123 - First position: 26 letters - Second position: 26 letters\n- Third position: 26 letters - Fourth position: 10 digits - Fifth position: 10 digits - Sixth position: 10 digits\n\nTotal possibilities: \\(26 \\times 26 \\times 26 \\times 10 \\times 10 \\times 10 = 26^3 \\times 10^3 = 17,576,000\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#restaurant-menu-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#restaurant-menu-example",
    "title": "PSTAT 5A: Counting",
    "section": "Restaurant Menu Example",
    "text": "Restaurant Menu Example\nA restaurant offers: - 4 appetizers - 6 main courses\n- 3 desserts\nHow many different three-course meals are possible?\n\nSolution: \\(4 \\times 6 \\times 3 = 72\\) different meals"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-1",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-1",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\nA password must contain: - Exactly 8 characters - Each character is either a letter (26 possibilities) or digit (10 possibilities)\nHow many possible passwords are there?\n\nSolution: Each position has \\(26 + 10 = 36\\) choices\nTotal: \\(36^8 = 2,821,109,907,456\\) passwords"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#what-are-permutations",
    "href": "files/lecture_notes/lecture5/lecture5.html#what-are-permutations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Permutations?",
    "text": "What Are Permutations?\nPermutation: An arrangement of objects where order matters\n\nExamples where order matters: - Race finish positions (1st, 2nd, 3rd) - Seating arrangements - Passwords - DNA sequences"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#permutations-of-n-distinct-objects",
    "href": "files/lecture_notes/lecture5/lecture5.html#permutations-of-n-distinct-objects",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(n\\) Distinct Objects",
    "text": "Permutations of \\(n\\) Distinct Objects\nThe number of ways to arrange \\(n\\) distinct objects is:\n\\[n! = n \\times (n-1) \\times (n-2) \\times \\cdots \\times 2 \\times 1\\]\n\nExample: How many ways can 5 people sit in a row?\n\\(5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#factorial-values",
    "href": "files/lecture_notes/lecture5/lecture5.html#factorial-values",
    "title": "PSTAT 5A: Counting",
    "section": "Factorial Values",
    "text": "Factorial Values\n\n\n\n\\(n\\)\n\\(n!\\)\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n2\n2\n\n\n3\n6\n\n\n4\n24\n\n\n5\n120\n\n\n10\n3,628,800\n\n\n\n\nNote: \\(0! = 1\\) by definition"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#permutations-of-r-objects-from-n",
    "href": "files/lecture_notes/lecture5/lecture5.html#permutations-of-r-objects-from-n",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(r\\) Objects from \\(n\\)",
    "text": "Permutations of \\(r\\) Objects from \\(n\\)\n\\(P(n,r)\\) or \\(_nP_r\\): Number of ways to arrange \\(r\\) objects selected from \\(n\\) distinct objects\n\\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\nExample: How many ways can we select and arrange 3 people from a group of 8 for president, vice-president, and secretary?\n\\(P(8,3) = \\frac{8!}{(8-3)!} = \\frac{8!}{5!} = 8 \\times 7 \\times 6 = 336\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#understanding-pnr",
    "href": "files/lecture_notes/lecture5/lecture5.html#understanding-pnr",
    "title": "PSTAT 5A: Counting",
    "section": "Understanding \\(P(n,r)\\)",
    "text": "Understanding \\(P(n,r)\\)\nWhy is \\(P(n,r) = \\frac{n!}{(n-r)!}\\)?\n\nFirst position: \\(n\\) choices\nSecond position: \\((n-1)\\) choices\n\nThird position: \\((n-2)\\) choices\n…\n\\(r\\)-th position: \\((n-r+1)\\) choices\n\n\nTotal: \\(n \\times (n-1) \\times (n-2) \\times \\cdots \\times (n-r+1) = \\frac{n!}{(n-r)!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-2",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-2",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\nA baseball team has 15 players. How many ways can the coach:\n\nArrange all 15 players in a line?\nChoose and arrange 9 players for the starting lineup (batting order matters)?\n\n\nSolutions: a) \\(15! = 1,307,674,368,000\\) b) \\(P(15,9) = \\frac{15!}{6!} = 1,816,214,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#permutations-with-repetition",
    "href": "files/lecture_notes/lecture5/lecture5.html#permutations-with-repetition",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition",
    "text": "Permutations with Repetition\nWhen some objects are identical, we have fewer distinct arrangements\nIf we have \\(n\\) objects where: - \\(n_1\\) are of type 1 - \\(n_2\\) are of type 2\n- … - \\(n_k\\) are of type \\(k\\)\nNumber of distinct arrangements: \\(\\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#permutations-with-repetition-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#permutations-with-repetition-example",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition Example",
    "text": "Permutations with Repetition Example\nHow many distinct arrangements are there of the letters in “STATISTICS”?\nS-T-A-T-I-S-T-I-C-S - Total letters: 10 - S appears 3 times - T appears 3 times\n- A appears 1 time - I appears 2 times - C appears 1 time\n\n\\(\\frac{10!}{3! \\times 3! \\times 1! \\times 2! \\times 1!} = \\frac{3,628,800}{6 \\times 6 \\times 1 \\times 2 \\times 1} = \\frac{3,628,800}{72} = 50,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#what-are-combinations",
    "href": "files/lecture_notes/lecture5/lecture5.html#what-are-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Combinations?",
    "text": "What Are Combinations?\nCombination: A selection of objects where order does NOT matter\n\nExamples where order doesn’t matter: - Choosing committee members - Selecting pizza toppings - Forming study groups - Lottery number selection"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#combinations-formula",
    "href": "files/lecture_notes/lecture5/lecture5.html#combinations-formula",
    "title": "PSTAT 5A: Counting",
    "section": "Combinations Formula",
    "text": "Combinations Formula\n\\(C(n,r)\\) or \\(\\binom{n}{r}\\): Number of ways to choose \\(r\\) objects from \\(n\\) distinct objects (order doesn’t matter)\n\\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]\n\nExample: How many ways can we choose 3 people from a group of 8 for a committee?\n\\(C(8,3) = \\frac{8!}{3!(8-3)!} = \\frac{8!}{3! \\times 5!} = \\frac{8 \\times 7 \\times 6}{3 \\times 2 \\times 1} = 56\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#relationship-permutations-vs-combinations",
    "href": "files/lecture_notes/lecture5/lecture5.html#relationship-permutations-vs-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "Relationship: Permutations vs Combinations",
    "text": "Relationship: Permutations vs Combinations\n\\[P(n,r) = C(n,r) \\times r!\\]\nWhy? For each combination of \\(r\\) objects, there are \\(r!\\) ways to arrange them\n\nExample: \\(P(8,3) = C(8,3) \\times 3! = 56 \\times 6 = 336\\) ✓"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#key-decision-permutation-or-combination",
    "href": "files/lecture_notes/lecture5/lecture5.html#key-decision-permutation-or-combination",
    "title": "PSTAT 5A: Counting",
    "section": "Key Decision: Permutation or Combination?",
    "text": "Key Decision: Permutation or Combination?\nAsk yourself: Does order matter?\nOrder matters → Use Permutations - Arrangements, sequences, rankings\nOrder doesn’t matter → Use Combinations\n- Selections, groups, subsets"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-3",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-3",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\nFrom a class of 20 students:\n\nHow many ways to choose 5 students for a study group?\nHow many ways to choose a president, vice-president, and secretary?\nHow many ways to arrange all 20 students in a circle?\n\n\nSolutions: a) \\(C(20,5) = \\frac{20!}{5! \\times 15!} = 15,504\\) (order doesn’t matter) b) \\(P(20,3) = \\frac{20!}{17!} = 6,840\\) (order matters) c) \\((20-1)! = 19!\\) (circular permutation)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#properties-of-combinations",
    "href": "files/lecture_notes/lecture5/lecture5.html#properties-of-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "Properties of Combinations",
    "text": "Properties of Combinations\n\nSymmetry: \\(\\binom{n}{r} = \\binom{n}{n-r}\\)\nPascal’s Identity: \\(\\binom{n}{r} = \\binom{n-1}{r-1} + \\binom{n-1}{r}\\)\nBoundary conditions: \\(\\binom{n}{0} = \\binom{n}{n} = 1\\)\n\n\nExample: \\(\\binom{8}{3} = \\binom{8}{5} = 56\\) ✓"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#pascals-triangle",
    "href": "files/lecture_notes/lecture5/lecture5.html#pascals-triangle",
    "title": "PSTAT 5A: Counting",
    "section": "Pascal’s Triangle",
    "text": "Pascal’s Triangle\n           1\n         1   1\n       1   2   1\n     1   3   3   1\n   1   4   6   4   1\n 1   5  10  10   5   1\n1   6  15  20  15   6   1\nEach number is \\(\\binom{n}{r}\\) where \\(n\\) is the row and \\(r\\) is the position"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#binomial-theorem",
    "href": "files/lecture_notes/lecture5/lecture5.html#binomial-theorem",
    "title": "PSTAT 5A: Counting",
    "section": "Binomial Theorem",
    "text": "Binomial Theorem\n\\[(x + y)^n = \\sum_{r=0}^{n} \\binom{n}{r} x^{n-r} y^r\\]\n\nExample: \\((x + y)^3 = \\binom{3}{0}x^3 + \\binom{3}{1}x^2y + \\binom{3}{2}xy^2 + \\binom{3}{3}y^3\\)\n\\(= x^3 + 3x^2y + 3xy^2 + y^3\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#counting-and-probability",
    "href": "files/lecture_notes/lecture5/lecture5.html#counting-and-probability",
    "title": "PSTAT 5A: Counting",
    "section": "Counting and Probability",
    "text": "Counting and Probability\nExample: A committee of 4 people is chosen from 7 women and 5 men. What’s the probability that exactly 2 are women?\nTotal ways to choose 4 from 12: \\(\\binom{12}{4} = 495\\)\nWays to choose 2 women from 7: \\(\\binom{7}{2} = 21\\) Ways to choose 2 men from 5: \\(\\binom{5}{2} = 10\\)\n\nFavorable outcomes: \\(\\binom{7}{2} \\times \\binom{5}{2} = 21 \\times 10 = 210\\)\nProbability: \\(\\frac{210}{495} = \\frac{14}{33}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-4",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-4",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\nA standard deck has 52 cards. What’s the probability that a 5-card hand contains:\n\nExactly 3 aces?\nAt least 1 ace?\n\n\n\nWays to get 3 aces from 4: \\(\\binom{4}{3} = 4\\) Ways to get 2 non-aces from 48: \\(\\binom{48}{2} = 1,128\\) Total 5-card hands: \\(\\binom{52}{5} = 2,598,960\\)\nProbability: \\(\\frac{4 \\times 1,128}{2,598,960} = \\frac{4,512}{2,598,960} \\approx 0.00174\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-4-continued",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-4-continued",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 4 (continued)",
    "text": "Practice Problem 4 (continued)\n\nAt least 1 ace = 1 - (no aces)\n\nWays to choose 5 cards with no aces: \\(\\binom{48}{5} = 1,712,304\\)\n\n\\(P(\\text{at least 1 ace}) = 1 - \\frac{\\binom{48}{5}}{\\binom{52}{5}} = 1 - \\frac{1,712,304}{2,598,960} \\approx 0.341\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#circular-permutations",
    "href": "files/lecture_notes/lecture5/lecture5.html#circular-permutations",
    "title": "PSTAT 5A: Counting",
    "section": "Circular Permutations",
    "text": "Circular Permutations\nWhen arranging objects in a circle, we fix one object to eliminate rotational symmetry\nNumber of circular permutations of \\(n\\) objects: \\((n-1)!\\)\n\nExample: How many ways can 6 people sit around a circular table?\n\\((6-1)! = 5! = 120\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#permutations-with-restrictions",
    "href": "files/lecture_notes/lecture5/lecture5.html#permutations-with-restrictions",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Restrictions",
    "text": "Permutations with Restrictions\nExample: How many 6-letter “words” can be formed from the letters A, B, C, D, E, F if: - No letter is repeated - A and B must be adjacent\n\nSolution: Treat AB as a single unit - 5 units to arrange: (AB), C, D, E, F → \\(5! = 120\\) ways - A and B can be arranged within their unit: \\(2! = 2\\) ways - Total: \\(5! \\times 2! = 240\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#the-inclusion-exclusion-principle",
    "href": "files/lecture_notes/lecture5/lecture5.html#the-inclusion-exclusion-principle",
    "title": "PSTAT 5A: Counting",
    "section": "The Inclusion-Exclusion Principle",
    "text": "The Inclusion-Exclusion Principle\nFor two sets \\(A\\) and \\(B\\): \\[|A \\cup B| = |A| + |B| - |A \\cap B|\\]\nFor three sets \\(A\\), \\(B\\), and \\(C\\): \\[|A \\cup B \\cup C| = |A| + |B| + |C| - |A \\cap B| - |A \\cap C| - |B \\cap C| + |A \\cap B \\cap C|\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#inclusion-exclusion-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#inclusion-exclusion-example",
    "title": "PSTAT 5A: Counting",
    "section": "Inclusion-Exclusion Example",
    "text": "Inclusion-Exclusion Example\nHow many integers from 1 to 100 are divisible by 2, 3, or 5?\nLet: - \\(A\\) = divisible by 2: \\(|A| = 50\\) - \\(B\\) = divisible by 3: \\(|B| = 33\\)\n- \\(C\\) = divisible by 5: \\(|C| = 20\\)\n\n\\(|A \\cap B| = 16\\) (divisible by 6) \\(|A \\cap C| = 10\\) (divisible by 10) \\(|B \\cap C| = 6\\) (divisible by 15) \\(|A \\cap B \\cap C| = 3\\) (divisible by 30)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#inclusion-exclusion-solution",
    "href": "files/lecture_notes/lecture5/lecture5.html#inclusion-exclusion-solution",
    "title": "PSTAT 5A: Counting",
    "section": "Inclusion-Exclusion Solution",
    "text": "Inclusion-Exclusion Solution\n\\[|A \\cup B \\cup C| = 50 + 33 + 20 - 16 - 10 - 6 + 3 = 74\\]\n\nAnswer: 74 integers from 1 to 100 are divisible by at least one of 2, 3, or 5"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#derangements",
    "href": "files/lecture_notes/lecture5/lecture5.html#derangements",
    "title": "PSTAT 5A: Counting",
    "section": "Derangements",
    "text": "Derangements\nA derangement is a permutation where no object appears in its original position\nNumber of derangements of \\(n\\) objects: \\[D_n = n! \\sum_{k=0}^{n} \\frac{(-1)^k}{k!} \\approx \\frac{n!}{e}\\]\n\nExample: How many ways can 4 people return hats to the wrong owners?\n\\(D_4 = 4! \\left(\\frac{1}{0!} - \\frac{1}{1!} + \\frac{1}{2!} - \\frac{1}{3!} + \\frac{1}{4!}\\right) = 24 \\times \\frac{9}{24} = 9\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#multinomial-coefficients",
    "href": "files/lecture_notes/lecture5/lecture5.html#multinomial-coefficients",
    "title": "PSTAT 5A: Counting",
    "section": "Multinomial Coefficients",
    "text": "Multinomial Coefficients\nNumber of ways to divide \\(n\\) objects into groups of sizes \\(n_1, n_2, \\ldots, n_k\\):\n\\[\\binom{n}{n_1, n_2, \\ldots, n_k} = \\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\]\n\nExample: How many ways can 12 people be divided into 3 teams of 4?\n\\(\\binom{12}{4,4,4} = \\frac{12!}{4! \\times 4! \\times 4!} = 34,650\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#stars-and-bars",
    "href": "files/lecture_notes/lecture5/lecture5.html#stars-and-bars",
    "title": "PSTAT 5A: Counting",
    "section": "Stars and Bars",
    "text": "Stars and Bars\nProblem: Number of ways to distribute \\(n\\) identical objects into \\(k\\) distinct bins\nSolution: \\(\\binom{n+k-1}{k-1}\\) or \\(\\binom{n+k-1}{n}\\)\n\nExample: How many ways can you distribute 10 identical candies to 4 children?\n\\(\\binom{10+4-1}{4-1} = \\binom{13}{3} = 286\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-5",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-5",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 5",
    "text": "Practice Problem 5\nA pizza shop offers 12 toppings. How many different pizzas can you order if:\n\nYou want exactly 4 toppings?\nYou want at most 3 toppings?\nYou want at least 1 topping?\n\n\nSolutions: a) \\(\\binom{12}{4} = 495\\) b) \\(\\binom{12}{0} + \\binom{12}{1} + \\binom{12}{2} + \\binom{12}{3} = 1 + 12 + 66 + 220 = 299\\) c) \\(2^{12} - 1 = 4,095\\) (all subsets except empty set)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#advanced-counting-stirling-numbers",
    "href": "files/lecture_notes/lecture5/lecture5.html#advanced-counting-stirling-numbers",
    "title": "PSTAT 5A: Counting",
    "section": "Advanced Counting: Stirling Numbers",
    "text": "Advanced Counting: Stirling Numbers\nStirling numbers of the second kind \\(S(n,k)\\): Number of ways to partition \\(n\\) objects into \\(k\\) non-empty subsets\nBell numbers \\(B_n\\): Total number of ways to partition \\(n\\) objects \\[B_n = \\sum_{k=0}^{n} S(n,k)\\]\nThese are advanced topics for further study"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture5/lecture5.html#problem-solving-strategy",
    "title": "PSTAT 5A: Counting",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\nRead carefully: What exactly are we counting?\nIdentify the type: Permutation, combination, or other?\nCheck for restrictions: Are there constraints?\nDoes order matter?: This determines permutation vs combination\nBreak down complex problems: Use multiplication principle\nVerify your answer: Does it make sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-mistakes-to-avoid",
    "title": "PSTAT 5A: Counting",
    "section": "Common Mistakes to Avoid",
    "text": "Common Mistakes to Avoid\n\nConfusing permutations and combinations\n\nAlways ask: “Does order matter?”\n\nForgetting about restrictions\n\nRead the problem carefully\n\nDouble counting\n\nMake sure you’re not counting the same arrangement twice\n\nNot considering the complement\n\nSometimes “at least” problems are easier using complements"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-6",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-6",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\nA class has 15 students: 8 women and 7 men. How many ways can we:\n\nForm a committee of 5 people with exactly 3 women?\nArrange 6 people in a row with alternating genders (starting with a woman)?\n\n\nSolutions: a) \\(\\binom{8}{3} \\times \\binom{7}{2} = 56 \\times 21 = 1,176\\) b) Choose 3 women from 8: \\(P(8,3) = 336\\) Choose 3 men from 7: \\(P(7,3) = 210\\) Total: \\(336 \\times 210 = 70,560\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#counting-in-computer-science",
    "href": "files/lecture_notes/lecture5/lecture5.html#counting-in-computer-science",
    "title": "PSTAT 5A: Counting",
    "section": "Counting in Computer Science",
    "text": "Counting in Computer Science\nPassword Security: - 8-character password with letters, digits, symbols - \\((26 + 26 + 10 + 32)^8 = 94^8 \\approx 6.1 \\times 10^{15}\\)\nHash Functions: - Distributing data into buckets - Collision probability calculations\nAlgorithm Analysis: - Counting operations, comparisons - Big O notation foundations"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#counting-in-genetics",
    "href": "files/lecture_notes/lecture5/lecture5.html#counting-in-genetics",
    "title": "PSTAT 5A: Counting",
    "section": "Counting in Genetics",
    "text": "Counting in Genetics\nDNA Sequences: - 4 bases (A, T, G, C) - Gene of length \\(n\\): \\(4^n\\) possible sequences\nProtein Folding: - Number of possible conformations - Combinatorial explosion\nPopulation Genetics: - Hardy-Weinberg calculations - Allele combinations"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#real-world-applications",
    "href": "files/lecture_notes/lecture5/lecture5.html#real-world-applications",
    "title": "PSTAT 5A: Counting",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nLottery: - Powerball: Choose 5 from 69, then 1 from 26 - Odds: \\(\\frac{1}{\\binom{69}{5} \\times 26} \\approx \\frac{1}{292,000,000}\\)\nCryptography: - Key space size determines security - RSA encryption relies on large number factorization\nSports Tournaments: - March Madness bracket: \\(2^{63}\\) possible outcomes - Round-robin tournaments: \\(\\binom{n}{2}\\) games"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture5/lecture5.html#key-formulas-summary",
    "title": "PSTAT 5A: Counting",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\nPermutations: \\(P(n,r) = \\frac{n!}{(n-r)!}\\)\nCombinations: \\(C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\)\nWith repetition: \\(\\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\)\nCircular: \\((n-1)!\\)\nInclusion-Exclusion: \\(|A \\cup B| = |A| + |B| - |A \\cap B|\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#technology-and-counting",
    "href": "files/lecture_notes/lecture5/lecture5.html#technology-and-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Technology and Counting",
    "text": "Technology and Counting\nCalculators: - Use nPr and nCr functions - Be careful with large numbers\nSoftware: - R: factorial(), choose(), combn() - Python: math.factorial(), math.comb() - Excel: FACT(), COMBIN(), PERMUT()\nOnline Tools: - Wolfram Alpha for complex calculations - Combination/permutation calculators"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-7",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-7",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\nA standard deck of cards is shuffled. What’s the probability that:\n\nThe top 4 cards are all hearts?\nIn a 13-card hand, you get exactly one card from each rank?\n\n\nSolutions: a) \\(\\frac{13}{52} \\times \\frac{12}{51} \\times \\frac{11}{50} \\times \\frac{10}{49} = \\frac{13 \\times 12 \\times 11 \\times 10}{52 \\times 51 \\times 50 \\times 49} \\approx 0.0026\\)\n\nChoose 1 card from each of 13 ranks: \\(4^{13}\\) Total 13-card hands: \\(\\binom{52}{13}\\) Probability: \\(\\frac{4^{13}}{\\binom{52}{13}} \\approx 6.3 \\times 10^{-6}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#extending-to-probability",
    "href": "files/lecture_notes/lecture5/lecture5.html#extending-to-probability",
    "title": "PSTAT 5A: Counting",
    "section": "Extending to Probability",
    "text": "Extending to Probability\nHypergeometric Distribution: - Drawing without replacement - Uses combinations: \\(P(X = k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}\\)\nBinomial Distribution: - Drawing with replacement\n- Uses combinations: \\(P(X = k) = \\binom{n}{k}p^k(1-p)^{n-k}\\)\nWe’ll explore these distributions in detail in future lectures"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#historical-note",
    "href": "files/lecture_notes/lecture5/lecture5.html#historical-note",
    "title": "PSTAT 5A: Counting",
    "section": "Historical Note",
    "text": "Historical Note\nBlaise Pascal (1623-1662) and Pierre de Fermat (1601-1665): - Founded probability theory through gambling problems - Pascal’s triangle and combinations\nLeonhard Euler (1707-1783): - Advanced combinatorics - Graph theory connections\nModern applications span computer science, biology, physics, and economics"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-student-questions",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-student-questions",
    "title": "PSTAT 5A: Counting",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: “When do I use permutations vs combinations?” A: Ask “Does order matter?” Order matters → permutation\nQ: “How do I handle restrictions?” A: Break the problem into cases or use complementary counting\nQ: “What if objects are identical?” A: Use the formula for permutations with repetition\nQ: “How do I check my answer?” A: Verify with small examples or use different methods"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#looking-ahead",
    "href": "files/lecture_notes/lecture5/lecture5.html#looking-ahead",
    "title": "PSTAT 5A: Counting",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture: Discrete Probability Distributions - Binomial distribution (using combinations!) - Hypergeometric distribution\n- Geometric distribution - Expected value and variance\nConnection: Today’s counting techniques are essential for probability calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#study-tips",
    "href": "files/lecture_notes/lecture5/lecture5.html#study-tips",
    "title": "PSTAT 5A: Counting",
    "section": "Study Tips",
    "text": "Study Tips\n\nPractice, practice, practice: Work through many examples\nIdentify patterns: Learn to recognize problem types\nStart simple: Build up to complex problems\nCheck your work: Use different approaches when possible\nUnderstand concepts: Don’t just memorize formulas"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#final-thoughts",
    "href": "files/lecture_notes/lecture5/lecture5.html#final-thoughts",
    "title": "PSTAT 5A: Counting",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nCounting is fundamental to: - Probability calculations - Statistical inference\n- Computer algorithms - Scientific modeling\n\nMaster the basics: Permutations and combinations are the building blocks for advanced statistical concepts"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#questions",
    "href": "files/lecture_notes/lecture5/lecture5.html#questions",
    "title": "PSTAT 5A: Counting",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: [Your office hours] Email: [Your email]\nNext Class: Discrete Probability Distributions\nRemember: Homework due [date]"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bonus-large-number-approximations",
    "href": "files/lecture_notes/lecture5/lecture5.html#bonus-large-number-approximations",
    "title": "PSTAT 5A: Counting",
    "section": "Bonus: Large Number Approximations",
    "text": "Bonus: Large Number Approximations\nStirling’s Approximation: \\(n! \\approx \\sqrt{2\\pi n} \\left(\\frac{n}{e}\\right)^n\\)\nNormal Approximation: For large \\(n\\), \\(\\binom{n}{k} \\approx \\frac{1}{\\sqrt{2\\pi n p(1-p)}} \\exp\\left(-\\frac{(k-np)^2}{2np(1-p)}\\right)\\)\nUseful for computational purposes when exact values are too large"
  },
  {
    "objectID": "files/worksheets/worksheet2.html",
    "href": "files/worksheets/worksheet2.html",
    "title": "PSTAT 5A Practice Worksheet",
    "section": "",
    "text": "⏰ Time Allocation: - Section A (Warm-up): 15 minutes\n\nSection B (Intermediate): 25 minutes\nSection C (Advanced): 20 minutes\nSection D (Variance Practice): 20 minutes\nTotal: 60 minutes\n\n\n\n📝 Important Instructions:\n\nShow all work clearly for full credit\nPartial credit awarded for correct methodology\nRound final answers to 4 decimal places unless otherwise specified\nIdentify your approach before calculating\nUse calculator and probability tables as needed\n\n\n\n📚 Key Formulas Reference:\nBasic Probability:\n\nConditional Probability: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nBayes’ Theorem: \\(P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\\)\nLaw of Total Probability: \\(P(A) = \\sum P(A|B_i) \\cdot P(B_i)\\)\n\nCounting:\n\nPermutations: \\(P(n,r) = \\frac{n!}{(n-r)!}\\)\nCombinations: \\(C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\)\n\nDiscrete Random Variables:\n\nBinomial PMF: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\)\nPoisson PMF: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\)\nExpected Value: \\(E[X] = \\sum x \\cdot P(X = x)\\)\nVariance: \\(\\text{Var}(X) = E[X^2] - (E[X])^2\\)\n\nVariance Formulas:\n\nPopulation Variance: \\(\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\)\nSample Variance: \\(s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\)\nVariance of Sample Mean: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\)\nStandard Error: \\(SE(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\\)"
  },
  {
    "objectID": "files/worksheets/worksheet2.html#understanding-variance-population-vs-sample",
    "href": "files/worksheets/worksheet2.html#understanding-variance-population-vs-sample",
    "title": "PSTAT 5A Practice Worksheet",
    "section": "5.1 Understanding Variance: Population vs Sample",
    "text": "5.1 Understanding Variance: Population vs Sample\n\n🎯 Key Variance Concepts:\nPopulation Variance (when you have ALL data): \\[\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\]\nSample Variance (when you have a sample): \\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\]\nWhy (n-1)? Using the sample mean to estimate deviations “uses up” one degree of freedom.\nVariance of Sample Mean: \\[\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\]\nStandard Error (Standard Deviation of Sample Mean): \\[SE(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\\]\n\n\nProblem D1: Basic Variance Calculations (6 points)\nThe following data represents the number of customer complaints per day for a small business over 8 days:\nData: 3, 7, 2, 8, 5, 6, 4, 9\nPart (a) [1 point]: Calculate the sample mean \\(\\bar{x}\\).\nPart (b) [2 points]: Calculate the sample variance \\(s^2\\) using the formula with \\((n-1)\\) in the denominator.\nPart (c) [1 point]: Calculate the sample standard deviation \\(s\\).\nPart (d) [1 point]: If this were treated as a complete population, what would the population variance \\(\\sigma^2\\) be?\nPart (e) [1 point]: Explain why we divide by \\((n-1)\\) for sample variance instead of \\(n\\).\nWork Space:\n\n\n\nProblem D2: Sample Mean Distribution (8 points)\nA factory produces bolts with a mean length of 5.0 cm and standard deviation of 0.2 cm. Quality control takes random samples to monitor production.\nPart (a) [1 point]: If a sample of 16 bolts is taken, what is the expected value of the sample mean \\(\\bar{X}\\)?\nPart (b) [1.5 points]: What is the variance of the sample mean \\(\\text{Var}(\\bar{X})\\)?\nPart (c) [1 point]: What is the standard error of the sample mean?\nPart (d) [1.5 points]: If the sample size is increased to 64 bolts, how does this change the standard error?\nPart (e) [1.5 points - Conceptual]: Explain why the variance of the sample mean decreases as sample size increases.\nPart (f) [1.5 points - Application]: What sample size would be needed to reduce the standard error to 0.025 cm?\nWork Space:\n\n\n\nProblem D3: Variance Properties with Random Variables (6 points)\nConsider two independent random variables: - \\(X \\sim \\text{Binomial}(20, 0.3)\\)\n- \\(Y \\sim \\text{Poisson}(4)\\)\nDefine \\(Z = 2X + 3Y - 5\\).\nPart (a) [2 points]: Find \\(E[X]\\), \\(\\text{Var}(X)\\), \\(E[Y]\\), and \\(\\text{Var}(Y)\\).\nPart (b) [1.5 points]: Calculate \\(E[Z]\\) using properties of expectation.\nPart (c) [2 points]: Calculate \\(\\text{Var}(Z)\\) using properties of variance.\nPart (d) [0.5 points]: What is the standard deviation of \\(Z\\)?\nWork Space:\n\n\n\nProblem D4: Real-World Variance Application (7 points)\nA pharmaceutical company tests the effectiveness of a new drug. They measure the reduction in symptoms (in points) for patients taking the drug. Historical data shows that symptom reduction follows a distribution with mean μ = 12 points and standard deviation σ = 4 points.\nPart (a) [1 point]: If they test the drug on a sample of 25 patients, what is the expected value of the average symptom reduction?\nPart (b) [1.5 points]: What is the standard error of the sample mean?\nPart (c) [1.5 points]: The company wants the standard error to be no more than 0.5 points. What minimum sample size is required?\nPart (d) [2 points - Practical Interpretation]: If the company observes a sample mean of 13.2 points from 25 patients, calculate how many standard errors this is above the expected value. Is this result likely due to random variation?\nPart (e) [1 point - Study Design]: The company is designing a larger study. If they want to detect a true difference of 1 point from the historical mean with a standard error of 0.3, what sample size should they use?\nWork Space:"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html",
    "href": "files/lecture_notes/lecture7/lecture7.html",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "",
    "text": "Discrete Random Variables\nFrom outcomes to numbers: quantifying randomness"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-7",
    "href": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-7",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "",
    "text": "Discrete Random Variables\nFrom outcomes to numbers: quantifying randomness"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Today’s Learning Objectives",
    "text": "Today’s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine random variables and distinguish discrete from continuous\nWork with probability mass functions (PMFs) and cumulative distribution functions (CDFs)\nCalculate expected values and variances for discrete random variables\nApply properties of expectation and variance\nWork with common discrete distributions (Bernoulli, Binomial, Geometric, Poisson)\nSolve real-world problems using discrete random variables\nUse technology to compute probabilities and parameters"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "href": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "What is a Random Variable?",
    "text": "What is a Random Variable?\nA random variable is a function that assigns a numerical value to each outcome of a random experiment\nNotation: Usually denoted by capital letters \\(X\\), \\(Y\\), \\(Z\\)\nKey insight: Random variables transform outcomes into numbers, making mathematical analysis possible\n\nExample: Rolling a die - Outcomes: \\(\\{1, 2, 3, 4, 5, 6\\}\\) - Random variable \\(X\\): the number shown - \\(X\\) can take values \\(\\{1, 2, 3, 4, 5, 6\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Why Use Random Variables?",
    "text": "Why Use Random Variables?\nRandom variables allow us to:\n\nQuantify outcomes numerically\nCalculate means, variances, and other statistics\nModel real-world phenomena mathematically\nMake predictions and decisions\nCompare different random processes\n\n\nExamples: Height, test scores, number of defects, wait times, stock prices"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Types of Random Variables",
    "text": "Types of Random Variables\nDiscrete Random Variable: - Takes on a countable number of values - Can list all possible values - Examples: dice rolls, number of emails, quiz scores\nContinuous Random Variable: - Takes on uncountably many values (intervals) - Cannot list all possible values\n- Examples: height, weight, time, temperature\n\nToday we focus on discrete random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#examples-of-discrete-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#examples-of-discrete-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Examples of Discrete Random Variables",
    "text": "Examples of Discrete Random Variables\n\\(X\\) = Number of heads in 3 coin flips - Possible values: \\(\\{0, 1, 2, 3\\}\\)\n\\(Y\\) = Number of customers in an hour - Possible values: \\(\\{0, 1, 2, 3, \\ldots\\}\\)\n\\(Z\\) = Score on a 10-question quiz - Possible values: \\(\\{0, 1, 2, \\ldots, 10\\}\\)\n\nNotice: All values are integers with gaps between them"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "href": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Probability Mass Function (PMF)",
    "text": "Probability Mass Function (PMF)\nThe probability mass function of a discrete random variable \\(X\\) is:\n\\[P(X = x) = \\text{probability that } X \\text{ takes the value } x\\]\nProperties of PMF: 1. \\(P(X = x) \\geq 0\\) for all \\(x\\) 2. \\(\\sum_{\\text{all } x} P(X = x) = 1\\)\n\nNotation: Sometimes written as \\(p(x)\\) or \\(f(x)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#pmf-example-fair-die",
    "href": "files/lecture_notes/lecture7/lecture7.html#pmf-example-fair-die",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "PMF Example: Fair Die",
    "text": "PMF Example: Fair Die\nLet \\(X\\) = outcome of rolling a fair six-sided die\n\\[P(X = x) = \\begin{cases}\n\\frac{1}{6} & \\text{if } x \\in \\{1, 2, 3, 4, 5, 6\\} \\\\\n0 & \\text{otherwise}\n\\end{cases}\\]\n\nVerification: - All probabilities ≥ 0 ✓ - Sum = \\(6 \\times \\frac{1}{6} = 1\\) ✓"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "href": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "PMF Example: Two Coin Flips",
    "text": "PMF Example: Two Coin Flips\nLet \\(X\\) = number of heads in two coin flips\nSample space: \\(\\{HH, HT, TH, TT\\}\\)\n\n\n\n\n\\(x\\)\nOutcomes\n\\(P(X = x)\\)\n\n\n\n\n0\nTT\n1/4\n\n\n1\nHT, TH\n2/4 = 1/2\n\n\n2\nHH\n1/4\n\n\n\nVerification: \\(\\frac{1}{4} + \\frac{1}{2} + \\frac{1}{4} = 1\\) ✓"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\nA box contains 3 red balls and 2 blue balls. Two balls are drawn without replacement. Let \\(X\\) = number of red balls drawn.\nFind the PMF of \\(X\\).\n\nSolution: \\(X\\) can be 0, 1, or 2\n\\(P(X = 0) = \\frac{\\binom{3}{0}\\binom{2}{2}}{\\binom{5}{2}} = \\frac{1 \\times 1}{10} = \\frac{1}{10}\\)\n\\(P(X = 1) = \\frac{\\binom{3}{1}\\binom{2}{1}}{\\binom{5}{2}} = \\frac{3 \\times 2}{10} = \\frac{6}{10}\\)\n\\(P(X = 2) = \\frac{\\binom{3}{2}\\binom{2}{0}}{\\binom{5}{2}} = \\frac{3 \\times 1}{10} = \\frac{3}{10}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "href": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\nThe cumulative distribution function of a random variable \\(X\\) is:\n\\[F(x) = P(X \\leq x)\\]\nProperties of CDF: 1. \\(F(x)\\) is non-decreasing 2. \\(\\lim_{x \\to -\\infty} F(x) = 0\\) 3. \\(\\lim_{x \\to \\infty} F(x) = 1\\) 4. \\(F(x)\\) is right-continuous"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#cdf-example-two-coin-flips",
    "href": "files/lecture_notes/lecture7/lecture7.html#cdf-example-two-coin-flips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "CDF Example: Two Coin Flips",
    "text": "CDF Example: Two Coin Flips\nFrom our previous example where \\(X\\) = number of heads:\n\\[F(x) = \\begin{cases}\n0 & \\text{if } x &lt; 0 \\\\\n\\frac{1}{4} & \\text{if } 0 \\leq x &lt; 1 \\\\\n\\frac{3}{4} & \\text{if } 1 \\leq x &lt; 2 \\\\\n1 & \\text{if } x \\geq 2\n\\end{cases}\\]\n\nKey insight: CDF is a step function for discrete random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#relationship-between-pmf-and-cdf",
    "href": "files/lecture_notes/lecture7/lecture7.html#relationship-between-pmf-and-cdf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Relationship Between PMF and CDF",
    "text": "Relationship Between PMF and CDF\nFrom PMF to CDF: \\(F(x) = \\sum_{k \\leq x} P(X = k)\\)\nFrom CDF to PMF: \\(P(X = k) = F(k) - F(k^-)\\)\nwhere \\(F(k^-)\\) is the limit from the left\n\nUseful CDF Properties: - \\(P(X &gt; x) = 1 - F(x)\\) - \\(P(a &lt; X \\leq b) = F(b) - F(a)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\nUsing the red balls example from Problem 1, find:\n\n\\(F(0.5)\\)\n\\(F(1)\\)\n\n\\(P(X &gt; 1)\\)\n\\(P(0.5 &lt; X \\leq 1.5)\\)\n\n\nSolutions: a) \\(F(0.5) = P(X \\leq 0.5) = P(X = 0) = \\frac{1}{10}\\) b) \\(F(1) = P(X \\leq 1) = P(X = 0) + P(X = 1) = \\frac{1}{10} + \\frac{6}{10} = \\frac{7}{10}\\) c) \\(P(X &gt; 1) = 1 - F(1) = 1 - \\frac{7}{10} = \\frac{3}{10}\\) d) \\(P(0.5 &lt; X \\leq 1.5) = F(1.5) - F(0.5) = \\frac{7}{10} - \\frac{1}{10} = \\frac{6}{10}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#expected-value-mean",
    "href": "files/lecture_notes/lecture7/lecture7.html#expected-value-mean",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value (Mean)",
    "text": "Expected Value (Mean)\nThe expected value of a discrete random variable \\(X\\) is:\n\\[E[X] = \\mu = \\sum_{\\text{all } x} x \\cdot P(X = x)\\]\nInterpretation: The long-run average value if the experiment is repeated many times\n\nAlso called: Mean, expectation, average"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#expected-value-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#expected-value-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value Example",
    "text": "Expected Value Example\nFor two coin flips where \\(X\\) = number of heads:\n\\[E[X] = 0 \\cdot P(X = 0) + 1 \\cdot P(X = 1) + 2 \\cdot P(X = 2)\\]\n\\[= 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 0 + \\frac{1}{2} + \\frac{1}{2} = 1\\]\n\nMakes sense: On average, we expect 1 head in 2 coin flips"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\nFind the expected value for the red balls example (Problem 1).\n\nSolution: \\[E[X] = 0 \\cdot \\frac{1}{10} + 1 \\cdot \\frac{6}{10} + 2 \\cdot \\frac{3}{10}\\]\n\\[= 0 + \\frac{6}{10} + \\frac{6}{10} = \\frac{12}{10} = 1.2\\]\nOn average, we expect to draw 1.2 red balls"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "href": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Properties of Expected Value",
    "text": "Properties of Expected Value\nLinearity of Expectation: 1. \\(E[c] = c\\) (constant) 2. \\(E[cX] = c \\cdot E[X]\\) (scaling) 3. \\(E[X + Y] = E[X] + E[Y]\\) (additivity) 4. \\(E[aX + bY + c] = aE[X] + bE[Y] + c\\)\n\nImportant: Property 3 holds even if \\(X\\) and \\(Y\\) are dependent!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#expected-value-of-functions",
    "href": "files/lecture_notes/lecture7/lecture7.html#expected-value-of-functions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value of Functions",
    "text": "Expected Value of Functions\nFor a function \\(g(X)\\) of a random variable \\(X\\):\n\\[E[g(X)] = \\sum_{\\text{all } x} g(x) \\cdot P(X = x)\\]\n\nCommon example: \\(g(X) = X^2\\)\n\\[E[X^2] = \\sum_{\\text{all } x} x^2 \\cdot P(X = x)\\]\nNote: Generally \\(E[g(X)] \\neq g(E[X])\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#variance",
    "href": "files/lecture_notes/lecture7/lecture7.html#variance",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Variance",
    "text": "Variance\nThe variance of a random variable \\(X\\) measures spread around the mean:\n\\[\\text{Var}(X) = \\sigma^2 = E[(X - \\mu)^2]\\]\nAlternative formula (often easier to compute): \\[\\text{Var}(X) = E[X^2] - (E[X])^2\\]\nStandard deviation: \\(\\sigma = \\sqrt{\\text{Var}(X)}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#variance-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#variance-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Variance Example",
    "text": "Variance Example\nFor two coin flips where \\(X\\) = number of heads, \\(E[X] = 1\\):\nFirst, find \\(E[X^2]\\): \\[E[X^2] = 0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4} = 0 + \\frac{1}{2} + 1 = \\frac{3}{2}\\]\n\nThen: \\(\\text{Var}(X) = E[X^2] - (E[X])^2 = \\frac{3}{2} - 1^2 = \\frac{1}{2}\\)\nStandard deviation: \\(\\sigma = \\sqrt{\\frac{1}{2}} \\approx 0.707\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#properties-of-variance",
    "href": "files/lecture_notes/lecture7/lecture7.html#properties-of-variance",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Properties of Variance",
    "text": "Properties of Variance\n\n\\(\\text{Var}(c) = 0\\) (constants have no variability)\n\\(\\text{Var}(cX) = c^2 \\text{Var}(X)\\) (scaling by \\(c\\) scales variance by \\(c^2\\))\n\\(\\text{Var}(X + c) = \\text{Var}(X)\\) (shifting doesn’t change spread)\nIf \\(X\\) and \\(Y\\) are independent: \\(\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y)\\)\n\n\nNote: Property 4 requires independence, unlike expectation!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-4",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-4",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\nFor the red balls example, find the variance and standard deviation.\nWe found \\(E[X] = 1.2\\). First find \\(E[X^2]\\):\n\n\\[E[X^2] = 0^2 \\cdot \\frac{1}{10} + 1^2 \\cdot \\frac{6}{10} + 2^2 \\cdot \\frac{3}{10}\\] \\[= 0 + \\frac{6}{10} + \\frac{12}{10} = \\frac{18}{10} = 1.8\\]\n\\[\\text{Var}(X) = 1.8 - (1.2)^2 = 1.8 - 1.44 = 0.36\\]\n\\[\\sigma = \\sqrt{0.36} = 0.6\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#bernoulli-distribution",
    "href": "files/lecture_notes/lecture7/lecture7.html#bernoulli-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\nA Bernoulli random variable models a single trial with two outcomes:\n\nSuccess (1) with probability \\(p\\)\nFailure (0) with probability \\(1-p\\)\n\nPMF: \\(P(X = x) = p^x(1-p)^{1-x}\\) for \\(x \\in \\{0, 1\\}\\)\nParameters: \\(p \\in [0, 1]\\)\n\nExamples: Coin flip, single exam question (pass/fail), defective item"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#bernoulli-properties",
    "href": "files/lecture_notes/lecture7/lecture7.html#bernoulli-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bernoulli Properties",
    "text": "Bernoulli Properties\nFor \\(X \\sim \\text{Bernoulli}(p)\\):\nMean: \\(E[X] = p\\)\nVariance: \\(\\text{Var}(X) = p(1-p)\\)\nStandard deviation: \\(\\sigma = \\sqrt{p(1-p)}\\)\n\nIntuition: - Mean \\(p\\) makes sense: probability of success - Variance maximized when \\(p = 0.5\\) (most uncertainty)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#binomial-distribution",
    "href": "files/lecture_notes/lecture7/lecture7.html#binomial-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\nA binomial random variable counts successes in \\(n\\) independent Bernoulli trials, each with success probability \\(p\\)\nPMF: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\) for \\(k = 0, 1, 2, \\ldots, n\\)\nParameters: \\(n\\) (number of trials), \\(p\\) (success probability)\nNotation: \\(X \\sim \\text{Binomial}(n, p)\\) or \\(X \\sim B(n, p)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#binomial-properties",
    "href": "files/lecture_notes/lecture7/lecture7.html#binomial-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Binomial Properties",
    "text": "Binomial Properties\nFor \\(X \\sim \\text{Binomial}(n, p)\\):\nMean: \\(E[X] = np\\)\nVariance: \\(\\text{Var}(X) = np(1-p)\\)\nStandard deviation: \\(\\sigma = \\sqrt{np(1-p)}\\)\n\nDerivation: Sum of \\(n\\) independent Bernoulli\\((p)\\) random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#binomial-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#binomial-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Binomial Example",
    "text": "Binomial Example\nA multiple choice quiz has 10 questions, each with 4 options. A student guesses randomly on each question. Let \\(X\\) = number of correct answers.\n\\(X \\sim \\text{Binomial}(10, 0.25)\\)\nWhat’s the probability of getting exactly 3 correct?\n\n\\[P(X = 3) = \\binom{10}{3} (0.25)^3 (0.75)^7\\] \\[= 120 \\times 0.015625 \\times 0.1335 \\approx 0.250\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-5",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-5",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 5",
    "text": "Practice Problem 5\nFor the quiz example:\n\nWhat’s the expected number of correct answers?\nWhat’s the standard deviation?\nWhat’s the probability of getting at least 4 correct?\n\n\nSolutions: a) \\(E[X] = np = 10 \\times 0.25 = 2.5\\) b) \\(\\sigma = \\sqrt{np(1-p)} = \\sqrt{10 \\times 0.25 \\times 0.75} = \\sqrt{1.875} \\approx 1.37\\) c) \\(P(X \\geq 4) = 1 - P(X \\leq 3) = 1 - [P(X=0) + P(X=1) + P(X=2) + P(X=3)]\\) Use binomial table or calculator: \\(P(X \\geq 4) \\approx 0.224\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#geometric-distribution",
    "href": "files/lecture_notes/lecture7/lecture7.html#geometric-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\nA geometric random variable counts the number of trials until the first success\nPMF: \\(P(X = k) = (1-p)^{k-1} p\\) for \\(k = 1, 2, 3, \\ldots\\)\nParameters: \\(p\\) (success probability per trial)\nNotation: \\(X \\sim \\text{Geometric}(p)\\)\n\nExamples: Number of coin flips until heads, number of shots until goal, number of calls until sale"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#geometric-properties",
    "href": "files/lecture_notes/lecture7/lecture7.html#geometric-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Geometric Properties",
    "text": "Geometric Properties\nFor \\(X \\sim \\text{Geometric}(p)\\):\nMean: \\(E[X] = \\frac{1}{p}\\)\nVariance: \\(\\text{Var}(X) = \\frac{1-p}{p^2}\\)\nMemoryless property: \\(P(X &gt; s + t | X &gt; s) = P(X &gt; t)\\)\n\nIntuition: If \\(p = 0.1\\), expect to wait \\(\\frac{1}{0.1} = 10\\) trials on average"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#geometric-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#geometric-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Geometric Example",
    "text": "Geometric Example\nA basketball player has a 60% free throw percentage. What’s the probability they make their first shot on the 3rd attempt?\n\\(X \\sim \\text{Geometric}(0.6)\\)\n\n\\[P(X = 3) = (1-0.6)^{3-1} \\times 0.6 = (0.4)^2 \\times 0.6 = 0.16 \\times 0.6 = 0.096\\]\nExpected number of attempts: \\(E[X] = \\frac{1}{0.6} \\approx 1.67\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-6",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-6",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\nA quality control inspector tests items until finding the first defective one. If 5% of items are defective:\n\nWhat’s the probability the first defective item is the 10th one tested?\nWhat’s the expected number of items tested?\nWhat’s the probability of testing more than 20 items?\n\n\nSolutions: a) \\(P(X = 10) = (0.95)^9 \\times 0.05 \\approx 0.0315\\) b) \\(E[X] = \\frac{1}{0.05} = 20\\) items c) \\(P(X &gt; 20) = (0.95)^{20} \\approx 0.358\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#poisson-distribution",
    "href": "files/lecture_notes/lecture7/lecture7.html#poisson-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution\nA Poisson random variable counts events occurring in a fixed interval when events happen at a constant average rate\nPMF: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\) for \\(k = 0, 1, 2, \\ldots\\)\nParameters: \\(\\lambda &gt; 0\\) (average rate)\nNotation: \\(X \\sim \\text{Poisson}(\\lambda)\\)\n\nExamples: Emails per hour, accidents per day, mutations per genome"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#poisson-properties",
    "href": "files/lecture_notes/lecture7/lecture7.html#poisson-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Poisson Properties",
    "text": "Poisson Properties\nFor \\(X \\sim \\text{Poisson}(\\lambda)\\):\nMean: \\(E[X] = \\lambda\\)\nVariance: \\(\\text{Var}(X) = \\lambda\\)\nStandard deviation: \\(\\sigma = \\sqrt{\\lambda}\\)\n\nUnique property: Mean equals variance!\nApproximation: Binomial\\((n, p)\\) ≈ Poisson\\((np)\\) when \\(n\\) large, \\(p\\) small"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#poisson-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#poisson-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Poisson Example",
    "text": "Poisson Example\nA call center receives an average of 3 calls per minute. What’s the probability of receiving exactly 5 calls in the next minute?\n\\(X \\sim \\text{Poisson}(3)\\)\n\n\\[P(X = 5) = \\frac{3^5 e^{-3}}{5!} = \\frac{243 \\times e^{-3}}{120} \\approx \\frac{243 \\times 0.0498}{120} \\approx 0.101\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-7",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-7",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\nFor the call center example:\n\nWhat’s the probability of no calls in a minute?\nWhat’s the probability of at most 2 calls?\nIn a 2-minute period, what’s the expected number of calls?\n\n\nSolutions: a) \\(P(X = 0) = \\frac{3^0 e^{-3}}{0!} = e^{-3} \\approx 0.0498\\) b) \\(P(X \\leq 2) = P(X=0) + P(X=1) + P(X=2) \\approx 0.0498 + 0.1494 + 0.2240 = 0.423\\) c) For 2 minutes: \\(Y \\sim \\text{Poisson}(6)\\), so \\(E[Y] = 6\\) calls"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-distribution",
    "href": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Hypergeometric Distribution",
    "text": "Hypergeometric Distribution\nA hypergeometric random variable counts successes when sampling without replacement from a finite population\nSetup: Population of \\(N\\) items, \\(K\\) are successes, draw \\(n\\) items\nPMF: \\(P(X = k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}\\)\nNotation: \\(X \\sim \\text{Hypergeometric}(N, K, n)\\)\n\nExamples: Defective items in a batch, aces in a card hand, tagged fish in a sample"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-properties",
    "href": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Hypergeometric Properties",
    "text": "Hypergeometric Properties\nFor \\(X \\sim \\text{Hypergeometric}(N, K, n)\\):\nMean: \\(E[X] = n \\cdot \\frac{K}{N}\\)\nVariance: \\(\\text{Var}(X) = n \\cdot \\frac{K}{N} \\cdot \\frac{N-K}{N} \\cdot \\frac{N-n}{N-1}\\)\n\nConnection to Binomial: When \\(N\\) is large relative to \\(n\\), hypergeometric ≈ binomial\\((n, K/N)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Hypergeometric Example",
    "text": "Hypergeometric Example\nA batch of 20 light bulbs contains 3 defective ones. If 5 bulbs are randomly selected, what’s the probability exactly 1 is defective?\n\\(X \\sim \\text{Hypergeometric}(20, 3, 5)\\)\n\n\\[P(X = 1) = \\frac{\\binom{3}{1}\\binom{17}{4}}{\\binom{20}{5}} = \\frac{3 \\times 2380}{15504} = \\frac{7140}{15504} \\approx 0.461\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-8",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-8",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 8",
    "text": "Practice Problem 8\nFor the light bulb example:\n\nWhat’s the expected number of defective bulbs in the sample?\nWhat’s the probability of no defective bulbs?\nWhat’s the probability of at least 2 defective bulbs?\n\n\nSolutions: a) \\(E[X] = 5 \\times \\frac{3}{20} = 0.75\\) bulbs b) \\(P(X = 0) = \\frac{\\binom{3}{0}\\binom{17}{5}}{\\binom{20}{5}} = \\frac{6188}{15504} \\approx 0.399\\) c) \\(P(X \\geq 2) = 1 - P(X = 0) - P(X = 1) \\approx 1 - 0.399 - 0.461 = 0.140\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#comparing-distributions",
    "href": "files/lecture_notes/lecture7/lecture7.html#comparing-distributions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Comparing Distributions",
    "text": "Comparing Distributions\n\n\n\n\n\n\n\n\n\n\nDistribution\nParameters\nMean\nVariance\nUse Case\n\n\n\n\nBernoulli\n\\(p\\)\n\\(p\\)\n\\(p(1-p)\\)\nSingle trial\n\n\nBinomial\n\\(n, p\\)\n\\(np\\)\n\\(np(1-p)\\)\nFixed trials\n\n\nGeometric\n\\(p\\)\n\\(1/p\\)\n\\((1-p)/p^2\\)\nWait for success\n\n\nPoisson\n\\(\\lambda\\)\n\\(\\lambda\\)\n\\(\\lambda\\)\nCount events\n\n\nHypergeometric\n\\(N, K, n\\)\n\\(n(K/N)\\)\nComplex\nSample w/o replacement"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#technology-and-software",
    "href": "files/lecture_notes/lecture7/lecture7.html#technology-and-software",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Technology and Software",
    "text": "Technology and Software\nCalculators: - Binomial: binompdf(), binomcdf() - Poisson: poissonpdf(), poissoncdf()\nR: - dbinom(), pbinom(), rbinom() - dpois(), ppois(), rpois() - dgeom(), pgeom(), rgeom()\nPython: - scipy.stats.binom, scipy.stats.poisson - numpy.random for simulation"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture7/lecture7.html#problem-solving-strategy",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\nIdentify the scenario: What type of process?\nCheck assumptions: Independence, constant probability, etc.\nChoose distribution: Match scenario to distribution\nIdentify parameters: \\(n\\), \\(p\\), \\(\\lambda\\), etc.\nCalculate probabilities: Use PMF, CDF, or technology\nInterpret results: Does the answer make sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#real-world-applications",
    "href": "files/lecture_notes/lecture7/lecture7.html#real-world-applications",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nQuality Control: - Binomial for defect rates - Hypergeometric for batch sampling\nReliability Engineering: - Geometric for time to failure - Poisson for system failures\nEpidemiology: - Binomial for disease spread - Poisson for rare events\nFinance: - Poisson for market events - Binomial for option pricing"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-9",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-9",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 9",
    "text": "Practice Problem 9\nA website receives an average of 2 orders per minute. Assuming orders follow a Poisson process:\n\nWhat’s the probability of exactly 3 orders in a minute?\nWhat’s the probability of no orders in 30 seconds?\nWhat’s the probability of more than 5 orders in 2 minutes?\n\n\nSolutions: a) \\(X \\sim \\text{Poisson}(2)\\): \\(P(X = 3) = \\frac{2^3 e^{-2}}{3!} \\approx 0.180\\) b) \\(Y \\sim \\text{Poisson}(1)\\): \\(P(Y = 0) = e^{-1} \\approx 0.368\\) c) \\(Z \\sim \\text{Poisson}(4)\\): \\(P(Z &gt; 5) = 1 - P(Z \\leq 5) \\approx 0.215\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#central-limit-theorem-preview",
    "href": "files/lecture_notes/lecture7/lecture7.html#central-limit-theorem-preview",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Central Limit Theorem Preview",
    "text": "Central Limit Theorem Preview\nFor large \\(n\\), many discrete distributions approach normal:\nBinomial: \\(X \\sim \\text{Binomial}(n, p)\\) → \\(N(np, np(1-p))\\) when \\(np &gt; 5\\) and \\(n(1-p) &gt; 5\\)\nPoisson: \\(X \\sim \\text{Poisson}(\\lambda)\\) → \\(N(\\lambda, \\lambda)\\) when \\(\\lambda &gt; 10\\)\n\nThis connection will be crucial for hypothesis testing and confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#common-mistakes",
    "href": "files/lecture_notes/lecture7/lecture7.html#common-mistakes",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Common Mistakes",
    "text": "Common Mistakes\n\nWrong distribution choice: Check assumptions carefully\nParameter confusion: Is it \\(n\\), \\(p\\), or \\(\\lambda\\)?\nInclusion errors: “At least 3” vs “More than 3”\nIndependence assumption: Sampling with/without replacement\nTechnology errors: pdf vs cdf functions"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-10",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-10",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 10",
    "text": "Practice Problem 10\nA multiple choice test has 20 questions with 5 options each. A student knows the answers to 12 questions and guesses on the rest.\n\nWhat’s the expected score?\nWhat’s the probability of scoring at least 15?\nWhat’s the standard deviation of the score?\n\n\nSolution: Let \\(X\\) = known correct, \\(Y\\) = guessed correct - \\(X = 12\\) (deterministic) - \\(Y \\sim \\text{Binomial}(8, 0.2)\\) - Total score \\(S = X + Y = 12 + Y\\)\n\n\\(E[S] = 12 + E[Y] = 12 + 8(0.2) = 13.6\\)\n\\(P(S \\geq 15) = P(Y \\geq 3) \\approx 0.203\\)\n\n\\(\\sigma_S = \\sigma_Y = \\sqrt{8(0.2)(0.8)} = \\sqrt{1.28} \\approx 1.13\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#extensions-and-advanced-topics",
    "href": "files/lecture_notes/lecture7/lecture7.html#extensions-and-advanced-topics",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Extensions and Advanced Topics",
    "text": "Extensions and Advanced Topics\nNegative Binomial: Number of trials to get \\(r\\) successes\nMultinomial: Extension of binomial to more than 2 categories\nCompound Distributions: Sums of random variables\nGenerating Functions: Advanced technique for deriving properties\n\nThese topics appear in advanced probability courses"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#historical-context",
    "href": "files/lecture_notes/lecture7/lecture7.html#historical-context",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Historical Context",
    "text": "Historical Context\nJacob Bernoulli (1654-1705): Bernoulli trials and law of large numbers\nSiméon Denis Poisson (1781-1840): Poisson distribution and approximation\nAbraham de Moivre (1667-1754): Normal approximation to binomial\nModern Applications: Computer science, machine learning, bioinformatics"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#common-student-questions",
    "href": "files/lecture_notes/lecture7/lecture7.html#common-student-questions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: “How do I choose between binomial and hypergeometric?” A: Use binomial for sampling with replacement, hypergeometric without\nQ: “When can I use Poisson approximation?” A: When \\(n\\) is large, \\(p\\) is small, and \\(np\\) is moderate\nQ: “Why does Poisson have mean = variance?” A: Mathematical property arising from its derivation as a limit\nQ: “How do I know if trials are independent?” A: Check if outcome of one trial affects others"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture7/lecture7.html#key-formulas-summary",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\nExpected Value: \\(E[X] = \\sum x \\cdot P(X = x)\\)\nVariance: \\(\\text{Var}(X) = E[X^2] - (E[X])^2\\)\nBinomial: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\)\nGeometric: \\(P(X = k) = (1-p)^{k-1} p\\)\nPoisson: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "href": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture: Continuous Random Variables - Probability density functions (PDFs) - Normal distribution - Exponential distribution\n- Central Limit Theorem applications\nConnection: Discrete distributions often approximate continuous ones, and vice versa"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#study-tips",
    "href": "files/lecture_notes/lecture7/lecture7.html#study-tips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Study Tips",
    "text": "Study Tips\n\nMaster the basics: PMF, CDF, expectation, variance\nLearn distribution characteristics: When to use each one\nPractice with technology: Get comfortable with calculators/software\nWork real problems: Apply distributions to actual scenarios\nCheck your intuition: Do answers make practical sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#final-thoughts",
    "href": "files/lecture_notes/lecture7/lecture7.html#final-thoughts",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nDiscrete random variables are fundamental to: - Modeling real-world phenomena - Making statistical inferences - Understanding probability theory - Building more complex models\n\nKey insight: Random variables transform unpredictable outcomes into predictable patterns"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#questions",
    "href": "files/lecture_notes/lecture7/lecture7.html#questions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: [Your office hours] Email: [Your email]\nNext Class: Continuous Random Variables\nRemember: Homework due [date]"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#bonus-law-of-large-numbers",
    "href": "files/lecture_notes/lecture7/lecture7.html#bonus-law-of-large-numbers",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bonus: Law of Large Numbers",
    "text": "Bonus: Law of Large Numbers\nAs \\(n\\) increases, the sample mean approaches the expected value:\n\\[\\bar{X}_n = \\frac{X_1 + X_2 + \\cdots + X_n}{n} \\to E[X]\\]\nExample: Flip a coin 1000 times - proportion of heads will be close to 0.5\nThis justifies our interpretation of expected value as “long-run average”"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#bonus-simulation",
    "href": "files/lecture_notes/lecture7/lecture7.html#bonus-simulation",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bonus: Simulation",
    "text": "Bonus: Simulation\nMonte Carlo Method: Use computer simulation to estimate probabilities\n# Simulate 10,000 binomial random variables\nX &lt;- rbinom(10000, size=10, prob=0.3)\nmean(X)  # Should be close to 10*0.3 = 3\nvar(X)   # Should be close to 10*0.3*0.7 = 2.1\nSimulation helps verify theoretical results and solve complex problems"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html",
    "href": "files/lecture_notes/lecture6/lecture6.html",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "",
    "text": "Conditional Probabilities\nUnderstanding probability when information changes the game"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#welcome-to-lecture-6",
    "href": "files/lecture_notes/lecture6/lecture6.html#welcome-to-lecture-6",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "",
    "text": "Conditional Probabilities\nUnderstanding probability when information changes the game"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture6/lecture6.html#todays-learning-objectives",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Today’s Learning Objectives",
    "text": "Today’s Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine and calculate conditional probabilities\nApply the multiplication rule for dependent events\nUse tree diagrams to solve multi-stage problems\nApply the law of total probability\nUse Bayes’ theorem to solve real-world problems\nDistinguish between independence and conditional independence\nRecognize and avoid common conditional probability fallacies"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#motivation-why-conditional-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#motivation-why-conditional-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Motivation: Why Conditional Probability?",
    "text": "Motivation: Why Conditional Probability?\nIn real life, we rarely make decisions with no information\nExamples: - Medical diagnosis with test results - Weather forecast with current conditions\n- Investment decisions with market data - Sports betting with team statistics - Insurance premiums based on risk factors\n\nConditional probability helps us update our beliefs when we gain new information"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#what-is-conditional-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#what-is-conditional-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "What is Conditional Probability?",
    "text": "What is Conditional Probability?\nConditional Probability is the probability of an event occurring, given that another event has already occurred\nNotation: \\(P(A|B)\\) read as “probability of A given B”\n\nKey insight: When we know B has occurred, our sample space effectively “shrinks” to only outcomes where B is true"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#intuitive-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#intuitive-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Intuitive Example",
    "text": "Intuitive Example\nYou roll a fair six-sided die, but before revealing the result, someone tells you “the number is even”\nWhat’s the probability it’s a 4?\n\nWithout information: \\(P(\\text{rolling 4}) = \\frac{1}{6}\\)\nWith information: \\(P(\\text{4 | even}) = ?\\)\nGiven it’s even, possible outcomes: \\(\\{2, 4, 6\\}\\) So \\(P(\\text{4 | even}) = \\frac{1}{3}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#formal-definition",
    "href": "files/lecture_notes/lecture6/lecture6.html#formal-definition",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Formal Definition",
    "text": "Formal Definition\nFor events A and B where \\(P(B) &gt; 0\\):\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\n\nInterpretation: - Numerator: Outcomes where both A and B occur - Denominator: All outcomes where B occurs\n- Ratio: Fraction of B-outcomes where A also occurs"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#understanding-the-formula",
    "href": "files/lecture_notes/lecture6/lecture6.html#understanding-the-formula",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Understanding the Formula",
    "text": "Understanding the Formula\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nWhy this formula makes sense: - We restrict our attention to outcomes where B occurs - Among those outcomes, what fraction also have A? - This is exactly \\(\\frac{P(A \\cap B)}{P(B)}\\)\n\nRearranging: \\(P(A \\cap B) = P(A|B) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-1",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-1",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\nA card is drawn from a standard 52-card deck. Find:\n\n\\(P(\\text{King | Face card})\\)\n\\(P(\\text{Heart | Red card})\\)\n\n\\(P(\\text{Ace | Black card})\\)\n\n\nSolutions: a) \\(P(\\text{King | Face}) = \\frac{4}{12} = \\frac{1}{3}\\) (4 kings among 12 face cards) b) \\(P(\\text{Heart | Red}) = \\frac{13}{26} = \\frac{1}{2}\\) (13 hearts among 26 red cards) c) \\(P(\\text{Ace | Black}) = \\frac{2}{26} = \\frac{1}{13}\\) (2 black aces among 26 black cards)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#two-way-tables",
    "href": "files/lecture_notes/lecture6/lecture6.html#two-way-tables",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Two-Way Tables",
    "text": "Two-Way Tables\nTwo-way tables are excellent for conditional probability problems\nExample: Survey of 1000 people about coffee preference\n\n\n\n\nCoffee\nNo Coffee\nTotal\n\n\n\n\nMorning\n350\n150\n500\n\n\nEvening\n200\n300\n500\n\n\nTotal\n550\n450\n1000"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#using-two-way-tables",
    "href": "files/lecture_notes/lecture6/lecture6.html#using-two-way-tables",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Using Two-Way Tables",
    "text": "Using Two-Way Tables\nFind: \\(P(\\text{Coffee | Morning person})\\)\nFrom the table: - Morning people: 500 - Morning people who drink coffee: 350\n\n\\(P(\\text{Coffee | Morning}) = \\frac{350}{500} = 0.7\\)\nCompare to: \\(P(\\text{Coffee}) = \\frac{550}{1000} = 0.55\\)\nBeing a morning person increases coffee probability!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-2",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-2",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\nUsing the coffee table, find:\n\n\\(P(\\text{Morning | Coffee drinker})\\)\n\\(P(\\text{No Coffee | Evening person})\\)\n\\(P(\\text{Evening | No Coffee})\\)\n\n\nSolutions: a) \\(P(\\text{Morning | Coffee}) = \\frac{350}{550} = \\frac{7}{11} \\approx 0.636\\) b) \\(P(\\text{No Coffee | Evening}) = \\frac{300}{500} = 0.6\\)\nc) \\(P(\\text{Evening | No Coffee}) = \\frac{300}{450} = \\frac{2}{3} \\approx 0.667\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#independence-revisited",
    "href": "files/lecture_notes/lecture6/lecture6.html#independence-revisited",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Independence Revisited",
    "text": "Independence Revisited\nEvents A and B are independent if knowing that B occurred doesn’t change the probability of A\n\\[P(A|B) = P(A)\\]\nEquivalently: \\[P(A \\cap B) = P(A) \\times P(B)\\]\n\nExample: Two coin flips are independent because \\(P(\\text{H}_2 | \\text{H}_1) = P(\\text{H}_2) = 0.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#testing-for-independence",
    "href": "files/lecture_notes/lecture6/lecture6.html#testing-for-independence",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Testing for Independence",
    "text": "Testing for Independence\nMethod 1: Check if \\(P(A|B) = P(A)\\) Method 2: Check if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nMethod 3: Check if \\(P(B|A) = P(B)\\)\n\nCoffee Example: Are coffee preference and time preference independent?\n\\(P(\\text{Coffee}) = 0.55\\) \\(P(\\text{Coffee | Morning}) = 0.7\\)\nSince \\(0.7 \\neq 0.55\\), they are not independent"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#the-multiplication-rule",
    "href": "files/lecture_notes/lecture6/lecture6.html#the-multiplication-rule",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "The Multiplication Rule",
    "text": "The Multiplication Rule\nGeneral Multiplication Rule: \\[P(A \\cap B) = P(A) \\times P(B|A) = P(B) \\times P(A|B)\\]\nFor Independent Events: \\[P(A \\cap B) = P(A) \\times P(B)\\]\n\nExtension to Multiple Events: \\[P(A_1 \\cap A_2 \\cap A_3) = P(A_1) \\times P(A_2|A_1) \\times P(A_3|A_1 \\cap A_2)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#multiplication-rule-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#multiplication-rule-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Multiplication Rule Example",
    "text": "Multiplication Rule Example\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement. What’s the probability both are red?\n\nLet \\(R_1\\) = first ball is red, \\(R_2\\) = second ball is red\n\\(P(R_1 \\cap R_2) = P(R_1) \\times P(R_2|R_1)\\)\n\\(= \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-3",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-3",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\nA box contains 4 defective and 6 working items. Three items are selected without replacement. Find the probability that:\n\nAll three work\nThe first two work and the third is defective\nExactly two work\n\n\nSolutions: a) \\(P(\\text{WWW}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}\\)\n\n\\(P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-3-continued",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-3-continued",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 3 (continued)",
    "text": "Practice Problem 3 (continued)\n\nExactly two work (three scenarios: WWD, WDW, DWW)\n\n\\(P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{1}{6}\\)\n\\(P(\\text{WDW}) = \\frac{6}{10} \\times \\frac{4}{9} \\times \\frac{5}{8} = \\frac{1}{6}\\)\n\\(P(\\text{DWW}) = \\frac{4}{10} \\times \\frac{6}{9} \\times \\frac{5}{8} = \\frac{1}{6}\\)\n\nTotal: \\(\\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#tree-diagrams",
    "href": "files/lecture_notes/lecture6/lecture6.html#tree-diagrams",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\nTree diagrams help visualize sequential events and conditional probabilities\n                    0.5   Red\n            0.6 ──┐\n                    0.5   Blue\nBall 1      \n                    0.4   Red  \n            0.4 ──┐\n                    0.6   Blue\nEach branch shows conditional probabilities"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#tree-diagram-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#tree-diagram-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagram Example",
    "text": "Tree Diagram Example\nMedical test scenario: - 2% of population has disease - Test is 95% accurate for sick people\n- Test is 90% accurate for healthy people\nWhat’s the probability of testing positive?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#tree-diagram-solution",
    "href": "files/lecture_notes/lecture6/lecture6.html#tree-diagram-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagram Solution",
    "text": "Tree Diagram Solution\n                    0.95   Test +\n            0.02 ──┐\n                    0.05   Test -\nDisease?    \n                    0.10   Test +\n            0.98 ──┐\n                    0.90   Test -\n\n\\(P(\\text{Test+}) = P(\\text{Test+|Disease}) \\times P(\\text{Disease}) + P(\\text{Test+|Healthy}) \\times P(\\text{Healthy})\\)\n\\(= 0.95 \\times 0.02 + 0.10 \\times 0.98 = 0.019 + 0.098 = 0.117\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#law-of-total-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#law-of-total-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space (mutually exclusive and exhaustive), then:\n\\[P(A) = \\sum_{i=1}^{n} P(A|B_i) \\times P(B_i)\\]\n\nPartition means: - \\(B_i \\cap B_j = \\emptyset\\) for \\(i \\neq j\\) (mutually exclusive) - \\(\\bigcup_{i=1}^{n} B_i = S\\) (exhaustive)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#law-of-total-probability-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\nA factory has three machines: - Machine A: 50% of production, 1% defective - Machine B: 30% of production, 2% defective\n- Machine C: 20% of production, 3% defective\nWhat’s the overall defect rate?\n\n\\(P(\\text{Defective}) = P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)\\)\n\\(= 0.01 \\times 0.5 + 0.02 \\times 0.3 + 0.03 \\times 0.2\\)\n\\(= 0.005 + 0.006 + 0.006 = 0.017 = 1.7\\%\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-4",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-4",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\nA student studies for an exam with three possible outcomes based on study time: - Studies hard (40%): 90% chance of passing - Studies moderately (35%): 70% chance of passing\n- Doesn’t study (25%): 30% chance of passing\nWhat’s the overall probability of passing?\n\n\\(P(\\text{Pass}) = 0.9 \\times 0.4 + 0.7 \\times 0.35 + 0.3 \\times 0.25\\)\n\\(= 0.36 + 0.245 + 0.075 = 0.68\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem",
    "href": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes’ Theorem",
    "text": "Bayes’ Theorem\nThe Foundation: We often want to “reverse” conditional probabilities\nGiven: \\(P(B|A)\\), \\(P(A)\\), \\(P(B)\\) Want: \\(P(A|B)\\)\nBayes’ Theorem: \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem-components",
    "href": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem-components",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes’ Theorem Components",
    "text": "Bayes’ Theorem Components\n\\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\n\n\\(P(A|B)\\): Posterior probability (what we want)\n\\(P(B|A)\\): Likelihood (what we observe)\n\n\\(P(A)\\): Prior probability (initial belief)\n\\(P(B)\\): Evidence (marginal probability)\n\n\n“In light of evidence B, how should we update our belief in A?”"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem-with-total-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem-with-total-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes’ Theorem with Total Probability",
    "text": "Bayes’ Theorem with Total Probability\nWhen we need to find \\(P(B)\\):\n\\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B|A) \\times P(A) + P(B|A^c) \\times P(A^c)}\\]\nThis is the most common form for applications"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#medical-diagnosis-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#medical-diagnosis-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Medical Diagnosis Example",
    "text": "Medical Diagnosis Example\nRevisiting our medical test: - 2% of population has disease (prior) - Test positive (evidence)\n- Test is 95% accurate for sick, 90% accurate for healthy\nGiven a positive test, what’s the probability of having the disease?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#medical-diagnosis-solution",
    "href": "files/lecture_notes/lecture6/lecture6.html#medical-diagnosis-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Medical Diagnosis Solution",
    "text": "Medical Diagnosis Solution\nLet D = disease, T+ = positive test\n\\[P(D|T+) = \\frac{P(T+|D) \\times P(D)}{P(T+|D) \\times P(D) + P(T+|D^c) \\times P(D^c)}\\]\n\\[= \\frac{0.95 \\times 0.02}{0.95 \\times 0.02 + 0.10 \\times 0.98}\\]\n\\[= \\frac{0.019}{0.019 + 0.098} = \\frac{0.019}{0.117} \\approx 0.162\\]\n\nSurprising: Only 16.2% chance of disease despite positive test!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#why-the-low-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#why-the-low-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Why the Low Probability?",
    "text": "Why the Low Probability?\nBase Rate Fallacy: When disease is rare (2%), most positive tests are false positives\nIntuition: Out of 10,000 people: - 200 have disease → 190 test positive\n- 9,800 healthy → 980 test positive - Total positive tests: 1,170 - True positives: 190\n\\(P(\\text{Disease | Positive}) = \\frac{190}{1,170} \\approx 0.162\\) ✓"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-5",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-5",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 5",
    "text": "Practice Problem 5\nEmail spam filter: - 60% of emails are spam - Filter catches 95% of spam - Filter incorrectly flags 8% of legitimate emails\nIf an email is flagged as spam, what’s the probability it’s actually spam?\n\n\\(P(\\text{Spam | Flagged}) = \\frac{0.95 \\times 0.6}{0.95 \\times 0.6 + 0.08 \\times 0.4}\\)\n\\(= \\frac{0.57}{0.57 + 0.032} = \\frac{0.57}{0.602} \\approx 0.947\\)\nThe filter is quite reliable!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#multiple-events-and-bayes",
    "href": "files/lecture_notes/lecture6/lecture6.html#multiple-events-and-bayes",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Multiple Events and Bayes’",
    "text": "Multiple Events and Bayes’\nExtended Bayes’ Theorem: If \\(A_1, A_2, \\ldots, A_n\\) partition the sample space:\n\\[P(A_i|B) = \\frac{P(B|A_i) \\times P(A_i)}{\\sum_{j=1}^{n} P(B|A_j) \\times P(A_j)}\\]\nThis allows us to update probabilities for multiple hypotheses"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#three-machine-example-revisited",
    "href": "files/lecture_notes/lecture6/lecture6.html#three-machine-example-revisited",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Three Machine Example Revisited",
    "text": "Three Machine Example Revisited\nA defective item is found. Which machine most likely produced it?\nFrom before: - Machine A: 50% production, 1% defective\n- Machine B: 30% production, 2% defective - Machine C: 20% production, 3% defective - Overall defect rate: 1.7%"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#three-machine-solution",
    "href": "files/lecture_notes/lecture6/lecture6.html#three-machine-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Three Machine Solution",
    "text": "Three Machine Solution\n\\[P(A|\\text{Defective}) = \\frac{0.01 \\times 0.5}{0.017} = \\frac{0.005}{0.017} \\approx 0.294\\]\n\\[P(B|\\text{Defective}) = \\frac{0.02 \\times 0.3}{0.017} = \\frac{0.006}{0.017} \\approx 0.353\\]\n\\[P(C|\\text{Defective}) = \\frac{0.03 \\times 0.2}{0.017} = \\frac{0.006}{0.017} \\approx 0.353\\]\n\nMachine B or C are most likely sources of the defective item"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-6",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-6",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\nThree boxes contain colored balls: - Box 1: 3 red, 2 blue (chosen 40% of time) - Box 2: 2 red, 3 blue (chosen 35% of time)\n- Box 3: 1 red, 4 blue (chosen 25% of time)\nA red ball is drawn. Which box was it most likely from?\n\n\\(P(\\text{Red}) = \\frac{3}{5} \\times 0.4 + \\frac{2}{5} \\times 0.35 + \\frac{1}{5} \\times 0.25 = 0.24 + 0.14 + 0.05 = 0.43\\)\n\\(P(\\text{Box 1 | Red}) = \\frac{0.6 \\times 0.4}{0.43} \\approx 0.558\\) \\(P(\\text{Box 2 | Red}) = \\frac{0.4 \\times 0.35}{0.43} \\approx 0.326\\)\n\\(P(\\text{Box 3 | Red}) = \\frac{0.2 \\times 0.25}{0.43} \\approx 0.116\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#conditional-independence",
    "href": "files/lecture_notes/lecture6/lecture6.html#conditional-independence",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Conditional Independence",
    "text": "Conditional Independence\nEvents A and B are conditionally independent given C if:\n\\[P(A \\cap B | C) = P(A|C) \\times P(B|C)\\]\nImportant: Conditional independence doesn’t imply independence!\n\nExample: Weather in two cities may be independent normally, but conditionally dependent given a major weather system"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#simpsons-paradox",
    "href": "files/lecture_notes/lecture6/lecture6.html#simpsons-paradox",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Simpson’s Paradox",
    "text": "Simpson’s Paradox\nSimpson’s Paradox: A trend in subgroups can reverse when groups are combined\nClassic Example: University admissions by gender\n\n\n\n\nMen\nWomen\n\n\n\n\nDept A\n62% (825/1327)\n82% (108/131)\n\n\nDept B\n63% (560/893)\n68% (25/37)\n\n\nOverall\n44% (1385/2220)\n30% (133/168)\n\n\n\nWomen have higher rates in each department but lower overall!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#common-fallacies",
    "href": "files/lecture_notes/lecture6/lecture6.html#common-fallacies",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Common Fallacies",
    "text": "Common Fallacies\n1. Confusion of the Inverse - Confusing \\(P(A|B)\\) with \\(P(B|A)\\) - “If it rains, the ground is wet” ≠ “If the ground is wet, it rained”\n2. Base Rate Neglect\n- Ignoring prior probabilities - Medical test example\n3. Prosecutor’s Fallacy - \\(P(\\text{Evidence | Innocent}) \\neq P(\\text{Innocent | Evidence})\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#prosecutors-fallacy-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#prosecutors-fallacy-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Prosecutor’s Fallacy Example",
    "text": "Prosecutor’s Fallacy Example\nDNA evidence matches defendant with probability 1 in a million for random person\nWrong reasoning: “Probability of innocence is 1 in a million”\nCorrect reasoning: Need to consider: - How many people could have committed the crime? - What’s the prior probability of guilt? - Possibility of lab error, planted evidence, etc."
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-7",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-7",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\nQuality control: 5% of items are defective. A test detects 96% of defective items but has a 4% false positive rate.\n\nWhat’s the probability an item testing positive is actually defective?\nWhat’s the probability an item testing negative is actually good?\n\n\n\n\\(P(\\text{Defective | Positive}) = \\frac{0.96 \\times 0.05}{0.96 \\times 0.05 + 0.04 \\times 0.95} = \\frac{0.048}{0.086} \\approx 0.558\\)\n\\(P(\\text{Good | Negative}) = \\frac{0.96 \\times 0.95}{0.96 \\times 0.95 + 0.04 \\times 0.05} = \\frac{0.912}{0.914} \\approx 0.998\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#real-world-applications",
    "href": "files/lecture_notes/lecture6/lecture6.html#real-world-applications",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Screening: - Mammograms, COVID tests - Balancing sensitivity vs specificity\nMachine Learning: - Naive Bayes classifiers - Spam detection, recommendation systems\nFinance: - Credit scoring - Fraud detection\nLegal System: - DNA evidence interpretation - Probability of guilt/innocence"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#technology-and-tools",
    "href": "files/lecture_notes/lecture6/lecture6.html#technology-and-tools",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Technology and Tools",
    "text": "Technology and Tools\nCalculators: - Basic probability calculations - Watch for rounding errors\nSoftware: - R: conditional probability tables - Python: pandas for two-way tables - Excel: pivot tables for conditional analysis\nVisualization: - Tree diagrams\n- Contingency tables - Bayes networks"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#diagnostic-thinking",
    "href": "files/lecture_notes/lecture6/lecture6.html#diagnostic-thinking",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Diagnostic Thinking",
    "text": "Diagnostic Thinking\nQuestions to ask: 1. What information am I conditioning on? 2. How does this information change the probability? 3. What’s the base rate or prior probability? 4. Am I confusing \\(P(A|B)\\) with \\(P(B|A)\\)? 5. Are the events independent?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture6/lecture6.html#problem-solving-strategy",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\nIdentify the type: Direct conditional, Bayes’, or law of total probability?\nDefine events clearly: Use precise notation\nOrganize information: Two-way tables or tree diagrams\nCheck for independence: Does additional info matter?\nApply appropriate formula: Don’t forget denominators!\nVerify answer: Does it make intuitive sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-8",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-8",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 8",
    "text": "Practice Problem 8\nA survey shows: - 70% of people like pizza - 60% of people like movies\n- 40% like both pizza and movies\n\nAre liking pizza and movies independent?\nWhat’s \\(P(\\text{Pizza | Movies})\\)?\nWhat’s \\(P(\\text{Movies | Pizza})\\)?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-8-solutions",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-8-solutions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 8 Solutions",
    "text": "Practice Problem 8 Solutions\n\nCheck independence: \\(P(\\text{Pizza}) \\times P(\\text{Movies}) = 0.7 \\times 0.6 = 0.42 \\neq 0.4\\) Not independent!\n\\(P(\\text{Pizza | Movies}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Movies})} = \\frac{0.4}{0.6} = \\frac{2}{3}\\)\n\\(P(\\text{Movies | Pizza}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Pizza})} = \\frac{0.4}{0.7} = \\frac{4}{7}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#advanced-topics-preview",
    "href": "files/lecture_notes/lecture6/lecture6.html#advanced-topics-preview",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Advanced Topics Preview",
    "text": "Advanced Topics Preview\nMarkov Chains: - Sequences where future depends only on present - \\(P(X_{n+1} | X_n, X_{n-1}, \\ldots, X_1) = P(X_{n+1} | X_n)\\)\nBayesian Statistics: - Using Bayes’ theorem for statistical inference - Updating beliefs with data\nInformation Theory: - Conditional entropy - Mutual information"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#historical-context",
    "href": "files/lecture_notes/lecture6/lecture6.html#historical-context",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Historical Context",
    "text": "Historical Context\nThomas Bayes (1701-1761): - Presbyterian minister and mathematician - Bayes’ theorem published posthumously\nPierre-Simon Laplace (1749-1827): - Developed and popularized Bayesian methods - “Probability is nothing but common sense reduced to calculation”\nModern Applications: AI, machine learning, medical diagnosis, finance"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#common-student-questions",
    "href": "files/lecture_notes/lecture6/lecture6.html#common-student-questions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: “How do I know when to use Bayes’ theorem?” A: When you want to “reverse” a conditional probability\nQ: “Why are medical test problems so counterintuitive?”\nA: Base rates matter more than we intuitively expect\nQ: “What’s the difference between independence and conditional independence?” A: Independence means no relationship; conditional independence means no relationship given specific information"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture6/lecture6.html#key-formulas-summary",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\nConditional Probability: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nMultiplication Rule: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nLaw of Total Probability: \\(P(A) = \\sum P(A|B_i) \\times P(B_i)\\)\nBayes’ Theorem: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)\nIndependence: \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#looking-ahead",
    "href": "files/lecture_notes/lecture6/lecture6.html#looking-ahead",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture: Discrete Random Variables - Random variables as functions - Probability mass functions - Expected value and variance - Common discrete distributions (binomial, geometric, Poisson)\nConnection: Conditional probability is essential for understanding dependence in random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#study-tips",
    "href": "files/lecture_notes/lecture6/lecture6.html#study-tips",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Study Tips",
    "text": "Study Tips\n\nPractice with real scenarios: Medical tests, quality control\nDraw diagrams: Tree diagrams and two-way tables\nCheck your intuition: Do answers make sense?\nMaster the basics: Conditional probability formula\nWatch for fallacies: Don’t confuse \\(P(A|B)\\) and \\(P(B|A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#final-thoughts",
    "href": "files/lecture_notes/lecture6/lecture6.html#final-thoughts",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nConditional probability is everywhere: - Updates beliefs with new information - Foundation of Bayesian thinking - Critical for proper statistical reasoning - Essential for machine learning and AI\n\nKey insight: Information changes probability - embrace this uncertainty!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#questions",
    "href": "files/lecture_notes/lecture6/lecture6.html#questions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: [Your office hours] Email: [Your email]\nNext Class: Discrete Random Variables\nRemember: Homework due [date]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#bonus-monty-hall-problem",
    "href": "files/lecture_notes/lecture6/lecture6.html#bonus-monty-hall-problem",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bonus: Monty Hall Problem",
    "text": "Bonus: Monty Hall Problem\nThree doors: one has a car, two have goats 1. You choose a door 2. Host opens a door with a goat 3. Do you switch?\n\nAnswer: Yes! Switch! - \\(P(\\text{Car behind your door}) = \\frac{1}{3}\\) - \\(P(\\text{Car behind other remaining door}) = \\frac{2}{3}\\)\nConditional probability in action!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#bonus-birthday-paradox-connection",
    "href": "files/lecture_notes/lecture6/lecture6.html#bonus-birthday-paradox-connection",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bonus: Birthday Paradox Connection",
    "text": "Bonus: Birthday Paradox Connection\nIn a room of 23 people, probability of shared birthday ≈ 50%\nConditional approach: What’s \\(P(\\text{no match | first $k$ people have different birthdays})\\)?\nThis helps build intuition for why the probability grows so quickly!\nSurprising results often involve conditional probability!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#population-vs-sample-variance",
    "href": "files/lecture_notes/lecture3/lecture3.html#population-vs-sample-variance",
    "title": "Descriptive Statistics Part II",
    "section": "Population vs Sample Variance",
    "text": "Population vs Sample Variance\nUnderstanding the mathematical foundations"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#side-by-side-comparison",
    "href": "files/lecture_notes/lecture3/lecture3.html#side-by-side-comparison",
    "title": "Descriptive Statistics Part II",
    "section": "Side-by-Side Comparison",
    "text": "Side-by-Side Comparison\n\n\n\nPopulation Variance\n\n\n\\[\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\]\n\n\\(\\sigma^2\\) = population variance\n\\(x_i\\) = value of \\(i^{th}\\) element\n\\(\\mu\\) = population mean\n\\(N\\) = population size\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\]\n\n\\(s^2\\) = sample variance\n\\(x_i\\) = value of \\(i^{th}\\) element\n\\(\\bar{x}\\) = sample mean\n\\(n\\) = sample size"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#key-differences",
    "href": "files/lecture_notes/lecture3/lecture3.html#key-differences",
    "title": "Descriptive Statistics Part II",
    "section": "Key Differences",
    "text": "Key Differences\n\nKey Difference: Sample variance uses \\((n-1)\\) instead of \\(N\\) in the denominator\n\nWhy \\((n-1)\\)?\n\nWhen we use sample mean \\(\\bar{x}\\) to estimate population mean \\(\\mu\\)\nWe lose one degree of freedom\nCalled Bessel’s correction\nMakes sample variance an unbiased estimator"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#when-to-use-each-formula",
    "href": "files/lecture_notes/lecture3/lecture3.html#when-to-use-each-formula",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Each Formula",
    "text": "When to Use Each Formula\n\nPopulation Variance (\\(\\sigma^2\\))\n\nYou have data for the entire population\nYou know the true population mean \\(\\mu\\)\nExample: Test scores for all students in a small class\n\n\n\nSample Variance (\\(s^2\\))\n\nYou have data from a sample only\nWant to estimate population variance\nExample: Survey responses from 100 people out of 10,000"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#degrees-of-freedom-concept",
    "href": "files/lecture_notes/lecture3/lecture3.html#degrees-of-freedom-concept",
    "title": "Descriptive Statistics Part II",
    "section": "Degrees of Freedom Concept",
    "text": "Degrees of Freedom Concept\n\n🎯 Definition\nDegrees of Freedom = Number of independent pieces of information available for estimating a parameter"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#example-calculation",
    "href": "files/lecture_notes/lecture3/lecture3.html#example-calculation",
    "title": "Descriptive Statistics Part II",
    "section": "Example Calculation",
    "text": "Example Calculation\nData: 3, 7, 2, 8, 5\nIf this is the entire population:\n\n\\(\\mu = \\frac{3+7+2+8+5}{5} = 5\\)\n\\(\\sigma^2 = \\frac{(3-5)^2+(7-5)^2+(2-5)^2+(8-5)^2+(5-5)^2}{5} = \\frac{22}{5} = 4.4\\)\n\nIf this is a sample:\n\n\\(\\bar{x} = 5\\) (same calculation)\n\\(s^2 = \\frac{22}{5-1} = \\frac{22}{4} = 5.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#mathematical-properties",
    "href": "files/lecture_notes/lecture3/lecture3.html#mathematical-properties",
    "title": "Descriptive Statistics Part II",
    "section": "Mathematical Properties",
    "text": "Mathematical Properties\nVariance measures: - Average squared deviation from the mean - Always non-negative: \\(\\sigma^2 \\geq 0\\), \\(s^2 \\geq 0\\) - Units: (original units)²\nStandard Deviation: - \\(\\sigma = \\sqrt{\\sigma^2}\\) (population) - \\(s = \\sqrt{s^2}\\) (sample) - Same units as original data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#bias-and-unbiasedness",
    "href": "files/lecture_notes/lecture3/lecture3.html#bias-and-unbiasedness",
    "title": "Descriptive Statistics Part II",
    "section": "Bias and Unbiasedness",
    "text": "Bias and Unbiasedness\nPopulation variance:\n\nTrue parameter value\nNo estimation involved\n\nSample variance with \\((n-1)\\):\n\n\\(E[s^2] = \\sigma^2\\) (unbiased)\nOn average, equals population variance\n\nSample variance with \\(n\\):\n\n\\(E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n}\\right] = \\frac{n-1}{n}\\sigma^2\\) (biased)\nSystematically underestimates population variance"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#common-student-questions",
    "href": "files/lecture_notes/lecture3/lecture3.html#common-student-questions",
    "title": "Descriptive Statistics Part II",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: “Why not just use \\(n\\) for sample variance?” A: It would systematically underestimate the true variance\nQ: “When does it matter?” A: More important for small samples; less difference as \\(n\\) increases\nQ: “What if I know the population mean?” A: Then you can use \\(n\\) in denominator: \\(\\frac{\\sum(x_i - \\mu)^2}{n}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#technology-implementation",
    "href": "files/lecture_notes/lecture3/lecture3.html#technology-implementation",
    "title": "Descriptive Statistics Part II",
    "section": "Technology Implementation",
    "text": "Technology Implementation\nCalculators:\n\nMost use \\((n-1)\\) by default for sample standard deviation\nCheck your calculator’s documentation\n\nSoftware:\n\nR: var() uses \\((n-1)\\), sd() uses \\((n-1)\\)\nExcel: VAR.S() uses \\((n-1)\\), VAR.P() uses \\(n\\)\nPython: np.var(ddof=1) uses \\((n-1)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practice-problem",
    "href": "files/lecture_notes/lecture3/lecture3.html#practice-problem",
    "title": "Descriptive Statistics Part II",
    "section": "Practice Problem",
    "text": "Practice Problem\nDataset: Number of hours studied by 6 students: 2, 4, 3, 5, 6, 4\nCalculate both:\n\nPopulation variance (assuming this is the entire population)\nSample variance (assuming this is a sample)\n\n\nSolution:\n\nMean: \\(\\bar{x} = \\frac{24}{6} = 4\\)\nPopulation variance: \\(\\sigma^2 = \\frac{10}{6} = 1.67\\)\nSample variance: \\(s^2 = \\frac{10}{5} = 2.0\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#summary",
    "href": "files/lecture_notes/lecture3/lecture3.html#summary",
    "title": "Descriptive Statistics Part II",
    "section": "Summary",
    "text": "Summary\n\nKey Takeaways\n\nPopulation variance uses \\(N\\) (entire population)\nSample variance uses \\((n-1)\\) (Bessel’s correction)\nSample variance is unbiased estimator of population variance\nDifference matters more for small samples\nAlways check which formula your software uses!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#questions",
    "href": "files/lecture_notes/lecture3/lecture3.html#questions",
    "title": "Descriptive Statistics Part II",
    "section": "Questions?",
    "text": "Questions?\nThank you for your attention!\nRemember: The goal of descriptive statistics is to understand your data story - let the visualizations guide your insights!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#recall",
    "href": "files/lecture_notes/lecture3/lecture3.html#recall",
    "title": "Descriptive Statistics Part II",
    "section": "Recall",
    "text": "Recall"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#properties",
    "href": "files/lecture_notes/lecture3/lecture3.html#properties",
    "title": "Descriptive Statistics Part II",
    "section": "Properties",
    "text": "Properties\nVariance measures:\n\nAverage squared deviation from the mean\nAlways non-negative: \\(\\sigma^2 \\geq 0\\), \\(s^2 \\geq 0\\)\nUnits: (original units)²\n\nStandard Deviation:\n\n\\(\\sigma = \\sqrt{\\sigma^2}\\) (population)\n\\(s = \\sqrt{s^2}\\) (sample)\nSame units as original data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#understanding-degrees-of-freedom",
    "href": "files/lecture_notes/lecture3/lecture3.html#understanding-degrees-of-freedom",
    "title": "Descriptive Statistics Part II",
    "section": "Understanding Degrees of Freedom",
    "text": "Understanding Degrees of Freedom\n\n\n📊 Population Case\nAll observations are independent\n\nWe know the true population mean \\(\\mu\\)\nEach of the \\(N\\) observations provides independent information\nNo constraints on the data\n\n\n\\[\\text{Degrees of Freedom} = N\\]\n\n\n\n📈 Sample Case\nConstraint introduced by sample mean\n\nWe must estimate \\(\\mu\\) using \\(\\bar{x}\\)\nOnce we know \\(\\bar{x}\\) and \\((n-1)\\) observations, the last one is determined\nWe “lose” one degree of freedom\n\n\n\\[\\text{Degrees of Freedom} = n-1\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#why-does-this-matter",
    "href": "files/lecture_notes/lecture3/lecture3.html#why-does-this-matter",
    "title": "Descriptive Statistics Part II",
    "section": "Why Does This Matter?",
    "text": "Why Does This Matter?\n\nKey Insight: Using \\(\\bar{x}\\) instead of \\(\\mu\\) creates dependency among observations\n\n\n🧠 Intuitive Explanation\nImagine you have 5 numbers that must average to 10:\nIf the mean is fixed at 10:\n\nChoose any 4 numbers freely: 8, 12, 7, 15\nThe 5th number is forced: \\(5 \\times 10 - (8+12+7+15) = 8\\)\nOnly 4 degrees of freedom, not 5!\n\nThis is exactly what happens with sample variance"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#visual-demonstration",
    "href": "files/lecture_notes/lecture3/lecture3.html#visual-demonstration",
    "title": "Descriptive Statistics Part II",
    "section": "Visual Demonstration",
    "text": "Visual Demonstration\n\nSample Mean Constraint\n\\[\\bar{x} = \\frac{x_1 + x_2 + \\cdots + x_n}{n}\\]\nRearranging: \\[x_n = n\\bar{x} - (x_1 + x_2 + \\cdots + x_{n-1})\\]\nOnce we know \\(\\bar{x}\\) and the first \\((n-1)\\) values, \\(x_n\\) is completely determined!\n\n\n\n✅ With \\((n-1)\\): Unbiased\n\\[E[s^2] = E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n-1}\\right] = \\sigma^2\\]\nSample variance is an unbiased estimator of population variance\n\n\n❌ With \\(n\\): Biased\n\\[E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n}\\right] = \\frac{n-1}{n}\\sigma^2\\]\nSystematically underestimates the true variance by factor \\(\\frac{n-1}{n}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#mathematical-consequences",
    "href": "files/lecture_notes/lecture3/lecture3.html#mathematical-consequences",
    "title": "Descriptive Statistics Part II",
    "section": "Mathematical Consequences",
    "text": "Mathematical Consequences\n\n\n✅ With \\((n-1)\\): Unbiased\n\\[E[s^2] = E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n-1}\\right] = \\sigma^2\\]\nSample variance is an unbiased estimator of population variance\n\n\n❌ With \\(n\\): Biased\n\\[E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n}\\right] = \\frac{n-1}{n}\\sigma^2\\]\nSystematically underestimates the true variance by factor \\(\\frac{n-1}{n}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practical-impact",
    "href": "files/lecture_notes/lecture3/lecture3.html#practical-impact",
    "title": "Descriptive Statistics Part II",
    "section": "Practical Impact",
    "text": "Practical Impact\n\n\n\nSmall Samples (n = 5)\n\nBias factor: \\(\\frac{n-1}{n} = \\frac{4}{5} = 0.8\\)\n20% underestimation if using \\(n\\)\n\nLarge impact on inference!\n\n\n\n\nLarge Samples (n = 100)\n\nBias factor: \\(\\frac{n-1}{n} = \\frac{99}{100} = 0.99\\)\n1% underestimation if using \\(n\\)\n\nMinimal practical difference"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#degrees-of-freedom-in-other-contexts",
    "href": "files/lecture_notes/lecture3/lecture3.html#degrees-of-freedom-in-other-contexts",
    "title": "Descriptive Statistics Part II",
    "section": "Degrees of Freedom in Other Contexts",
    "text": "Degrees of Freedom in Other Contexts\n\n📚 General Pattern\nDegrees of Freedom = Sample Size - Number of Parameters Estimated\nExamples:\n\nSample mean: \\(df = n - 0 = n\\) (no parameters estimated from data)\nSample variance: \\(df = n - 1\\) (estimate \\(\\mu\\) with \\(\\bar{x}\\))\nLinear regression: \\(df = n - p - 1\\) (estimate \\(p\\) coefficients + intercept)\nChi-square test: \\(df = (rows-1) \\times (cols-1)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#common-student-questions-1",
    "href": "files/lecture_notes/lecture3/lecture3.html#common-student-questions-1",
    "title": "Descriptive Statistics Part II",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: “Why not just use \\(n\\) for sample variance?” A: It would systematically underestimate the true variance\nQ: “When does it matter?” A: More important for small samples; less difference as \\(n\\) increases\nQ: “What if I know the population mean?” A: Then you can use \\(n\\) in denominator: \\(\\frac{\\sum(x_i - \\mu)^2}{n}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#variance-properties",
    "href": "files/lecture_notes/lecture3/lecture3.html#variance-properties",
    "title": "Descriptive Statistics Part II",
    "section": "Variance Properties",
    "text": "Variance Properties\nVariance measures:\n\nAverage squared deviation from the mean\nAlways non-negative: \\(\\sigma^2 \\geq 0\\), \\(s^2 \\geq 0\\)\nUnits: (original units)²\n\nStandard Deviation:\n\n\\(\\sigma = \\sqrt{\\sigma^2}\\) (population)\n\\(s = \\sqrt{s^2}\\) (sample)\nSame units as original data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#common-questions-1",
    "href": "files/lecture_notes/lecture3/lecture3.html#common-questions-1",
    "title": "Descriptive Statistics Part II",
    "section": "Common Questions",
    "text": "Common Questions\n\n❓ “Why not just use \\(n\\) for sample variance?”\nAnswer: It would systematically underestimate the true variance\n\n\n❓ “When does it matter?”\nAnswer: More important for small samples; less difference as \\(n\\) increases\n\n\n❓ “What if I know the population mean?”\nAnswer: Then you can use \\(n\\) in denominator: \\(\\frac{\\sum(x_i - \\mu)^2}{n}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#data-selection-example",
    "href": "files/lecture_notes/lecture3/lecture3.html#data-selection-example",
    "title": "Descriptive Statistics Part II",
    "section": "Data Selection Example",
    "text": "Data Selection Example"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#step-1-population-dataset",
    "href": "files/lecture_notes/lecture3/lecture3.html#step-1-population-dataset",
    "title": "Descriptive Statistics Part II",
    "section": "Step 1: Population Dataset",
    "text": "Step 1: Population Dataset\n\n📊 Complete Population Data (Test Scores)\nWe have test scores from 100 students arranged in a grid:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nM\nN\nO\nP\nQ\nR\nS\nT\n\n\n\n\n1\n24\n96\n30\n69\n85\n60\n55\n18\n30\n66\n64\n99\n92\n95\n84\n55\n72\n38\n86\n32\n\n\n2\n53\n81\n30\n89\n42\n94\n31\n26\n53\n78\n38\n60\n93\n90\n82\n85\n89\n54\n30\n58\n\n\n3\n62\n67\n75\n47\n99\n25\n32\n63\n49\n45\n30\n97\n57\n32\n37\n62\n33\n16\n11\n41\n\n\n4\n95\n74\n28\n73\n82\n97\n65\n88\n56\n95\n85\n44\n70\n65\n34\n85\n58\n15\n64\n84\n\n\n5\n76\n46\n83\n56\n98\n16\n76\n77\n35\n19\n97\n42\n90\n79\n73\n28\n82\n92\n90\n22\n\n\n\n\n\n🎯 Random Sample Selection\nWe randomly select 5 scores from different positions in our population:\n\nPosition O2: 82\nPosition J4: 95\nPosition C5: 83\nPosition F1: 60\nPosition R5: 92"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#step-2-selected-sample-data",
    "href": "files/lecture_notes/lecture3/lecture3.html#step-2-selected-sample-data",
    "title": "Descriptive Statistics Part II",
    "section": "Step 2: Selected Sample Data",
    "text": "Step 2: Selected Sample Data\n\nOur Sample: 82, 95, 83, 60, 92\n\n\nSample Size: n = 5\nThese 5 values will be used for our standard deviation calculation"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#step-3-calculate-standard-deviation",
    "href": "files/lecture_notes/lecture3/lecture3.html#step-3-calculate-standard-deviation",
    "title": "Descriptive Statistics Part II",
    "section": "Step 3: Calculate Standard Deviation",
    "text": "Step 3: Calculate Standard Deviation\n\nSample Mean Calculation\n\\[\\bar{x} = \\frac{82 + 95 + 83 + 60 + 92}{5} = \\frac{412}{5} = 82.4\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#step-4-detailed-calculation-table",
    "href": "files/lecture_notes/lecture3/lecture3.html#step-4-detailed-calculation-table",
    "title": "Descriptive Statistics Part II",
    "section": "Step 4: Detailed Calculation Table",
    "text": "Step 4: Detailed Calculation Table\n\n\n\n\\(x_i\\)\n\\(x_i - \\bar{x}\\)\n\\((x_i - \\bar{x})^2\\)\n\n\n\n\n82\n\\(82 - 82.4 = -0.4\\)\n\\((-0.4)^2 = 0.16\\)\n\n\n95\n\\(95 - 82.4 = 12.6\\)\n\\((12.6)^2 = 158.76\\)\n\n\n83\n\\(83 - 82.4 = 0.6\\)\n\\((0.6)^2 = 0.36\\)\n\n\n60\n\\(60 - 82.4 = -22.4\\)\n\\((-22.4)^2 = 501.76\\)\n\n\n92\n\\(92 - 82.4 = 9.6\\)\n\\((9.6)^2 = 92.16\\)\n\n\nSum\n\n\\(\\sum = 753.2\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#step-5-final-calculations",
    "href": "files/lecture_notes/lecture3/lecture3.html#step-5-final-calculations",
    "title": "Descriptive Statistics Part II",
    "section": "Step 5: Final Calculations",
    "text": "Step 5: Final Calculations\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum(x_i - \\bar{x})^2}{n-1}\\] \\[s^2 = \\frac{753.2}{5-1} = \\frac{753.2}{4} = 188.3\\]\n\n\n\n\nSample Standard Deviation\n\n\n\\[s = \\sqrt{s^2}\\] \\[s = \\sqrt{188.3} = 13.72\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#example-1",
    "href": "files/lecture_notes/lecture3/lecture3.html#example-1",
    "title": "Descriptive Statistics Part II",
    "section": "Example",
    "text": "Example\n\n\n📊 Complete Population Data (Test Scores)\nWe have test scores from 100 students arranged in a grid:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nM\nN\nO\nP\nQ\nR\nS\nT\n\n\n\n\n1\n24\n96\n30\n69\n85\n60\n55\n18\n30\n66\n64\n99\n92\n95\n84\n55\n72\n38\n86\n32\n\n\n2\n53\n81\n30\n89\n42\n94\n31\n26\n53\n78\n38\n60\n93\n90\n82\n85\n89\n54\n30\n58\n\n\n3\n62\n67\n75\n47\n99\n25\n32\n63\n49\n45\n30\n97\n57\n32\n37\n62\n33\n16\n11\n41\n\n\n4\n95\n74\n28\n73\n82\n97\n65\n88\n56\n95\n85\n44\n70\n65\n34\n85\n58\n15\n64\n84\n\n\n5\n76\n46\n83\n56\n98\n16\n76\n77\n35\n19\n97\n42\n90\n79\n73\n28\n82\n92\n90\n22\n\n\n\n\n\n\n🎯 Random Sample Selection\nWe randomly select 5 scores from different positions in our population:\nOur Sample: 82, 95, 83, 60, 92"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#detailed-calculation-table",
    "href": "files/lecture_notes/lecture3/lecture3.html#detailed-calculation-table",
    "title": "Descriptive Statistics Part II",
    "section": "Detailed Calculation Table",
    "text": "Detailed Calculation Table\n\n\n\n\\(x_i\\)\n\\(x_i - \\bar{x}\\)\n\\((x_i - \\bar{x})^2\\)\n\n\n\n\n82\n\\(82 - 82.4 = -0.4\\)\n\\((-0.4)^2 = 0.16\\)\n\n\n95\n\\(95 - 82.4 = 12.6\\)\n\\((12.6)^2 = 158.76\\)\n\n\n83\n\\(83 - 82.4 = 0.6\\)\n\\((0.6)^2 = 0.36\\)\n\n\n60\n\\(60 - 82.4 = -22.4\\)\n\\((-22.4)^2 = 501.76\\)\n\n\n92\n\\(92 - 82.4 = 9.6\\)\n\\((9.6)^2 = 92.16\\)\n\n\nSum\n\n\\(\\sum = 753.2\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#final-calculations",
    "href": "files/lecture_notes/lecture3/lecture3.html#final-calculations",
    "title": "Descriptive Statistics Part II",
    "section": "Final Calculations",
    "text": "Final Calculations\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum(x_i - \\bar{x})^2}{n-1}\\] \\[s^2 = \\frac{753.2}{5-1} = \\frac{753.2}{4} = 188.3\\]\n\n\n\n\nSample Standard Deviation\n\n\n\\[s = \\sqrt{s^2}\\] \\[s = \\sqrt{188.3} = 13.72\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#learning-objectives",
    "href": "files/lecture_notes/lecture3/test2.html#learning-objectives",
    "title": "Descriptive Statistics Part II",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture, you will be able to:\n\nCalculate and interpret measures of variability (range, variance, standard deviation)\nUnderstand and compute measures of position (percentiles, quartiles, z-scores)\nAssess distribution shape using skewness and kurtosis\nCreate and interpret histograms with appropriate bin widths\nConstruct and analyze boxplots for data exploration\nIdentify trends, patterns, and outliers in data visualizations\nApply Python for comprehensive descriptive analysis and visualization"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#lecture-outline",
    "href": "files/lecture_notes/lecture3/test2.html#lecture-outline",
    "title": "Descriptive Statistics Part II",
    "section": "Lecture Outline",
    "text": "Lecture Outline\n\n\nPart I: Measures of Variability (25 min) - Range, Variance, Standard Deviation - Coefficient of Variation - Python Implementation\nPart II: Measures of Position (20 min) - Percentiles and Quartiles - Z-scores and Standardization\n\n\nPart III: Distribution Shape (10 min) - Skewness and Kurtosis\nPart IV: Data Visualization (20 min) - Histograms and Bin Width Selection - Boxplots and Interpretation\nPart V: Identifying Patterns (5 min)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#what-is-variability",
    "href": "files/lecture_notes/lecture3/test2.html#what-is-variability",
    "title": "Descriptive Statistics Part II",
    "section": "What is Variability?",
    "text": "What is Variability?\n\n🎯 Definition\nVariability (or dispersion) measures how spread out or scattered the data points are around the center.\n\nWhy Variability Matters\n\nTwo datasets can have the same mean but very different spreads\nVariability indicates consistency and predictability\nEssential for risk assessment and quality control\nHelps determine confidence in our central tendency measures"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#comparing-datasets-with-same-mean",
    "href": "files/lecture_notes/lecture3/test2.html#comparing-datasets-with-same-mean",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Datasets with Same Mean",
    "text": "Comparing Datasets with Same Mean\n\nDataset A: 98, 99, 100, 101, 102 (Mean = 100)\nDataset B: 80, 90, 100, 110, 120 (Mean = 100)\n\n\n\nBoth have the same mean (100), but Dataset B is much more variable!\nThis is why we need measures of variability."
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#range",
    "href": "files/lecture_notes/lecture3/test2.html#range",
    "title": "Descriptive Statistics Part II",
    "section": "Range",
    "text": "Range\n\nRange = Maximum value - Minimum value\n\nExample\nData: 12, 15, 18, 22, 25, 30, 35\n\nRange = 35 - 12 = 23"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#properties-of-range",
    "href": "files/lecture_notes/lecture3/test2.html#properties-of-range",
    "title": "Descriptive Statistics Part II",
    "section": "Properties of Range",
    "text": "Properties of Range\n\n\n✅ Advantages\n\nSimple to calculate and understand\nQuick measure of spread\nEasy to communicate\n\n\n\n❌ Disadvantages\n\nUses only two values (ignores all others)\nSensitive to outliers\nLimited information about distribution"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#when-to-use-range",
    "href": "files/lecture_notes/lecture3/test2.html#when-to-use-range",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Range",
    "text": "When to Use Range\n\nUse range when:\n\nNeed a quick, simple measure of spread\nWorking with small datasets\nCommunicating to non-technical audiences\n\nAvoid range when:\n\nOutliers are present\nNeed detailed information about variability\nWorking with large datasets"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#variance-definition",
    "href": "files/lecture_notes/lecture3/test2.html#variance-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Variance Definition",
    "text": "Variance Definition\n\n🎯 Definition\nVariance measures the average squared deviation from the mean."
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#population-vs-sample-variance",
    "href": "files/lecture_notes/lecture3/test2.html#population-vs-sample-variance",
    "title": "Descriptive Statistics Part II",
    "section": "Population vs Sample Variance",
    "text": "Population vs Sample Variance\nUnderstanding the mathematical foundations"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#recall-population-vs-sample",
    "href": "files/lecture_notes/lecture3/test2.html#recall-population-vs-sample",
    "title": "Descriptive Statistics Part II",
    "section": "Recall: Population vs Sample",
    "text": "Recall: Population vs Sample"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#side-by-side-comparison",
    "href": "files/lecture_notes/lecture3/test2.html#side-by-side-comparison",
    "title": "Descriptive Statistics Part II",
    "section": "Side-by-Side Comparison",
    "text": "Side-by-Side Comparison\n\n\n\nPopulation Variance\n\n\n\\[\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\]\n\n\n\n\\(\\sigma^2\\) = population variance\n\n\n\\(x_i\\) = value of \\(i^{th}\\) element\n\n\n\\(\\mu\\) = population mean\n\n\n\\(N\\) = population size\n\n\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\]\n\n\n\n\\(s^2\\) = sample variance\n\n\n\\(x_i\\) = value of \\(i^{th}\\) element\n\n\n\\(\\bar{x}\\) = sample mean\n\n\n\\(n\\) = sample size"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#key-differences",
    "href": "files/lecture_notes/lecture3/test2.html#key-differences",
    "title": "Descriptive Statistics Part II",
    "section": "Key Differences",
    "text": "Key Differences\n\nKey Difference: Sample variance uses \\((n-1)\\) instead of \\(N\\) in the denominator\n\nWhy \\((n-1)\\)? - When we use sample mean \\(\\bar{x}\\) to estimate population mean \\(\\mu\\) - We lose one degree of freedom - Called Bessel’s correction - Makes sample variance an unbiased estimator"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#when-to-use-each-formula",
    "href": "files/lecture_notes/lecture3/test2.html#when-to-use-each-formula",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Each Formula",
    "text": "When to Use Each Formula\n\n\nPopulation Variance (\\(\\sigma^2\\))\n\nYou have data for the entire population\nYou know the true population mean \\(\\mu\\)\nExample: Test scores for all students in a small class\n\n\n\nSample Variance (\\(s^2\\))\n\nYou have data from a sample only\nWant to estimate population variance\nExample: Survey responses from 100 people out of 10,000"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#degrees-of-freedom-concept",
    "href": "files/lecture_notes/lecture3/test2.html#degrees-of-freedom-concept",
    "title": "Descriptive Statistics Part II",
    "section": "Degrees of Freedom Concept",
    "text": "Degrees of Freedom Concept\n\n🎯 Definition\nDegrees of Freedom = Number of independent pieces of information available for estimating a parameter"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#understanding-degrees-of-freedom",
    "href": "files/lecture_notes/lecture3/test2.html#understanding-degrees-of-freedom",
    "title": "Descriptive Statistics Part II",
    "section": "Understanding Degrees of Freedom",
    "text": "Understanding Degrees of Freedom\n\n\n📊 Population Case\nAll observations are independent\n\nWe know the true population mean \\(\\mu\\)\nEach of the \\(N\\) observations provides independent information\nNo constraints on the data\n\n\n\\[\\text{Degrees of Freedom} = N\\]\n\n\n\n📈 Sample Case\nConstraint introduced by sample mean\n\nWe must estimate \\(\\mu\\) using \\(\\bar{x}\\)\nOnce we know \\(\\bar{x}\\) and \\((n-1)\\) observations, the last one is determined\nWe “lose” one degree of freedom\n\n\n\\[\\text{Degrees of Freedom} = n-1\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#why-does-this-matter",
    "href": "files/lecture_notes/lecture3/test2.html#why-does-this-matter",
    "title": "Descriptive Statistics Part II",
    "section": "Why Does This Matter?",
    "text": "Why Does This Matter?\n\nKey Insight: Using \\(\\bar{x}\\) instead of \\(\\mu\\) creates dependency among observations\n\n\n🧠 Intuitive Explanation\nImagine you have 5 numbers that must average to 10:\nIf the mean is fixed at 10: - Choose any 4 numbers freely: 8, 12, 7, 15 - The 5th number is forced: \\(5 \\times 10 - (8+12+7+15) = 8\\) - Only 4 degrees of freedom, not 5!\nThis is exactly what happens with sample variance"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#mathematical-consequences",
    "href": "files/lecture_notes/lecture3/test2.html#mathematical-consequences",
    "title": "Descriptive Statistics Part II",
    "section": "Mathematical Consequences",
    "text": "Mathematical Consequences\n\n\n✅ With \\((n-1)\\): Unbiased\n\\[E[s^2] = E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n-1}\\right] = \\sigma^2\\]\nSample variance is an unbiased estimator of population variance\n\n\n❌ With \\(n\\): Biased\n\\[E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n}\\right] = \\frac{n-1}{n}\\sigma^2\\]\nSystematically underestimates the true variance by factor \\(\\frac{n-1}{n}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#practical-impact",
    "href": "files/lecture_notes/lecture3/test2.html#practical-impact",
    "title": "Descriptive Statistics Part II",
    "section": "Practical Impact",
    "text": "Practical Impact\n\n\n\nSmall Samples (n = 5)\n\nBias factor: \\(\\frac{n-1}{n} = \\frac{4}{5} = 0.8\\)\n20% underestimation if using \\(n\\)\n\nLarge impact on inference!\n\n\n\n\nLarge Samples (n = 100)\n\nBias factor: \\(\\frac{n-1}{n} = \\frac{99}{100} = 0.99\\)\n1% underestimation if using \\(n\\)\n\nMinimal practical difference"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#example-calculation",
    "href": "files/lecture_notes/lecture3/test2.html#example-calculation",
    "title": "Descriptive Statistics Part II",
    "section": "Example Calculation",
    "text": "Example Calculation\nData: 3, 7, 2, 8, 5\n\n\nIf this is the entire population:\n\n\\(\\mu = \\frac{3+7+2+8+5}{5} = 5\\)\n\\(\\sigma^2 = \\frac{(3-5)^2+(7-5)^2+(2-5)^2+(8-5)^2+(5-5)^2}{5} = \\frac{22}{5} = 4.4\\)\n\n\n\nSolution (If this is a sample:). \n\n\\(\\bar{x} = 5\\) (same calculation)\n\\(s^2 = \\frac{22}{5-1} = \\frac{22}{4} = 5.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#standard-deviation-definition",
    "href": "files/lecture_notes/lecture3/test2.html#standard-deviation-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Standard Deviation Definition",
    "text": "Standard Deviation Definition\n\n🎯 Definition\nStandard Deviation is the square root of variance.\n\n\n\nSample Standard Deviation\n\\[s = \\sqrt{s^2} = \\sqrt{\\frac{\\sum(x_i - \\bar{x})^2}{n-1}}\\]\n\n\nPopulation Standard Deviation\n\\[\\sigma = \\sqrt{\\sigma^2} = \\sqrt{\\frac{\\sum(x_i - \\mu)^2}{N}}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#step-by-step-standard-deviation-example",
    "href": "files/lecture_notes/lecture3/test2.html#step-by-step-standard-deviation-example",
    "title": "Descriptive Statistics Part II",
    "section": "Step-by-Step Standard Deviation Example",
    "text": "Step-by-Step Standard Deviation Example\nGiven Data\n\nSample Data: 82, 95, 83, 60, 92\nSample Size: n = 5"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#step-1-calculate-the-sample-mean",
    "href": "files/lecture_notes/lecture3/test2.html#step-1-calculate-the-sample-mean",
    "title": "Descriptive Statistics Part II",
    "section": "Step 1: Calculate the Sample Mean",
    "text": "Step 1: Calculate the Sample Mean\n\n\\[\\bar{x} = \\frac{\\sum x_i}{n} = \\frac{82 + 95 + 83 + 60 + 92}{5} = \\frac{412}{5} = 82.4\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#step-2-calculate-deviations-and-squared-deviations",
    "href": "files/lecture_notes/lecture3/test2.html#step-2-calculate-deviations-and-squared-deviations",
    "title": "Descriptive Statistics Part II",
    "section": "Step 2: Calculate Deviations and Squared Deviations",
    "text": "Step 2: Calculate Deviations and Squared Deviations\n\n\n\n\\(x_i\\)\n\\(x_i - \\bar{x}\\)\n\\((x_i - \\bar{x})^2\\)\n\n\n\n\n82\n\\(82 - 82.4 = -0.4\\)\n\\((-0.4)^2 = 0.16\\)\n\n\n95\n\\(95 - 82.4 = 12.6\\)\n\\((12.6)^2 = 158.76\\)\n\n\n83\n\\(83 - 82.4 = 0.6\\)\n\\((0.6)^2 = 0.36\\)\n\n\n60\n\\(60 - 82.4 = -22.4\\)\n\\((-22.4)^2 = 501.76\\)\n\n\n92\n\\(92 - 82.4 = 9.6\\)\n\\((9.6)^2 = 92.16\\)\n\n\nSum\n\n\\(\\sum = 753.2\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#step-3-calculate-sample-variance",
    "href": "files/lecture_notes/lecture3/test2.html#step-3-calculate-sample-variance",
    "title": "Descriptive Statistics Part II",
    "section": "Step 3: Calculate Sample Variance",
    "text": "Step 3: Calculate Sample Variance\n\n\\[s^2 = \\frac{\\sum(x_i - \\bar{x})^2}{n-1} = \\frac{753.2}{5-1} = \\frac{753.2}{4} = 188.3\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#step-4-calculate-sample-standard-deviation",
    "href": "files/lecture_notes/lecture3/test2.html#step-4-calculate-sample-standard-deviation",
    "title": "Descriptive Statistics Part II",
    "section": "Step 4: Calculate Sample Standard Deviation",
    "text": "Step 4: Calculate Sample Standard Deviation\n\n\\[s = \\sqrt{s^2} = \\sqrt{188.3} = 13.72\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#final-answer",
    "href": "files/lecture_notes/lecture3/test2.html#final-answer",
    "title": "Descriptive Statistics Part II",
    "section": "Final Answer",
    "text": "Final Answer\n\nSample Standard Deviation = 13.72\n\n\nSummary of Results:\n\nSample Mean: \\(\\bar{x} = 82.4\\)\nSample Variance: \\(s^2 = 188.3\\)\n\nSample Standard Deviation: \\(s = 13.72\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#properties-of-standard-deviation",
    "href": "files/lecture_notes/lecture3/test2.html#properties-of-standard-deviation",
    "title": "Descriptive Statistics Part II",
    "section": "Properties of Standard Deviation",
    "text": "Properties of Standard Deviation\n\nKey Properties:\n\nSame units as the original data\nAlways non-negative\nZero only when all values are identical\nLarger values indicate more variability\nApproximately 68% of data within 1 SD of mean (for normal distributions)\nApproximately 95% of data within 2 SD of mean"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#empirical-rule-68-95-99.7-rule",
    "href": "files/lecture_notes/lecture3/test2.html#empirical-rule-68-95-99.7-rule",
    "title": "Descriptive Statistics Part II",
    "section": "Empirical Rule (68-95-99.7 Rule)",
    "text": "Empirical Rule (68-95-99.7 Rule)\n\nFor approximately normal distributions:\n\n68% of data falls within 1 standard deviation of the mean\n95% of data falls within 2 standard deviations of the mean\n99.7% of data falls within 3 standard deviations of the mean\n\nThis rule helps us understand what constitutes “typical” vs “unusual” values."
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#coefficient-of-variation",
    "href": "files/lecture_notes/lecture3/test2.html#coefficient-of-variation",
    "title": "Descriptive Statistics Part II",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\n\nCoefficient of Variation (CV) = \\(\\frac{\\text{Standard Deviation}}{\\text{Mean}} \\times 100\\%\\)\n\nWhy Use CV?\n\nCompares variability across different units or scales\nRelative measure of variability\nUseful when means differ substantially"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#cv-example-comparing-variability",
    "href": "files/lecture_notes/lecture3/test2.html#cv-example-comparing-variability",
    "title": "Descriptive Statistics Part II",
    "section": "CV Example: Comparing Variability",
    "text": "CV Example: Comparing Variability\n\n\nStock A\n\nMean return = $50\nSD = $10\nCV = 20%\n\n\n\nStock B\n\nMean return = $500\nSD = $50\nCV = 10%\n\n\n\n\n\nStock B has higher absolute variability ($50 vs $10) but lower relative variability (10% vs 20%)\nStock B is relatively less risky per dollar invested."
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#python-implementation---variability",
    "href": "files/lecture_notes/lecture3/test2.html#python-implementation---variability",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Variability",
    "text": "Python Implementation - Variability\n\nimport numpy as np\nimport pandas as pd\n\n# Sample data\ndata = [10, 12, 14, 16, 18, 22, 25]\n\n# Calculate measures of variability\nrange_val = np.max(data) - np.min(data)\nvariance_sample = np.var(data, ddof=1)  # Sample variance\nstd_sample = np.std(data, ddof=1)       # Sample standard deviation\ncv = (std_sample / np.mean(data)) * 100\n\nprint(f\"Range: {range_val}\")\nprint(f\"Variance: {variance_sample:.2f}\")\nprint(f\"Standard Deviation: {std_sample:.2f}\")\nprint(f\"Coefficient of Variation: {cv:.1f}%\")"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#what-are-measures-of-position",
    "href": "files/lecture_notes/lecture3/test2.html#what-are-measures-of-position",
    "title": "Descriptive Statistics Part II",
    "section": "What are Measures of Position?",
    "text": "What are Measures of Position?\n\n🎯 Purpose\nMeasures of position tell us where a particular value stands relative to the rest of the data.\n\nThey answer questions like: - “What percentage of students scored below 85?” - “Is this value typical or unusual?” - “How does this observation compare to others?”"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#percentiles-definition",
    "href": "files/lecture_notes/lecture3/test2.html#percentiles-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Percentiles Definition",
    "text": "Percentiles Definition\n\nThe k-th percentile\nThe value below which k% of the data falls.\n\nExamples:\n\n50th percentile = Median (50% of data below this value)\n90th percentile = 90% of data falls below this value\n25th percentile = 25% of data falls below this value"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#quartiles",
    "href": "files/lecture_notes/lecture3/test2.html#quartiles",
    "title": "Descriptive Statistics Part II",
    "section": "Quartiles",
    "text": "Quartiles\n\nQuartiles divide the data into four equal parts:\n\nQ1 (First Quartile) = 25th percentile\nQ2 (Second Quartile) = 50th percentile = Median\nQ3 (Third Quartile) = 75th percentile"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#interquartile-range-iqr",
    "href": "files/lecture_notes/lecture3/test2.html#interquartile-range-iqr",
    "title": "Descriptive Statistics Part II",
    "section": "Interquartile Range (IQR)",
    "text": "Interquartile Range (IQR)\n\nIQR = Q3 - Q1\n\nProperties of IQR:\n\nContains the middle 50% of the data\nResistant to outliers\nUsed in boxplot construction\nUseful for outlier detection"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#five-number-summary",
    "href": "files/lecture_notes/lecture3/test2.html#five-number-summary",
    "title": "Descriptive Statistics Part II",
    "section": "Five-Number Summary",
    "text": "Five-Number Summary\n\nThe five-number summary provides a complete picture of data distribution:\n\nMinimum\nQ1 (25th percentile)\nMedian (50th percentile)\nQ3 (75th percentile)\nMaximum\n\nThis forms the basis for boxplots!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#z-scores-and-standardization",
    "href": "files/lecture_notes/lecture3/test2.html#z-scores-and-standardization",
    "title": "Descriptive Statistics Part II",
    "section": "Z-scores and Standardization",
    "text": "Z-scores and Standardization\n\nZ-score tells us how many standard deviations a value is from the mean.\n\\[z = \\frac{x - \\mu}{\\sigma} \\text{ or } z = \\frac{x - \\bar{x}}{s}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#interpreting-z-scores",
    "href": "files/lecture_notes/lecture3/test2.html#interpreting-z-scores",
    "title": "Descriptive Statistics Part II",
    "section": "Interpreting Z-scores",
    "text": "Interpreting Z-scores\n\nZ-score Interpretation:\n\nz = 0: Value equals the mean\nz = 1: Value is 1 standard deviation above the mean\nz = -2: Value is 2 standard deviations below the mean\n|z| &gt; 2: Often considered “unusual” (beyond 95% of data)\n|z| &gt; 3: Very unusual (beyond 99.7% of data)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#z-score-example",
    "href": "files/lecture_notes/lecture3/test2.html#z-score-example",
    "title": "Descriptive Statistics Part II",
    "section": "Z-score Example",
    "text": "Z-score Example\n\nProblem:\nStudent’s test score: 85\nClass mean: 78, Class standard deviation: 6\n\\[z = \\frac{85 - 78}{6} = \\frac{7}{6} = 1.17\\]\nInterpretation: This student scored 1.17 standard deviations above the class average."
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#benefits-of-standardization",
    "href": "files/lecture_notes/lecture3/test2.html#benefits-of-standardization",
    "title": "Descriptive Statistics Part II",
    "section": "Benefits of Standardization",
    "text": "Benefits of Standardization\n\nWhy use z-scores?\n\nCompare across different scales (test scores vs income)\nIdentify outliers systematically\n\nCombine different variables meaningfully\nPrepare data for certain statistical methods"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#python-implementation---position-shape",
    "href": "files/lecture_notes/lecture3/test2.html#python-implementation---position-shape",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Position & Shape",
    "text": "Python Implementation - Position & Shape\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndata = [12, 15, 18, 22, 25, 28, 30, 35, 40, 45]\n\n# Percentiles and quartiles\nq1 = np.percentile(data, 25)\nmedian = np.percentile(data, 50)\nq3 = np.percentile(data, 75)\niqr = q3 - q1\n\n# Z-scores\nz_scores = stats.zscore(data)\n\n# Shape measures\nskewness = stats.skew(data)\nkurt = stats.kurtosis(data)\n\nprint(f\"Q1: {q1}, Median: {median}, Q3: {q3}\")\nprint(f\"IQR: {iqr}\")\nprint(f\"Skewness: {skewness:.3f}\")\nprint(f\"Kurtosis: {kurt:.3f}\")"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#skewness",
    "href": "files/lecture_notes/lecture3/test2.html#skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Skewness",
    "text": "Skewness\n\n🎯 Definition\nSkewness measures the asymmetry of a distribution.\n\nTypes of Skewness:\n\nSymmetric (Skewness ≈ 0): Mean ≈ Median ≈ Mode\nRight-skewed (Positive skewness): Mean &gt; Median, long tail to the right\nLeft-skewed (Negative skewness): Mean &lt; Median, long tail to the left"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#visual-examples-of-skewness",
    "href": "files/lecture_notes/lecture3/test2.html#visual-examples-of-skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Visual Examples of Skewness",
    "text": "Visual Examples of Skewness\n\n\nRight-skewed (Income data):\n\nMost people earn moderate amounts\nFew people earn very high amounts\nMean &gt; Median\n\n\n\nLeft-skewed (Test scores with ceiling effect):\n\nMost students score high\nFew students score very low\n\nMean &lt; Median"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#kurtosis",
    "href": "files/lecture_notes/lecture3/test2.html#kurtosis",
    "title": "Descriptive Statistics Part II",
    "section": "Kurtosis",
    "text": "Kurtosis\n\n🎯 Definition\nKurtosis measures the “tailedness” of a distribution.\n\nTypes:\n\nMesokurtic (Normal-like): Kurtosis ≈ 3\nLeptokurtic (Heavy tails): Kurtosis &gt; 3, more peaked\nPlatykurtic (Light tails): Kurtosis &lt; 3, flatter\n\nExcess Kurtosis = Kurtosis - 3 (makes normal distributions have excess kurtosis of 0)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#what-is-a-histogram",
    "href": "files/lecture_notes/lecture3/test2.html#what-is-a-histogram",
    "title": "Descriptive Statistics Part II",
    "section": "What is a Histogram?",
    "text": "What is a Histogram?\n\n🎯 Definition\nA histogram displays the distribution of a continuous variable by dividing data into bins and showing the frequency of observations in each bin.\n\nKey Components:\n\nX-axis: Variable values (continuous)\nY-axis: Frequency or density\nBins: Intervals that group the data\nBars: Height represents frequency in each bin"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#choosing-bin-width-critical-decision",
    "href": "files/lecture_notes/lecture3/test2.html#choosing-bin-width-critical-decision",
    "title": "Descriptive Statistics Part II",
    "section": "Choosing Bin Width: Critical Decision",
    "text": "Choosing Bin Width: Critical Decision\n\nBin width dramatically affects histogram interpretation!\n\n\n\nToo Few Bins (Wide bins):\n\nOversmoothing - lose important details\nMay hide multimodality\nDistribution appears simpler than it is\n\n\n\nToo Many Bins (Narrow bins):\n\nUndersmoothing - too much noise\nMay create artificial gaps\nHard to see overall pattern"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#bin-width-guidelines",
    "href": "files/lecture_notes/lecture3/test2.html#bin-width-guidelines",
    "title": "Descriptive Statistics Part II",
    "section": "Bin Width Guidelines",
    "text": "Bin Width Guidelines\n\nRule of Thumb Methods:\n\nSquare Root Rule: Number of bins ≈ \\(\\sqrt{n}\\)\nSturges’ Rule: Number of bins = \\(1 + \\log_2(n)\\)\nScott’s Rule: Bin width = \\(\\frac{3.5 \\times \\text{SD}}{n^{1/3}}\\)\nFreedman-Diaconis Rule: Bin width = \\(\\frac{2 \\times \\text{IQR}}{n^{1/3}}\\)\n\nBest practice: Try multiple bin widths and choose based on the story your data tells!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#interpreting-histograms",
    "href": "files/lecture_notes/lecture3/test2.html#interpreting-histograms",
    "title": "Descriptive Statistics Part II",
    "section": "Interpreting Histograms",
    "text": "Interpreting Histograms\n\nWhat to Look For:\n\nShape: Normal, skewed, uniform, bimodal?\nCenter: Where is the “typical” value?\nSpread: How variable is the data?\nOutliers: Any unusual values?\nGaps: Are there missing values in certain ranges?\nMultiple peaks: Suggests multiple subgroups"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#anatomy-of-a-boxplot",
    "href": "files/lecture_notes/lecture3/test2.html#anatomy-of-a-boxplot",
    "title": "Descriptive Statistics Part II",
    "section": "Anatomy of a Boxplot",
    "text": "Anatomy of a Boxplot\n\nBoxplot Components:\nThe Box: - Left edge: Q1 (25th percentile) - Middle line: Median (Q2, 50th percentile)\n- Right edge: Q3 (75th percentile) - Box width: IQR (contains middle 50% of data)\nThe Whiskers: - Extend to: Most extreme values within 1.5 × IQR from box edges\nOutliers: - Points beyond whiskers: Values &gt; Q3 + 1.5×IQR or &lt; Q1 - 1.5×IQR"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#what-boxplots-tell-us",
    "href": "files/lecture_notes/lecture3/test2.html#what-boxplots-tell-us",
    "title": "Descriptive Statistics Part II",
    "section": "What Boxplots Tell Us",
    "text": "What Boxplots Tell Us\n\n\nDistribution Shape:\n\nSymmetric: Median in center of box, whiskers equal length\nRight-skewed: Median closer to Q1, longer upper whisker\nLeft-skewed: Median closer to Q3, longer lower whisker\n\n\n\nVariability:\n\nWide box: High variability in middle 50%\nLong whiskers: High overall variability\nMany outliers: Extreme variability"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#comparing-groups-with-boxplots",
    "href": "files/lecture_notes/lecture3/test2.html#comparing-groups-with-boxplots",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Groups with Boxplots",
    "text": "Comparing Groups with Boxplots\n\n# Comparing multiple groups\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create sample data for different groups\nnp.random.seed(42)\ngroup_a = np.random.normal(70, 10, 100)\ngroup_b = np.random.normal(75, 15, 100)  \ngroup_c = np.random.normal(80, 8, 100)\n\n# Combine into DataFrame\ndf = pd.DataFrame({\n    'Score': np.concatenate([group_a, group_b, group_c]),\n    'Group': ['A']*100 + ['B']*100 + ['C']*100\n})\n\n# Create comparative boxplot\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=df, x='Group', y='Score')\nplt.title('Comparing Score Distributions Across Groups')\nplt.ylabel('Test Score')\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#common-patterns-in-data",
    "href": "files/lecture_notes/lecture3/test2.html#common-patterns-in-data",
    "title": "Descriptive Statistics Part II",
    "section": "Common Patterns in Data",
    "text": "Common Patterns in Data\n\nDistribution Patterns:\n\nNormal/Bell-shaped: Symmetric, single peak\nUniform: All values equally likely\nBimodal: Two distinct peaks (suggests subgroups)\nMultimodal: Multiple peaks\nU-shaped: High values at extremes, low in middle\n\nOutlier Patterns:\n\nIndividual outliers: Data entry errors, measurement errors\nClustered outliers: Distinct subpopulation\nSystematic outliers: May indicate process changes"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#red-flags-in-data-visualization",
    "href": "files/lecture_notes/lecture3/test2.html#red-flags-in-data-visualization",
    "title": "Descriptive Statistics Part II",
    "section": "Red Flags in Data Visualization",
    "text": "Red Flags in Data Visualization\n\nWarning Signs:\n\nGaps in histograms: Missing data or measurement limitations\nHeaping: Values cluster at round numbers (10, 50, 100)\nTruncation: Data cut off at certain values\nDigit preference: People prefer certain ending digits\nMultiple modes: Hidden subgroups in your data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#essential-concepts-to-remember",
    "href": "files/lecture_notes/lecture3/test2.html#essential-concepts-to-remember",
    "title": "Descriptive Statistics Part II",
    "section": "Essential Concepts to Remember",
    "text": "Essential Concepts to Remember\n\n\nVariability:\n\nStandard deviation is preferred over range for most analyses\nCV allows comparison across different scales\nIQR is resistant to outliers\n\nPosition:\n\nPercentiles and quartiles provide relative position\nZ-scores standardize across different distributions\nFive-number summary gives complete overview\n\n\n\nVisualization:\n\nBin width choice is critical for histogram interpretation\nBoxplots excel at comparing groups and identifying outliers\nMultiple visualizations provide different insights\n\nGeneral:\n\nAlways visualize before calculating statistics\nUse multiple measures - no single statistic tells the whole story"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#practice-problems",
    "href": "files/lecture_notes/lecture3/test2.html#practice-problems",
    "title": "Descriptive Statistics Part II",
    "section": "Practice Problems",
    "text": "Practice Problems\n\nTry These Exercises\n\nCalculate the five-number summary for: 12, 15, 18, 22, 25, 28, 30, 35, 40, 45\nCreate histograms with 5, 15, and 50 bins for the same dataset. What patterns do you observe?\nInterpret this scenario: Dataset A has mean=50, SD=5. Dataset B has mean=100, SD=10. Which is more variable?\nA student scores 85 on a test where the class mean is 78 and SD is 6. Calculate and interpret the z-score.\nDesign a boxplot comparison for three different customer segments in your business."
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#questions",
    "href": "files/lecture_notes/lecture3/test2.html#questions",
    "title": "Descriptive Statistics Part II",
    "section": "Questions?",
    "text": "Questions?\nThank you for your attention!\nRemember: The goal of descriptive statistics is to understand your data story - let the visualizations guide your insights!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/test2.html#additional-resources",
    "href": "files/lecture_notes/lecture3/test2.html#additional-resources",
    "title": "Descriptive Statistics Part II",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nFor Further Learning:\n\nMatplotlib gallery: Histogram and boxplot examples\nSeaborn documentation: Statistical visualizations\nNumPy/SciPy: Statistical functions reference\nRecommended reading: Chapter 4-5 in course textbook\n\nNext Steps:\n\nCorrelation and association between variables\nTime series analysis for temporal patterns\nStatistical inference based on descriptive findings"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#range",
    "href": "files/lecture_notes/lecture3/lecture3.html#range",
    "title": "Descriptive Statistics Part II",
    "section": "Range",
    "text": "Range\n\nRange = Maximum value - Minimum value\n\nExample\nData: 12, 15, 18, 22, 25, 30, 35\n\nRange = 35 - 12 = 23"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#recall-population-vs-sample",
    "href": "files/lecture_notes/lecture3/lecture3.html#recall-population-vs-sample",
    "title": "Descriptive Statistics Part II",
    "section": "Recall: Population vs Sample",
    "text": "Recall: Population vs Sample"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#step-by-step-standard-deviation-example",
    "href": "files/lecture_notes/lecture3/lecture3.html#step-by-step-standard-deviation-example",
    "title": "Descriptive Statistics Part II",
    "section": "Step-by-Step Standard Deviation Example",
    "text": "Step-by-Step Standard Deviation Example\nGiven Data\n\nSample Data: 82, 95, 83, 60, 92\nSample Size: n = 5"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#step-1-calculate-the-sample-mean",
    "href": "files/lecture_notes/lecture3/lecture3.html#step-1-calculate-the-sample-mean",
    "title": "Descriptive Statistics Part II",
    "section": "Step 1: Calculate the Sample Mean",
    "text": "Step 1: Calculate the Sample Mean\n\n\\[\\bar{x} = \\frac{\\sum x_i}{n} = \\frac{82 + 95 + 83 + 60 + 92}{5} = \\frac{412}{5} = 82.4\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#step-2-calculate-deviations-and-squared-deviations",
    "href": "files/lecture_notes/lecture3/lecture3.html#step-2-calculate-deviations-and-squared-deviations",
    "title": "Descriptive Statistics Part II",
    "section": "Step 2: Calculate Deviations and Squared Deviations",
    "text": "Step 2: Calculate Deviations and Squared Deviations\n\n\n\n\\(x_i\\)\n\\(x_i - \\bar{x}\\)\n\\((x_i - \\bar{x})^2\\)\n\n\n\n\n82\n\\(82 - 82.4 = -0.4\\)\n\\((-0.4)^2 = 0.16\\)\n\n\n95\n\\(95 - 82.4 = 12.6\\)\n\\((12.6)^2 = 158.76\\)\n\n\n83\n\\(83 - 82.4 = 0.6\\)\n\\((0.6)^2 = 0.36\\)\n\n\n60\n\\(60 - 82.4 = -22.4\\)\n\\((-22.4)^2 = 501.76\\)\n\n\n92\n\\(92 - 82.4 = 9.6\\)\n\\((9.6)^2 = 92.16\\)\n\n\nSum\n\n\\(\\sum = 753.2\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#step-3-calculate-sample-variance",
    "href": "files/lecture_notes/lecture3/lecture3.html#step-3-calculate-sample-variance",
    "title": "Descriptive Statistics Part II",
    "section": "Step 3: Calculate Sample Variance",
    "text": "Step 3: Calculate Sample Variance\n\n\\[s^2 = \\frac{\\sum(x_i - \\bar{x})^2}{n-1} = \\frac{753.2}{5-1} = \\frac{753.2}{4} = 188.3\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#step-4-calculate-sample-standard-deviation",
    "href": "files/lecture_notes/lecture3/lecture3.html#step-4-calculate-sample-standard-deviation",
    "title": "Descriptive Statistics Part II",
    "section": "Step 4: Calculate Sample Standard Deviation",
    "text": "Step 4: Calculate Sample Standard Deviation\n\n\\[s = \\sqrt{s^2} = \\sqrt{188.3} = 13.72\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#final-answer",
    "href": "files/lecture_notes/lecture3/lecture3.html#final-answer",
    "title": "Descriptive Statistics Part II",
    "section": "Final Answer",
    "text": "Final Answer\n\nSample Standard Deviation = 13.72\n\n\nSummary of Results:\n\nSample Mean: \\(\\bar{x} = 82.4\\)\nSample Variance: \\(s^2 = 188.3\\)\n\nSample Standard Deviation: \\(s = 13.72\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#coefficient-of-variation",
    "href": "files/lecture_notes/lecture3/lecture3.html#coefficient-of-variation",
    "title": "Descriptive Statistics Part II",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\n\nCoefficient of Variation (CV) = \\(\\frac{\\text{Standard Deviation}}{\\text{Mean}} \\times 100\\%\\)\n\nWhy Use CV?\n\nCompares variability across different units or scales\nRelative measure of variability\nUseful when means differ substantially"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#cv-example-comparing-variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#cv-example-comparing-variability",
    "title": "Descriptive Statistics Part II",
    "section": "CV Example: Comparing Variability",
    "text": "CV Example: Comparing Variability\n\n\nStock A\n\nMean return = $50\nSD = $10\nCV = 20%\n\n\n\nStock B\n\nMean return = $500\nSD = $50\nCV = 10%\n\n\n\n\n\nStock B has higher absolute variability ($50 vs $10) but lower relative variability (10% vs 20%)\nStock B is relatively less risky per dollar invested."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#z-scores-and-standardization",
    "href": "files/lecture_notes/lecture3/lecture3.html#z-scores-and-standardization",
    "title": "Descriptive Statistics Part II",
    "section": "Z-scores and Standardization",
    "text": "Z-scores and Standardization\n\nZ-score tells us how many standard deviations a value is from the mean.\n\\[z = \\frac{x - \\mu}{\\sigma} \\text{ or } z = \\frac{x - \\bar{x}}{s}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practice-problems",
    "href": "files/lecture_notes/lecture3/lecture3.html#practice-problems",
    "title": "Descriptive Statistics Part II",
    "section": "Practice Problems",
    "text": "Practice Problems\n\nTry These Exercises\n\nCalculate the five-number summary for: 12, 15, 18, 22, 25, 28, 30, 35, 40, 45\nCreate histograms with 5, 15, and 50 bins for the same dataset. What patterns do you observe?\nInterpret this scenario: Dataset A has mean=50, SD=5. Dataset B has mean=100, SD=10. Which is more variable?\nA student scores 85 on a test where the class mean is 78 and SD is 6. Calculate and interpret the z-score.\nDesign a boxplot comparison for three different customer segments in your business."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#definition",
    "title": "Descriptive Statistics Part II",
    "section": "🎯 Definition",
    "text": "🎯 Definition\nVariability (or dispersion) measures how spread out or scattered the data points are around the center."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#when-to-use-the-range",
    "href": "files/lecture_notes/lecture3/lecture3.html#when-to-use-the-range",
    "title": "Descriptive Statistics Part II",
    "section": "When to use the range",
    "text": "When to use the range\n\nUse range when:\n\nNeed a quick, simple measure of spread\nWorking with small datasets\nCommunicating to non-technical audiences\n\nAvoid range when:\n\nOutliers are present\nNeed detailed information about variability\nWorking with large datasets"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#key-difference",
    "href": "files/lecture_notes/lecture3/lecture3.html#key-difference",
    "title": "Descriptive Statistics Part II",
    "section": "Key Difference",
    "text": "Key Difference\n\nOur Sample: 82, 95, 83, 60, 92"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#implementation",
    "href": "files/lecture_notes/lecture3/lecture3.html#implementation",
    "title": "Descriptive Statistics Part II",
    "section": "Implementation",
    "text": "Implementation\nCalculators:\n\nMost use \\((n-1)\\) by default for sample standard deviation\nCheck your calculator’s documentation\n\nSoftware:\n\nR: var() uses \\((n-1)\\), sd() uses \\((n-1)\\)\nExcel: VAR.S() uses \\((n-1)\\), VAR.P() uses \\(n\\)\nPython: np.var(ddof=1) uses \\((n-1)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#demonstration",
    "href": "files/lecture_notes/lecture3/lecture3.html#demonstration",
    "title": "Descriptive Statistics Part II",
    "section": "Demonstration",
    "text": "Demonstration\n\nSample Mean Constraint\n\\[\\bar{x} = \\frac{x_1 + x_2 + \\cdots + x_n}{n}\\]\nRearranging: \\[x_n = n\\bar{x} - (x_1 + x_2 + \\cdots + x_{n-1})\\]\nOnce we know \\(\\bar{x}\\) and the first \\((n-1)\\) values, \\(x_n\\) is completely determined!\n\n\n\n✅ With \\((n-1)\\): Unbiased\n\\[E[s^2] = E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n-1}\\right] = \\sigma^2\\]\nSample variance is an unbiased estimator of population variance\n\n\n❌ With \\(n\\): Biased\n\\[E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n}\\right] = \\frac{n-1}{n}\\sigma^2\\]\nSystematically underestimates the true variance by factor \\(\\frac{n-1}{n}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#section",
    "href": "files/lecture_notes/lecture3/lecture3.html#section",
    "title": "Descriptive Statistics Part II",
    "section": "",
    "text": "Sample Mean Constraint\n\\[\\bar{x} = \\frac{x_1 + x_2 + \\cdots + x_n}{n}\\]\nRearranging: \\[x_n = n\\bar{x} - (x_1 + x_2 + \\cdots + x_{n-1})\\]\nOnce we know \\(\\bar{x}\\) and the first \\((n-1)\\) values, \\(x_n\\) is completely determined!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#examples-of-skewness",
    "href": "files/lecture_notes/lecture3/lecture3.html#examples-of-skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Examples of Skewness",
    "text": "Examples of Skewness\nRight-skewed (Income data):\n\nMost people earn moderate amounts\nFew people earn very high amounts\nMean &gt; Median\n\nLeft-skewed (Test scores with ceiling effect):\n\nMost students score high\nFew students score very low\nMean &lt; Median"
  }
]