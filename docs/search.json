[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Class Schedule",
    "section": "",
    "text": "‚ö†Ô∏è\n\nImportant: This schedule is subject to change. Please check back regularly for updates and announcements.\n\n\n\n\n\n\nLabs & Worksheets\n\n\n\n\n\nQuizzes & Exams\n\n\n\n\n\nLecture Materials\n\n\n\n\n\n\n\nAnonymous Feedback Survey\n\n\n\n\n\nWeek 1: Introduction & Descriptive Statistics\n\n\n\n\n1\n\n\n6/23\n\n\nIntroduction\n\n\nLab 1\nlab1 Solutions\n\n\nWorksheet 1\n\n\n\n\n\n\n\n6/24\n\n\nNo class (lecture canceled)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n6/25\n\n\nDescriptive Statistics I\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n6/26\n\n\nDescriptive Statistics II\nLinear Transformations (Worksheet 1 Q3)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 2: Probability Foundations\n\n\n\n\n2\n\n\n6/30\n\n\nDescriptive Statistics II (Continued)\n\n\nLab2\nLab2 Notebook\nlab2 Solutions\n\n\nWorksheet 2\nWorksheet 2 Solutions\n\n\n\n\n\n\n\n7/01\n\n\nIntro to Probability\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/02\n\n\nIntro to Probability (Continued)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/03\n\n\nConditional Probability, Independence, & Bayes Theorem\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 3: Conditional Probability, Counting & Random Variables\n\n\n\n\n3\n\n\n7/07\n\n\nConditional Probability & Bayes Theorem\n\n\nLab3\nLab3 Solutions\n\n\nWorksheet 3\nWorksheet 3 Solutions\n\n\n\n\n\n\n\n7/08\n\n\nIntro to Counting & Permutations\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/09\n\n\nIntro to Counting & Combinations\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/10\n\n\nDiscrete Random Variables\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/11\n\n\nQuiz 1 (Weeks 1‚Äì2)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 4: Random Variables & Distributions - Confidence Intervals\n\n\n\n\n4\n\n\n7/14\n\n\nContinuous Random Variables & Distributions\n\n\nLab 4\nlab 4 Solutions\n\n\nWorksheet 4\nWorksheet 4 Solutions\n\n\n\n\n\n\n\n7/15\n\n\nContinuous Random Variables & Distributions Continued\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/16\n\n\nContinuous Random Variables & Distributions Wrap Up & Exercises\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/17\n\n\nRandom Variables, Sampling & Intro to Confidence Intervals\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 5: Inference & Statistical Modeling\n\n\n\n\n5\n\n\n7/21\n\n\nSampling Principles and Strategies\n\n\nLab 5\nLab5 Solutions\n\n\nWorksheet 5\nWorksheet 5 Solutions\n\n\n\n\n\n\n\n7/22\n\n\nConfidence Intervals (Means & Proportions)\n\nZ-table, t-table\n\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/23\n\n\nIntro to Hypothesis Testing\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/24\n\n\nHypothesis Testing Continued\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/25\n\n\nQuiz 2 (Weeks 3‚Äì4)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 6: Regression & Course Wrap-Up\n\n\n\n\n6\n\n\n7/28\n\n\nRegression Analysis\n\n\nLab 6\n\n\nWorksheet 6\n\n\n\n\n\n\n\n7/29\n\n\nRegression Diagnostics, Sampling\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/30\n\n\nWrap-Up\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/31\n\n\nQuiz 3 (Weeks 5‚Äì6)\n\n\n‚Äî\n\n\n‚Äî"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html",
    "href": "files/lecture_notes/lecture13/lecture13.html",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Making Decisions with Data: From Questions to Statistical Evidence\n‚ÄúThe goal is not to eliminate uncertainty, but to make informed decisions despite it‚Äù\n\n\n\n\n\n\n\nWhen:\n- üìÖ Date: Friday, July 25\n- ‚è∞ Window: 7 AM ‚Äì 12 AM\n- ‚è≥ Duration: 1 hour once started\nWhere: üíª Online via Canvas\n\n\n\n\n\nFoundation: Logic of hypothesis testing\nPractice: Real examples with Python\nSkills: Making statistical decisions\nApplications: From medicine to marketing\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstand the logic of hypothesis testing\nMaster the language of statistical decisions\nRecognize different types of errors and their consequences\nConnect to confidence intervals from last lecture\n\n\n\n\n\n\nFormulate hypotheses from research questions\nCalculate and interpret p-values correctly\nPerform hypothesis tests in Python\nMake informed decisions using statistical evidence\nCommunicate results effectively\n\n\n\n\n\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nHypothesis testing helps us answer: ‚ÄúIs what we observed in our sample strong enough evidence to conclude something about the population?‚Äù\n\n\n\n\n\n\n                            \n                                            \n\n\nKey Insight: Just like in court, we never ‚Äúprove‚Äù innocence or ‚Äúaccept‚Äù the null hypothesis. We only determine if there‚Äôs sufficient evidence to reject it!\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\nKey Message: P-value tells us ‚ÄúHow surprised should we be by this data if H‚ÇÄ were true?‚Äù\n\n\n\n\n\n\n                            \n                                            \n\n\nBottom Line: There‚Äôs always a trade-off between Type I and Type II errors. Choose Œ± based on which error is more costly in your context!\n\n\n\n\n\n\n                            \n                                            \n\n\nKey Insight: Higher power means you‚Äôre more likely to detect a true effect when it exists. Aim for power ‚â• 0.80!\n\n\n\n\n\n\nResearch Question: A new study technique claims to improve test scores. The current average is 75. We test 25 students using the new method.\n\n\nüìä Sample Data Summary:\n========================================\nSample size (n): 25\nSample mean (xÃÑ): 77.19\nSample std (s): 7.65\nCurrent average (Œº‚ÇÄ): 75\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\nüéØ DETAILED RESULTS:\n==================================================\nTest Statistic: t = 1.432\nP-value: 0.0825\nCritical Value: 1.711\nEffect Size (Cohen's d): 0.286\n\n‚ùå DECISION: Fail to reject H‚ÇÄ\nüìä CONCLUSION: There is insufficient evidence (p = 0.0825) that the new study method improves test scores.\nüí° PRACTICAL IMPACT: The observed difference could reasonably be due to chance.\n\n\n\n\n\n\n\nüêç PYTHON IMPLEMENTATION:\n========================================\nMethod 1: scipy.stats.ttest_1samp\nt-statistic: 1.432\np-value (two-tailed): 0.1650\np-value (one-tailed): 0.0825\n\nMethod 2: Manual with 95% Confidence Interval\n95% CI: (74.03, 80.35)\nInterpretation: We're 95% confident the true mean is between 74.0 and 80.4\n\nEffect Size (Cohen's d): 0.286\nEffect size interpretation: small effect\n\n\n\n\n\n\n\n\n\nResearch Question: Compare effectiveness of two teaching methods\n\n\nüìä TWO-GROUP COMPARISON:\n========================================\nMethod A (Traditional):\n  n = 30, mean = 75.45, std = 11.87\n\nMethod B (New):\n  n = 28, mean = 82.72, std = 14.82\n\nDifference in means: 7.27 points\n\n\n\n\n\n\n\n\n                            \n                                            \n\n\nüîë KEY LESSON: Statistical Significance ‚â† Practical Importance\n============================================================\nLeft: Tiny effect (0.02) but significant due to large sample\nRight: Large effect (8.7) but significant with small sample\n\nüí° Always consider BOTH statistical significance AND effect size!\n\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n# =============================================================================\n# COMPLETE HYPOTHESIS TESTING TOOLKIT\n# =============================================================================\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# -----------------------------------------------------------------------------\n# Template 1: One-Sample t-test\n# -----------------------------------------------------------------------------\ndef one_sample_ttest(data, null_value, alpha=0.05, alternative='two-sided'):\n    \"\"\"\n    Perform one-sample t-test with complete analysis\n    \n    Parameters:\n    -----------\n    data : array-like\n        Sample data\n    null_value : float\n        Hypothesized population mean\n    alpha : float\n        Significance level (default 0.05)\n    alternative : str\n        'two-sided', 'greater', or 'less'\n    \"\"\"\n    \n    # Calculate statistics\n    n = len(data)\n    x_bar = np.mean(data)\n    s = np.std(data, ddof=1)\n    se = s / np.sqrt(n)\n    \n    # Test statistic\n    t_stat = (x_bar - null_value) / se\n    df = n - 1\n    \n    # P-value calculation\n    if alternative == 'two-sided':\n        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    elif alternative == 'greater':\n        p_value = 1 - stats.t.cdf(t_stat, df)\n    elif alternative == 'less':\n        p_value = stats.t.cdf(t_stat, df)\n    \n    # Effect size (Cohen's d)\n    cohens_d = (x_bar - null_value) / s\n    \n    # Confidence interval\n    t_crit = stats.t.ppf(1 - alpha/2, df)\n    ci_lower = x_bar - t_crit * se\n    ci_upper = x_bar + t_crit * se\n    \n    # Results\n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'confidence_interval': (ci_lower, ci_upper),\n        'reject_null': p_value &lt;= alpha,\n        'sample_mean': x_bar,\n        'sample_std': s,\n        'sample_size': n\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 2: Two-Sample t-test\n# -----------------------------------------------------------------------------\ndef two_sample_ttest(group1, group2, alpha=0.05, equal_var=True):\n    \"\"\"\n    Perform two-sample t-test with complete analysis\n    \"\"\"\n    \n    # Calculate statistics\n    n1, n2 = len(group1), len(group2)\n    mean1, mean2 = np.mean(group1), np.mean(group2)\n    s1, s2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n    \n    if equal_var:\n        # Pooled variance\n        pooled_var = ((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2)\n        se = np.sqrt(pooled_var * (1/n1 + 1/n2))\n        df = n1 + n2 - 2\n    else:\n        # Welch's t-test\n        se = np.sqrt(s1**2/n1 + s2**2/n2)\n        df = (s1**2/n1 + s2**2/n2)**2 / ((s1**2/n1)**2/(n1-1) + (s2**2/n2)**2/(n2-1))\n    \n    # Test statistic\n    t_stat = (mean1 - mean2) / se\n    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    \n    # Effect size (Cohen's d)\n    if equal_var:\n        pooled_std = np.sqrt(pooled_var)\n    else:\n        pooled_std = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2))\n    \n    cohens_d = (mean1 - mean2) / pooled_std\n    \n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'reject_null': p_value &lt;= alpha,\n        'group1_stats': {'mean': mean1, 'std': s1, 'n': n1},\n        'group2_stats': {'mean': mean2, 'std': s2, 'n': n2}\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 3: Power Analysis\n# -----------------------------------------------------------------------------\ndef power_analysis(effect_size, alpha=0.05, power=0.8):\n    \"\"\"\n    Calculate required sample size for desired power\n    \"\"\"\n    from scipy.stats import norm\n    \n    z_alpha = norm.ppf(1 - alpha/2)\n    z_beta = norm.ppf(power)\n    \n    n = ((z_alpha + z_beta) / effect_size) ** 2\n    \n    return int(np.ceil(n))\n\n# -----------------------------------------------------------------------------\n# Example Usage\n# -----------------------------------------------------------------------------\n\n# Generate sample data\nnp.random.seed(42)\nsample_data = np.random.normal(105, 15, 25)\n\n# Perform one-sample t-test\nresults = one_sample_ttest(sample_data, null_value=100, alternative='greater')\n\nprint(\"One-Sample t-test Results:\")\nprint(f\"Test statistic: {results['test_statistic']:.3f}\")\nprint(f\"P-value: {results['p_value']:.4f}\")\nprint(f\"Effect size (d): {results['effect_size']:.3f}\")\nprint(f\"95% CI: ({results['confidence_interval'][0]:.2f}, {results['confidence_interval'][1]:.2f})\")\nprint(f\"Reject null: {results['reject_null']}\")\n\n# Power analysis\nrequired_n = power_analysis(effect_size=0.5, power=0.8)\nprint(f\"\\nRequired sample size for d=0.5, power=0.8: {required_n}\")\n\n\n\n\n\n\n\n\n\n\nHypothesis testing provides a framework for making decisions under uncertainty\nP-values quantify how surprising our data would be if H‚ÇÄ were true\nStatistical significance ‚â† practical importance - always consider effect size\nType I and II errors represent different kinds of mistakes with different costs\nPower is the ability to detect true effects when they exist\n\n\n\n\n\n\nPlan before you analyze - specify hypotheses and Œ± level in advance\nCheck assumptions and use appropriate tests\nReport effect sizes and confidence intervals, not just p-values\nConsider practical significance alongside statistical significance\nBe honest about limitations and acknowledge uncertainty"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#quick-announcements",
    "href": "files/lecture_notes/lecture13/lecture13.html#quick-announcements",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "When:\n- üìÖ Date: Friday, July 25\n- ‚è∞ Window: 7 AM ‚Äì 12 AM\n- ‚è≥ Duration: 1 hour once started\nWhere: üíª Online via Canvas\n\n\n\n\n\nFoundation: Logic of hypothesis testing\nPractice: Real examples with Python\nSkills: Making statistical decisions\nApplications: From medicine to marketing"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#learning-journey-today",
    "href": "files/lecture_notes/lecture13/lecture13.html#learning-journey-today",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Understand the logic of hypothesis testing\nMaster the language of statistical decisions\nRecognize different types of errors and their consequences\nConnect to confidence intervals from last lecture\n\n\n\n\n\n\nFormulate hypotheses from research questions\nCalculate and interpret p-values correctly\nPerform hypothesis tests in Python\nMake informed decisions using statistical evidence\nCommunicate results effectively"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#what-is-hypothesis-testing",
    "href": "files/lecture_notes/lecture13/lecture13.html#what-is-hypothesis-testing",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Hypothesis testing helps us answer: ‚ÄúIs what we observed in our sample strong enough evidence to conclude something about the population?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#the-courtroom-analogy",
    "href": "files/lecture_notes/lecture13/lecture13.html#the-courtroom-analogy",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Key Insight: Just like in court, we never ‚Äúprove‚Äù innocence or ‚Äúaccept‚Äù the null hypothesis. We only determine if there‚Äôs sufficient evidence to reject it!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#understanding-p-values",
    "href": "files/lecture_notes/lecture13/lecture13.html#understanding-p-values",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Key Message: P-value tells us ‚ÄúHow surprised should we be by this data if H‚ÇÄ were true?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#types-of-errors-the-trade-off",
    "href": "files/lecture_notes/lecture13/lecture13.html#types-of-errors-the-trade-off",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Bottom Line: There‚Äôs always a trade-off between Type I and Type II errors. Choose Œ± based on which error is more costly in your context!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#statistical-power-detecting-true-effects",
    "href": "files/lecture_notes/lecture13/lecture13.html#statistical-power-detecting-true-effects",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Key Insight: Higher power means you‚Äôre more likely to detect a true effect when it exists. Aim for power ‚â• 0.80!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#example-1-one-sample-t-test",
    "href": "files/lecture_notes/lecture13/lecture13.html#example-1-one-sample-t-test",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Research Question: A new study technique claims to improve test scores. The current average is 75. We test 25 students using the new method.\n\n\nüìä Sample Data Summary:\n========================================\nSample size (n): 25\nSample mean (xÃÑ): 77.19\nSample std (s): 7.65\nCurrent average (Œº‚ÇÄ): 75\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\nüéØ DETAILED RESULTS:\n==================================================\nTest Statistic: t = 1.432\nP-value: 0.0825\nCritical Value: 1.711\nEffect Size (Cohen's d): 0.286\n\n‚ùå DECISION: Fail to reject H‚ÇÄ\nüìä CONCLUSION: There is insufficient evidence (p = 0.0825) that the new study method improves test scores.\nüí° PRACTICAL IMPACT: The observed difference could reasonably be due to chance.\n\n\n\n\n\n\n\nüêç PYTHON IMPLEMENTATION:\n========================================\nMethod 1: scipy.stats.ttest_1samp\nt-statistic: 1.432\np-value (two-tailed): 0.1650\np-value (one-tailed): 0.0825\n\nMethod 2: Manual with 95% Confidence Interval\n95% CI: (74.03, 80.35)\nInterpretation: We're 95% confident the true mean is between 74.0 and 80.4\n\nEffect Size (Cohen's d): 0.286\nEffect size interpretation: small effect"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#example-2-two-sample-t-test",
    "href": "files/lecture_notes/lecture13/lecture13.html#example-2-two-sample-t-test",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Research Question: Compare effectiveness of two teaching methods\n\n\nüìä TWO-GROUP COMPARISON:\n========================================\nMethod A (Traditional):\n  n = 30, mean = 75.45, std = 11.87\n\nMethod B (New):\n  n = 28, mean = 82.72, std = 14.82\n\nDifference in means: 7.27 points"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#statistical-vs-practical-significance",
    "href": "files/lecture_notes/lecture13/lecture13.html#statistical-vs-practical-significance",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "üîë KEY LESSON: Statistical Significance ‚â† Practical Importance\n============================================================\nLeft: Tiny effect (0.02) but significant due to large sample\nRight: Large effect (8.7) but significant with small sample\n\nüí° Always consider BOTH statistical significance AND effect size!"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#python-code-templates",
    "href": "files/lecture_notes/lecture13/lecture13.html#python-code-templates",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "# =============================================================================\n# COMPLETE HYPOTHESIS TESTING TOOLKIT\n# =============================================================================\n\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# -----------------------------------------------------------------------------\n# Template 1: One-Sample t-test\n# -----------------------------------------------------------------------------\ndef one_sample_ttest(data, null_value, alpha=0.05, alternative='two-sided'):\n    \"\"\"\n    Perform one-sample t-test with complete analysis\n    \n    Parameters:\n    -----------\n    data : array-like\n        Sample data\n    null_value : float\n        Hypothesized population mean\n    alpha : float\n        Significance level (default 0.05)\n    alternative : str\n        'two-sided', 'greater', or 'less'\n    \"\"\"\n    \n    # Calculate statistics\n    n = len(data)\n    x_bar = np.mean(data)\n    s = np.std(data, ddof=1)\n    se = s / np.sqrt(n)\n    \n    # Test statistic\n    t_stat = (x_bar - null_value) / se\n    df = n - 1\n    \n    # P-value calculation\n    if alternative == 'two-sided':\n        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    elif alternative == 'greater':\n        p_value = 1 - stats.t.cdf(t_stat, df)\n    elif alternative == 'less':\n        p_value = stats.t.cdf(t_stat, df)\n    \n    # Effect size (Cohen's d)\n    cohens_d = (x_bar - null_value) / s\n    \n    # Confidence interval\n    t_crit = stats.t.ppf(1 - alpha/2, df)\n    ci_lower = x_bar - t_crit * se\n    ci_upper = x_bar + t_crit * se\n    \n    # Results\n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'confidence_interval': (ci_lower, ci_upper),\n        'reject_null': p_value &lt;= alpha,\n        'sample_mean': x_bar,\n        'sample_std': s,\n        'sample_size': n\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 2: Two-Sample t-test\n# -----------------------------------------------------------------------------\ndef two_sample_ttest(group1, group2, alpha=0.05, equal_var=True):\n    \"\"\"\n    Perform two-sample t-test with complete analysis\n    \"\"\"\n    \n    # Calculate statistics\n    n1, n2 = len(group1), len(group2)\n    mean1, mean2 = np.mean(group1), np.mean(group2)\n    s1, s2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n    \n    if equal_var:\n        # Pooled variance\n        pooled_var = ((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2)\n        se = np.sqrt(pooled_var * (1/n1 + 1/n2))\n        df = n1 + n2 - 2\n    else:\n        # Welch's t-test\n        se = np.sqrt(s1**2/n1 + s2**2/n2)\n        df = (s1**2/n1 + s2**2/n2)**2 / ((s1**2/n1)**2/(n1-1) + (s2**2/n2)**2/(n2-1))\n    \n    # Test statistic\n    t_stat = (mean1 - mean2) / se\n    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n    \n    # Effect size (Cohen's d)\n    if equal_var:\n        pooled_std = np.sqrt(pooled_var)\n    else:\n        pooled_std = np.sqrt(((n1-1)*s1**2 + (n2-1)*s2**2) / (n1+n2-2))\n    \n    cohens_d = (mean1 - mean2) / pooled_std\n    \n    results = {\n        'test_statistic': t_stat,\n        'p_value': p_value,\n        'degrees_of_freedom': df,\n        'effect_size': cohens_d,\n        'reject_null': p_value &lt;= alpha,\n        'group1_stats': {'mean': mean1, 'std': s1, 'n': n1},\n        'group2_stats': {'mean': mean2, 'std': s2, 'n': n2}\n    }\n    \n    return results\n\n# -----------------------------------------------------------------------------\n# Template 3: Power Analysis\n# -----------------------------------------------------------------------------\ndef power_analysis(effect_size, alpha=0.05, power=0.8):\n    \"\"\"\n    Calculate required sample size for desired power\n    \"\"\"\n    from scipy.stats import norm\n    \n    z_alpha = norm.ppf(1 - alpha/2)\n    z_beta = norm.ppf(power)\n    \n    n = ((z_alpha + z_beta) / effect_size) ** 2\n    \n    return int(np.ceil(n))\n\n# -----------------------------------------------------------------------------\n# Example Usage\n# -----------------------------------------------------------------------------\n\n# Generate sample data\nnp.random.seed(42)\nsample_data = np.random.normal(105, 15, 25)\n\n# Perform one-sample t-test\nresults = one_sample_ttest(sample_data, null_value=100, alternative='greater')\n\nprint(\"One-Sample t-test Results:\")\nprint(f\"Test statistic: {results['test_statistic']:.3f}\")\nprint(f\"P-value: {results['p_value']:.4f}\")\nprint(f\"Effect size (d): {results['effect_size']:.3f}\")\nprint(f\"95% CI: ({results['confidence_interval'][0]:.2f}, {results['confidence_interval'][1]:.2f})\")\nprint(f\"Reject null: {results['reject_null']}\")\n\n# Power analysis\nrequired_n = power_analysis(effect_size=0.5, power=0.8)\nprint(f\"\\nRequired sample size for d=0.5, power=0.8: {required_n}\")"
  },
  {
    "objectID": "files/lecture_notes/lecture13/lecture13.html#summary-key-takeaways",
    "href": "files/lecture_notes/lecture13/lecture13.html#summary-key-takeaways",
    "title": "Hypothesis Testing: Making Decisions with Data",
    "section": "",
    "text": "Hypothesis testing provides a framework for making decisions under uncertainty\nP-values quantify how surprising our data would be if H‚ÇÄ were true\nStatistical significance ‚â† practical importance - always consider effect size\nType I and II errors represent different kinds of mistakes with different costs\nPower is the ability to detect true effects when they exist\n\n\n\n\n\n\nPlan before you analyze - specify hypotheses and Œ± level in advance\nCheck assumptions and use appropriate tests\nReport effect sizes and confidence intervals, not just p-values\nConsider practical significance alongside statistical significance\nBe honest about limitations and acknowledge uncertainty"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "",
    "text": "Introduction to Probability\nUnderstanding uncertainty through statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#welcome-to-lecture-4",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#welcome-to-lecture-4",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Welcome to Lecture 4",
    "text": "Welcome to Lecture 4\nIntroduction to Probability\nUnderstanding uncertainty through statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-objectives",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities\nDetermine when events are independent\nUse Bayes‚Äô theorem in simple applications"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-prob",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-prob",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is Probability?",
    "text": "What is Probability?\n\nüéØ Definition\nProbability is a measure of the likelihood that an event will occur"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-range",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-range",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Range",
    "text": "Probability Range\n\n\n\nRanges from 0 to 1 (or 0% to 100%)\n0: Event will never occur (impossible)\n1: Event will certainly occur (certain)\n0.5: Event has equal chance of occurring or not"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#three-ways-to-express-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#three-ways-to-express-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Three Ways to Express Probability",
    "text": "Three Ways to Express Probability\n\nFraction: \\(\\frac{1}{2}\\), \\(\\frac{3}{4}\\), \\(\\frac{2}{6}\\)\nDecimal: 0.5, 0.75, 0.33\nPercentage: 50%, 75%, 33%"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example",
    "text": "Example\nWhen we roll a die, there are six possible outcomes:\n1, 2, 3, 4, 5, 6.\nThe probability of any of them turning up is 1/6 or 16%."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#why-study-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#why-study-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Why Study Probability?",
    "text": "Why Study Probability?\nProbability helps us:\n\nMake decisions under uncertainty\nUnderstand random processes\nAnalyze data and draw conclusions\nModel real-world phenomena\nAssess risk and likelihood\n\n\n\nApplications: Weather forecasting, medical diagnosis, finance, quality control, gaming, insurance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#random-experiments",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#random-experiments",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Random Experiments",
    "text": "Random Experiments\nA random experiment is a process that:\n\nCan be repeated under similar conditions\nHas multiple possible outcomes\nThe outcome cannot be predicted with certainty\n\n\n\nExamples\n\nü™ô Flipping a coin\nüé≤ Rolling a die\nüÉè Drawing a card from a deck\nüí° Measuring the lifetime of a light bulb"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space",
    "text": "Sample Space\n\nüéØ Definition The sample space (denoted \\(S\\) or \\(\\Omega\\)) is the set of all possible outcomes of a random experiment"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space-examples",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space Examples",
    "text": "Sample Space Examples\n\nCoin flip: \\(S = \\{H, T\\}\\)\nTwo coin flips: \\(S = \\{HH, HT, TH, TT\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#types-of-sample-spaces",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#types-of-sample-spaces",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Types of Sample Spaces",
    "text": "Types of Sample Spaces\n\n\nFinite Sample Space\n\nLimited number of outcomes\n\nExample: Rolling a die\n\n\n\n\n\n\n\n\n\n\n\nInfinite Sample Space\n\nUnlimited outcomes (countable or uncountable)\n\nExample: Measuring exact height of students"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#events",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Events",
    "text": "Events\n\nüéØ Definition An event is a subset of the sample space\n\nSimple event: Contains exactly one outcome (Ex: \\(A = \\{3\\}\\) (rolling a 3))\nCompound event: Contains multiple outcomes (Ex: \\(B = \\{2, 4, 6\\}\\) (rolling an even number))"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#event-notation",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#event-notation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Event Notation",
    "text": "Event Notation\nFor a die roll with \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (rolling an odd number)\n\\(B = \\{4, 5, 6\\}\\) (rolling 4 or higher)\n\\(C = \\{6\\}\\) (rolling a six)\n\n\n\nWe can describe events in words or using set notation"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#set-operations-overview",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#set-operations-overview",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Set Operations Overview",
    "text": "Set Operations Overview\n\n\n\n\nüéØ Definition:\n\nSet: Collection of distinct objects\nUnion: A OR B occurs\n\nIntersection: A AND B occurs\nComplement: A does NOT occur\nSample Space: All possible outcomes"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#what-is-a-set",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#what-is-a-set",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is a Set?",
    "text": "What is a Set?\n\n\n\n\nüéØ Definition: A collection of things that share common characteristics. They can be elements, members, objects or similar terms.\nExamples:\n\nSet of even numbers:\n\n{2, 4, 6, 8, ‚Ä¶}\n\nSet of vowels: {a, e, i, o, u}"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#union-a-b",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#union-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Union: A ‚à™ B",
    "text": "Union: A ‚à™ B\n\n\n\n\nüéØ Definition: Contains all set elements, including intersections.\nIn Probability: The event that A OR B occurs (or both).\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#intersection-a-b",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#intersection-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Intersection: A ‚à© B",
    "text": "Intersection: A ‚à© B\n\n\n\n\nüéØ Definition: Area where two or more sets overlap.\nIn Probability: The event that A AND B occurs.\nProperties:\n\nAlways smaller than or equal to individual sets\nCan be empty (disjoint sets)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#absolute-complement-ac",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#absolute-complement-ac",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Absolute Complement: \\(A^c\\)",
    "text": "Absolute Complement: \\(A^c\\)\n\n\n\nüéØ Definition: All elements that do not belong to the set.\nIn Probability: The event that A does NOT occur.\n\n\\(P(A^c) = 1 - P(A)\\)\n\nKey Property:\n\n\\(A \\cup A^c = S\\) (Sample Space)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#summary-table",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#summary-table",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Summary Table",
    "text": "Summary Table\n\n\n\n\n\n\n\n\n\nOperation\nSymbol\nMeaning\nProbability\n\n\n\n\nUnion\n\\(A \\cup B\\)\nOccurs if \\(A\\) or \\(B\\)\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\nIntersection\n\\(A \\cap B\\)\nOccurs if \\(A\\) and \\(B\\)\n\\(P(A \\cap B)\\)\n\n\nComplement\n\\(A^c\\)\nOccurs if \\(A\\) does not occur\n\\(P(A^c) = 1 - P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-commutative",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-commutative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Commutative",
    "text": "Probability Axioms: Commutative\n\nCommutative\n\\(A \\cup B = B \\cup A\\)\n\\(A \\cap B = B \\cap A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-associative",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-associative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Associative",
    "text": "Probability Axioms: Associative\n\nAssociative\n\\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\)\n\\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-distributive",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-distributive",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Distributive",
    "text": "Probability Axioms: Distributive\n\nDistributive\n\\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\n\\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-de-morgans-laws",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-de-morgans-laws",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: De Morgan‚Äôs Laws",
    "text": "Probability Axioms: De Morgan‚Äôs Laws\n\nDe Morgan‚Äôs Laws\n\\((A \\cup B)^c = A^c \\cap B^c\\)\n\\((A \\cap B)^c = A^c \\cup B^c\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-examples",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Examples",
    "text": "Practice Examples\n\nExample 1: In a class of students:\n\nSet A = Students who like Math\nSet B = Students who like Science\n\nQ: What does A ‚à™ B represent?\n\n\n\nSolution. Students who like Math OR Science (or both)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#example-set-operations",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#example-set-operations",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example: Set Operations",
    "text": "Example: Set Operations\n\n\nFor die roll \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (odd numbers)\n\\(B = \\{4, 5, 6\\}\\) (4 or higher)\n\n\n\n\nFind:\n\n\\(A \\cup B\\)\n\\(A \\cap B\\)\n\\(A^c\\)\n\n\n\n\n\nSolution. \n\n\\(A \\cup B = \\{1, 3, 4, 5, 6\\}\\)\n\\(A \\cap B = \\{5\\}\\)\n\\(A^c = \\{2, 4, 6\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-events",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive Events",
    "text": "Mutually Exclusive Events\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive (or disjoint) if they cannot occur simultaneously\n\\[A \\cap B = \\emptyset\\]\n\n\n\nWhen rolling a die\n\n\\(A = \\{1, 3, 5\\}\\) (odd)\n\\(B = \\{2, 4, 6\\}\\) (even)\n\n\\(A\\) and \\(B\\) are mutually exclusive"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#the-classical-definition-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#the-classical-definition-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Classical Definition of Probability",
    "text": "The Classical Definition of Probability\n\nüéØ Definition: For equally likely outcomes:\n\\[P(A) = \\frac{\\text{Number of outcomes in } A}{\\text{Total number of outcomes in } S}\\]\n\n\nProbability of rolling an even number on a fair die\n\n\n\\[P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#properties-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#properties-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Properties of Probability",
    "text": "Properties of Probability\n\nNon-negativity: \\(P(A) \\geq 0\\) for any event \\(A\\)\nNormalization: \\(P(S) = 1\\)\nAdditivity: If \\(A\\) and \\(B\\) are mutually exclusive, then\n\n\n\\[P(A \\cup B) = P(A) + P(B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#the-complement-rule",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#the-complement-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Complement Rule",
    "text": "The Complement Rule\n\n\\[P(A) + P(A^c) = 1\\]\n\\[P(A^c) = 1 - P(A)\\]\n\n\n\nIf the probability of rain is 0.3, what‚Äôs the probability of no rain?\n\n\n\n\nSolution. \\[P(\\text{no rain}) = 1 - P(\\text{rain}) = 1 - 0.3 = 0.7\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-1",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\n\n\n\nA standard deck has 52 cards. What is the probability of drawing:\n\nA heart \\(\\heartsuit\\)?\nA face card (Jack, Queen, King)?\nThe ace of spades \\(\\spadesuit\\)?\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{heart}) = \\frac{13}{52} = \\frac{1}{4}\\)\n\\(P(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\\)\n\\(P(\\text{ace of spades}) = \\frac{1}{52}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#the-addition-rule",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#the-addition-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Addition Rule",
    "text": "The Addition Rule\nFor any two events \\(A\\) and \\(B\\):\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\n\nWhy subtract \\(P(A \\cap B)\\)?\n\n\n\nSolution. We don‚Äôt want to double-count outcomes that are in both events"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#addition-rule-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#addition-rule-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Addition Rule Example",
    "text": "Addition Rule Example\n\n\n\n\nDrawing from a standard deck:\n\n\\(A\\): Drawing a heart \\(\\heartsuit\\) (\\(P(A) = \\frac{13}{52}\\))\n\\(B\\): Drawing a face card (\\(P(B) = \\frac{12}{52}\\))\nWhat‚Äôs \\(P(A \\cup B)\\) (heart OR face card)?"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\n\n\n\nüéØConditional probability is the probability of event \\(A\\) given that event \\(B\\) has occurred\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nprovided \\(P(B) &gt; 0\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-interpretation",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-interpretation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Interpretation",
    "text": "Conditional Probability Interpretation\n\\(P(A|B)\\) means:\n\nWe know event  \\(B\\) has occurred \nWhat‚Äôs the probability that \\(A\\) also occurred?\nWe ‚Äúrestrict‚Äù our sample space to only outcomes in \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Example",
    "text": "Conditional Probability Example\n\n\n\nDrawing a card from a standard deck:\n\n\\(A\\): Card is a heart \\(\\heartsuit\\)\n\\(B\\): Card is red\nQ: Find \\(P(A|B)\\)\n\n\n\n\n\n\nSolution. \\(P(A \\cap B) = P(\\text{heart}) = \\frac{13}{52}\\)\n\\(P(B) = P(\\text{red}) = \\frac{26}{52}\\)\n\\(P(A|B) = \\frac{13/52}{26/52} = \\frac{13}{26} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#independence",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#independence",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\nüéØ Definition Events \\(A\\) and \\(B\\) are independent if:\n\\[P(A|B) = P(A)\\]\nor equivalently:\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\n\n\nKnowing that \\(B\\) occurred doesn‚Äôt change the probability of \\(A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#independence-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#independence-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence Example",
    "text": "Independence Example\n\nTwo coin flips:\n\n\\(A\\): First flip is heads\n\\(B\\): Second flip is heads\n\nQ: Are \\(A\\) and \\(B\\) independent?\n\n\n\nSolution. \\(P(A) = \\frac{1}{2}\\), \\(P(B) = \\frac{1}{2}\\)\n\\(P(A \\cap B) = P(\\text{HH}) = \\frac{1}{4}\\)\n\\(P(A) \\times P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\)\nYes, they are independent!"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.¬†Independent",
    "text": "Mutually Exclusive vs.¬†Independent\n\nMutually Exclusive (left): the circles A and B do not overlap, so \\(P(A\\cap B)=0\\).\nIndependent (right): the circles overlap, and we‚Äôve sized the intersection so that \\(P(A\\cap B)=P(A)\\,P(B)\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.¬†Independent Example",
    "text": "Mutually Exclusive vs.¬†Independent Example\n\n\n\nDraw a single card from a 52-card deck:\n\nLet A={‚Äúdraw an Ace‚Äù}, so P(A)=4/52.\nLet B={‚Äúdraw a King‚Äù}, so P(B)=4/52.\n\nQ: What is \\(P(A\\cap B)\\) ?\n\n\n\n\n\nSolution. They‚Äôre disjoint (you can‚Äôt draw an Ace and a King), so \\(P(A\\cap B) = 0\\).\nBut \\(P(A)\\,P(B) = \\frac{4}{52}\\times\\frac{4}{52} = \\frac{16}{2704} \\neq 0\\).\nHence, \\(P(A\\cap B)\\neq P(A)P(B)\\), so they‚Äôre not independent."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#multiplication-rule",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#multiplication-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Multiplication Rule",
    "text": "Multiplication Rule\nGeneral case: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nIndependent events: \\(P(A \\cap B) = P(A) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagrams",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagrams",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\n\nüéØ Definition Tree diagrams help visualize sequential events and calculate probabilities."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagram-examples",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagram-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagram Examples",
    "text": "Tree Diagram Examples"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-2",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-2",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\n\n\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement.\n\nWhat‚Äôs the probability both balls are red?\nWhat‚Äôs the probability the first is red and second is blue?\n\n\n\n\n\nSolution. \n\n\\(P(\\text{both red}) = \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)\n\\(P(\\text{red then blue}) = \\frac{5}{8} \\times \\frac{3}{7} = \\frac{15}{56}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nüéØ Definition\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space, then:\n\\[P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \\cdots + P(A|B_n)P(B_n)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\n\nA factory has two machines:\n\nMachine 1: Produces 60% of items, 5% defective\nMachine 2: Produces 40% of items, 3% defective\n\nQ: What‚Äôs the overall probability an item is defective?\n\n\n\nSolution. \\(P(\\text{defective}) = P(D|M_1)P(M_1) + P(D|M_2)P(M_2)\\)\n\\(= 0.05 \\times 0.6 + 0.03 \\times 0.4 = 0.03 + 0.012 = 0.042\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem",
    "text": "Bayes‚Äô Theorem\n\nüéØ Definition \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\nThis allows us to ‚Äúreverse‚Äù conditional probabilities\nNamed after Thomas Bayes (1701-1761)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-components",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-components",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Components",
    "text": "Bayes‚Äô Theorem Components\n\n\\(A,B\\): Events\n\\(P(A|B)\\): Posterior probability - what we want to find\n\\(P(B|A)\\): Likelihood - given \\(A\\), probability of observing \\(B\\)\n\\(P(A)\\): Prior probability - initial probability of \\(A\\)\n\\(P(B)\\): Marginal probability - total probability of \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Example",
    "text": "Bayes‚Äô Theorem Example\n\n\n\nMedical test for a disease: 1\n\nDisease affects 1% of population\nTest is 95% accurate for sick people\nTest is 90% accurate for healthy people\n\nQ:If someone tests positive, what‚Äôs the probability they have the disease?\n\n\n\n\n\\(P(\\neg D \\,\\wedge\\, \\text{Negative})\n\\;=\\;P(\\neg D)\\times P(\\text{Negative}\\mid \\neg D)\n\\;=\\;0.99\\times0.90\n\\;=\\;0.891\\;(89.1\\%)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Solution",
    "text": "Bayes‚Äô Theorem Solution\nLet:\n\n\\(D\\): Person has disease\n\\(T^+\\): Test is positive\n\nGiven:\n\n\\(P(D) = 0.01\\)\n\\(P(T^+|D) = 0.95\\)\n\\(P(T^-|D^c) = 0.90\\), so \\(P(T^+|D^c) = 0.10\\)\n\n\n\nSolution. \\(P(T^+) = P(T^+|D)P(D) + P(T^+|D^c)P(D^c)\\)\n\\(= 0.95 \\times 0.01 + 0.10 \\times 0.99 = 0.1085\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution-cont.",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution-cont.",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Solution (cont.)",
    "text": "Bayes‚Äô Theorem Solution (cont.)\n\\[P(D|T^+) = \\frac{P(T^+|D) \\times P(D)}{P(T^+)} = \\frac{0.95 \\times 0.01}{0.1085} \\approx 0.088\\]\n\n\nSurprising result: Even with a positive test, there‚Äôs only an 8.8% chance of having the disease!\nThis is due to the low base rate of the disease"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nConfusing \\(P(A|B)\\) with \\(P(B|A)\\)\n\n\nProsecutor‚Äôs fallacy is a specific error in interpreting conditional probabilities. Confusing\n\\(P(\\text{Evidence}\\mid\\text{Innocent})\n\\quad\\text{with}\\quad\nP(\\text{Innocent}\\mid\\text{Evidence})\\).\nEx: OJ Simpson Case 1\n\nthe DNA evidence in the O. J. Simpson trial are a classic example of the prosecutor‚Äôs fallacy. Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was ‚Äúone in 170 million,‚Äù then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes-1",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nAssuming independence when events are dependent\nIgnoring base rates (as in the medical test example)\n\n\nBase rate fallacy is when you ignore or underweight the prior probability \\(P(H)\\) of a hypothesis, focusing only on the new evidence \\(E\\).\n\n\nDouble counting in union calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-3",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-3",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nTwo fair dice are rolled. Find:\n\n\\(P(\\text{sum} = 7)\\)\n\\(P(\\text{sum} = 7 | \\text{first die shows 3})\\)\nAre these events independent?\n\n\n\n\nSolution. \n\n6 ways out of 36: \\(P(\\text{sum} = 7) = \\frac{6}{36} = \\frac{1}{6}\\)\nGiven first die is 3, need second die to be 4: \\(P(\\text{sum} = 7 | \\text{first} = 3) = \\frac{1}{6}\\)\nYes, they‚Äôre independent since \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-and-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-and-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Counting and Probability",
    "text": "Counting and Probability\n\nSometimes we need to count outcomes:\n\nMultiplication Principle: If task 1 can be done in \\(m\\) ways and task 2 in \\(n\\) ways, both can be done in \\(m \\times n\\) ways\n\n\nPermutations: Arrangements where order matters \\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\n\nCombinations: Selections where order doesn‚Äôt matter \\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Counting Example",
    "text": "Counting Example\n\nQ: How many ways can you arrange 5 people in a row?\n\n\n\nSolution. This is a permutation: \\(P(5,5) = 5! = 120\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-with-counting",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-with-counting",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability with Counting",
    "text": "Probability with Counting\n\nExample: A committee of 3 people is chosen from 8 people (5 women, 3 men). What‚Äôs the probability all 3 are women?\n\n\n\nSolution. Total ways to choose 3 from 8: \\(\\binom{8}{3} = 56\\)\nWays to choose 3 women from 5: \\(\\binom{5}{3} = 10\\)\nProbability: \\(\\frac{10}{56} = \\frac{5}{28}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#real-world-applications",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#real-world-applications",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Diagnosis: Using Bayes‚Äô theorem for test interpretation\nQuality Control: Probability of defective items\nFinance: Risk assessment and portfolio theory\nSports: Probability of wins, fantasy sports\nInsurance: Calculating premiums based on risk"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#key-formulas-summary",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\nBasic probability: \\(P(A) = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\\)\nComplement: \\(P(A^c) = 1 - P(A)\\)\nAddition: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nConditional: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nIndependence: \\(P(A \\cap B) = P(A) \\times P(B)\\)\nBayes‚Äô: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#problem-solving-strategy",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\nIdentify the sample space and events\nDetermine if events are independent or mutually exclusive\nChoose the appropriate rule or formula\nCalculate step by step\nCheck if your answer makes sense"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\n\nA bag contains 4 red, 3 blue, and 2 green marbles. Three marbles are drawn without replacement.\nFind the probability that: a) All three are red b) No two are the same color c) At least one is blue"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4-solutions",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4-solutions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 4 Solutions",
    "text": "Practice Problem 4 Solutions\n\nSolution. \n\nAll red: \\(\\frac{4}{9} \\times \\frac{3}{8} \\times \\frac{2}{7} = \\frac{24}{504} = \\frac{1}{21}\\)\nDifferent colors: \\(\\frac{4 \\times 3 \\times 2}{9 \\times 8 \\times 7} \\times 3! = \\frac{24 \\times 6}{504} = \\frac{144}{504} = \\frac{2}{7}\\)\nAt least one blue: \\(1 - P(\\text{no blue}) = 1 - \\frac{6 \\times 5 \\times 4}{9 \\times 8 \\times 7} = 1 - \\frac{120}{504} = \\frac{384}{504} = \\frac{16}{21}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#common-questions",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#common-questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Questions",
    "text": "Common Questions\n\nQ1.: ‚ÄúWhy isn‚Äôt \\(P(A \\cup B) = P(A) + P(B)\\) always?‚Äù\nA: We‚Äôd double-count outcomes in both events\nQ2.: ‚ÄúHow do I know if events are independent?‚Äù\nA: Check if \\(P(A|B) = P(A)\\) or if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nQ3.: ‚ÄúWhen do I use Bayes‚Äô theorem?‚Äù\nA: When you want to ‚Äúreverse‚Äù a conditional probability\n\n\nQ3 note (Bayes Example)\n\nForward: I know my test picks up disease 95% of the time ‚áí \\(P(+\\mid D)=0.95\\).\nReverse: I want the chance I really have the disease when the test is positive ‚áí \\(P(D\\mid +)\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#looking-ahead",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#looking-ahead",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture:\n\nRandom Variables and Probability Distributions\nDiscrete vs.¬†continuous random variables\nExpected value and variance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#final-thoughts",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#final-thoughts",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Final Thoughts",
    "text": "Final Thoughts\n\nProbability is the foundation of statistics:\n\nHelps us quantify uncertainty\nProvides tools for making decisions with incomplete information\nEssential for understanding statistical inference\n\n\n\nPractice: The key to mastering probability is working through many problems!"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#questions",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday‚Äôs 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Random Variables and Distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#resources",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#footnotes",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#footnotes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\\(P(\\neg D \\,\\wedge\\, \\text{Negative})\n\\;=\\;P(\\neg D)\\times P(\\text{Negative}\\mid \\neg D)\n\\;=\\;0.99\\times0.90\n\\;=\\;0.891\\;(89.1\\%)\\)‚Ü©Ô∏é\nthe DNA evidence in the O. J. Simpson trial are a classic example of the prosecutor‚Äôs fallacy. Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was ‚Äúone in 170 million,‚Äù then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent.‚Ü©Ô∏é"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html",
    "href": "files/resources/prob_cheat_sheet.html",
    "title": "Probability Rules Cheat Sheet",
    "section": "",
    "text": "Download PDF"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#basic-probability-concepts",
    "href": "files/resources/prob_cheat_sheet.html#basic-probability-concepts",
    "title": "Probability Rules Cheat Sheet",
    "section": "Basic Probability Concepts",
    "text": "Basic Probability Concepts\n\nProbability Definition: \\[P(A) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total number of outcomes}}\\]\nProperties: - \\(0 \\leq P(A) \\leq 1\\) - \\(P(\\emptyset) = 0\\) (impossible event) - \\(P(S) = 1\\) (certain event, where \\(S\\) is sample space)\n\n\nExample: Rolling a fair die, probability of getting an even number:\n\\[P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2} = 0.5\\]\n\n\nPractice: What is the probability of drawing a face card from a standard deck?\nAnswer: \\(P(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#complement-rule",
    "href": "files/resources/prob_cheat_sheet.html#complement-rule",
    "title": "Probability Rules Cheat Sheet",
    "section": "Complement Rule",
    "text": "Complement Rule\n\nFormula: \\[P(A^c) = 1 - P(A)\\] Alternative notation: \\(P(A') = 1 - P(A)\\)\n\nExplanation: The probability that event \\(A\\) does not occur.\n\nIf the probability that Anya will graduate is 0.9, then the probability she will not graduate is:\n\\[P(\\text{not graduate}) = 1 - 0.9 = 0.1\\]\n\n\nIf \\(P(\\text{rain}) = 0.3\\), what is \\(P(\\text{no rain})\\)?\nAnswer: \\(P(\\text{no rain}) = 1 - 0.3 = 0.7\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#addition-rules",
    "href": "files/resources/prob_cheat_sheet.html#addition-rules",
    "title": "Probability Rules Cheat Sheet",
    "section": "Addition Rules",
    "text": "Addition Rules\n\nGeneral Addition Rule (For Any Two Events)\n\nFormula: \\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\nExplanation: We subtract \\(P(A \\cap B)\\) to avoid double-counting the overlap.\n\nIn a class of 24 students, 10 are girls, 11 are A students, and 6 are girls who are A students.\nProbability of selecting a girl or an A student:\n\\[P(\\text{girl or A}) = \\frac{10}{24} + \\frac{11}{24} - \\frac{6}{24} = \\frac{15}{24} = 0.625\\]\n\n\n\nAddition Rule for Mutually Exclusive Events\n\nFormula: \\[P(A \\cup B) = P(A) + P(B)\\] Condition: \\(P(A \\cap B) = 0\\) (events cannot occur simultaneously)\n\n\nProbability of rolling a 2 or 6 on a die:\n\\[P(2 \\text{ or } 6) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6} = 0.333\\]\n\n\nA bag contains 4 red, 3 blue, and 2 green marbles. What‚Äôs the probability of drawing a red or green marble?\nAnswer: \\(P(\\text{red or green}) = \\frac{4}{9} + \\frac{2}{9} = \\frac{6}{9} = \\frac{2}{3}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#multiplication-rules",
    "href": "files/resources/prob_cheat_sheet.html#multiplication-rules",
    "title": "Probability Rules Cheat Sheet",
    "section": "Multiplication Rules",
    "text": "Multiplication Rules\n\nMultiplication Rule for Dependent Events\n\nFormula: \\[P(A \\cap B) = P(A) \\times P(B|A)\\] Alternative: \\(P(A \\cap B) = P(B) \\times P(A|B)\\)\n\n\nDrawing two red cards without replacement from a standard deck:\n\\[P(\\text{red and red}) = \\frac{26}{52} \\times \\frac{25}{51} = 0.245\\]\n\n\n\nMultiplication Rule for Independent Events\n\nFormula: \\[P(A \\cap B) = P(A) \\times P(B)\\] Condition: Events are independent if \\(P(A|B) = P(A)\\)\n\n\nDrawing two red cards with replacement:\n\\[P(\\text{red and red}) = \\frac{26}{52} \\times \\frac{26}{52} = 0.25\\]\n\n\nTwo fair coins are flipped. What‚Äôs the probability of getting two heads?\nAnswer: \\(P(HH) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#conditional-probability",
    "href": "files/resources/prob_cheat_sheet.html#conditional-probability",
    "title": "Probability Rules Cheat Sheet",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nFormula: \\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\] Condition: \\(P(B) &gt; 0\\)\n\nExplanation: The probability of event \\(A\\) occurring given that event \\(B\\) has occurred.\n\nIn a group of 100 people, 60 are employed and 40 are unemployed. Of the employed, 45 are satisfied with their job.\nWhat‚Äôs the probability someone is satisfied given they are employed?\n\\[P(\\text{satisfied} | \\text{employed}) = \\frac{45}{60} = 0.75\\]\n\n\nA card is drawn from a deck. Given that it‚Äôs red, what‚Äôs the probability it‚Äôs a heart?\nAnswer: \\(P(\\text{heart} | \\text{red}) = \\frac{13}{26} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#set-operations-and-probability",
    "href": "files/resources/prob_cheat_sheet.html#set-operations-and-probability",
    "title": "Probability Rules Cheat Sheet",
    "section": "Set Operations and Probability",
    "text": "Set Operations and Probability\n\nUnion (OR): - Symbol: \\(A \\cup B\\) - Meaning: Event \\(A\\) OR event \\(B\\) (or both) occurs - Formula: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\nIntersection (AND): - Symbol: \\(A \\cap B\\) - Meaning: Both events \\(A\\) AND \\(B\\) occur - Formula: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\n\n\nComplement (NOT): - Symbol: \\(A^c\\) or \\(A'\\) - Meaning: Event \\(A\\) does NOT occur - Formula: \\(P(A^c) = 1 - P(A)\\)"
  },
  {
    "objectID": "files/labs/lab4/lab4_v2_sln.html",
    "href": "files/labs/lab4/lab4_v2_sln.html",
    "title": "Lab 4 Solutions: Discrete Random Variables and Distributions",
    "section": "",
    "text": "Setup\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport pandas as pd\n\n# Set up plotting\n%matplotlib inline\nplt.style.use('seaborn-v0_8-whitegrid')\n\n\n\nTask 1 Solution\nProblem: Consider a biased coin where P(Heads) = 0.7 and P(Tails) = 0.3. Let X be a random variable where X = 1 for Heads and X = 0 for Tails.\n\n# Task 1 Solution\n# 1. Create lists for values and probabilities\ncoin_values = [0, 1]  # 0 for Tails, 1 for Heads\ncoin_probabilities = [0.3, 0.7]  # P(Tails) = 0.3, P(Heads) = 0.7\n\nprint(\"Coin Values (X):\", coin_values)\nprint(\"Probabilities:\", coin_probabilities)\n\n# 2. Verify probabilities sum to 1\nprob_sum = sum(coin_probabilities)\nprint(f\"Sum of probabilities: {prob_sum}\")\nprint(f\"Probabilities sum to 1: {prob_sum == 1.0}\")\n\n# 3. Create bar plot\nplt.figure(figsize=(8, 5))\nplt.bar(coin_values, coin_probabilities, alpha=0.7, color='lightcoral', edgecolor='black', width=0.6)\nplt.xlabel('Value (X)')\nplt.ylabel('Probability')\nplt.title('PMF of Biased Coin (P(Heads) = 0.7)')\nplt.xticks([0, 1], ['Tails (0)', 'Heads (1)'])\nplt.ylim(0, 0.8)\nplt.show()\n\nCoin Values (X): [0, 1]\nProbabilities: [0.3, 0.7]\nSum of probabilities: 1.0\nProbabilities sum to 1: True\n\n\n\n\n\n\n\n\n\n\n\nTask 2 Solution\nProblem: Calculate the expected value and variance for the biased coin from Task 1.\n\n# Task 2 Solution\n# Expected value calculation: E[X] = Œ£ k * P(X = k)\nexpected_value = sum(k * p for k, p in zip(coin_values, coin_probabilities))\nprint(f\"Expected value E[X]: {expected_value}\")\n\n# Step-by-step calculation\nprint(\"\\nStep-by-step calculation:\")\nprint(f\"E[X] = 0 √ó P(X=0) + 1 √ó P(X=1)\")\nprint(f\"E[X] = 0 √ó 0.3 + 1 √ó 0.7 = {0*0.3 + 1*0.7}\")\n\n# Variance calculation: Var(X) = E[X¬≤] - (E[X])¬≤\n# First calculate E[X¬≤]\nexpected_x_squared = sum(k**2 * p for k, p in zip(coin_values, coin_probabilities))\nvariance = expected_x_squared - expected_value**2\n\nprint(f\"\\nVariance calculation:\")\nprint(f\"E[X¬≤] = 0¬≤ √ó 0.3 + 1¬≤ √ó 0.7 = {0**2 * 0.3 + 1**2 * 0.7}\")\nprint(f\"Var(X) = E[X¬≤] - (E[X])¬≤ = {expected_x_squared} - ({expected_value})¬≤ = {variance}\")\nprint(f\"Standard deviation: {np.sqrt(variance):.4f}\")\n\n# Verify using theoretical formula for Bernoulli: Var(X) = p(1-p)\ntheoretical_variance = 0.7 * (1 - 0.7)\nprint(f\"\\nVerification using Bernoulli formula: Var(X) = p(1-p) = 0.7 √ó 0.3 = {theoretical_variance}\")\n\nExpected value E[X]: 0.7\n\nStep-by-step calculation:\nE[X] = 0 √ó P(X=0) + 1 √ó P(X=1)\nE[X] = 0 √ó 0.3 + 1 √ó 0.7 = 0.7\n\nVariance calculation:\nE[X¬≤] = 0¬≤ √ó 0.3 + 1¬≤ √ó 0.7 = 0.7\nVar(X) = E[X¬≤] - (E[X])¬≤ = 0.7 - (0.7)¬≤ = 0.21000000000000002\nStandard deviation: 0.4583\n\nVerification using Bernoulli formula: Var(X) = p(1-p) = 0.7 √ó 0.3 = 0.21000000000000002\n\n\n\n\nTask 3 Solution\nProblem: A basketball player makes 70% of their free throws. They take 15 free throws.\n\n# Task 3 Solution\n# This is a binomial distribution with n=15, p=0.7\nn = 15\np = 0.7\n\nbinom = stats.binom(n, p)\n\n# 1. Probability of making exactly 10 free throws\nprob_exactly_10 = binom.pmf(10)\nprint(f\"1. P(X = 10) = {prob_exactly_10:.4f}\")\n\n# 2. Probability of making at least 12 free throws\nprob_at_least_12 = 1 - binom.cdf(11)  # P(X ‚â• 12) = 1 - P(X ‚â§ 11)\n# Alternative: prob_at_least_12 = sum(binom.pmf(k) for k in range(12, 16))\nprint(f\"2. P(X ‚â• 12) = {prob_at_least_12:.4f}\")\n\n# 3. Expected number of free throws made\nexpected_makes = binom.mean()\nprint(f\"3. Expected number of makes: {expected_makes}\")\nprint(f\"   (Theoretical: n√óp = {n}√ó{p} = {n*p})\")\n\n# 4. Create bar plot showing PMF\nk_values = range(0, n+1)\nprobabilities = [binom.pmf(k) for k in k_values]\n\nplt.figure(figsize=(12, 6))\nplt.bar(k_values, probabilities, alpha=0.7, color='lightgreen', edgecolor='black')\nplt.xlabel('Number of Successful Free Throws')\nplt.ylabel('Probability')\nplt.title(f'Binomial Distribution: Basketball Free Throws (n={n}, p={p})')\nplt.axvline(x=expected_makes, color='red', linestyle='--', linewidth=2, label=f'Expected Value = {expected_makes}')\nplt.legend()\nplt.show()\n\nprint(f\"\\nSummary Statistics:\")\nprint(f\"Mean: {binom.mean()}\")\nprint(f\"Variance: {binom.var()}\")\nprint(f\"Standard Deviation: {binom.std():.4f}\")\n\n1. P(X = 10) = 0.2061\n2. P(X ‚â• 12) = 0.2969\n3. Expected number of makes: 10.5\n   (Theoretical: n√óp = 15√ó0.7 = 10.5)\n\n\n\n\n\n\n\n\n\n\nSummary Statistics:\nMean: 10.5\nVariance: 3.1500000000000012\nStandard Deviation: 1.7748\n\n\n\n\nTask 4 Solution\nProblem: A call center receives an average of 5 calls per minute.\n\n# Task 4 Solution\n# This is a Poisson distribution with Œª = 5\nlam = 5\npoisson = stats.poisson(lam)\n\n# 1. Probability of receiving exactly 7 calls\nprob_exactly_7 = poisson.pmf(7)\nprint(f\"1. P(X = 7) = {prob_exactly_7:.4f}\")\n\n# 2. Probability of receiving no calls\nprob_no_calls = poisson.pmf(0)\nprint(f\"2. P(X = 0) = {prob_no_calls:.4f}\")\n\n# 3. Probability of receiving more than 8 calls\nprob_more_than_8 = 1 - poisson.cdf(8)  # P(X &gt; 8) = 1 - P(X ‚â§ 8)\nprint(f\"3. P(X &gt; 8) = {prob_more_than_8:.4f}\")\n\n# 4. Plot PMF for k = 0 to 15\nk_values = range(0, 16)\nprobabilities = [poisson.pmf(k) for k in k_values]\n\nplt.figure(figsize=(12, 6))\nplt.bar(k_values, probabilities, alpha=0.7, color='purple', edgecolor='black')\nplt.xlabel('Number of Calls per Minute')\nplt.ylabel('Probability')\nplt.title(f'Poisson Distribution: Call Center (Œª = {lam})')\nplt.axvline(x=lam, color='red', linestyle='--', linewidth=2, label=f'Expected Value = {lam}')\nplt.legend()\nplt.show()\n\nprint(f\"\\nSummary Statistics:\")\nprint(f\"Expected value (Œª): {poisson.mean()}\")\nprint(f\"Variance (Œª): {poisson.var()}\")\nprint(f\"Standard Deviation: {poisson.std():.4f}\")\n\n1. P(X = 7) = 0.1044\n2. P(X = 0) = 0.0067\n3. P(X &gt; 8) = 0.0681\n\n\n\n\n\n\n\n\n\n\nSummary Statistics:\nExpected value (Œª): 5.0\nVariance (Œª): 5.0\nStandard Deviation: 2.2361\n\n\n\n\nTask 5 Solution\nProblem: Distribution Identification Practice\n\n# Task 5 Solutions\n\nprint(\"=== SCENARIO A ===\")\nprint(\"Flip a fair coin 20 times. Probability of exactly 12 heads?\")\nprint(\"Distribution: Binomial(n=20, p=0.5)\")\n\nn_a = 20\np_a = 0.5\nbinom_a = stats.binom(n_a, p_a)\nprob_a = binom_a.pmf(12)\nprint(f\"Answer: P(X = 12) = {prob_a:.4f}\")\n\nprint(\"\\n=== SCENARIO B ===\")\nprint(\"Roll a die until you get a 6. Probability it takes exactly 4 rolls?\")\nprint(\"Distribution: Geometric(p=1/6)\")\n\np_b = 1/6\ngeom_b = stats.geom(p_b)\nprob_b = geom_b.pmf(4)\nprint(f\"Answer: P(X = 4) = {prob_b:.4f}\")\n\nprint(\"\\n=== SCENARIO C ===\")\nprint(\"Website gets average 2 visitors per minute. Probability of exactly 3 visitors?\")\nprint(\"Distribution: Poisson(Œª=2)\")\n\nlam_c = 2\npoisson_c = stats.poisson(lam_c)\nprob_c = poisson_c.pmf(3)\nprint(f\"Answer: P(X = 3) = {prob_c:.4f}\")\n\nprint(\"\\n=== SCENARIO D ===\")\nprint(\"5% of items are defective. Probability first defective item found on 8th test?\")\nprint(\"Distribution: Geometric(p=0.05)\")\n\np_d = 0.05\ngeom_d = stats.geom(p_d)\nprob_d = geom_d.pmf(8)\nprint(f\"Answer: P(X = 8) = {prob_d:.4f}\")\n\n=== SCENARIO A ===\nFlip a fair coin 20 times. Probability of exactly 12 heads?\nDistribution: Binomial(n=20, p=0.5)\nAnswer: P(X = 12) = 0.1201\n\n=== SCENARIO B ===\nRoll a die until you get a 6. Probability it takes exactly 4 rolls?\nDistribution: Geometric(p=1/6)\nAnswer: P(X = 4) = 0.0965\n\n=== SCENARIO C ===\nWebsite gets average 2 visitors per minute. Probability of exactly 3 visitors?\nDistribution: Poisson(Œª=2)\nAnswer: P(X = 3) = 0.1804\n\n=== SCENARIO D ===\n5% of items are defective. Probability first defective item found on 8th test?\nDistribution: Geometric(p=0.05)\nAnswer: P(X = 8) = 0.0349\n\n\n\n\nTask 6 Solution\nProblem: Simulation of basketball free throw scenario\n\n# Task 6 Solution\nnp.random.seed(42)  # For reproducible results\n\n# Parameters from Task 3\nn_shots = 15\np_success = 0.7\nn_simulations = 1000\n\n# Theoretical probability of exactly 10 makes\ntheoretical_prob = stats.binom(n_shots, p_success).pmf(10)\nprint(f\"Theoretical P(X = 10): {theoretical_prob:.4f}\")\n\n# Simulate the scenario 1000 times\nsimulation_results = []\nexactly_10_count = 0\n\nfor i in range(n_simulations):\n    # Simulate 15 free throws (1 = make, 0 = miss)\n    shots = np.random.binomial(1, p_success, n_shots)\n    makes = np.sum(shots)\n    simulation_results.append(makes)\n    \n    if makes == 10:\n        exactly_10_count += 1\n\n# Calculate proportion of simulations with exactly 10 makes\nsimulated_prob = exactly_10_count / n_simulations\nprint(f\"Simulated P(X = 10): {simulated_prob:.4f}\")\nprint(f\"Difference: {abs(theoretical_prob - simulated_prob):.4f}\")\n\n# Create histogram with theoretical PMF overlay\nplt.figure(figsize=(14, 8))\n\n# Histogram of simulation results\nplt.hist(simulation_results, bins=range(0, n_shots+2), alpha=0.7, density=True, \n         color='lightblue', edgecolor='black', label='Simulation Results')\n\n# Theoretical PMF overlay\nbinom_theory = stats.binom(n_shots, p_success)\nk_values = range(0, n_shots+1)\ntheoretical_probs = [binom_theory.pmf(k) for k in k_values]\nplt.plot(k_values, theoretical_probs, 'ro-', linewidth=2, markersize=8, \n         label='Theoretical PMF')\n\nplt.xlabel('Number of Successful Free Throws')\nplt.ylabel('Probability/Density')\nplt.title(f'Simulation vs Theory: Basketball Free Throws\\n({n_simulations} simulations, n={n_shots}, p={p_success})')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(f\"\\nSimulation Summary:\")\nprint(f\"Mean of simulations: {np.mean(simulation_results):.2f}\")\nprint(f\"Theoretical mean: {binom_theory.mean():.2f}\")\nprint(f\"Standard deviation of simulations: {np.std(simulation_results):.2f}\")\nprint(f\"Theoretical standard deviation: {binom_theory.std():.2f}\")\n\nTheoretical P(X = 10): 0.2061\nSimulated P(X = 10): 0.2150\nDifference: 0.0089\n\n\n\n\n\n\n\n\n\n\nSimulation Summary:\nMean of simulations: 10.59\nTheoretical mean: 10.50\nStandard deviation of simulations: 1.74\nTheoretical standard deviation: 1.77\n\n\n\n\nFinal Challenge Solution\nProblem: Customer service center analysis\n\n# Final Challenge Solution\n\nprint(\"=== CUSTOMER SERVICE CENTER ANALYSIS ===\\n\")\n\n# Given information:\n# - 20% of calls result in a sale (Bernoulli process)\n# - Calls arrive at average rate of 4 per hour (Poisson process)  \n# - Agents work until first sale (Geometric process)\n\np_sale = 0.2  # Probability of sale per call\ncalls_per_hour = 4\nhours_per_day = 8\n\nprint(\"Given:\")\nprint(f\"- Probability of sale per call: {p_sale}\")\nprint(f\"- Average calls per hour: {calls_per_hour}\")\nprint(f\"- Hours of operation per day: {hours_per_day}\")\n\n# 1. Expected number of calls in 8-hour day\nexpected_calls_per_day = calls_per_hour * hours_per_day\nprint(f\"\\n1. Expected calls in {hours_per_day}-hour day: {expected_calls_per_day}\")\n\n# 2. Probability that exactly 2 of next 10 calls result in sales\nn_calls = 10\nbinom_sales = stats.binom(n_calls, p_sale)\nprob_2_sales = binom_sales.pmf(2)\nprint(f\"\\n2. P(exactly 2 sales in 10 calls): {prob_2_sales:.4f}\")\n\n# 3. Expected number of calls until first sale\ngeom_first_sale = stats.geom(p_sale)\nexpected_calls_until_sale = geom_first_sale.mean()\nprint(f\"\\n3. Expected calls until first sale: {expected_calls_until_sale:.1f}\")\n\n# 4. Comprehensive visualization\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# Plot 1: Poisson - Calls per hour\npoisson_calls = stats.poisson(calls_per_hour)\nk_poisson = range(0, 15)\nprob_poisson = [poisson_calls.pmf(k) for k in k_poisson]\n\naxes[0, 0].bar(k_poisson, prob_poisson, alpha=0.7, color='skyblue', edgecolor='black')\naxes[0, 0].set_title(f'Calls per Hour\\nPoisson(Œª={calls_per_hour})')\naxes[0, 0].set_xlabel('Number of Calls')\naxes[0, 0].set_ylabel('Probability')\naxes[0, 0].axvline(x=calls_per_hour, color='red', linestyle='--', label=f'Mean = {calls_per_hour}')\naxes[0, 0].legend()\n\n# Plot 2: Binomial - Sales in 10 calls\nk_binom = range(0, n_calls + 1)\nprob_binom = [binom_sales.pmf(k) for k in k_binom]\n\naxes[0, 1].bar(k_binom, prob_binom, alpha=0.7, color='lightgreen', edgecolor='black')\naxes[0, 1].set_title(f'Sales in {n_calls} Calls\\nBinomial(n={n_calls}, p={p_sale})')\naxes[0, 1].set_xlabel('Number of Sales')\naxes[0, 1].set_ylabel('Probability')\naxes[0, 1].axvline(x=binom_sales.mean(), color='red', linestyle='--', \n                   label=f'Mean = {binom_sales.mean():.1f}')\naxes[0, 1].legend()\n\n# Plot 3: Geometric - Calls until first sale\nk_geom = range(1, 21)\nprob_geom = [geom_first_sale.pmf(k) for k in k_geom]\n\naxes[1, 0].bar(k_geom, prob_geom, alpha=0.7, color='orange', edgecolor='black')\naxes[1, 0].set_title(f'Calls Until First Sale\\nGeometric(p={p_sale})')\naxes[1, 0].set_xlabel('Call Number')\naxes[1, 0].set_ylabel('Probability')\naxes[1, 0].axvline(x=expected_calls_until_sale, color='red', linestyle='--', \n                   label=f'Mean = {expected_calls_until_sale:.1f}')\naxes[1, 0].legend()\n\n# Plot 4: Poisson - Calls per day\npoisson_day = stats.poisson(expected_calls_per_day)\nk_day = range(15, 50)  # Focus on reasonable range around mean\nprob_day = [poisson_day.pmf(k) for k in k_day]\n\naxes[1, 1].bar(k_day, prob_day, alpha=0.7, color='purple', edgecolor='black')\naxes[1, 1].set_title(f'Calls per Day\\nPoisson(Œª={expected_calls_per_day})')\naxes[1, 1].set_xlabel('Number of Calls')\naxes[1, 1].set_ylabel('Probability')\naxes[1, 1].axvline(x=expected_calls_per_day, color='red', linestyle='--', \n                   label=f'Mean = {expected_calls_per_day}')\naxes[1, 1].legend()\n\nplt.tight_layout()\nplt.show()\n\n# Additional insights\nprint(f\"\\n=== ADDITIONAL INSIGHTS ===\")\nprint(f\"Daily sales expectations:\")\nexpected_daily_sales = expected_calls_per_day * p_sale\nprint(f\"- Expected calls per day: {expected_calls_per_day}\")\nprint(f\"- Expected sales per day: {expected_daily_sales:.1f}\")\n\nprint(f\"\\nProbability calculations:\")\nprint(f\"- P(no sales in 10 calls): {binom_sales.pmf(0):.4f}\")\nprint(f\"- P(at least 1 sale in 10 calls): {1 - binom_sales.pmf(0):.4f}\")\nprint(f\"- P(first sale on call 1): {geom_first_sale.pmf(1):.4f}\")\nprint(f\"- P(first sale within 5 calls): {geom_first_sale.cdf(5):.4f}\")\n\n=== CUSTOMER SERVICE CENTER ANALYSIS ===\n\nGiven:\n- Probability of sale per call: 0.2\n- Average calls per hour: 4\n- Hours of operation per day: 8\n\n1. Expected calls in 8-hour day: 32\n\n2. P(exactly 2 sales in 10 calls): 0.3020\n\n3. Expected calls until first sale: 5.0\n\n\n\n\n\n\n\n\n\n\n=== ADDITIONAL INSIGHTS ===\nDaily sales expectations:\n- Expected calls per day: 32\n- Expected sales per day: 6.4\n\nProbability calculations:\n- P(no sales in 10 calls): 0.1074\n- P(at least 1 sale in 10 calls): 0.8926\n- P(first sale on call 1): 0.2000\n- P(first sale within 5 calls): 0.6723\n\n\n\n\nSummary\nThis lab covered the fundamental concepts of discrete random variables and probability distributions:\n\nBasic Concepts: PMF, expected value, variance\nKey Distributions: Bernoulli, Binomial, Geometric, Poisson\nPython Tools: scipy.stats for probability calculations\nSimulation: Verifying theoretical results with Monte Carlo methods\nReal Applications: Identifying appropriate distributions for real-world scenarios\n\nKey Takeaways: - Always identify the underlying process to choose the right distribution - Use simulation to verify theoretical calculations - Visualizations help understand distribution shapes and parameters - scipy.stats provides powerful tools for probability work"
  },
  {
    "objectID": "files/worksheets/drafts/worksheet4_sln_draft.html",
    "href": "files/worksheets/drafts/worksheet4_sln_draft.html",
    "title": "PSTAT 5A Practice Worksheet 3 - SOLUTIONS",
    "section": "",
    "text": "Section A: Probability - SOLUTIONS\n‚è±Ô∏è Estimated time: 8 minutes\n\nProblem A1: Probability Distributions - SOLUTION\nFor a valid probability distribution, two conditions must be met:\n\nAll probabilities must be non-negative (‚â• 0)\nThe sum of all probabilities must equal 1\n\nAnalysis:\n(a) Invalid\n\nSum = 0.3 + 0.3 + 0.3 + 0.2 + 0.1 = 1.2 &gt; 1 The probabilities sum to more than 1, violating the second condition.\n\n(b) Valid\n\nSum = 0 + 0 + 1 + 0 + 0 = 1 All probabilities are non-negative and sum to 1. This represents a class where everyone receives a C.\n\n(c) Invalid\n\nSum = 0.3 + 0.3 + 0.3 + 0 + 0 = 0.9 &lt; 1 The probabilities sum to less than 1, violating the second condition.\n\n(d) Invalid\n\nContains F = -0.1 &lt; 0 Although the sum would equal 1.0, the probability for grade F is negative, violating the first condition.\n\n(e) Valid\n\nSum = 0.2 + 0.4 + 0.2 + 0.1 + 0.1 = 1.0 All probabilities are non-negative and sum to 1.\n\n(f) Invalid\n\nContains B = -0.1 &lt; 0 Although the sum equals 1.0, the probability for grade B is negative, violating the first condition.\n\n\n\n\nSection B: Permutations and Combinations - SOLUTIONS\n‚è±Ô∏è Estimated time: 15 minutes\n\nProblem B1: Permutations and Combinations - SOLUTION\nPart (a): How many 6-character passwords can be formed using 3 specific letters and 3 specific digits if repetitions are not allowed and letters must come before digits?\nSolution: Since letters must come before digits, we have a fixed structure: LLL DDD\n\nStep 1: Arrange 3 letters in the first 3 positions\n\nThis is a permutation: P(3,3) = 3! = 6 ways\n\nStep 2: Arrange 3 digits in the last 3 positions\n\nThis is a permutation: P(3,3) = 3! = 6 ways\n\nStep 3: Apply multiplication principle\n\nTotal passwords = 6 √ó 6 = 36 passwords\n\n\nPart (b): If the team wants to select 4 people from 12 employees to form a security committee where order doesn‚Äôt matter, how many ways can this be done?\nSolution: Since order doesn‚Äôt matter, this is a combination problem.\n\\[C(12,4) = \\binom{12}{4} = \\frac{12!}{4!(12-4)!} = \\frac{12!}{4! \\cdot 8!}\\]\n\\[= \\frac{12 \\times 11 \\times 10 \\times 9}{4 \\times 3 \\times 2 \\times 1} = \\frac{11880}{24} = \\textbf{495 ways}\\]\n\n\n\nSection C: Conditional Probability - SOLUTIONS\n‚è±Ô∏è Estimated time: 15 minutes\n\nProblem B1: Conditional Probability and Medical Testing - SOLUTION\nGiven Information:\n\nP(has variant) = 0.03\nP(test positive | has variant) = 0.95 (sensitivity)\nP(test negative | no variant) = 0.92 (specificity)\nTherefore: P(test positive | no variant) = 1 - 0.92 = 0.08\n\nPart (a): What is the probability that a randomly selected person tests positive?\nSolution:\nUsing the Law of Total Probability:\n\\[P(\\text{test positive}) = P(\\text{test positive | has variant}) \\times P(\\text{has variant}) + P(\\text{test positive | no variant}) \\times P(\\text{no variant})\\]\n\\[P(\\text{test positive}) = 0.95 \\times 0.03 + 0.08 \\times 0.97\\] \\[= 0.0285 + 0.0776 = \\textbf{0.1061}\\]\nPart (b): If someone tests positive, what is the probability they actually have the variant?\nSolution: Using Bayes‚Äô Theorem:\n\\[P(\\text{has variant | test positive}) = \\frac{P(\\text{test positive | has variant}) \\times P(\\text{has variant})}{P(\\text{test positive})}\\]\n\\[= \\frac{0.95 \\times 0.03}{0.1061} = \\frac{0.0285}{0.1061} = \\textbf{0.2686}\\]\nPart (c): If someone tests negative, what is the probability they actually don‚Äôt have the variant?\nSolution: First, find P(test negative): \\[P(\\text{test negative}) = 1 - P(\\text{test positive}) = 1 - 0.1061 = 0.8939\\]\nUsing Bayes‚Äô Theorem: \\[P(\\text{no variant | test negative}) = \\frac{P(\\text{test negative | no variant}) \\times P(\\text{no variant})}{P(\\text{test negative})}\\]\n\\[= \\frac{0.92 \\times 0.97}{0.8939} = \\frac{0.8924}{0.8939} = \\textbf{0.9983}\\]\nPart (d) [Challenge]: Two consecutive positive tests - what is the probability they actually have the variant?\nSolution: Assuming independence between tests:\n\\[P(\\text{two positive | has variant}) = 0.95^2 = 0.9025\\] \\[P(\\text{two positive | no variant}) = 0.08^2 = 0.0064\\]\n\\[P(\\text{two positive}) = 0.9025 \\times 0.03 + 0.0064 \\times 0.97 = 0.027075 + 0.006208 = 0.033283\\]\n\\[P(\\text{has variant | two positive}) = \\frac{0.027075}{0.033283} = \\textbf{0.8134}\\]\n\n\nProblem C1: Advanced Counting with Restrictions - SOLUTION\nPart (a): How many valid meal combinations are possible?\nSolution: We need to consider cases based on the restrictions.\nCase 1: Seafood appetizer is chosen\n\n1 appetizer option (seafood)\n7 main course options (cannot choose vegetarian)\n5 dessert options\nCombinations: 1 √ó 7 √ó 5 = 35\n\nCase 2: Non-seafood appetizer + chocolate dessert\n\n5 appetizer options (non-seafood)\n3 main course options (only beef or chicken allowed with chocolate)\n1 dessert option (chocolate)\nCombinations: 5 √ó 3 √ó 1 = 15\n\nCase 3: Non-seafood appetizer + non-chocolate dessert - 5 appetizer options (non-seafood)\n\n8 main course options (no restrictions)\n4 dessert options (non-chocolate)\nCombinations: 5 √ó 8 √ó 4 = 160\n\nTotal valid combinations: 35 + 15 + 160 = 210 combinations\nPart (b): If customers choose randomly among valid combinations, what is the probability someone chooses the chocolate dessert?\nSolution: Combinations with chocolate dessert: 15 (from Case 2 above) Total valid combinations: 210\n\\[P(\\text{chocolate dessert}) = \\frac{15}{210} = \\frac{1}{14} = \\textbf{0.0714}\\]\n\n\n\nSection D: Review - SOLUTIONS\n‚è±Ô∏è Estimated time: 12 minutes\n\nProblem B3: Daily Expenses - SOLUTION\nGiven:\n\nCoffee: Mean = $1.40, SD = $0.30\nMuffin: Mean = $2.50, SD = $0.15\nPrices are independent\n\nPart (a): What is the mean and standard deviation of the amount she spends on breakfast daily?\nSolution: For the sum of independent random variables:\nMean of daily expenses: \\[E[\\text{Daily}] = E[\\text{Coffee}] + E[\\text{Muffin}] = \\$1.40 + \\$2.50 = \\textbf{\\$3.90}\\]\nVariance of daily expenses: \\[\\text{Var}[\\text{Daily}] = \\text{Var}[\\text{Coffee}] + \\text{Var}[\\text{Muffin}] = (0.30)^2 + (0.15)^2 = 0.09 + 0.0225 = 0.1125\\]\nStandard deviation of daily expenses: \\[SD[\\text{Daily}] = \\sqrt{0.1125} = \\textbf{\\$0.3354}\\]\nPart (b): What is the mean and standard deviation of the amount she spends on breakfast weekly (7 days)?\nSolution: For the sum of 7 independent daily expenses:\nMean of weekly expenses: \\[E[\\text{Weekly}] = 7 \\times E[\\text{Daily}] = 7 \\times \\$3.90 = \\textbf{\\$27.30}\\]\nVariance of weekly expenses: \\[\\text{Var}[\\text{Weekly}] = 7 \\times \\text{Var}[\\text{Daily}] = 7 \\times 0.1125 = 0.7875\\]\nStandard deviation of weekly expenses: \\[SD[\\text{Weekly}] = \\sqrt{0.7875} = \\textbf{\\$0.8874}\\]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "",
    "text": "Conditional Probabilities\nUnderstanding probability when information changes the game"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#welcome-to-lecture-6",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#welcome-to-lecture-6",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Welcome to Lecture 6",
    "text": "Welcome to Lecture 6\nConditional Probabilities\nUnderstanding probability when information changes the game"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#todays-learning-objectives",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#todays-learning-objectives",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine and calculate conditional probabilities\nApply the multiplication rule for dependent events\nUse tree diagrams to solve multi-stage problems\nApply the law of total probability\nUse Bayes‚Äô theorem to solve real-world problems\nDistinguish between independence and conditional independence\nRecognize and avoid common conditional probability fallacies"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#motivation-why-conditional-probability",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#motivation-why-conditional-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Motivation: Why Conditional Probability?",
    "text": "Motivation: Why Conditional Probability?\nIn real life, we rarely make decisions with no information\nExamples: - Medical diagnosis with test results - Weather forecast with current conditions\n- Investment decisions with market data - Sports betting with team statistics - Insurance premiums based on risk factors\n\nConditional probability helps us update our beliefs when we gain new information"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#what-is-conditional-probability",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#what-is-conditional-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "What is Conditional Probability?",
    "text": "What is Conditional Probability?\nConditional Probability is the probability of an event occurring, given that another event has already occurred\nNotation: \\(P(A|B)\\) read as ‚Äúprobability of A given B‚Äù\n\nKey insight: When we know B has occurred, our sample space effectively ‚Äúshrinks‚Äù to only outcomes where B is true"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#intuitive-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#intuitive-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Intuitive Example",
    "text": "Intuitive Example\nYou roll a fair six-sided die, but before revealing the result, someone tells you ‚Äúthe number is even‚Äù\nWhat‚Äôs the probability it‚Äôs a 4?\n\nWithout information: \\(P(\\text{rolling 4}) = \\frac{1}{6}\\)\nWith information: \\(P(\\text{4 | even}) = ?\\)\nGiven it‚Äôs even, possible outcomes: \\(\\{2, 4, 6\\}\\) So \\(P(\\text{4 | even}) = \\frac{1}{3}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#formal-definition",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#formal-definition",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Formal Definition",
    "text": "Formal Definition\nFor events A and B where \\(P(B) &gt; 0\\):\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\n\nInterpretation:\n\nNumerator: Outcomes where both A and B occur\nDenominator: All outcomes where B occurs\nRatio: Fraction of B-outcomes where A also occurs"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#understanding-the-formula",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#understanding-the-formula",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Understanding the Formula",
    "text": "Understanding the Formula\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nWhy this formula makes sense:\n\nWe restrict our attention to outcomes where B occurs\nAmong those outcomes, what fraction also have A?\nThis is exactly \\(\\frac{P(A \\cap B)}{P(B)}\\)\n\n\nRearranging: \\(P(A \\cap B) = P(A|B) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-1",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-1",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\nA card is drawn from a standard 52-card deck. Find:\n\n\\(P(\\text{King | Face card})\\)\n\\(P(\\text{Heart | Red card})\\)\n\n\\(P(\\text{Ace | Black card})\\)\n\n\nSolutions:\n\n\\(P(\\text{King | Face}) = \\frac{4}{12} = \\frac{1}{3}\\) (4 kings among 12 face cards)\n\\(P(\\text{Heart | Red}) = \\frac{13}{26} = \\frac{1}{2}\\) (13 hearts among 26 red cards)\n\\(P(\\text{Ace | Black}) = \\frac{2}{26} = \\frac{1}{13}\\) (2 black aces among 26 black cards)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#two-way-tables",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#two-way-tables",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Two-Way Tables",
    "text": "Two-Way Tables\nTwo-way tables are excellent for conditional probability problems\nExample: Survey of 1000 people about coffee preference\n\n\n\n\nCoffee\nNo Coffee\nTotal\n\n\n\n\nMorning\n350\n150\n500\n\n\nEvening\n200\n300\n500\n\n\nTotal\n550\n450\n1000"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#using-two-way-tables",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#using-two-way-tables",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Using Two-Way Tables",
    "text": "Using Two-Way Tables\nFind: \\(P(\\text{Coffee | Morning person})\\)\nFrom the table:\n\nMorning people: 500\nMorning people who drink coffee: 350\n\n\n\\(P(\\text{Coffee | Morning}) = \\frac{350}{500} = 0.7\\)\nCompare to: \\(P(\\text{Coffee}) = \\frac{550}{1000} = 0.55\\)\nBeing a morning person increases coffee probability!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-2",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-2",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\nUsing the coffee table, find:\n\n\\(P(\\text{Morning | Coffee drinker})\\)\n\\(P(\\text{No Coffee | Evening person})\\)\n\\(P(\\text{Evening | No Coffee})\\)\n\n\nSolutions:\n\n\\(P(\\text{Morning | Coffee}) = \\frac{350}{550} = \\frac{7}{11} \\approx 0.636\\)\n\\(P(\\text{No Coffee | Evening}) = \\frac{300}{500} = 0.6\\)\n\\(P(\\text{Evening | No Coffee}) = \\frac{300}{450} = \\frac{2}{3} \\approx 0.667\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#independence-revisited",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#independence-revisited",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Independence Revisited",
    "text": "Independence Revisited\nEvents A and B are independent if knowing that B occurred doesn‚Äôt change the probability of A\n\\[P(A|B) = P(A)\\]\nEquivalently: \\[P(A \\cap B) = P(A) \\times P(B)\\]\n\nExample: Two coin flips are independent because \\(P(\\text{H}_2 | \\text{H}_1) = P(\\text{H}_2) = 0.5\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#testing-for-independence",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#testing-for-independence",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Testing for Independence",
    "text": "Testing for Independence\nMethod 1: Check if \\(P(A|B) = P(A)\\)\nMethod 2: Check if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nMethod 3: Check if \\(P(B|A) = P(B)\\)\n\nCoffee Example: Are coffee preference and time preference independent?\n\\(P(\\text{Coffee}) = 0.55\\)\n\\(P(\\text{Coffee | Morning}) = 0.7\\)\nSince \\(0.7 \\neq 0.55\\), they are not independent"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#the-multiplication-rule",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#the-multiplication-rule",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "The Multiplication Rule",
    "text": "The Multiplication Rule\nGeneral Multiplication Rule: \\[P(A \\cap B) = P(A) \\times P(B|A) = P(B) \\times P(A|B)\\]\nFor Independent Events: \\[P(A \\cap B) = P(A) \\times P(B)\\]\n\nExtension to Multiple Events: \\[P(A_1 \\cap A_2 \\cap A_3) = P(A_1) \\times P(A_2|A_1) \\times P(A_3|A_1 \\cap A_2)\\]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#multiplication-rule-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#multiplication-rule-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Multiplication Rule Example",
    "text": "Multiplication Rule Example\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement. What‚Äôs the probability both are red?\n\nLet \\(R_1\\) = first ball is red, \\(R_2\\) = second ball is red\n\\(P(R_1 \\cap R_2) = P(R_1) \\times P(R_2|R_1)\\)\n\\(= \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-3",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-3",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\nA box contains 4 defective and 6 working items. Three items are selected without replacement. Find the probability that:\n\nAll three work\nThe first two work and the third is defective\nExactly two work\n\n\nSolutions: a) \\(P(\\text{WWW}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}\\)\n\n\\(P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-3-continued",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-3-continued",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 3 (continued)",
    "text": "Practice Problem 3 (continued)\n\nExactly two work (three scenarios: WWD, WDW, DWW)\n\n\\(P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{1}{6}\\)\n\\(P(\\text{WDW}) = \\frac{6}{10} \\times \\frac{4}{9} \\times \\frac{5}{8} = \\frac{1}{6}\\)\n\\(P(\\text{DWW}) = \\frac{4}{10} \\times \\frac{6}{9} \\times \\frac{5}{8} = \\frac{1}{6}\\)\n\nTotal: \\(\\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagrams",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagrams",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\nTree diagrams help visualize sequential events and conditional probabilities\n                    0.5   Red\n            0.6 ‚îÄ‚îÄ‚îê\n                    0.5   Blue\nBall 1      \n                    0.4   Red  \n            0.4 ‚îÄ‚îÄ‚îê\n                    0.6   Blue\nEach branch shows conditional probabilities"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagram-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagram-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagram Example",
    "text": "Tree Diagram Example\nMedical test scenario: - 2% of population has disease - Test is 95% accurate for sick people\n- Test is 90% accurate for healthy people\nWhat‚Äôs the probability of testing positive?"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagram-solution",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#tree-diagram-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagram Solution",
    "text": "Tree Diagram Solution\n                    0.95   Test +\n            0.02 ‚îÄ‚îÄ‚îê\n                    0.05   Test -\nDisease?    \n                    0.10   Test +\n            0.98 ‚îÄ‚îÄ‚îê\n                    0.90   Test -\n\n\\(P(\\text{Test+}) = P(\\text{Test+|Disease}) \\times P(\\text{Disease}) + P(\\text{Test+|Healthy}) \\times P(\\text{Healthy})\\)\n\\(= 0.95 \\times 0.02 + 0.10 \\times 0.98 = 0.019 + 0.098 = 0.117\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#law-of-total-probability",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#law-of-total-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space (mutually exclusive and exhaustive), then:\n\\[P(A) = \\sum_{i=1}^{n} P(A|B_i) \\times P(B_i)\\]\n\nPartition means:\n\n\\(B_i \\cap B_j = \\emptyset\\) for \\(i \\neq j\\) (mutually exclusive)\n\\(\\bigcup_{i=1}^{n} B_i = S\\) (exhaustive)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#law-of-total-probability-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\nA factory has three machines: - Machine A: 50% of production, 1% defective - Machine B: 30% of production, 2% defective\n- Machine C: 20% of production, 3% defective\nWhat‚Äôs the overall defect rate?\n\n\\(P(\\text{Defective}) = P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)\\)\n\\(= 0.01 \\times 0.5 + 0.02 \\times 0.3 + 0.03 \\times 0.2\\)\n\\(= 0.005 + 0.006 + 0.006 = 0.017 = 1.7\\%\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-4",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-4",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\nA student studies for an exam with three possible outcomes based on study time: - Studies hard (40%): 90% chance of passing - Studies moderately (35%): 70% chance of passing\n- Doesn‚Äôt study (25%): 30% chance of passing\nWhat‚Äôs the overall probability of passing?\n\n\\(P(\\text{Pass}) = 0.9 \\times 0.4 + 0.7 \\times 0.35 + 0.3 \\times 0.25\\)\n\\(= 0.36 + 0.245 + 0.075 = 0.68\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem",
    "text": "Bayes‚Äô Theorem\nThe Foundation: We often want to ‚Äúreverse‚Äù conditional probabilities\nGiven: \\(P(B|A)\\), \\(P(A)\\), \\(P(B)\\) Want: \\(P(A|B)\\)\nBayes‚Äô Theorem: \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem-components",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem-components",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem Components",
    "text": "Bayes‚Äô Theorem Components\n\\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\n\n\\(P(A|B)\\): Posterior probability (what we want)\n\\(P(B|A)\\): Likelihood (what we observe)\n\n\\(P(A)\\): Prior probability (initial belief)\n\\(P(B)\\): Evidence (marginal probability)\n\n\n‚ÄúIn light of evidence B, how should we update our belief in A?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem-with-total-probability",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#bayes-theorem-with-total-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem with Total Probability",
    "text": "Bayes‚Äô Theorem with Total Probability\nWhen we need to find \\(P(B)\\):\n\\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B|A) \\times P(A) + P(B|A^c) \\times P(A^c)}\\]\nThis is the most common form for applications"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#medical-diagnosis-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#medical-diagnosis-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Medical Diagnosis Example",
    "text": "Medical Diagnosis Example\nRevisiting our medical test: - 2% of population has disease (prior) - Test positive (evidence)\n- Test is 95% accurate for sick, 90% accurate for healthy\nGiven a positive test, what‚Äôs the probability of having the disease?"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#medical-diagnosis-solution",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#medical-diagnosis-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Medical Diagnosis Solution",
    "text": "Medical Diagnosis Solution\nLet D = disease, T+ = positive test\n\\[P(D|T+) = \\frac{P(T+|D) \\times P(D)}{P(T+|D) \\times P(D) + P(T+|D^c) \\times P(D^c)}\\]\n\\[= \\frac{0.95 \\times 0.02}{0.95 \\times 0.02 + 0.10 \\times 0.98}\\]\n\\[= \\frac{0.019}{0.019 + 0.098} = \\frac{0.019}{0.117} \\approx 0.162\\]\n\nSurprising: Only 16.2% chance of disease despite positive test!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#why-the-low-probability",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#why-the-low-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Why the Low Probability?",
    "text": "Why the Low Probability?\nBase Rate Fallacy: When disease is rare (2%), most positive tests are false positives\nIntuition: Out of 10,000 people: - 200 have disease ‚Üí 190 test positive\n- 9,800 healthy ‚Üí 980 test positive - Total positive tests: 1,170 - True positives: 190\n\\(P(\\text{Disease | Positive}) = \\frac{190}{1,170} \\approx 0.162\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-5",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-5",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 5",
    "text": "Practice Problem 5\nEmail spam filter: - 60% of emails are spam - Filter catches 95% of spam - Filter incorrectly flags 8% of legitimate emails\nIf an email is flagged as spam, what‚Äôs the probability it‚Äôs actually spam?\n\n\\(P(\\text{Spam | Flagged}) = \\frac{0.95 \\times 0.6}{0.95 \\times 0.6 + 0.08 \\times 0.4}\\)\n\\(= \\frac{0.57}{0.57 + 0.032} = \\frac{0.57}{0.602} \\approx 0.947\\)\nThe filter is quite reliable!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#multiple-events-and-bayes",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#multiple-events-and-bayes",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Multiple Events and Bayes‚Äô",
    "text": "Multiple Events and Bayes‚Äô\nExtended Bayes‚Äô Theorem: If \\(A_1, A_2, \\ldots, A_n\\) partition the sample space:\n\\[P(A_i|B) = \\frac{P(B|A_i) \\times P(A_i)}{\\sum_{j=1}^{n} P(B|A_j) \\times P(A_j)}\\]\nThis allows us to update probabilities for multiple hypotheses"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#three-machine-example-revisited",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#three-machine-example-revisited",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Three Machine Example Revisited",
    "text": "Three Machine Example Revisited\nA defective item is found. Which machine most likely produced it?\nFrom before: - Machine A: 50% production, 1% defective\n- Machine B: 30% production, 2% defective - Machine C: 20% production, 3% defective - Overall defect rate: 1.7%"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#three-machine-solution",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#three-machine-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Three Machine Solution",
    "text": "Three Machine Solution\n\\[P(A|\\text{Defective}) = \\frac{0.01 \\times 0.5}{0.017} = \\frac{0.005}{0.017} \\approx 0.294\\]\n\\[P(B|\\text{Defective}) = \\frac{0.02 \\times 0.3}{0.017} = \\frac{0.006}{0.017} \\approx 0.353\\]\n\\[P(C|\\text{Defective}) = \\frac{0.03 \\times 0.2}{0.017} = \\frac{0.006}{0.017} \\approx 0.353\\]\n\nMachine B or C are most likely sources of the defective item"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-6",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-6",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\nThree boxes contain colored balls: - Box 1: 3 red, 2 blue (chosen 40% of time) - Box 2: 2 red, 3 blue (chosen 35% of time)\n- Box 3: 1 red, 4 blue (chosen 25% of time)\nA red ball is drawn. Which box was it most likely from?\n\n\\(P(\\text{Red}) = \\frac{3}{5} \\times 0.4 + \\frac{2}{5} \\times 0.35 + \\frac{1}{5} \\times 0.25 = 0.24 + 0.14 + 0.05 = 0.43\\)\n\\(P(\\text{Box 1 | Red}) = \\frac{0.6 \\times 0.4}{0.43} \\approx 0.558\\) \\(P(\\text{Box 2 | Red}) = \\frac{0.4 \\times 0.35}{0.43} \\approx 0.326\\)\n\\(P(\\text{Box 3 | Red}) = \\frac{0.2 \\times 0.25}{0.43} \\approx 0.116\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#conditional-independence",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#conditional-independence",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Conditional Independence",
    "text": "Conditional Independence\nEvents A and B are conditionally independent given C if:\n\\[P(A \\cap B | C) = P(A|C) \\times P(B|C)\\]\nImportant: Conditional independence doesn‚Äôt imply independence!\n\nExample: Weather in two cities may be independent normally, but conditionally dependent given a major weather system"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#simpsons-paradox",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#simpsons-paradox",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Simpson‚Äôs Paradox",
    "text": "Simpson‚Äôs Paradox\nSimpson‚Äôs Paradox: A trend in subgroups can reverse when groups are combined\nClassic Example: University admissions by gender\n\n\n\n\nMen\nWomen\n\n\n\n\nDept A\n62% (825/1327)\n82% (108/131)\n\n\nDept B\n63% (560/893)\n68% (25/37)\n\n\nOverall\n44% (1385/2220)\n30% (133/168)\n\n\n\nWomen have higher rates in each department but lower overall!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#common-fallacies",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#common-fallacies",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Common Fallacies",
    "text": "Common Fallacies\n1. Confusion of the Inverse - Confusing \\(P(A|B)\\) with \\(P(B|A)\\) - ‚ÄúIf it rains, the ground is wet‚Äù ‚â† ‚ÄúIf the ground is wet, it rained‚Äù\n2. Base Rate Neglect\n- Ignoring prior probabilities - Medical test example\n3. Prosecutor‚Äôs Fallacy - \\(P(\\text{Evidence | Innocent}) \\neq P(\\text{Innocent | Evidence})\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#prosecutors-fallacy-example",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#prosecutors-fallacy-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Prosecutor‚Äôs Fallacy Example",
    "text": "Prosecutor‚Äôs Fallacy Example\nDNA evidence matches defendant with probability 1 in a million for random person\nWrong reasoning: ‚ÄúProbability of innocence is 1 in a million‚Äù\nCorrect reasoning: Need to consider: - How many people could have committed the crime? - What‚Äôs the prior probability of guilt? - Possibility of lab error, planted evidence, etc."
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-7",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-7",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\nQuality control: 5% of items are defective. A test detects 96% of defective items but has a 4% false positive rate.\n\nWhat‚Äôs the probability an item testing positive is actually defective?\nWhat‚Äôs the probability an item testing negative is actually good?\n\n\n\n\\(P(\\text{Defective | Positive}) = \\frac{0.96 \\times 0.05}{0.96 \\times 0.05 + 0.04 \\times 0.95} = \\frac{0.048}{0.086} \\approx 0.558\\)\n\\(P(\\text{Good | Negative}) = \\frac{0.96 \\times 0.95}{0.96 \\times 0.95 + 0.04 \\times 0.05} = \\frac{0.912}{0.914} \\approx 0.998\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#real-world-applications",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#real-world-applications",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Screening: - Mammograms, COVID tests - Balancing sensitivity vs specificity\nMachine Learning: - Naive Bayes classifiers - Spam detection, recommendation systems\nFinance: - Credit scoring - Fraud detection\nLegal System: - DNA evidence interpretation - Probability of guilt/innocence"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#technology-and-tools",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#technology-and-tools",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Technology and Tools",
    "text": "Technology and Tools\nCalculators: - Basic probability calculations - Watch for rounding errors\nSoftware: - R: conditional probability tables - Python: pandas for two-way tables - Excel: pivot tables for conditional analysis\nVisualization: - Tree diagrams\n- Contingency tables - Bayes networks"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#diagnostic-thinking",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#diagnostic-thinking",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Diagnostic Thinking",
    "text": "Diagnostic Thinking\nQuestions to ask: 1. What information am I conditioning on? 2. How does this information change the probability? 3. What‚Äôs the base rate or prior probability? 4. Am I confusing \\(P(A|B)\\) with \\(P(B|A)\\)? 5. Are the events independent?"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#problem-solving-strategy",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#problem-solving-strategy",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\nIdentify the type: Direct conditional, Bayes‚Äô, or law of total probability?\nDefine events clearly: Use precise notation\nOrganize information: Two-way tables or tree diagrams\nCheck for independence: Does additional info matter?\nApply appropriate formula: Don‚Äôt forget denominators!\nVerify answer: Does it make intuitive sense?"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-8",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-8",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 8",
    "text": "Practice Problem 8\nA survey shows: - 70% of people like pizza - 60% of people like movies\n- 40% like both pizza and movies\n\nAre liking pizza and movies independent?\nWhat‚Äôs \\(P(\\text{Pizza | Movies})\\)?\nWhat‚Äôs \\(P(\\text{Movies | Pizza})\\)?"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-8-solutions",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#practice-problem-8-solutions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 8 Solutions",
    "text": "Practice Problem 8 Solutions\n\nCheck independence: \\(P(\\text{Pizza}) \\times P(\\text{Movies}) = 0.7 \\times 0.6 = 0.42 \\neq 0.4\\) Not independent!\n\\(P(\\text{Pizza | Movies}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Movies})} = \\frac{0.4}{0.6} = \\frac{2}{3}\\)\n\\(P(\\text{Movies | Pizza}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Pizza})} = \\frac{0.4}{0.7} = \\frac{4}{7}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#advanced-topics-preview",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#advanced-topics-preview",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Advanced Topics Preview",
    "text": "Advanced Topics Preview\nMarkov Chains: - Sequences where future depends only on present - \\(P(X_{n+1} | X_n, X_{n-1}, \\ldots, X_1) = P(X_{n+1} | X_n)\\)\nBayesian Statistics: - Using Bayes‚Äô theorem for statistical inference - Updating beliefs with data\nInformation Theory: - Conditional entropy - Mutual information"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#historical-context",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#historical-context",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Historical Context",
    "text": "Historical Context\nThomas Bayes (1701-1761): - Presbyterian minister and mathematician - Bayes‚Äô theorem published posthumously\nPierre-Simon Laplace (1749-1827): - Developed and popularized Bayesian methods - ‚ÄúProbability is nothing but common sense reduced to calculation‚Äù\nModern Applications: AI, machine learning, medical diagnosis, finance"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#common-student-questions",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#common-student-questions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: ‚ÄúHow do I know when to use Bayes‚Äô theorem?‚Äù A: When you want to ‚Äúreverse‚Äù a conditional probability\nQ: ‚ÄúWhy are medical test problems so counterintuitive?‚Äù\nA: Base rates matter more than we intuitively expect\nQ: ‚ÄúWhat‚Äôs the difference between independence and conditional independence?‚Äù A: Independence means no relationship; conditional independence means no relationship given specific information"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#key-formulas-summary",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#key-formulas-summary",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\nConditional Probability: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nMultiplication Rule: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nLaw of Total Probability: \\(P(A) = \\sum P(A|B_i) \\times P(B_i)\\)\nBayes‚Äô Theorem: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)\nIndependence: \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#looking-ahead",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#looking-ahead",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture: Discrete Random Variables - Random variables as functions - Probability mass functions - Expected value and variance - Common discrete distributions (binomial, geometric, Poisson)\nConnection: Conditional probability is essential for understanding dependence in random variables"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#study-tips",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#study-tips",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Study Tips",
    "text": "Study Tips\n\nPractice with real scenarios: Medical tests, quality control\nDraw diagrams: Tree diagrams and two-way tables\nCheck your intuition: Do answers make sense?\nMaster the basics: Conditional probability formula\nWatch for fallacies: Don‚Äôt confuse \\(P(A|B)\\) and \\(P(B|A)\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#final-thoughts",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#final-thoughts",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nConditional probability is everywhere: - Updates beliefs with new information - Foundation of Bayesian thinking - Critical for proper statistical reasoning - Essential for machine learning and AI\n\nKey insight: Information changes probability - embrace this uncertainty!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#questions",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#questions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: [Your office hours] Email: [Your email]\nNext Class: Discrete Random Variables\nRemember: Homework due [date]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#bonus-monty-hall-problem",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#bonus-monty-hall-problem",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bonus: Monty Hall Problem",
    "text": "Bonus: Monty Hall Problem\nThree doors: one has a car, two have goats 1. You choose a door 2. Host opens a door with a goat 3. Do you switch?\n\nAnswer: Yes! Switch! - \\(P(\\text{Car behind your door}) = \\frac{1}{3}\\) - \\(P(\\text{Car behind other remaining door}) = \\frac{2}{3}\\)\nConditional probability in action!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture8_condProb.html#bonus-birthday-paradox-connection",
    "href": "files/lecture_notes/test_lectures/lecture8_condProb.html#bonus-birthday-paradox-connection",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bonus: Birthday Paradox Connection",
    "text": "Bonus: Birthday Paradox Connection\nIn a room of 23 people, probability of shared birthday ‚âà 50%\nConditional approach: What‚Äôs \\(P(\\text{no match | first $k$ people have different birthdays})\\)?\nThis helps build intuition for why the probability grows so quickly!\nSurprising results often involve conditional probability!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html",
    "href": "files/lecture_notes/lecture6/lecture6.html",
    "title": "PSTAT 5A: Counting",
    "section": "",
    "text": "The art and science of systematic enumeration"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#welcome-to-lecture-6-part-1",
    "href": "files/lecture_notes/lecture6/lecture6.html#welcome-to-lecture-6-part-1",
    "title": "PSTAT 5A: Counting",
    "section": "Welcome to Lecture 6 (Part 1)",
    "text": "Welcome to Lecture 6 (Part 1)\nThe art and science of systematic enumeration"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#learning-objectives",
    "href": "files/lecture_notes/lecture6/lecture6.html#learning-objectives",
    "title": "PSTAT 5A: Counting",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\n\n\n\n\n\n\n\nLearning Objectives\n\n\nBy the end of this lecture, you will be able to:\n\nApply the fundamental counting principles (Section¬†0.4)\nCalculate permutations with and without repetition (Section¬†0.8, Section¬†0.11, Section¬†0.14)\nCalculate combinations and understand when to use them (Section¬†0.16, Section¬†0.17)\nDistinguish between permutations and combinations (Section¬†0.19)\nUse counting techniques to solve probability problems (Section¬†0.24)\nApply the inclusion-exclusion principle (Section¬†0.28)\nSolve complex counting problems systematically (Section¬†0.32)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#why-study-counting",
    "href": "files/lecture_notes/lecture6/lecture6.html#why-study-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Why Study Counting?",
    "text": "Why Study Counting?\n\n\n\n\n\nCounting helps us:\n\nCalculate probabilities for complex events\n\nSolve optimization problems\n\nUnderstand combinations in genetics, computer science\n\nAnalyze algorithms and data structures\n\nMake decisions involving arrangements and selections\n\n\n\nReal-world applications of counting include:\n\nCryptography: Password strength and encryption key space\nGenetics: DNA sequence analysis and gene combinations\n\nTournament brackets: March Madness and sports competitions\nLottery odds: Probability calculations for games of chance\nPassword security: Character combinations and brute force protection"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-fundamental-counting",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-fundamental-counting",
    "title": "PSTAT 5A: Counting",
    "section": "The Fundamental Counting Principle",
    "text": "The Fundamental Counting Principle\n\n\n\n\n\n\n\n\n\nMultiplication Rule\n\n\nIf a procedure consists of \\(k\\) separate tasks where:\n\nTask 1 can be performed in \\(n_1\\) ways\nTask 2 can be performed in \\(n_2\\) ways\n‚Ä¶\nTask \\(k\\) can be performed in \\(n_k\\) ways\n\nThen, the entire procedure can be performed in \\(n_1 \\times n_2 \\times \\cdots \\times n_k\\) ways\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n    Start([Start]) --&gt; T1[\"Task¬†1:¬†n‚ÇÅ¬†ways\"]\n    T1 --&gt; C1[Choice¬†1]\n    T1 --&gt; C2[Choice¬†2]\n    T1 --&gt; Cn1[Choice¬†n‚ÇÅ]\n    C1 --&gt; T2[\"Task¬†2:¬†n‚ÇÇ¬†ways\"]\n    C2 --&gt; T2\n    Cn1 --&gt; T2\n    T2 --&gt; C21[Choice¬†1]\n    T2 --&gt; C22[Choice¬†2]\n    T2 --&gt; C2n[Choice¬†n‚ÇÇ]\n    C21 --&gt; Total((\"Total¬†ways:\\n¬†n‚ÇÅ¬†√ó¬†n‚ÇÇ¬†√ó¬†...¬†√ó¬†n‚Çñ\"))\n    C22 --&gt; Total\n    C2n --&gt; Total"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#simple-counting-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#simple-counting-example",
    "title": "PSTAT 5A: Counting",
    "section": "Simple Counting Example",
    "text": "Simple Counting Example\n\nFormat ABC-123\n\nFirst position: 26 letters\nSecond position: 26 letters\nThird position: 26 letters\nFourth position: 10 digits\nFifth position: 10 digits\nSixth position: 10 digits\n\n\n\n\nSolution. Total possibilities: \\(26 \\times 26 \\times 26 \\times 10 \\times 10 \\times 10 = 26^3 \\times 10^3 = 17,576,000\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#restaurant-menu-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#restaurant-menu-example",
    "title": "PSTAT 5A: Counting",
    "section": "Restaurant Menu Example",
    "text": "Restaurant Menu Example\n\nA restaurant offers:\nüç§ Appetizers: 4\nüç≤ Main Courses: 6\nüç∞ Desserts: 3\nHow many different three-course meals are possible?\n\n\nSolution. \\(4 \\times 6 \\times 3 = 72\\) different meals"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-1",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-1",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\nA password must contain:\n\nExactly 8 characters\nEach character is either a letter (26 possibilities) or digit (10 possibilities)\n\nHow many possible passwords are there?\n\n\n\n\n\n\n\nSolution. Each position has \\(26 + 10 = 36\\) choices.\nTotal: \\(36^8 = 2,821,109,907,456\\) passwords"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-permutations",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-permutations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Permutations?",
    "text": "What Are Permutations?\n\n\n\n\n\n\n\nPermutation\n\n\nAn arrangement of objects where order matters\n\n\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nAll permutations of ABC:\n1. ABC\n2. ACB\n3. BAC\n4. BCA\n5. CAB\n6. CBA\n\n\n\n\n\nRace finish positions (1st, 2nd, 3rd)\nSeating arrangements\nPasswords\nDNA sequences"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#permutations-of-n-distinct-objects",
    "href": "files/lecture_notes/lecture6/lecture6.html#permutations-of-n-distinct-objects",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(n\\) Distinct Objects",
    "text": "Permutations of \\(n\\) Distinct Objects\n\n\n\n\n\n\n\n\n\nKey Formula\n\n\nThe number of ways to arrange \\(n\\) distinct objects is:\n\\[n! = n \\times (n-1) \\times (n-2) \\times \\cdots \\times 2 \\times 1\\]\n\n\n\n\n\n\n\n\n\n\n\nSeating Process:\n1st position: 5 choices (Alice, Bob, Carol, David, Eve)\n2nd position: 4 choices (whoever is left)\n3rd position: 3 choices (whoever is left)\n4th position: 2 choices (whoever is left)\n5th position: 1 choice (last person)\nHow many ways can 5 people sit in a row?\n\n\nSolution. \\(5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#factorial-values",
    "href": "files/lecture_notes/lecture6/lecture6.html#factorial-values",
    "title": "PSTAT 5A: Counting",
    "section": "Factorial Values",
    "text": "Factorial Values\n\n\n\n\n\n\\(n\\)\n\\(n!\\)\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n2\n2\n\n\n3\n6\n\n\n4\n24\n\n\n5\n120\n\n\n10\n3,628,800\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\n\nNote\n\n\n\\(0! = 1\\) by definition"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-permutations-r-from-n",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-permutations-r-from-n",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(r\\) Objects from \\(n\\)",
    "text": "Permutations of \\(r\\) Objects from \\(n\\)\n\n\n\n\n\n\n\nKey Formula\n\n\n\\(P(n,r)\\) or \\(_nP_r\\): Number of ways to arrange \\(r\\) objects selected from \\(n\\) distinct objects\n\\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\n\n\n\n\nHow many ways can we select and arrange 3 people from a group of 8 for president, vice-president, and secretary?\n\n\nSolution. \\(P(8,3) = \\frac{8!}{(8-3)!} = \\frac{8!}{5!} = 8 \\times 7 \\times 6 = 336\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#understanding-pnr",
    "href": "files/lecture_notes/lecture6/lecture6.html#understanding-pnr",
    "title": "PSTAT 5A: Counting",
    "section": "Understanding \\(P(n,r)\\)",
    "text": "Understanding \\(P(n,r)\\)\nWhy is \\(P(n,r) = \\frac{n!}{(n-r)!}\\)?\n\nFirst position: \\(n\\) choices\nSecond position: \\((n-1)\\) choices\n\nThird position: \\((n-2)\\) choices\n‚Ä¶\n\\(r\\)-th position: \\((n-r+1)\\) choices\n\n\nTotal: \\(n \\times (n-1) \\times (n-2) \\times \\cdots \\times (n-r+1) = \\frac{n!}{(n-r)!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-2",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-2",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\nA baseball team has 15 players. How many ways can the coach:\n\nArrange all 15 players in a line?\nChoose and arrange 9 players for the starting lineup (batting order matters)?\n\n\n\nSolution. \n\n\\(15! = 1,307,674,368,000\\)\n\\(P(15,9) = \\frac{15!}{6!} = 1,816,214,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-permutations-repetition",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-permutations-repetition",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition",
    "text": "Permutations with Repetition\n\n\n\n\n\n\n\nPermutations with Repetition\n\n\nWhen some objects are identical, we have fewer distinct arrangements\nIf we have \\(n\\) objects where:\n\n\\(n_1\\) are of type 1\n\\(n_2\\) are of type 2\n‚Ä¶\n\\(n_k\\) are of type \\(k\\)\n\nNumber of distinct arrangements: \\(\\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#permutations-with-repetition-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#permutations-with-repetition-example",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition Example",
    "text": "Permutations with Repetition Example\n\n\n\nHow many distinct arrangements are there of the letters in ‚ÄúSTATISTICS‚Äù?\n\nS-T-A-T-I-S-T-I-C-S\n\nTotal letters: 10\nS appears 3 times\nT appears 3 times\nA appears 1 time\nI appears 2 times\nC appears 1 time\n\n\n\nSolution. \\(\\frac{10!}{3! \\times 3! \\times 1! \\times 2! \\times 1!} = \\frac{3,628,800}{6 \\times 6 \\times 1 \\times 2 \\times 1} = \\frac{3,628,800}{72} = 50,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-combinations",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Combinations?",
    "text": "What Are Combinations?\n\n\n\n\n\n\n\n\n\nCombination\n\n\nA selection of objects where order does NOT matter\n\n\n\n\n\nCommittee Selection:\nABC, BAC, CAB ‚Üí Same committee!\n\nRace Results:\nABC, BAC, CAB ‚Üí Different outcomes!\n\nKey Point: Order doesn't matter for combinations\n\n\n\nChoosing committee members\nSelecting pizza toppings\nForming study groups\nLottery number selection\n\n\n\n\n\n\n                            \n                                            \n\n\nAll combinations of 4 items taken 2 at a time:\n1. A, B\n2. A, C\n3. A, D\n4. B, C\n5. B, D\n6. C, D"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-combinations-formula",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-combinations-formula",
    "title": "PSTAT 5A: Counting",
    "section": "Combinations Formula",
    "text": "Combinations Formula\n\n\n\n\n\n\n\nKey Formula\n\n\n\\(C(n,r)\\) or \\(\\binom{n}{r}\\): Number of ways to choose \\(r\\) objects from \\(n\\) distinct objects (order doesn‚Äôt matter)\n\\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]\n\n\n\n\n\nHow many ways can we choose 3 people from a group of 8 for a committee?\n\\(C(8,3) = \\frac{8!}{3!(8-3)!} = \\frac{8!}{3! \\times 5!} = \\frac{8 \\times 7 \\times 6}{3 \\times 2 \\times 1} = 56\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#relationship-permutations-vs-combinations",
    "href": "files/lecture_notes/lecture6/lecture6.html#relationship-permutations-vs-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "Relationship: Permutations vs Combinations",
    "text": "Relationship: Permutations vs Combinations\n\n\n\n\n\n\n\nRelationship\n\n\n\\(P(n,r) = C(n,r) \\times r!\\)\nWhy? For each combination of \\(r\\) objects, there are \\(r!\\) ways to arrange them\n\n\n\n\n\nRelationship: P(n,r) = C(n,r) √ó r!\n\nExample: Choose 3 from 8 people\n- C(8,3) = 56 combinations\n- For each combination, arrange 3 people: 3! = 6 ways\n- Total: 56 √ó 6 = 336 = P(8,3)\n\nCombination ABC ‚Üí Permutations: ABC, ACB, BAC, BCA, CAB, CBA\n\n\n\\(P(8,3) = C(8,3) \\times 3! = 56 \\times 6 = 336\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-permutation-vs-combination",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-permutation-vs-combination",
    "title": "PSTAT 5A: Counting",
    "section": "Key Decision: Permutation or Combination?",
    "text": "Key Decision: Permutation or Combination?\n\n\n\n\n\n\n\n\n\nHow to Decide\n\n\nAsk yourself: Does order matter?\nOrder matters ‚Üí Use Permutations - Arrangements, sequences, rankings\nOrder doesn‚Äôt matter ‚Üí Use Combinations\n- Selections, groups, subsets\n\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nTip\n\n\n‚úÖ \\(P(n,r)\\) = counts both selection & arrangement ‚Üí grows faster\n‚úÖ \\(C(n,r)\\) = counts only selection ‚Üí grows slower\n‚úÖ The difference comes from \\(r!\\), which is big even for modest \\(r\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-3",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-3",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nFrom a class of 20 students:\n\nHow many ways to choose 5 students for a study group?\nHow many ways to choose a president, vice-president, and secretary?\n\n\n\nSolution. \n\n\\(C(20,5) = \\frac{20!}{5! \\times 15!} = 15,504\\) (order doesn‚Äôt matter)\n\\(P(20,3) = \\frac{20!}{17!} = 6,840\\) (order matters)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#properties-of-combinations",
    "href": "files/lecture_notes/lecture6/lecture6.html#properties-of-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "Properties of Combinations",
    "text": "Properties of Combinations\n\n\n\n\n\n\n\nProperties\n\n\n\nSymmetry: \\(\\binom{n}{r} = \\binom{n}{n-r}\\)\nPascal‚Äôs Identity: \\(\\binom{n}{r} = \\binom{n-1}{r-1} + \\binom{n-1}{r}\\)\nBoundary conditions: \\(\\binom{n}{0} = \\binom{n}{n} = 1\\)\n\n\n\n\n\n\n\\(\\binom{8}{3} = \\binom{8}{5} = 56\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#pascals-triangle",
    "href": "files/lecture_notes/lecture6/lecture6.html#pascals-triangle",
    "title": "PSTAT 5A: Counting",
    "section": "Pascal‚Äôs Triangle",
    "text": "Pascal‚Äôs Triangle\n\n\n\n           1\n         1   1\n       1   2   1\n     1   3   3   1\n   1   4   6   4   1\n 1   5  10  10   5   1\n1   6  15  20  15   6   1\nPattern: Each number is the sum of the two numbers above it.\nFormula: \\(\\binom{n}{r} = \\binom{n-1}{r-1} + \\binom{n-1}{r}\\)\nEach number is \\(\\binom{n}{r}\\) where \\(n\\) is the row and \\(r\\) is the position\nExample: \\(\\binom{4}{2} = 6\\) (row 4, position 2)\nRow 3:       1   3   3   1\n            ‚Üô ‚Üò ‚Üô ‚Üò ‚Üô ‚Üò ‚Üô ‚Üò\nRow 4:     1   4   6   4   1\n\n\n\n\n\n\n                            \n                                            \n\n\nPascal's Triangle (showing C(n,r) values):\nRow 0: [1]\nRow 1: [1, 1]\nRow 2: [1, 2, 1]\nRow 3: [1, 3, 3, 1]\nRow 4: [1, 4, 6, 4, 1]\nRow 5: [1, 5, 10, 10, 5, 1]\nRow 6: [1, 6, 15, 20, 15, 6, 1]\nRow 7: [1, 7, 21, 35, 35, 21, 7, 1]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#binomial-theorem",
    "href": "files/lecture_notes/lecture6/lecture6.html#binomial-theorem",
    "title": "PSTAT 5A: Counting",
    "section": "Binomial Theorem",
    "text": "Binomial Theorem\n\n\n\n\n\n\n\nKey Formula\n\n\n\\[(x + y)^n = \\sum_{r=0}^{n} \\binom{n}{r} x^{n-r} y^r\\]\n\n\n\n\n\n\\((x + y)^3 = \\binom{3}{0}x^3 + \\binom{3}{1}x^2y + \\binom{3}{2}xy^2 + \\binom{3}{3}y^3\\)\n\\(= x^3 + 3x^2y + 3xy^2 + y^3\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-counting-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-counting-probability",
    "title": "PSTAT 5A: Counting",
    "section": "Counting and Probability",
    "text": "Counting and Probability\n\n\n\nA committee of 4 people is chosen from 7 women and 5 men. What‚Äôs the probability that exactly 2 are women?\n\nTotal ways to choose 4 from 12: \\(\\binom{12}{4} = 495\\)\nWays to choose 2 women from 7: \\(\\binom{7}{2} = 21\\)\nWays to choose 2 men from 5: \\(\\binom{5}{2} = 10\\)\n\nSolution. Favorable outcomes: \\(\\binom{7}{2} \\times \\binom{5}{2} = 21 \\times 10 = 210\\)\nProbability: \\(\\frac{210}{495} = \\frac{14}{33}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-4",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-4",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\n\nA standard deck has 52 cards. What‚Äôs the probability that a 5-card hand contains:\n\nExactly 3 aces?\nAt least 1 ace?\n\n\n\nSolution. \n\nWays to get 3 aces from 4: \\(\\binom{4}{3} = 4\\) Ways to get 2 non-aces from 48: \\(\\binom{48}{2} = 1,128\\) Total 5-card hands: \\(\\binom{52}{5} = 2,598,960\\)\nProbability: \\(\\frac{4 \\times 1,128}{2,598,960} = \\frac{4,512}{2,598,960} \\approx 0.00174\\)\nWays to choose 5 cards with no aces: \\(\\binom{48}{5} = 1,712,304\\)\n\\(P(\\text{at least 1 ace}) = 1 - \\frac{\\binom{48}{5}}{\\binom{52}{5}} = 1 - \\frac{1,712,304}{2,598,960} \\approx 0.341\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-4-continued",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-4-continued",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 4 (continued)",
    "text": "Practice Problem 4 (continued)\n\n\nAt least 1 ace = 1 - (no aces)\n\n\n\n\n\n\n\n\nTip\n\n\nWays to choose 5 cards with no aces: \\(\\binom{48}{5} = 1,712,304\\)\n\n\n\n\nSolution. \\(P(\\text{at least 1 ace}) = 1 - \\frac{\\binom{48}{5}}{\\binom{52}{5}} = 1 - \\frac{1,712,304}{2,598,960} \\approx 0.341\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#permutations-with-restrictions",
    "href": "files/lecture_notes/lecture6/lecture6.html#permutations-with-restrictions",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Restrictions",
    "text": "Permutations with Restrictions\n\nHow many 6-letter ‚Äúwords‚Äù can be formed from the letters A, B, C, D, E, F if:\n\nNo letter is repeated\nA and B must be adjacent\n\n\n\nSolution. Treat AB as a single unit\n\n5 units to arrange: (AB), C, D, E, F ‚Üí \\(5! = 120\\) ways\nA and B can be arranged within their unit: \\(2! = 2\\) ways\nTotal: \\(5! \\times 2! = 240\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-inclusion-exclusion",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-inclusion-exclusion",
    "title": "PSTAT 5A: Counting",
    "section": "The Inclusion-Exclusion Principle",
    "text": "The Inclusion-Exclusion Principle\n\n\n\nFor two sets \\(A\\) and \\(B\\): \\[|A \\cup B| = |A| + |B| - |A \\cap B|\\]\nFor three sets \\(A\\), \\(B\\), and \\(C\\): \\[|A \\cup B \\cup C| = |A| + |B| + |C| - |A \\cap B| \\\\\n- |A \\cap C| - |B \\cap C| + |A \\cap B \\cap C|\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#inclusion-exclusion-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#inclusion-exclusion-example",
    "title": "PSTAT 5A: Counting",
    "section": "Inclusion-Exclusion Example",
    "text": "Inclusion-Exclusion Example\n\nHow many integers from 1 to 100 are divisible by 2, 3, or 5?\n\nLet:\n\n\\(A\\) = divisible by 2: \\(|A| = 50\\)\n\\(B\\) = divisible by 3: \\(|B| = 33\\)\n\\(C\\) = divisible by 5: \\(|C| = 20\\)\n\n\n\n\n\n\n\nNote\n\n\n\\(|A \\cap B| = 16\\) (divisible by 6)\n\\(|A \\cap C| = 10\\) (divisible by 10)\n\\(|B \\cap C| = 6\\) (divisible by 15)\n\\(|A \\cap B \\cap C| = 3\\) (divisible by 30)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#inclusion-exclusion-solution",
    "href": "files/lecture_notes/lecture6/lecture6.html#inclusion-exclusion-solution",
    "title": "PSTAT 5A: Counting",
    "section": "Inclusion-Exclusion Solution",
    "text": "Inclusion-Exclusion Solution\n\nSolution. \\[|A \\cup B \\cup C| = 50 + 33 + 20 - 16 - 10 - 6 + 3 = 74\\]\nAnswer: 74 integers from 1 to 100 are divisible by at least one of 2, 3, or 5"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#multinomial-coefficients",
    "href": "files/lecture_notes/lecture6/lecture6.html#multinomial-coefficients",
    "title": "PSTAT 5A: Counting",
    "section": "Multinomial Coefficients",
    "text": "Multinomial Coefficients\n\n\n\n\n\n\n\nMultinomial Coefficient\n\n\nNumber of ways to divide \\(n\\) objects into groups of sizes \\(n_1, n_2, \\ldots, n_k\\):\n\\[\\binom{n}{n_1, n_2, \\ldots, n_k} = \\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\]\n\n\n\n\n\nHow many ways can 12 people be divided into 3 teams of 4?\n\\(\\binom{12}{4,4,4} = \\frac{12!}{4! \\times 4! \\times 4!} = 34,650\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#sec-problem-solving-strategy",
    "href": "files/lecture_notes/lecture6/lecture6.html#sec-problem-solving-strategy",
    "title": "PSTAT 5A: Counting",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\n\n\n\n\n\nStrategy\n\n\n\nRead carefully: What exactly are we counting?\nIdentify the type: Permutation, combination, or other?\nCheck for restrictions: Are there constraints?\nDoes order matter?: This determines permutation vs combination\nBreak down complex problems: Use multiplication principle\nVerify your answer: Does it make sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/lecture6/lecture6.html#common-mistakes-to-avoid",
    "title": "PSTAT 5A: Counting",
    "section": "Common Mistakes to Avoid",
    "text": "Common Mistakes to Avoid\n\n\n\n\n\n\n\nCommon Mistakes\n\n\n\nConfusing permutations and combinations\n\nAlways ask: ‚ÄúDoes order matter?‚Äù\n\nForgetting about restrictions\n\nRead the problem carefully\n\nDouble counting\n\nMake sure you‚Äôre not counting the same arrangement twice\n\nNot considering the complement\n\nSometimes ‚Äúat least‚Äù problems are easier using complements"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-6",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-6",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\n\nA class has 15 students: 8 women and 7 men. How many ways can we:\n\nForm a committee of 5 people with exactly 3 women?\nArrange 6 people in a row with alternating genders (starting with a woman)?\n\n\n\nSolution. \n\n\\(\\binom{8}{3} \\times \\binom{7}{2} = 56 \\times 21 = 1,176\\)\nChoose 3 women from 8: \\(P(8,3) = 336\\) Choose 3 men from 7: \\(P(7,3) = 210\\) Total: \\(336 \\times 210 = 70,560\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#counting-in-computer-science",
    "href": "files/lecture_notes/lecture6/lecture6.html#counting-in-computer-science",
    "title": "PSTAT 5A: Counting",
    "section": "Counting in Computer Science",
    "text": "Counting in Computer Science\n\nPassword Security:\n\n8-character password with letters, digits, symbols\n\\((26 + 26 + 10 + 32)^8 = 94^8 \\approx 6.1 \\times 10^{15}\\)\n\nHash Functions:\n\nDistributing data into buckets\nCollision probability calculations\n\nAlgorithm Analysis:\n\nCounting operations, comparisons\nBig O notation foundations"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#counting-in-genetics",
    "href": "files/lecture_notes/lecture6/lecture6.html#counting-in-genetics",
    "title": "PSTAT 5A: Counting",
    "section": "Counting in Genetics",
    "text": "Counting in Genetics\n\nDNA Sequences:\n\n4 bases (A, T, G, C)\nGene of length \\(n\\): \\(4^n\\) possible sequences\n\nProtein Folding:\n\nNumber of possible conformations\nCombinatorial explosion\n\nPopulation Genetics:\n\nHardy-Weinberg calculations\nAllele combinations"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#real-world-applications",
    "href": "files/lecture_notes/lecture6/lecture6.html#real-world-applications",
    "title": "PSTAT 5A: Counting",
    "section": "Real-World Applications",
    "text": "Real-World Applications\n\nLottery:\n\nPowerball: Choose 5 from 69, then 1 from 26\nOdds: \\(\\frac{1}{\\binom{69}{5} \\times 26} \\approx \\frac{1}{292,000,000}\\)\n\nCryptography:\n\nKey space size determines security\nRSA encryption relies on large number factorization\n\nSports Tournaments:\n\nMarch Madness bracket: \\(2^{63}\\) possible outcomes\nRound-robin tournaments: \\(\\binom{n}{2}\\) games"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture6/lecture6.html#key-formulas-summary",
    "title": "PSTAT 5A: Counting",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\n\n\n\n\n\n\n\nSummary of Key Formulas\n\n\n\nPermutations: \\(P(n,r) = \\frac{n!}{(n-r)!}\\)\nCombinations: \\(C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\)\nWith repetition: \\(\\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\)\nInclusion-Exclusion: \\(|A \\cup B| = |A| + |B| - |A \\cap B|\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#technology-and-counting",
    "href": "files/lecture_notes/lecture6/lecture6.html#technology-and-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Technology and Counting",
    "text": "Technology and Counting\n\n\n\n\n\n\n\nTools\n\n\nCalculators:\n\nUse nPr and nCr functions\nBe careful with large numbers\n\nSoftware:\n\nR: factorial(), choose(), combn()\nPython: math.factorial(), math.comb()\nExcel: FACT(), COMBIN(), PERMUT()\n\nOnline Tools:\n\nWolfram Alpha for complex calculations\nCombination/permutation calculators"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-7",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-7",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\n\nA standard deck of cards is shuffled. What‚Äôs the probability that:\n\nThe top 4 cards are all hearts?\nIn a 13-card hand, you get exactly one card from each rank?\n\n\n\nSolution. \n\n\\(\\frac{13}{52} \\times \\frac{12}{51} \\times \\frac{11}{50} \\times \\frac{10}{49} = \\frac{13 \\times 12 \\times 11 \\times 10}{52 \\times 51 \\times 50 \\times 49} \\approx 0.0026\\)\nChoose 1 card from each of 13 ranks: \\(4^{13}\\) Total 13-card hands: \\(\\binom{52}{13}\\) Probability: \\(\\frac{4^{13}}{\\binom{52}{13}} \\approx 6.3 \\times 10^{-6}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#extending-to-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#extending-to-probability",
    "title": "PSTAT 5A: Counting",
    "section": "Extending to Probability",
    "text": "Extending to Probability\n\n\n\n\n\n\n\nDistributions\n\n\nHypergeometric Distribution:\n\nDrawing without replacement\nUses combinations: \\(P(X = k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}\\)\n\nBinomial Distribution:\n\nDrawing with replacement\nUses combinations: \\(P(X = k) = \\binom{n}{k}p^k(1-p)^{n-k}\\)\n\nWe‚Äôll explore these distributions in detail in future lectures"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#historical-note",
    "href": "files/lecture_notes/lecture6/lecture6.html#historical-note",
    "title": "PSTAT 5A: Counting",
    "section": "Historical Note",
    "text": "Historical Note\n\n\n\n\n\n\n\nHistory\n\n\nBlaise Pascal (1623-1662) and Pierre de Fermat (1601-1665): - Founded probability theory through gambling problems - Pascal‚Äôs triangle and combinations\nLeonhard Euler (1707-1783): - Advanced combinatorics - Graph theory connections\nModern applications span computer science, biology, physics, and economics"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#common-student-questions",
    "href": "files/lecture_notes/lecture6/lecture6.html#common-student-questions",
    "title": "PSTAT 5A: Counting",
    "section": "Common Student Questions",
    "text": "Common Student Questions\n\nQ: ‚ÄúWhen do I use permutations vs combinations?‚Äù\nA: Ask ‚ÄúDoes order matter?‚Äù Order matters ‚Üí permutation\nQ: ‚ÄúHow do I handle restrictions?‚Äù\nA: Break the problem into cases or use complementary counting\nQ: ‚ÄúWhat if objects are identical?‚Äù\nA: Use the formula for permutations with repetition\nQ: ‚ÄúHow do I check my answer?‚Äù\nA: Verify with small examples or use different methods"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#looking-ahead",
    "href": "files/lecture_notes/lecture6/lecture6.html#looking-ahead",
    "title": "PSTAT 5A: Counting",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\n\n\n\n\nNext Lecture\n\n\nNext lecture: Discrete Probability Distributions - Binomial distribution (using combinations!)\n\nHypergeometric distribution\nGeometric distribution\nExpected value and variance\n\nConnection: Today‚Äôs counting techniques are essential for probability calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#study-tips",
    "href": "files/lecture_notes/lecture6/lecture6.html#study-tips",
    "title": "PSTAT 5A: Counting",
    "section": "Study Tips",
    "text": "Study Tips\n\n\n\n\n\n\n\nTips\n\n\n\nPractice, practice, practice: Work through many examples\nIdentify patterns: Learn to recognize problem types\nStart simple: Build up to complex problems\nCheck your work: Use different approaches when possible\nUnderstand concepts: Don‚Äôt just memorize formulas"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#learning-summary",
    "href": "files/lecture_notes/lecture6/lecture6.html#learning-summary",
    "title": "PSTAT 5A: Counting",
    "section": "Learning Objectives Summary",
    "text": "Learning Objectives Summary\n\n\n\n\n\n\n\nWhat We‚Äôve Covered\n\n\nIn this lecture, we‚Äôve addressed all the learning objectives:\n\n‚úÖ Apply the fundamental counting principles: Covered in Section¬†0.4\n‚úÖ Calculate permutations with and without repetition: Covered in Section¬†0.8, Section¬†0.11, and Section¬†0.14\n\n‚úÖ Calculate combinations and understand when to use them: Covered in Section¬†0.16 and Section¬†0.17\n‚úÖ Distinguish between permutations and combinations: Covered in Section¬†0.19\n‚úÖ Use counting techniques to solve probability problems: Covered in Section¬†0.24\n‚úÖ Apply the inclusion-exclusion principle: Covered in Section¬†0.28\n‚úÖ Solve complex counting problems systematically: Covered in Section¬†0.32"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#final-thoughts",
    "href": "files/lecture_notes/lecture6/lecture6.html#final-thoughts",
    "title": "PSTAT 5A: Counting",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nCounting is fundamental to:\n\nProbability calculations\nStatistical inference\nComputer algorithms\nScientific modeling\n\n\n\n\n\n\n\n\nKnow the Basics\n\n\nPermutations and combinations are the building blocks for advanced statistical concepts"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#questions",
    "href": "files/lecture_notes/lecture6/lecture6.html#questions",
    "title": "PSTAT 5A: Counting",
    "section": "Questions?",
    "text": "Questions?"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "href": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Today‚Äôs Agenda",
    "text": "Today‚Äôs Agenda\n\nIntroduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\nWhy it matters before any modeling\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset they‚Äôve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "href": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Learning Objectives (LOs)",
    "text": "Learning Objectives (LOs)\nBy the end of this lecture you should be able to:\n\nDefine descriptive statistics and explain its importance in data analysis (Section¬†1)\nDistinguish between different types of data and measurement scales (Section¬†2)\nCalculate and interpret measures of central tendency (mean, median, mode)(Section¬†3)\nUnderstand when to use each measure of central tendency\nApply Python to compute descriptive statistics(Section¬†9)\nInterpret basic descriptive statistics in real-world contexts(Section¬†10)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Statistics",
    "text": "Statistics\nFacts are stubborn, but statistics are more pliable.\nMark Twain\n\nStatistics refers to the mathematics and techniques with which we understand data. 1\n\n\n(source)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What are Descriptive Statistics?",
    "text": "What are Descriptive Statistics?\nDescriptive statistics are numerical and graphical methods used to summarize, organize, and describe data in a meaningful way.\n\nPurpose of Descriptive Statistics\n\nSummarize large datasets into manageable information\nIdentify patterns and trends in data\nCommunicate findings clearly to others\nPrepare data for further analysis\nMake initial assessments about data quality"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs.¬†Inferential Statistics",
    "text": "Descriptive vs.¬†Inferential Statistics\n\n\n\n\n\n\n\nDescriptive Statistics\nInferential Statistics\n\n\n\n\nDescribes what the data shows\nMakes predictions about populations\n\n\nSummarizes sample data\nUses sample data to make generalizations\n\n\nNo conclusions beyond the data\nDraws conclusions beyond the immediate data\n\n\nExamples: mean, median, graphs\nExamples: hypothesis testing, confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs.¬†Inferential Statistics",
    "text": "Descriptive vs.¬†Inferential Statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "href": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Why Data Types Matter",
    "text": "Why Data Types Matter\nUnderstanding data types is crucial because:\n\nDifferent statistics are appropriate for different data types\nStatistical methods depend on the level of measurement\nMisapplying statistics can lead to incorrect conclusions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Data",
    "text": "Types of Data\ngraph TD\n    A[Variable Types]\n    A --&gt; B[Categorical]\n    A --&gt; C[Numerical]\n    B --&gt; B1[\"Nominal&lt;br/&gt;e.g., gender, major\"]\n    B --&gt; B2[\"Ordinal&lt;br/&gt;e.g., rating, education level\"]\n    C --&gt; C1[\"Discrete&lt;br/&gt;e.g., count (# of students)\"]\n    C --&gt; C2[\"Continuous&lt;br/&gt;e.g., measurements like height, weight\"]\n    \n    classDef root fill:#e1f5fe,stroke:#01579b,stroke-width:3px\n    classDef categorical fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef numerical fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px\n    classDef nominal fill:#fce4ec,stroke:#880e4f,stroke-width:2px\n    classDef ordinal fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef discrete fill:#e0f2f1,stroke:#00695c,stroke-width:2px\n    classDef continuous fill:#f1f8e9,stroke:#33691e,stroke-width:2px\n    \n    class A root\n    class B categorical\n    class C numerical\n    class B1 nominal\n    class B2 ordinal\n    class C1 discrete\n    class C2 continuous\n\nPrompt: Which summary stat would you pick for ‚Äúmajor‚Äù? For ‚Äúgpa‚Äù?"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Categorical Data (Qualitative)",
    "text": "Categorical Data (Qualitative)\n\n\nNominal Data\n\nCategories with no natural order\nExamples: gender, color, brand names, marital status\nAppropriate statistics: mode, frequency counts, proportions\n\n\nOrdinal Data\n\nCategories with a natural order or ranking\nExamples: education level, satisfaction ratings, letter grades\nAppropriate statistics: mode, median, percentiles"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Numerical Data (Quantitative)",
    "text": "Numerical Data (Quantitative)\n\nDiscrete Data\n\nCountable values, often integers\nExamples: number of children, cars sold, defective items\nCan take on finite or countably infinite values\n\n\n\nContinuous Data\n\nCan take any value within a range\nExamples: height, weight, temperature, time\nMeasured rather than counted"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "href": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Measurement Scales Summary",
    "text": "Measurement Scales Summary\n\n\n\n\n\n\n\n\n\n\nScale\nType\nProperties\nExamples\nAppropriate Statistics\n\n\n\n\nNominal\nCategorical\nCategories only\nGender, Color\nMode, Frequency\n\n\nOrdinal\nCategorical\nOrder matters\nRankings, Grades\nMode, Median\n\n\nInterval\nNumerical\nEqual intervals, no true zero\nTemperature (¬∞C)\nMean, Median, Mode\n\n\nRatio\nNumerical\nEqual intervals, true zero\nHeight, Weight, Income\nAll statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What is Central Tendency?",
    "text": "What is Central Tendency?\nCentral tendency describes the center or typical value of a dataset.\nIt answers the question: ‚ÄúWhat is a representative value for this data?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition and Formula",
    "text": "Definition and Formula\n\nüéØ Definition: The mean is the sum of all values divided by the number of values.\n\n\nFormula\n\nFor a sample: \\(\\bar{x} = \\frac{\\sum x}{n}\\)\nFor a population: \\(\\mu = \\frac{\\sum x}{N}\\)\n\nWhere:\n\n\\(\\bar{x}\\) (x-bar) = sample mean\n\\(\\mu\\) (mu) = population mean\n\\(\\sum x\\) = sum of all values\n\\(n\\) = sample size, \\(N\\) = population size"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example Calculation",
    "text": "Example Calculation\nStudent test scores: 85, 90, 78, 92, 88\n\nMean = \\(\\frac{85 + 90 + 78 + 92 + 88}{5} = \\frac{433}{5} = 86.6\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mean",
    "text": "Properties of the Mean\n\nUses all data points - every value affects the mean\nSensitive to outliers - extreme values can distort the mean\nUnique - there is only one mean for a dataset\nCan be calculated for interval and ratio data\nBalancing point - sum of deviations from mean equals zero"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mean",
    "text": "When to Use the Mean\n‚úÖ Use the mean when:\n\nData is approximately symmetric\nNo extreme outliers present\nWorking with interval or ratio data\nNeed to use the value in further calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "href": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Advantages and Disadvantages",
    "text": "Advantages and Disadvantages\n\n\nAdvantages\n\nUses all information in the dataset\nAlgebraically defined and mathematically tractable\nWidely understood and accepted\n\n\nDisadvantages\n\nAffected by outliers and skewed distributions\nMay not represent a typical value in skewed data\nCannot be used with nominal or ordinal data"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\n\nüéØ Definition: The median is the middle value when data is arranged in ascending or descending order."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "href": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Calculation Steps",
    "text": "Calculation Steps\n\nArrange data in ascending order\nFind the middle position:\n\nIf n is odd: position = \\(\\frac{n + 1}{2}\\)\nIf n is even: average of positions \\(\\frac{n}{2}\\) and \\(\\frac{n}{2} + 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#examples",
    "href": "files/lecture_notes/lecture2/lecture2.html#examples",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Examples",
    "text": "Examples\n\nOdd number of values:\n\nData: 12, 15, 18, 20, 25\nWhat is the median here ?\nMedian = 18 (middle value)\n\n\n\nEven number of values:\n\nData: 10, 15, 20, 25, 30, 35\nWhat is the median here ?\nMedian = \\(\\frac{20 + 25}{2} = 22.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Median",
    "text": "Properties of the Median\n\nNot affected by outliers - resistant measure\nRepresents the 50th percentile\nMay not be an actual data value (when n is even)\nAppropriate for ordinal, interval, and ratio data\nDivides data into two equal halves"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Median",
    "text": "When to Use the Median\n‚úÖ Use the median when:\n\nData is skewed (not symmetric)\nOutliers are present\nWorking with ordinal data\nWant a robust measure of central tendency\nData represents income, housing prices, or similar distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "href": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Median vs Mean with Outliers",
    "text": "Median vs Mean with Outliers\nConsider household incomes: $30,000, $32,000, $35,000, $38,000, $2,000,000\n\n\nMean = $427,000 (not representative of typical household)\nMedian = $35,000 (better represents typical household)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\n\nüéØ Definition: The mode is the value that appears most frequently in a dataset.\n\n%%{init: {'flowchart': {'nodeSpacing': 100, 'rankSpacing': 100}, 'width': 600, 'height': 400}}%%\ngraph TD\n    A[\"Mode Types\"]\n    A --&gt; B[\"Unimodal&lt;br/&gt;One peak\"]\n    A --&gt; C[\"Bimodal&lt;br/&gt;Two peaks\"]\n    A --&gt; D[\"Multimodal&lt;br/&gt;Multiple peaks\"]\n    A --&gt; E[\"No Mode&lt;br/&gt;No repeated values\"]\n    \n    classDef main fill:#e1f5fe,stroke:#01579b,stroke-width:3px,font-size:16px\n    classDef types fill:#f5f5f5,stroke:#424242,stroke-width:2px,font-size:14px\n    \n    class A main\n    class B,C,D,E types"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Distributions by Mode",
    "text": "Types of Distributions by Mode\n\nUnimodal: One mode\nBimodal: Two modes\n\nMultimodal: More than two modes\nNo mode: All values appear with equal frequency"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 1:",
    "text": "Example 1:\nData: 2, 3, 3, 4, 5, 5, 5, 6, 7\n\nAnalysis:\n\nCount each value: 2(1), 3(2), 4(1), 5(3), 6(1), 7(1)\nMost frequent value: 5 appears 3 times\nMode = 5\nType: Unimodal (one mode)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 2:",
    "text": "Example 2:\nData: 1, 2, 2, 3, 4, 4, 5\n\nAnalysis:\n\nCount each value: 1(1), 2(2), 3(1), 4(2), 5(1)\nMost frequent values: 2 and 4 both appear twice\nModes = 2 and 4\nType: Bimodal (two modes)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 3:",
    "text": "Example 3:\nData: 1, 2, 3, 4, 5\n\nAnalysis:\n\nCount each value: 1(1), 2(1), 3(1), 4(1), 5(1)\nAll values appear exactly once\nNo mode (no value repeats)\nType: No mode"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "href": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mode for Different Data Types",
    "text": "Mode for Different Data Types\nCategorical Data:\nFavorite colors: Red, Blue, Blue, Green, Blue, Red, Blue Mode = Blue\nContinuous Data:\nOften requires grouping into intervals or bins Example: Heights grouped into ranges"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mode",
    "text": "Properties of the Mode\n\nCan be used with any type of data (nominal, ordinal, interval, ratio)\nNot affected by outliers\nMay not exist or may not be unique\nRepresents the most common value\nEasy to identify in frequency distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mode",
    "text": "When to Use the Mode\n‚úÖ Use the mode when:\n\nWorking with categorical (nominal) data\nWant to identify the most popular or common choice\nData has clear peaks in frequency\nQuality control applications (most common defect type)\nBusiness applications (best-selling product, most common customer complaint)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Comparing Measures of Central Tendency",
    "text": "Comparing Measures of Central Tendency\n\n\n\n\n\n\n\n\n\n\nMeasure\nBest for Data Type\nStrengths\nWeaknesses\nAffected by Outliers?\n\n\n\n\nMean\nInterval, Ratio\nUses all data, mathematically tractable\nSensitive to outliers\nYes\n\n\nMedian\nOrdinal, Interval, Ratio\nRobust to outliers, represents middle\nIgnores extreme values\nNo\n\n\nMode\nAll types\nWorks with categorical, identifies most common\nMay not exist/be unique\nNo"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "href": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Shape of Distribution Effects",
    "text": "Shape of Distribution Effects\n\nSymmetric distribution: Mean ‚âà Median ‚âà Mode\nRight-skewed (positively skewed): Mean &gt; Median &gt; Mode\n\nLeft-skewed (negatively skewed): Mode &gt; Median &gt; Mean"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "href": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Central Measures",
    "text": "Central Measures\n\n\n\nMean CalculationMedian CalculationMode Calculation\n\n\n\n# Import numpy library for numeric operations\nimport numpy as np \n\n# Import pandas library for data structures\nimport pandas as pd\n\n# Define sample data as a list of test scores\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\n\n# Compute the arithmetic mean using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np:.2f}\")\n\n# Convert the data list into a pandas DataFrame\ndf = pd.DataFrame({'scores': data})\n\n# Compute the arithmetic mean using Pandas\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd:.2f}\")\n\n# Manually sum all scores and divide by count\nmanual_mean = sum(data) / len(data)\nprint(f\"Mean (Manual): {manual_mean:.2f}\")\n\nMean (NumPy): 87.10\nMean (Pandas): 87.10\nMean (Manual): 87.10\n\n\n\n\n\n# Compute the median value using NumPy\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np:.2f}\")\n\n# Compute the median value using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd:.2f}\")\n\n# Sort the data list in ascending order\nsorted_data = sorted(data)\n\n# Determine the number of elements\nn = len(sorted_data)\n\n# If even count, average the two middle elements; else take middle element\nif n % 2 == 0:\n    manual_median = (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2\nelse:\n    manual_median = sorted_data[n//2]\n\nprint(f\"Median (Manual): {manual_median:.2f}\")\n\nMedian (NumPy): 87.50\nMedian (Pandas): 87.50\nMedian (Manual): 87.50\n\n\n\n\n\n# Import SciPy stats module to compute mode\nfrom scipy import stats\n\n# Use SciPy to find the most common value and its count\nmode_result = stats.mode(data, keepdims=True)\nprint(f\"Mode (SciPy): {mode_result.mode[0]}, Count: {mode_result.count[0]}\")\n\n# Use Pandas to get mode(s) from the DataFrame\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\n# Import Counter for manual frequency counting\nfrom collections import Counter\n\n# Count occurrences of each score\ncounter = Counter(data)\n\n# Find the highest frequency\nmax_count = max(counter.values())\n\n# Identify all values that appear with that frequency\nmodes = [k for k, v in counter.items() if v == max_count]\n\nprint(f\"Mode (Manual): {modes}, Count: {max_count}\")\n\nMode (SciPy): 85, Count: 2\nMode (Pandas): [85]\nMode (Manual): [85], Count: 2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "href": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mean, Mode and Median Visualization",
    "text": "Mean, Mode and Median Visualization\n\nCodeVisualization\n\n\n\n# import libraries\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n# define your data and compute statistics here\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\nmean_np   = np.mean(data)\nmedian_np = np.median(data)\n# for mode, use Counter\ncounter   = Counter(data)\nmax_count = max(counter.values())\nmodes     = [k for k,v in counter.items() if v==max_count]\nmode_val  = modes[0]\n\n\n\n\n\n\n\n\nDistribution of Test Scores with Central Tendency Measures"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Business Applications",
    "text": "Business Applications\n\nCustomer Satisfaction: Mean rating shows overall satisfaction, median shows typical experience\nSales Data: Mode identifies best-selling products, median shows typical sale amount\n\nEmployee Performance: Mean for overall team performance, median for typical employee"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Educational Applications",
    "text": "Educational Applications\n\nTest Scores: Mean for class average, median for typical student performance\nGrade Distribution: Mode shows most common grade\nAttendance: Mean for overall attendance rate"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Healthcare Applications",
    "text": "Healthcare Applications\n\nPatient Wait Times: Median often preferred due to skewed distributions\nTreatment Outcomes: Mean for overall effectiveness, mode for most common result\nVital Signs: All three measures provide different insights"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "href": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Interpretation Guidelines",
    "text": "Interpretation Guidelines\n\nAlways consider the context of your data\nReport multiple measures when appropriate\n\nBe aware of data distribution shape\nConsider the presence of outliers\nChoose the most appropriate measure for your specific question"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "href": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Remember These Points",
    "text": "Remember These Points\n\nData type determines which statistics are appropriate\nMean uses all data but is sensitive to outliers\nMedian is robust and represents the middle value\nMode identifies the most common value and works with all data types\nContext matters when choosing and interpreting measures\nPython provides powerful tools for calculating descriptive statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "href": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Next Lecture Preview",
    "text": "Next Lecture Preview\nDescriptive Statistics Part II will cover:\n\nMeasures of variability (range, variance, standard deviation)\nMeasures of position (percentiles, quartiles, z-scores)\nShape of distributions (skewness and kurtosis)\nAdvanced Python visualization techniques"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "href": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Try These Problems",
    "text": "Try These Problems\n\nCalculate mean, median, and mode for: 12, 15, 18, 12, 20, 25, 12, 30\nA dataset has mean = 50 and median = 45. What does this tell you about the distribution?\nWhy might median be preferred over mean for reporting household income?\nCreate a Python function to identify the most appropriate measure of central tendency for a given dataset."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Download the full syllabus as a PDF\n\n\n\n\nüìö\n\n\nCourse Information\n\n\n\n\n\nLecture Time\n\n\nM/W/T/R 8:00 AM‚Äì9:30 AM\n\n\n\n\nLecture Hall\n\n\nHSSB 1173\n\n\n\n\nSections\n\n\nAs scheduled on GOLD (see Canvas for Zoom links)\n\n\n\n\nEmail\n\n\nnmathlouthi@ucsb.edu\n\n\n\n\nOffice\n\n\nEllison Hall 5829\n\n\n\n\nOffice Hours\n\n\nThursdays 11:00 AM‚Äì12:00 PM (via Zoom or by appointment)\n\n\n\n\n\nNote: Zoom links are posted on the Canvas page for the class.\n\n\n\n\n\n\nüë•\n\n\nTeaching Assistants\n\n\n\n\n\nSL\n\n\nSummer Le\n\n\nsle@ucsb.edu\n\n\n\n\nMH\n\n\nMingzhu He\n\n\nmingzhuhe@ucsb.edu\n\n\n\n\n\nEmail policy: Include [PSTAT 5A] in your subject. Allow 24‚Äì48 hours for a reply (avoid weekends).\n\n\n\n\n\n\nüéØ\n\n\nCourse Description\n\n\nThis introductory course covers the foundations of statistical thinking, including data description, probability, and inference. Students will learn how to summarize data, compute basic probabilities, and make informed decisions using statistical tools.\n\nStudent Learning Objectives\nBy the end of this course, you will be able to:\n\nSummarize data using descriptive statistics\nUnderstand fundamental probability rules and distributions\nConduct basic inferential procedures (confidence intervals, hypothesis tests)\nInterpret results and communicate findings\n\n\n\n\n\n\nüìñ\n\n\nCourse Materials\n\n\n\n\n\nCanvas\n\n\nAnnouncements, Zoom links, and grades (canvas.ucsb.edu)\n\n\n\n\nCalculator\n\n\nScientific calculator for in-class and quiz work\n\n\n\n\nComputer\n\n\nUse our JupyterHub instance\n\n\n\n\nRecommended Texts\n\n\nOpenIntro Statistics (free online)\nThink Stats by Allen Downey (free online)\n\n\n\n\n\n\n\nüìÖ\n\n\nClass Schedule\n\n\n\n\nNote: For the most up-to-date details, please visit the Class Schedule tab on our website: Class Schedule\n\n\n\n\n\n\nüìä\n\n\nGrading\n\n\n\n\nGrade Breakdown:\n\n\n\nLecture attendance: 5%\nSection attendance: 5%\nQuiz 1: 30%\nQuiz 2: 30%\nQuiz 3: 30%\n\n\n\nGrading Scale:\n\n\n\n\nA Grades\nB Grades\nC Grades\nD/F Grades\n\n\n\n\nA+: 97‚Äì100\nB+: 87‚Äì89\nC+: 77‚Äì79\nD+: 67‚Äì69\n\n\nA: 93‚Äì96\nB: 83‚Äì86\nC: 73‚Äì76\nD: 60‚Äì66\n\n\nA‚Äì: 90‚Äì92\nB‚Äì: 80‚Äì82\nC‚Äì: 70‚Äì72\nF: &lt; 60\n\n\n\n\n\n\nGrades round to the nearest whole number (e.g., 89.7 ‚Üí 90).\n\n\n\n\n\n\nüìù\n\n\nQuizzes\n\n\n\n\n\n1\n\n\n\nQuiz 1: Weeks 1‚Äì2\n\n\nJuly 11th\n\n\nCovers introduction, descriptive statistics and Intro to Probability\n\n\n\n\n\n2\n\n\n\nQuiz 2: Weeks 3‚Äì4\n\n\nJuly 25th\n\n\nCovers Conditional Probability, Counting & Random Variables (Discrete & Continuous)\n\n\n\n\n\n3\n\n\n\nQuiz 3: Weeks 5‚Äì6\n\n\nJuly 31st\n\n\nCovers Confidence Intervals & Hypothesis testing\n\n\n\n\n\n\nFormat: Multiple choice & short answer (open book)\nPlatform: Canvas /-or Gradescope\nAvailability: Fridays 7 AM‚Äì12 AM (1‚Äëhour limit)\nMake‚Äëup policy: Notify within 48 h; documentation required.\n\n\n\n\n\n\nüéØ\n\n\nHow to Succeed\n\n\n\nAttend lectures & sections\nEngage actively & ask questions\nUse office hours for help\n\n\nClassroom Expectations\nRespect peers & TAs. Stay engaged. Seek support if needed.\n\n\nCommunication Guidelines\n\nUse UCSB email with clear subject\nAllow 24‚Äì48 h for replies\nUse office hours or appointments\n\n\n\n\n\n\nüõ°Ô∏è\n\n\nAcademic Integrity\n\n\nDo your own work. Cite sources properly. See:\n\nAcademic Integrity Policy\nStudent Conduct Code\n\n\n\n\n\nü§ù\n\n\nStudent Resources\n\n\n\n\nü¶Ω DSP & Accommodations Disability services and accommodations\n\n\nüìö CLAS Campus Learning Assistance Services\n\n\nüè• Student Health Health and wellness services\n\n\nüçé Basic Needs Food security and basic needs support\n\n\nüíö CAPS Counseling & Psychological Services\n\n\nüéì EOP Educational Opportunity Program\n\n\nüë• ONDAS First-Generation Support\n\n\nüìã Undocumented Services Support for undocumented students\n\n\nüîÑ Transfer Center Transfer student support\n\n\n\n\n\n\nüìÖ\n\n\nImportant Dates\n\n\n\n\n\nAdd w/o Code\n\n\nJune 29\n\n\n\n\nDrop w/ Refund\n\n\nJune 29\n\n\n\n\nAdd w/ Code\n\n\nJuly 3\n\n\n\n\nDrop Course\n\n\nJuly 9\n\n\n\n\nChange Grade Option\n\n\nAugust 1"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSTAT 5A: Understanding Data",
    "section": "",
    "text": "Learn the fundamentals of data science and statistical thinking\n\n\nSummer Session A 2025 ‚Ä¢ Taught by Narjes Mathlouthi\n\nGet Started ‚Üí"
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Course Overview",
    "text": "Course Overview\n\nTransform raw data into meaningful insights through hands-on learning and real-world applications"
  },
  {
    "objectID": "index.html#quick-navigation",
    "href": "index.html#quick-navigation",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Quick Navigation",
    "text": "Quick Navigation\n\nEverything you need for the course, organized and accessible"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-8",
    "href": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-8",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Welcome to Lecture 8",
    "text": "Welcome to Lecture 8\nDiscrete Random Variables\nFrom outcomes to numbers: quantifying randomness"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine random variables and distinguish discrete from continuous\nWork with probability mass functions (PMFs) and cumulative distribution functions (CDFs)\nCalculate expected values and variances for discrete random variables\nApply properties of expectation and variance\nWork with common discrete distributions (Bernoulli, Binomial, Geometric, Poisson)\nSolve real-world problems using discrete random variables\nUse python to compute probabilities and parameters"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "href": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "What is a Random Variable?",
    "text": "What is a Random Variable?\n\nDefinition: A random variable is a function that assigns a numerical value to each outcome of a random experiment.\nNotation: Usually denoted by capital letters \\(X\\), \\(Y\\), \\(Z\\)\nKey insight: Random variables transform outcomes into numbers, making statistical analysis possible\n\n\n\nTreena - Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#die-roll-example-mapping-outcomes-to-numbers",
    "href": "files/lecture_notes/lecture7/lecture7.html#die-roll-example-mapping-outcomes-to-numbers",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Die Roll Example: Mapping Outcomes to Numbers",
    "text": "Die Roll Example: Mapping Outcomes to Numbers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n\n\n\nRandom Variable X maps each die face to its numerical value."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Why Use Random Variables?",
    "text": "Why Use Random Variables?\n\n\nRandom variables allow us to:\n\nQuantify outcomes numerically\nCalculate means, variances, and other statistics\nModel real-world phenomena\nMake predictions and decisions\nCompare different random processes\n\nExamples: Height, test scores, number of defects, wait times, stock prices\n\n\n\nTreena - Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Types of Random Variables",
    "text": "Types of Random Variables\n\n\nToday we focus on discrete random variables - notice there are gaps between possible values!\n\n\n\nDiscrete vs.¬†Continuous: Demystifying the type of Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "href": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Probability Mass Function (PMF)",
    "text": "Probability Mass Function (PMF)\n\n\nDefinition: The Probability Mass Function (PMF) of a discrete random variable \\(X\\) is:\n\n\n\\[P(X = x) = \\text{probability that } X \\text{ takes the value } x\\]\n\n\nProperties of PMF:\n\n\n\n\\(P(X = x) \\geq 0\\) for all \\(x\\)\n\n\n\\(\\sum_{\\text{all } x} P(X = x) = 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "href": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "PMF Example: Two Coin Flips",
    "text": "PMF Example: Two Coin Flips\n\nTwo Coin Flips - Number of Heads\nLet \\(X\\) = number of heads in two coin flips\nSample Space: \\(\\{HH, HT, TH, TT\\}\\)\n\n\n\nH T H T\n\n\nCurrent outcome: H T H T\n\nClick coins to flip them!\n\nTable summarizes by number of heads, not the exact sequence.\n\n\n\n\n\n\\(x\\) (heads)\n\n\nOutcomes\n\n\n\\(P(X = x)\\)\n\n\nEmpirical\n\n\n\n\n\n\n0\n\n\nTT\n\n\n0.25\n\n\n0\n\n\n\n\n1\n\n\nHT, TH\n\n\n0.50\n\n\n0\n\n\n\n\n2\n\n\nHH\n\n\n0.25\n\n\n0\n\n\n\n\n\nEmpirical probability updates as you flip!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "href": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\n\n\n\nThe cumulative distribution function of a random variable \\(X\\) is:\n\\[F(x) = P(X \\leq x)\\]\nProperties of CDF: 1. \\(F(x)\\) is non-decreasing 2. \\(\\lim_{x \\to -\\infty} F(x) = 0\\) 3. \\(\\lim_{x \\to \\infty} F(x) = 1\\) 4. \\(F(x)\\) is right-continuous"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#expected-value-and-variance",
    "href": "files/lecture_notes/lecture7/lecture7.html#expected-value-and-variance",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value and Variance",
    "text": "Expected Value and Variance\nThe expected value of a discrete random variable \\(X\\) is:\n\\[E[X] = \\mu = \\sum_{\\text{all } x} x \\cdot P(X = x)\\]\nThe variance of a random variable \\(X\\) measures spread around the mean:\n\\[\\text{Var}(X) = \\sigma^2 = E[(X - \\mu)^2] = E[X^2] - (E[X])^2\\]\n\nExpected value represents the long-run average if we repeat the experiment many times."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#law-of-large-numbers-demo",
    "href": "files/lecture_notes/lecture7/lecture7.html#law-of-large-numbers-demo",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Law of Large Numbers Demo",
    "text": "Law of Large Numbers Demo\n\nLaw of Large Numbers Demo\n\n\nRun Simulation\n\n 100 trials 500 trials 1000 trials 5000 trials \n\n\n\n\n\nWatch how the sample mean converges to the expected value! {.smaller}"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#common-discrete-distributions",
    "href": "files/lecture_notes/lecture7/lecture7.html#common-discrete-distributions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Common Discrete Distributions",
    "text": "Common Discrete Distributions\n\nBernoulli\nSingle trial, two outcomes\nParameters: \\(p\\) (success probability)\nPMF: \\(P(X = 1) = p\\), \\(P(X = 0) = 1-p\\)\nMean: \\(p\\)\nVariance: \\(p(1-p)\\)\n\n\nBinomial\n\\(n\\) independent Bernoulli trials\nParameters: \\(n\\) (trials), \\(p\\) (success prob.)\nPMF: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\)\nMean: \\(np\\)\nVariance: \\(np(1-p)\\)\n\n\nGeometric\nTrials until first success\nParameters: \\(p\\) (success probability)\nPMF: \\(P(X = k) = (1-p)^{k-1} p\\)\nMean: \\(1/p\\)\nVariance: \\((1-p)/p^2\\)\n\n\nPoisson\nEvents in fixed interval\nParameters: \\(\\lambda\\) (average rate)\nPMF: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\)\nMean: \\(\\lambda\\)\nVariance: \\(\\lambda\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#interactive-distribution-explorer",
    "href": "files/lecture_notes/lecture7/lecture7.html#interactive-distribution-explorer",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Interactive Distribution Explorer",
    "text": "Interactive Distribution Explorer\n\nDistribution Visualizer\n\n Binomial Geometric Poisson  Parameter 1:  Parameter 2:"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\nA box contains 3 red balls and 2 blue balls. Two balls are drawn without replacement. Let \\(X\\) = number of red balls drawn. Find the PMF of \\(X\\).\n\nShow Solution\n\n\nSolution. \\(X\\) can take values 0, 1, or 2.\n\\(P(X = 0) = \\frac{\\binom{3}{0}\\binom{2}{2}}{\\binom{5}{2}} = \\frac{1 \\times 1}{10} = \\frac{1}{10}\\)\n\\(P(X = 1) = \\frac{\\binom{3}{1}\\binom{2}{1}}{\\binom{5}{2}} = \\frac{3 \\times 2}{10} = \\frac{6}{10}\\)\n\\(P(X = 2) = \\frac{\\binom{3}{2}\\binom{2}{0}}{\\binom{5}{2}} = \\frac{3 \\times 1}{10} = \\frac{3}{10}\\)\nCheck: \\(\\frac{1}{10} + \\frac{6}{10} + \\frac{3}{10} = 1\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2-expected-value",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2-expected-value",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 2: Expected Value",
    "text": "Practice Problem 2: Expected Value\n\nUsing the red balls example from Problem 1, find \\(E[X]\\) and \\(\\text{Var}(X)\\).\n\nShow Solution\n\n\nSolution. Expected Value: \\[E[X] = 0 \\times \\frac{1}{10} + 1 \\times \\frac{6}{10} + 2 \\times \\frac{3}{10} = 0 + \\frac{6}{10} + \\frac{6}{10} = 1.2\\]\nVariance: \\[E[X^2] = 0^2 \\times \\frac{1}{10} + 1^2 \\times \\frac{6}{10} + 2^2 \\times \\frac{3}{10} = 0 + \\frac{6}{10} + \\frac{12}{10} = 1.8\\]\n\\[\\text{Var}(X) = E[X^2] - (E[X])^2 = 1.8 - (1.2)^2 = 1.8 - 1.44 = 0.36\\]\nStandard Deviation: \\(\\sigma = \\sqrt{0.36} = 0.6\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nA student takes a 10-question multiple choice quiz with 4 options per question. If the student guesses randomly, what‚Äôs the probability of getting exactly 3 correct?\n\nShow Solution\n\n\nSolution. This is a binomial distribution with \\(n = 10\\), \\(p = 1/4 = 0.25\\)\n\\[P(X = 3) = \\binom{10}{3} \\times (0.25)^3 \\times (0.75)^7\\]\n\\[P(X = 3) = 120 \\times 0.015625 \\times 0.1335 \\approx 0.2503\\]\nSo there‚Äôs about a 25% chance of getting exactly 3 correct by guessing."
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "href": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Properties of Expected Value",
    "text": "Properties of Expected Value\n\n\n\nLinearity of Expectation\n\n\\(E[c] = c\\) (constant)\n\\(E[cX] = c \\cdot E[X]\\) (scaling)\n\\(E[X + Y] = E[X] + E[Y]\\) (additivity)\n\\(E[aX + bY + c] = aE[X] + bE[Y] + c\\)\n\n\nVariance Properties\n\n\\(\\text{Var}(aX + b) = a^2 \\text{Var}(X)\\)\n\\(\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y)\\) (if \\(X\\) and \\(Y\\) are independent)\n\n\nImportant: Property 3 holds even if \\(X\\) and \\(Y\\) are dependent!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#key-takeaways",
    "href": "files/lecture_notes/lecture7/lecture7.html#key-takeaways",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\n\n\nMain Concepts\n\nRandom variables transform outcomes into numbers for mathematical analysis\nPMF gives probabilities for specific values; CDF gives cumulative probabilities\nExpected value is the long-run average; variance measures spread\n\n\nDistribution Selection\nChoose distributions based on the underlying process:\n\nBernoulli for single trials\nBinomial for fixed trials\nGeometric for waiting times\nPoisson for rates\n\nKey Principle\n\nLaw of Large Numbers connects theoretical expectations with observed averages"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "href": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\nNext Lecture: Continuous Random Variables\nTopics we‚Äôll cover:\n\nProbability density functions (PDFs)\nNormal distribution\nExponential distribution\nCentral Limit Theorem applications\n\n\nConnection: Discrete distributions often approximate continuous ones, and vice versa"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#questions",
    "href": "files/lecture_notes/lecture7/lecture7.html#questions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: 11AM on Thursday (link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Continuous Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#resources",
    "href": "files/lecture_notes/lecture7/lecture7.html#resources",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Resources",
    "text": "Resources\n\n\n\n Read OpenIntro Statistics Chapter 3 section 3.4\n\n\n Random Variable - Treena Courses\n\n\n Random Variables and Probability Functions\n\n\n Random Variables - Distribution and Expectation\n\n\n Khan Academy - Unit9: Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#sec-objectives",
    "href": "files/lecture_notes/lecture5/lecture5.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-1",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\n\n\n\nA standard deck has 52 cards. What is the probability of drawing:\n\nA heart \\(\\heartsuit\\)?\nA face card (Jack, Queen, King)?\nThe ace of spades \\(\\spadesuit\\)?\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{heart}) = \\frac{13}{52} = \\frac{1}{4}\\)\n\\(P(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\\)\n\\(P(\\text{ace of spades}) = \\frac{1}{52}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#the-addition-rule",
    "href": "files/lecture_notes/lecture5/lecture5.html#the-addition-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Addition Rule",
    "text": "The Addition Rule\nFor any two events \\(A\\) and \\(B\\):\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\n\nWhy subtract \\(P(A \\cap B)\\)?\n\n\n\nSolution. We don‚Äôt want to double-count outcomes that are in both events"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#addition-rule-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#addition-rule-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Addition Rule Example",
    "text": "Addition Rule Example\n\n\n\n\nDrawing from a standard deck:\n\n\\(A\\): Drawing a heart \\(\\heartsuit\\) (\\(P(A) = \\frac{13}{52}\\))\n\\(B\\): Drawing a face card (\\(P(B) = \\frac{12}{52}\\))\nWhat‚Äôs \\(P(A \\cup B)\\) (heart OR face card)?"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\n\n\n\nüéØConditional probability is the probability of event \\(A\\) given that event \\(B\\) has occurred\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nprovided \\(P(B) &gt; 0\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-interpretation",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-interpretation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Interpretation",
    "text": "Conditional Probability Interpretation\n\\(P(A|B)\\) means:\n\nWe know event  \\(B\\) has occurred \nWhat‚Äôs the probability that \\(A\\) also occurred?\nWe ‚Äúrestrict‚Äù our sample space to only outcomes in \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Example",
    "text": "Conditional Probability Example\n\n\n\nDrawing a card from a standard deck:\n\n\\(A\\): Card is a heart \\(\\heartsuit\\)\n\\(B\\): Card is red\nQ: Find \\(P(A|B)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution. \\(P(A \\cap B) = P(\\text{heart}) = \\frac{13}{52}\\)\n\\(P(B) = P(\\text{red}) = \\frac{26}{52}\\)\n\\(P(A|B) = \\frac{13/52}{26/52} = \\frac{13}{26} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#independence",
    "href": "files/lecture_notes/lecture5/lecture5.html#independence",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\nüéØ Definition Events \\(A\\) and \\(B\\) are independent if:\n\\[P(A|B) = P(A)\\]\nor equivalently:\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\n\n\nKnowing that \\(B\\) occurred doesn‚Äôt change the probability of \\(A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#independence-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#independence-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence Example",
    "text": "Independence Example\n\nTwo coin flips:\n\n\\(A\\): First flip is heads\n\\(B\\): Second flip is heads\n\nQ: Are \\(A\\) and \\(B\\) independent?\n\n\n\nSolution. \\(P(A) = \\frac{1}{2}\\), \\(P(B) = \\frac{1}{2}\\)\n\\(P(A \\cap B) = P(\\text{HH}) = \\frac{1}{4}\\)\n\\(P(A) \\times P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\)\nYes, they are independent!"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent",
    "href": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.¬†Independent",
    "text": "Mutually Exclusive vs.¬†Independent\n\nMutually Exclusive (left): the circles A and B do not overlap, so \\(P(A\\cap B)=0\\).\nIndependent (right): the circles overlap, and we‚Äôve sized the intersection so that \\(P(A\\cap B)=P(A)\\,P(B)\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#mutually-exclusive-vs.-independent-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.¬†Independent Example",
    "text": "Mutually Exclusive vs.¬†Independent Example\n\n\n\nDraw a single card from a 52-card deck:\n\nLet A={‚Äúdraw an Ace‚Äù}, so P(A)=4/52.\nLet B={‚Äúdraw a King‚Äù}, so P(B)=4/52.\n\nQ: What is \\(P(A\\cap B)\\) ?\n\n\n\n\n\nSolution. They‚Äôre disjoint (you can‚Äôt draw an Ace and a King), so \\(P(A\\cap B) = 0\\).\nBut \\(P(A)\\,P(B) = \\frac{4}{52}\\times\\frac{4}{52} = \\frac{16}{2704} \\neq 0\\).\nHence, \\(P(A\\cap B)\\neq P(A)P(B)\\), so they‚Äôre not independent."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#multiplication-rule",
    "href": "files/lecture_notes/lecture5/lecture5.html#multiplication-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Multiplication Rule",
    "text": "Multiplication Rule\nGeneral case: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nIndependent events: \\(P(A \\cap B) = P(A) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#tree-diagrams",
    "href": "files/lecture_notes/lecture5/lecture5.html#tree-diagrams",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\n\nüéØ Definition Tree diagrams help visualize sequential events and calculate probabilities."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#tree-diagram-examples",
    "href": "files/lecture_notes/lecture5/lecture5.html#tree-diagram-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagram Examples",
    "text": "Tree Diagram Examples"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-2",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-2",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\n\n\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement.\n\nWhat‚Äôs the probability both balls are red?\nWhat‚Äôs the probability the first is red and second is blue?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{both red}) = \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)\n\\(P(\\text{red then blue}) = \\frac{5}{8} \\times \\frac{3}{7} = \\frac{15}{56}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability",
    "href": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nüéØ Definition\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space, then:\n\\[P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \\cdots + P(A|B_n)P(B_n)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\n\nA factory has two machines:\n\nMachine 1: Produces 60% of items, 5% defective\nMachine 2: Produces 40% of items, 3% defective\n\nQ: What‚Äôs the overall probability an item is defective?\n\n\n\nSolution. \\(P(\\text{defective}) = P(D|M_1)P(M_1) + P(D|M_2)P(M_2)\\)\n\\(= 0.05 \\times 0.6 + 0.03 \\times 0.4 = 0.03 + 0.012 = 0.042\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem",
    "text": "Bayes‚Äô Theorem\n\nüéØ Definition \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\nThis allows us to ‚Äúreverse‚Äù conditional probabilities\nNamed after Thomas Bayes (1701-1761)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-components",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-components",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Components",
    "text": "Bayes‚Äô Theorem Components\n\n\\(A,B\\): Events\n\\(P(A|B)\\): Posterior probability - what we want to find\n\\(P(B|A)\\): Likelihood - given \\(A\\), probability of observing \\(B\\)\n\\(P(A)\\): Prior probability - initial probability of \\(A\\)\n\\(P(B)\\): Marginal probability - total probability of \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Example",
    "text": "Bayes‚Äô Theorem Example\n\n\n\nMedical test for a disease: 1\n\nDisease affects 1% of population\nTest is 95% accurate for sick people\nTest is 90% accurate for healthy people\n\nQ:If someone tests positive, what‚Äôs the probability they have the disease?\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n\\(P(\\neg D \\,\\wedge\\, \\text{Negative})\n\\;=\\;P(\\neg D)\\times P(\\text{Negative}\\mid \\neg D)\n\\;=\\;0.99\\times0.90\n\\;=\\;0.891\\;(89.1\\%)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Solution",
    "text": "Bayes‚Äô Theorem Solution\nLet:\n\n\\(D\\): Person has disease\n\\(T^+\\): Test is positive\n\nGiven:\n\n\\(P(D) = 0.01\\)\n\\(P(T^+|D) = 0.95\\)\n\\(P(T^-|D^c) = 0.90\\), so \\(P(T^+|D^c) = 0.10\\)\n\n\n\nSolution. \\(P(T^+) = P(T^+|D)P(D) + P(T^+|D^c)P(D^c)\\)\n\\(= 0.95 \\times 0.01 + 0.10 \\times 0.99 = 0.1085\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution-cont.",
    "href": "files/lecture_notes/lecture5/lecture5.html#bayes-theorem-solution-cont.",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Solution (cont.)",
    "text": "Bayes‚Äô Theorem Solution (cont.)\n\\[P(D|T^+) = \\frac{P(T^+|D) \\times P(D)}{P(T^+)} = \\frac{0.95 \\times 0.01}{0.1085} \\approx 0.088\\]\n\n\n\nSurprising result: Even with a positive test, there‚Äôs only an 8.8% chance of having the disease!\nThis is due to the low base rate of the disease"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nConfusing \\(P(A|B)\\) with \\(P(B|A)\\)\n\n\nProsecutor‚Äôs fallacy is a specific error in interpreting conditional probabilities. Confusing\n\\(P(\\text{Evidence}\\mid\\text{Innocent})\n\\quad\\text{with}\\quad\nP(\\text{Innocent}\\mid\\text{Evidence})\\).\nEx: OJ Simpson Case 1\n\nthe DNA evidence in the O. J. Simpson trial are a classic example of the prosecutor‚Äôs fallacy. Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was ‚Äúone in 170 million,‚Äù then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes-1",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-probability-mistakes-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nAssuming independence when events are dependent\nIgnoring base rates (as in the medical test example)\n\n\nBase rate fallacy is when you ignore or underweight the prior probability \\(P(H)\\) of a hypothesis, focusing only on the new evidence \\(E\\).\n\n\nDouble counting in union calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-3",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-3",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nTwo fair dice are rolled. Find:\n\n\\(P(\\text{sum} = 7)\\)\n\\(P(\\text{sum} = 7 | \\text{first die shows 3})\\)\nAre these events independent?\n\n\n\n\nSolution. \n\n6 ways out of 36: \\(P(\\text{sum} = 7) = \\frac{6}{36} = \\frac{1}{6}\\)\nGiven first die is 3, need second die to be 4: \\(P(\\text{sum} = 7 | \\text{first} = 3) = \\frac{1}{6}\\)\nYes, they‚Äôre independent since \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#real-world-applications",
    "href": "files/lecture_notes/lecture5/lecture5.html#real-world-applications",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Diagnosis: Using Bayes‚Äô theorem for test interpretation\nQuality Control: Probability of defective items\nFinance: Risk assessment and portfolio theory\nSports: Probability of wins, fantasy sports\nInsurance: Calculating premiums based on risk"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture5/lecture5.html#key-formulas-summary",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\nBasic probability: \\(P(A) = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\\)\nComplement: \\(P(A^c) = 1 - P(A)\\)\nAddition: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nConditional: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nIndependence: \\(P(A \\cap B) = P(A) \\times P(B)\\)\nBayes‚Äô: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture5/lecture5.html#problem-solving-strategy",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\nIdentify the sample space and events\nDetermine if events are independent or mutually exclusive\nChoose the appropriate rule or formula\nCalculate step by step\nCheck if your answer makes sense"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-questions",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Questions",
    "text": "Common Questions\n\nQ1.: ‚ÄúWhy isn‚Äôt \\(P(A \\cup B) = P(A) + P(B)\\) always?‚Äù\nA: We‚Äôd double-count outcomes in both events\nQ2.: ‚ÄúHow do I know if events are independent?‚Äù\nA: Check if \\(P(A|B) = P(A)\\) or if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nQ3.: ‚ÄúWhen do I use Bayes‚Äô theorem?‚Äù\nA: When you want to ‚Äúreverse‚Äù a conditional probability\n\n\nQ3 note (Bayes Example)\n\nForward: I know my test picks up disease 95% of the time ‚áí \\(P(+\\mid D)=0.95\\).\nReverse: I want the chance I really have the disease when the test is positive ‚áí \\(P(D\\mid +)\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#looking-ahead",
    "href": "files/lecture_notes/lecture5/lecture5.html#looking-ahead",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture:\n\nCounting\nRandom Variables and Probability Distributions\nDiscrete vs.¬†continuous random variables\nExpected value and variance"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#final-thoughts",
    "href": "files/lecture_notes/lecture5/lecture5.html#final-thoughts",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Final Thoughts",
    "text": "Final Thoughts\n\nProbability is the foundation of statistics:\n\nHelps us quantify uncertainty\nProvides tools for making decisions with incomplete information\nEssential for understanding statistical inference\n\n\n\nPractice: The key to mastering probability is working through many problems!"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#questions",
    "href": "files/lecture_notes/lecture5/lecture5.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday‚Äôs 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Conditional Probability & Bayes Theorem"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#resources",
    "href": "files/lecture_notes/lecture5/lecture5.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms\nInteractive Set Theory & Conditional Probability"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#sec-objectives",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#sec-objectives",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities\nDetermine when events are independent\nUse Bayes‚Äô theorem in simple applications"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#mutually-exclusive-vs.-independent",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#mutually-exclusive-vs.-independent",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Mutually Exclusive vs.¬†Independent",
    "text": "Mutually Exclusive vs.¬†Independent\n\nMutually Exclusive (left): the circles A and B do not overlap, so \\(P(A\\cap B)=0\\).\nIndependent (right): the circles overlap, and we‚Äôve sized the intersection so that \\(P(A\\cap B)=P(A)\\,P(B)\\)."
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#mutually-exclusive-vs.-independent-example",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#mutually-exclusive-vs.-independent-example",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Mutually Exclusive vs.¬†Independent Example",
    "text": "Mutually Exclusive vs.¬†Independent Example\n\n\n\nDraw a single card from a 52-card deck:\n\nLet A={‚Äúdraw an Ace‚Äù}, so P(A)=4/52.\nLet B={‚Äúdraw a King‚Äù}, so P(B)=4/52.\n\nQ: What is \\(P(A\\cap B)\\) ?\n\n\n\n\n\nSolution. They‚Äôre disjoint (you can‚Äôt draw an Ace and a King), so \\(P(A\\cap B) = 0\\).\nBut \\(P(A)\\,P(B) = \\frac{4}{52}\\times\\frac{4}{52} = \\frac{16}{2704} \\neq 0\\).\nHence, \\(P(A\\cap B)\\neq P(A)P(B)\\), so they‚Äôre not independent."
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#multiplication-rule",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#multiplication-rule",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Multiplication Rule",
    "text": "Multiplication Rule\nGeneral case: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nIndependent events: \\(P(A \\cap B) = P(A) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#tree-diagrams",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#tree-diagrams",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\n\nüéØ Definition Tree diagrams help visualize sequential events and calculate probabilities."
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#tree-diagram-examples",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#tree-diagram-examples",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Tree Diagram Examples",
    "text": "Tree Diagram Examples"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-2",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-2",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\n\n\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement.\n\nWhat‚Äôs the probability both balls are red?\nWhat‚Äôs the probability the first is red and second is blue?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{both red}) = \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)\n\\(P(\\text{red then blue}) = \\frac{5}{8} \\times \\frac{3}{7} = \\frac{15}{56}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#law-of-total-probability",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#law-of-total-probability",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nüéØ Definition\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space, then:\n\\[P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \\cdots + P(A|B_n)P(B_n)\\]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#law-of-total-probability-example",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\n\nA factory has two machines:\n\nMachine 1: Produces 60% of items, 5% defective\nMachine 2: Produces 40% of items, 3% defective\n\nQ: What‚Äôs the overall probability an item is defective?\n\n\n\nSolution. \\(P(\\text{defective}) = P(D|M_1)P(M_1) + P(D|M_2)P(M_2)\\)\n\\(= 0.05 \\times 0.6 + 0.03 \\times 0.4 = 0.03 + 0.012 = 0.042\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Bayes‚Äô Theorem",
    "text": "Bayes‚Äô Theorem\n\nüéØ Definition \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\nThis allows us to ‚Äúreverse‚Äù conditional probabilities\nNamed after Thomas Bayes (1701-1761)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-components",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-components",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Bayes‚Äô Theorem Components",
    "text": "Bayes‚Äô Theorem Components\n\n\\(A,B\\): Events\n\\(P(A|B)\\): Posterior probability - what we want to find\n\\(P(B|A)\\): Likelihood - given \\(A\\), probability of observing \\(B\\)\n\\(P(A)\\): Prior probability - initial probability of \\(A\\)\n\\(P(B)\\): Marginal probability - total probability of \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-example",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-example",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Bayes‚Äô Theorem Example",
    "text": "Bayes‚Äô Theorem Example\n\n\n\nMedical test for a disease: 1\n\nDisease affects 1% of population\nTest is 95% accurate for sick people\nTest is 90% accurate for healthy people\n\nQ:If someone tests positive, what‚Äôs the probability they have the disease?\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n\\(P(\\neg D \\,\\wedge\\, \\text{Negative})\n\\;=\\;P(\\neg D)\\times P(\\text{Negative}\\mid \\neg D)\n\\;=\\;0.99\\times0.90\n\\;=\\;0.891\\;(89.1\\%)\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-solution",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-solution",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Bayes‚Äô Theorem Solution",
    "text": "Bayes‚Äô Theorem Solution\nLet:\n\n\\(D\\): Person has disease\n\\(T^+\\): Test is positive\n\nGiven:\n\n\\(P(D) = 0.01\\)\n\\(P(T^+|D) = 0.95\\)\n\\(P(T^-|D^c) = 0.90\\), so \\(P(T^+|D^c) = 0.10\\)\n\n\n\nSolution. \\(P(T^+) = P(T^+|D)P(D) + P(T^+|D^c)P(D^c)\\)\n\\(= 0.95 \\times 0.01 + 0.10 \\times 0.99 = 0.1085\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-solution-cont.",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#bayes-theorem-solution-cont.",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Bayes‚Äô Theorem Solution (cont.)",
    "text": "Bayes‚Äô Theorem Solution (cont.)\n\\[P(D|T^+) = \\frac{P(T^+|D) \\times P(D)}{P(T^+)} = \\frac{0.95 \\times 0.01}{0.1085} \\approx 0.088\\]\n\n\n\nSurprising result: Even with a positive test, there‚Äôs only an 8.8% chance of having the disease!\nThis is due to the low base rate of the disease"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#common-probability-mistakes",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#common-probability-mistakes",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nConfusing \\(P(A|B)\\) with \\(P(B|A)\\)\n\n\nProsecutor‚Äôs fallacy is a specific error in interpreting conditional probabilities. Confusing\n\\(P(\\text{Evidence}\\mid\\text{Innocent})\n\\quad\\text{with}\\quad\nP(\\text{Innocent}\\mid\\text{Evidence})\\).\nEx: OJ Simpson Case 1\n\nthe DNA evidence in the O. J. Simpson trial are a classic example of the prosecutor‚Äôs fallacy. Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was ‚Äúone in 170 million,‚Äù then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent."
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#common-probability-mistakes-1",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#common-probability-mistakes-1",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nAssuming independence when events are dependent\nIgnoring base rates (as in the medical test example)\n\n\nBase rate fallacy is when you ignore or underweight the prior probability \\(P(H)\\) of a hypothesis, focusing only on the new evidence \\(E\\).\n\n\nDouble counting in union calculations"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-3",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-3",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nTwo fair dice are rolled. Find:\n\n\\(P(\\text{sum} = 7)\\)\n\\(P(\\text{sum} = 7 | \\text{first die shows 3})\\)\nAre these events independent?\n\n\n\n\nSolution. \n\n6 ways out of 36: \\(P(\\text{sum} = 7) = \\frac{6}{36} = \\frac{1}{6}\\)\nGiven first die is 3, need second die to be 4: \\(P(\\text{sum} = 7 | \\text{first} = 3) = \\frac{1}{6}\\)\nYes, they‚Äôre independent since \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#counting-and-probability",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#counting-and-probability",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Counting and Probability",
    "text": "Counting and Probability\n\nSometimes we need to count outcomes:\n\nMultiplication Principle: If task 1 can be done in \\(m\\) ways and task 2 in \\(n\\) ways, both can be done in \\(m \\times n\\) ways\n\n\nPermutations: Arrangements where order matters \\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\n\nCombinations: Selections where order doesn‚Äôt matter \\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#counting-example",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#counting-example",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Counting Example",
    "text": "Counting Example\n\nQ: How many ways can you arrange 5 people in a row?\n\n\n\nSolution. This is a permutation: \\(P(5,5) = 5! = 120\\) ways"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#probability-with-counting",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#probability-with-counting",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Probability with Counting",
    "text": "Probability with Counting\n\nExample: A committee of 3 people is chosen from 8 people (5 women, 3 men). What‚Äôs the probability all 3 are women?\n\n\n\nSolution. Total ways to choose 3 from 8: \\(\\binom{8}{3} = 56\\)\nWays to choose 3 women from 5: \\(\\binom{5}{3} = 10\\)\nProbability: \\(\\frac{10}{56} = \\frac{5}{28}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#real-world-applications",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#real-world-applications",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Diagnosis: Using Bayes‚Äô theorem for test interpretation\nQuality Control: Probability of defective items\nFinance: Risk assessment and portfolio theory\nSports: Probability of wins, fantasy sports\nInsurance: Calculating premiums based on risk"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#key-formulas-summary",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#key-formulas-summary",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\nBasic probability: \\(P(A) = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\\)\nComplement: \\(P(A^c) = 1 - P(A)\\)\nAddition: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nConditional: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nIndependence: \\(P(A \\cap B) = P(A) \\times P(B)\\)\nBayes‚Äô: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#problem-solving-strategy",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#problem-solving-strategy",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\nIdentify the sample space and events\nDetermine if events are independent or mutually exclusive\nChoose the appropriate rule or formula\nCalculate step by step\nCheck if your answer makes sense"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-4",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-4",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\n\nA bag contains 4 red, 3 blue, and 2 green marbles. Three marbles are drawn without replacement.\nFind the probability that: a) All three are red b) No two are the same color c) At least one is blue"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-4-solutions",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#practice-problem-4-solutions",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Practice Problem 4 Solutions",
    "text": "Practice Problem 4 Solutions\n\nSolution. \n\nAll red: \\(\\frac{4}{9} \\times \\frac{3}{8} \\times \\frac{2}{7} = \\frac{24}{504} = \\frac{1}{21}\\)\nDifferent colors: \\(\\frac{4 \\times 3 \\times 2}{9 \\times 8 \\times 7} \\times 3! = \\frac{24 \\times 6}{504} = \\frac{144}{504} = \\frac{2}{7}\\)\nAt least one blue: \\(1 - P(\\text{no blue}) = 1 - \\frac{6 \\times 5 \\times 4}{9 \\times 8 \\times 7} = 1 - \\frac{120}{504} = \\frac{384}{504} = \\frac{16}{21}\\)"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#common-questions",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#common-questions",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Common Questions",
    "text": "Common Questions\n\nQ1.: ‚ÄúWhy isn‚Äôt \\(P(A \\cup B) = P(A) + P(B)\\) always?‚Äù\nA: We‚Äôd double-count outcomes in both events\nQ2.: ‚ÄúHow do I know if events are independent?‚Äù\nA: Check if \\(P(A|B) = P(A)\\) or if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nQ3.: ‚ÄúWhen do I use Bayes‚Äô theorem?‚Äù\nA: When you want to ‚Äúreverse‚Äù a conditional probability\n\n\nQ3 note (Bayes Example)\n\nForward: I know my test picks up disease 95% of the time ‚áí \\(P(+\\mid D)=0.95\\).\nReverse: I want the chance I really have the disease when the test is positive ‚áí \\(P(D\\mid +)\\)."
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#looking-ahead",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#looking-ahead",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture:\n\nRandom Variables and Probability Distributions\nDiscrete vs.¬†continuous random variables\nExpected value and variance"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#final-thoughts",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#final-thoughts",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Final Thoughts",
    "text": "Final Thoughts\n\nProbability is the foundation of statistics:\n\nHelps us quantify uncertainty\nProvides tools for making decisions with incomplete information\nEssential for understanding statistical inference\n\n\n\nPractice: The key to mastering probability is working through many problems!"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#questions",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#questions",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday‚Äôs 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Random Variables and Distributions"
  },
  {
    "objectID": "files/lecture_notes/test_lectures/lecture5-6.html#resources",
    "href": "files/lecture_notes/test_lectures/lecture5-6.html#resources",
    "title": "PSTAT 5A: Conditional Probability Continued & Bayes‚Äô Theorem",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#important-announcements",
    "href": "files/lecture_notes/lecture11/lecture11.html#important-announcements",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "üì¢ Important Announcements",
    "text": "üì¢ Important Announcements\n\n\nüìù Quiz 2 Details\nWhen:\n- üìÖ Date: Friday, July 25\n- ‚è∞ Window: 7 AM ‚Äì 12 AM\n- ‚è≥ Duration: 1 hour once started\nWhere: üíª Online via Canvas\nCovers: Material from Weeks 3-4\n\nüìö What to Expect\n\nDiscrete & continuous distributions\nProbability calculations\nExpected value & variance\nNormal distribution applications\nNote: Upload photos of written work for calculation problems"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#what-well-learn-today",
    "href": "files/lecture_notes/lecture11/lecture11.html#what-well-learn-today",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "What We‚Äôll Learn Today üéØ",
    "text": "What We‚Äôll Learn Today üéØ\n\n\nBig Ideas:\n\nHow sample means behave (they‚Äôre surprisingly predictable!)\nWhy we use intervals instead of single numbers\nHow confident we can be in our estimates\nPlanning studies for the right precision\n\n\nSkills You‚Äôll Gain:\n\nBuild confidence intervals step-by-step\nInterpret what confidence really means\nChoose appropriate sample sizes\nAvoid common mistakes in interpretation"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#from-observation-experimentation-why-design-matters",
    "href": "files/lecture_notes/lecture11/lecture11.html#from-observation-experimentation-why-design-matters",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "From Observation ‚û°Ô∏è Experimentation: Why Design¬†Matters",
    "text": "From Observation ‚û°Ô∏è Experimentation: Why Design¬†Matters\n\nObservational Study: Passively record what already happens ‚Äî good for spotting patterns, but hidden confounders can fool us.\nControlled Experiment: Actively assign treatments; randomization balances the lurking variables so we can talk about cause.\nRandomization¬†& Replication: Twin shields that protect us from bias and one‚Äëoff flukes.\nProbability Framework: Sample space, events, and probabilities let us quantify uncertainty."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#the-big-picture-from-sample-to-population",
    "href": "files/lecture_notes/lecture11/lecture11.html#the-big-picture-from-sample-to-population",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "The Big Picture: From Sample to Population",
    "text": "The Big Picture: From Sample to Population\n\n\nThink of this like trying to understand a huge library by reading just a few books\n\n\n                            \n                                            \n\n\n\nKey Terms Made Simple:\n\nPopulation (\\(\\mu\\)): Everyone we care about (like all students at UCSB)\nSample (\\(\\bar x\\)): The people we actually measured (like 100 students we surveyed)\nParameter: The true answer we want (population mean)\nStatistic: Our best guess (sample mean)"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#why-point-estimates-arent-enough",
    "href": "files/lecture_notes/lecture11/lecture11.html#why-point-estimates-arent-enough",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Why Point Estimates Aren‚Äôt Enough",
    "text": "Why Point Estimates Aren‚Äôt Enough\n\n\nImagine asking: ‚ÄúWhat‚Äôs the average height of UCSB students?‚Äù\n\n\n                            \n                                            \n\n\n\nThe Problem: Each sample gives a slightly different answer!\n\nThe Solution: Use confidence intervals to show the range of reasonable values."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#sampling-distributions",
    "href": "files/lecture_notes/lecture11/lecture11.html#sampling-distributions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\n\n\nThink of sampling distributions like ‚ÄúWhat if we repeated our study 1000 times?‚Äù\n\n\n                            \n                                            \n\n\n\nKey Insights:\n\nPopulation can be any shape (skewed, normal, weird)\nOne sample might not look like the population\nSample means vary from sample to sample\nMany sample means form a beautiful normal distribution!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#the-central-limit-theorem-clt",
    "href": "files/lecture_notes/lecture11/lecture11.html#the-central-limit-theorem-clt",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "The Central Limit Theorem (CLT) üéØ",
    "text": "The Central Limit Theorem (CLT) üéØ\n\n\n\n\n                            \n                                            \nCentral Limit Theorem: Larger Samples ‚Üí More Normal!\n\n\n\nThe Magic Rule: No matter what shape your population is, sample means will be approximately normal!\nThe Rule of Thumb: With n ‚â• 30, sample means will be approximately normal, regardless of population shape!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#standard-error",
    "href": "files/lecture_notes/lecture11/lecture11.html#standard-error",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Standard Error",
    "text": "Standard Error\n\n\nWhat it measures\n\nStandard deviation¬†(\\(\\sigma\\) or \\(s\\)): spread of individual data points\n\nStandard error¬†(SE): spread of sample means\n\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}}\n\\qquad(\\text{if } \\sigma \\text{ is known})\n\\]\n\\[\nSE = \\frac{s}{\\sqrt{n}}\n\\qquad(\\text{usual case, } \\sigma \\text{ unknown})\n\\]\nKey facts\n\nSE shrinks at rate¬†\\(1/\\sqrt{n}\\)¬†‚Äî every 4√ó more observations ‚áí ¬Ω the SE\n\nSmaller SE ‚áí narrower confidence intervals and more powerful tests\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nImportant\n\n\nDoubling your sample size doesn‚Äôt halve the error - you need 4 times the sample for half the error!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-the-intuitive-idea",
    "href": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-the-intuitive-idea",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals: The Intuitive Idea",
    "text": "Confidence Intervals: The Intuitive Idea\n\n\nImagine you‚Äôre trying to guess someone‚Äôs height just by looking at their shadow‚Ä¶\n\n\n                            \n                                            \n\n\n\nSimple Interpretation: ‚ÄúWe‚Äôre \\(95\\\\%\\) confident the true average height is between \\(64.3\\) and \\(70.1\\)¬†inches.‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#what-exactly-is-a-confidence-interval",
    "href": "files/lecture_notes/lecture11/lecture11.html#what-exactly-is-a-confidence-interval",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "What Exactly Is a Confidence Interval? ü§ì",
    "text": "What Exactly Is a Confidence Interval? ü§ì\n\n\n\nA confidence interval (CI) is point estimate¬†\\(\\pm\\) margin of error\n\\[\n  \\text{CI} = \\text{statistic} \\;\\pm\\; \\bigl(\\text{critical value}\\bigr)\\times\\bigl(\\text{SE}\\bigr)\n\\]\nThe ‚Äúcritical value‚Äù comes from a probability model (e.g., \\(z^{\\star}\\) or \\(t^{\\star}\\)).\nThe standard error (SE) captures sampling variation.\n\nFrequentist meaning\n\nIf we repeated the study infinitely many times and built a \\(95‚ÄØ\\%\\) CI each time, about \\(95‚ÄØ\\%\\) of those intervals would cover the true parameter.\n\n(For any one computed interval the parameter is fixed, the process has a \\(95‚ÄØ\\%\\) success rate, not the individual interval.)\n\n\n\n\n\n\n\n\nWhat controls the width?\n\n\n\nVariability in the data: larger \\(\\sigma\\) or \\(s\\) ‚áí wider CI\nSample size \\(n\\): width shrinks at rate \\(1/\\sqrt{n}\\)\nConfidence level: 99‚ÄØ% CIs are wider than 90‚ÄØ% CIs\n\n\n\n\n\n\n\n\n\n\nCommon pitfalls\n\n\n\nSaying ‚Äúthere is a \\(95‚ÄØ\\%\\) probability¬†that \\(\\mu\\) lies in this interval‚Äù (wrong)\nInterpreting the CI as covering \\(95‚ÄØ\\%\\) of future observations (it does not)\nIgnoring conditions (normality or CLT) before using the formulae"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#building-confidence-intervals-step-by-step",
    "href": "files/lecture_notes/lecture11/lecture11.html#building-confidence-intervals-step-by-step",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Building Confidence Intervals Step-by-Step",
    "text": "Building Confidence Intervals Step-by-Step\n\n\nFor Population Means (Most Common Case)\nWhen we DON‚ÄôT know the population standard deviation (\\(\\sigma\\)):\n\n\n                            \n                                            \n\n\n\nThe Formula: \\(\\bar{x} \\pm t^* \\cdot \\frac{s}{\\sqrt{n}}\\)\nBreaking it down:\n\n\\(\\bar{x}\\) = our sample average (the center of our guess)\n\\(t^*\\) = critical value (how many standard errors to go out)\n\\(\\frac{s}{\\sqrt{n}}\\) = standard error (our uncertainty measure)"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#the-t-distribution-when-sigma-is-unknown",
    "href": "files/lecture_notes/lecture11/lecture11.html#the-t-distribution-when-sigma-is-unknown",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "The t-Distribution: When \\(\\sigma\\) is Unknown",
    "text": "The t-Distribution: When \\(\\sigma\\) is Unknown\n\n\nWhy not use the normal distribution? Because when we estimate \\(\\sigma\\) with \\(s\\), we add extra uncertainty!\n\n\n                            \n                                            \n\n\n\nKey Points:\n\nSmall samples (\\(n &lt; 30\\)): Use t-distribution\nLarge samples (\\(n ‚â• 30\\)): \\(t\\) ‚âà normal\nDegrees of freedom (df)= \\(n - 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-for-proportions",
    "href": "files/lecture_notes/lecture11/lecture11.html#confidence-intervals-for-proportions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals for Proportions",
    "text": "Confidence Intervals for Proportions\n\n\nFor Yes/No questions like: ‚ÄúWhat percentage of students prefer online classes?‚Äù\n\n\n                            \n                                            \n\n\n\nThe Formula: \\(\\hat{p} \\pm z^* \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\)\nResults: Sample: 60% prefer online (120/200)\n95% CI: (53.2%, 66.8%) - We‚Äôre 95% confident the true percentage is in this range."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#what-does-95-confident-really-mean",
    "href": "files/lecture_notes/lecture11/lecture11.html#what-does-95-confident-really-mean",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "What Does ‚Äú95% Confident‚Äù Really Mean? ü§î",
    "text": "What Does ‚Äú95% Confident‚Äù Really Mean? ü§î\n\n\nThe Biggest Misconception: ‚ÄúThere‚Äôs a 95% chance the true mean is in our interval‚Äù\nActually: ‚ÄúIf we repeated this study 100 times, about 95 of our intervals would contain the true mean‚Äù\n\n\n                            \n                                            \n\n\n\nRemember: The interval either contains the true value or it doesn‚Äôt - there‚Äôs no probability involved for a single interval!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#sample-size-planning-getting-the-precision-you-want",
    "href": "files/lecture_notes/lecture11/lecture11.html#sample-size-planning-getting-the-precision-you-want",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Sample Size Planning: Getting the Precision You Want",
    "text": "Sample Size Planning: Getting the Precision You Want\n\n\nThe Question: ‚ÄúHow many people do we need to survey?‚Äù\n\n\n                            \n                                            \n\n\n\nKey Formula for Means: \\(n = \\left(\\frac{z^* \\sigma}{ME}\\right)^2\\)\nTrade-offs:\n\nWant smaller margin of error? Need bigger sample\nWant higher confidence? Need bigger sample\nWant to save money? Accept wider intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#real-example-student-sleep-study",
    "href": "files/lecture_notes/lecture11/lecture11.html#real-example-student-sleep-study",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Real Example: Student Sleep Study üò¥",
    "text": "Real Example: Student Sleep Study üò¥\n\n\nResearch Question: How many hours do UCSB students sleep per night?\n\n\n                            \n                                            \n\n\n\nBottom Line: We‚Äôre 95% confident that UCSB students sleep between 6.73 and 7.47 hours per night on average."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/lecture11/lecture11.html#common-mistakes-to-avoid",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Common Mistakes to Avoid ‚ö†Ô∏è",
    "text": "Common Mistakes to Avoid ‚ö†Ô∏è\n\n\n‚ùå Wrong Interpretations\n‚Äú95% of students sleep in this range‚Äù - NO! This is about the population mean, not individual students\n‚ÄúThere‚Äôs a 95% chance Œº is in our interval‚Äù - NO! \\(\\mu\\) is fixed; our interval varies\n‚ÄúWe can be 95% certain‚Äù - NO! Use ‚Äúconfident‚Äù not ‚Äúcertain‚Äù\n\n‚úÖ Correct Approach\n‚ÄúWe are 95% confident the population mean is in this interval‚Äù\nKey Reminders:\n\nCheck conditions before using formulas\nUse t-distribution when \\(\\sigma\\) is unknown\nLarger samples give narrower intervals\nHigher confidence gives wider intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#problem-1-coffee-shop-revenue",
    "href": "files/lecture_notes/lecture11/lecture11.html#problem-1-coffee-shop-revenue",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Problem 1: Coffee Shop Revenue",
    "text": "Problem 1: Coffee Shop Revenue\nA coffee shop owner samples 36 days and finds average daily revenue of $850 with standard deviation $120.\nYour turn: Calculate a 90% confidence interval for the true average daily revenue.\n\n\nShow Solution\n\n\nGiven (from the prompt)\n\\(n = 36,\\; \\bar{x} = \\$850,\\; s = \\$120,\\; \\text{confidence level} = 90\\%\\)\n\nStep¬†1¬†‚Äì Conditions\n\n\\(n \\ge 30\\) ‚áí a \\(t\\)‚Äëinterval is justified by the Central Limit Theorem.\n\nAssume daily revenues are independent.\n\nStep¬†2¬†‚Äì Critical value\n\\(\\alpha = 1-0.90 = 0.10 \\;\\Rightarrow\\; \\alpha/2 = 0.05\\)\nDegrees of freedom: \\(df = n-1 = 35\\)\n\\(\\displaystyle t^{\\star}_{0.90,\\,35} \\approx 1.690\\)\nStep¬†3¬†‚Äì Standard error\n\\[SE = \\frac{s}{\\sqrt{n}}\n        = \\frac{120}{\\sqrt{36}}\n        = \\frac{120}{6}\n        = \\$20\\]\nStep¬†4¬†‚Äì Margin of error\n\\[ME = t^{\\star}\\; SE\n       = 1.690 \\times \\$20\n       = \\$33.8\\]\nStep¬†5¬†‚Äì Confidence interval\n\\[\\bar{x} \\pm ME\n     = 850 \\pm 33.8\n     \\;\\Longrightarrow\\;\n     (\\$816.2,\\; \\$883.8)\\]\nInterpretation ‚Äì We are 90‚ÄØ% confident that the true mean daily revenue lies between $816.20 and $883.80."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#problem-2-student-survey",
    "href": "files/lecture_notes/lecture11/lecture11.html#problem-2-student-survey",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Problem 2: Student Survey",
    "text": "Problem 2: Student Survey\nIn a survey of 400 students, 280 say they would recommend their major to a friend.\nYour turn:\n\nCalculate the sample proportion\nBuild a \\(95\\%\\) confidence interval\nCheck if conditions are met\n\n\n\nShow Solution\n\n\nGiven (from the survey)\n\\(n = 400,\\; x = 280\\) ‚Äúyes‚Äù responses\n\nStep¬†1¬†‚Äì Sample proportion\n\\[\\hat{p} = \\frac{x}{n} = \\frac{280}{400} = 0.70\\]\nStep¬†2¬†‚Äì Conditions for a \\(z\\)‚Äëinterval\n\\(n\\hat{p} = 400(0.70)=280 \\ge 10\\)\n\\(n(1-\\hat{p}) = 400(0.30)=120 \\ge 10\\)\nBoth counts ‚â•‚ÄØ10, so the normal approximation is appropriate.\nStep¬†3¬†‚Äì Standard error\n\\[SE = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n        = \\sqrt{\\frac{0.70(0.30)}{400}}\n        = \\sqrt{0.000525}\n        \\approx 0.0229\\]\nStep¬†4¬†‚Äì Critical value & margin of error\nFor 95‚ÄØ% confidence, \\(z^{\\star} = 1.96\\)\n\\[ME = z^{\\star}\\; SE\n       = 1.96 \\times 0.0229\n       \\approx 0.045\\]\nStep¬†5¬†‚Äì Confidence interval\n\\[\\hat{p} \\pm ME\n     = 0.70 \\pm 0.045\n     \\;\\Longrightarrow\\;\n     (0.655,\\; 0.745)\\]\nInterpretation ‚Äì We are 95‚ÄØ% confident that between 65.5‚ÄØ% and 74.5‚ÄØ% of all students would recommend their major to a friend."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#looking-ahead-hypothesis-testing",
    "href": "files/lecture_notes/lecture11/lecture11.html#looking-ahead-hypothesis-testing",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Looking Ahead: Hypothesis Testing üîÆ",
    "text": "Looking Ahead: Hypothesis Testing üîÆ\n\n\nNext week we‚Äôll learn:\n\nHow to test specific claims about populations\nWhen to reject or fail to reject hypotheses\nThe connection between confidence intervals and hypothesis tests"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#key-takeaways",
    "href": "files/lecture_notes/lecture11/lecture11.html#key-takeaways",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Key Takeaways üéØ",
    "text": "Key Takeaways üéØ\n\n\nBig Ideas:\n\nSamples vary - confidence intervals capture this uncertainty\nLarger samples give more precise estimates\nHigher confidence means wider intervals\nThe CLT makes normal-based inference possible\n\n\nPractical Skills:\n\nBuild CIs for means and proportions\nInterpret confidence correctly\nPlan sample sizes for desired precision\nAvoid common interpretation mistakes"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#comprehensive-resources",
    "href": "files/lecture_notes/lecture11/lecture11.html#comprehensive-resources",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Comprehensive Resources üìö",
    "text": "Comprehensive Resources üìö\n\n\nüìñ Required Reading\n\nOpenIntro Statistics\n\nSection 1.3: Sampling principles and strategies\nSection 3.3: Confidence intervals for a mean\nSection 4.1: Central Limit Theorem\nSection 7.1.1 The distribution of \\(\\bar x\\)\nSection7.1.2 Evaluating the two conditions required for modeling \\(\\bar x\\)\nSection 7.1.3 Introducing the \\(t\\)-distribution\n\n\nüé• Video Resources\n\nKhan Academy: Central Limit Theorem\nStatQuest: Confidence Intervals Explained\n3Blue1Brown: Central Limit Theorem Visualization\n\n\nüíª Interactive Tools\n\nSeeing Theory: Probability Visualizations\nRossman & Chance Applets: Sampling Distributions\nCentral Limit Theorem Simulator"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11.html#questions",
    "href": "files/lecture_notes/lecture11/lecture11.html#questions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Questions? ü§î",
    "text": "Questions? ü§î\n\n\nOffice Hours: Thursday 11AM (link on Canvas)\nEmail: nmathlouthi@ucsb.edu\n‚ÄúThe goal is not to eliminate uncertainty, but to understand and work with it‚Äù\n\n\n\n\nüè† Back to Main Page"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#todays-learning-objectives",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nUnderstand sampling distributions and their properties (Section¬†1.2)\nApply the Central Limit Theorem to sampling (Section¬†1.4)\nConstruct confidence intervals for population means (Section¬†1.6)\nConstruct confidence intervals for population proportions (Section¬†1.8)\nInterpret confidence intervals correctly (Section¬†1.5)\nDetermine appropriate sample sizes for desired precision\nUse python to calculate confidence intervals\nDistinguish between different types of sampling methods"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-sampling-dist",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-sampling-dist",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "The Big Picture: Statistical Inference",
    "text": "The Big Picture: Statistical Inference\n\n\n\n\nPopulation vs Sample\n\n\n\nPopulation: All individuals of interest\n\n\nSample: Subset we actually observe\n\n\nParameter: Population characteristic (\\(\\mu\\), \\(p\\))\n\n\nStatistic: Sample characteristic (\\(\\bar{x}\\), \\(\\hat{p}\\))\n\n\n\nGoal: Use sample statistics to estimate population parameters\n\n\n\n\n\n\n\n\n\nWhy Confidence Intervals?\n\n\n\nPoint estimates are rarely exactly correct\n\n\nInterval estimates capture uncertainty\n\n\nConfidence level quantifies our certainty\n\n\nMargin of error shows precision\n\n\n\nKey Insight: We trade precision for confidence"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sampling-distributions",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sampling-distributions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\n\nA sampling distribution is the distribution of a statistic (like \\(\\bar{x}\\)) across all possible samples of size \\(n\\).\n\n\n\nKey Properties:\nCenter:\n\\(E[\\bar{X}] = \\mu\\) (unbiased)\nSpread:\n\\(SE(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\\)\nShape:\nApproaches normal as \\(n\\) increases (Central Limit Theorem)\nStandard Error vs Standard Deviation:\n\n\\(\\sigma\\): spread of individual observations\n\\(SE = \\frac{\\sigma}{\\sqrt{n}}\\): spread of sample means\n\n\n\n\n\n\nDrag the slider to see how sample size affects the sampling distribution"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-clt-sampling",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-clt-sampling",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Central Limit Theorem in Action",
    "text": "Central Limit Theorem in Action\n\n\n\n\nNew Population\n\n Uniform Population Exponential Population Bimodal Population Right-Skewed Population  Sample Size:  Collect 1000 Sample Means\n\n\n\nPopulation Œº: - | Sample Means Œº: - | Standard Error: -"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-interpretation",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-interpretation",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals: The Concept",
    "text": "Confidence Intervals: The Concept\n\n\nWhat is a Confidence Interval? A confidence interval provides a range of plausible values for a population parameter. 95% Confidence Interval: If we repeated our sampling process many times, about \\(95\\%\\) of the intervals we construct would contain the true population parameter.\n\n\n\n\n\nClick to generate new 95% confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-means",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-means",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals for Population Means",
    "text": "Confidence Intervals for Population Means\n\n\n\n\n üéØ When œÉ is Known:\n\n\n\\[\\bar{x} \\pm z^* \\cdot \\frac{\\sigma}{\\sqrt{n}}\\]\n\n\nWhen \\(\\sigma\\) is Unknown (more common):\n\n\n\\[\\bar{x} \\pm t^* \\cdot \\frac{s}{\\sqrt{n}}\\]\n\n\nKey Components:\n\n\n\n\\(\\bar{x}\\): sample mean\n\n\n\\(t^*\\): critical value (df = n-1)\n\n\n\\(\\frac{s}{\\sqrt{n}}\\): standard error\n\n\n\n\n\n\nCommon Confidence Levels:\n\n\n\n90%: z* = 1.645, more precise\n\n\n95%: z* = 1.96, most common\n\n\n99%: z* = 2.576, more confident\n\n\n\nConditions Required:\n\n\n\nRandom sampling\nNearly normal population OR n ‚â• 30\nIndependent observations"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#interactive-ci-demo-confidence-intervals-for-means",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#interactive-ci-demo-confidence-intervals-for-means",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Interactive CI Demo: Confidence Intervals for Means",
    "text": "Interactive CI Demo: Confidence Intervals for Means\n\n\n\nSample Size:  Confidence Level:  90% 95% 99%   Population Œº:  Population œÉ:  Generate New Sample & CI Simulate 100 CIs\n\n\n\nCurrent CI: Generate a sample to see CI Captures Œº? - | Margin of Error: -"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-proportions",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sec-ci-proportions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals for Population Proportions",
    "text": "Confidence Intervals for Population Proportions\n\n\n\n üéØ Formula:\n\n\n\\[\\hat{p} \\pm z^* \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\]\n\n\nKey Components:\n\n\n\n\\(\\hat{p} = \\frac{x}{n}\\): sample proportion\n\n\n\\(z^*\\): critical value\n\n\n\\(\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\): standard error\n\n\n\n\nConditions Required:\n\n\n\nRandom sampling\n\n\n\\(n\\hat{p} \\geq 10\\) and \\(n(1-\\hat{p}) \\geq 10\\)\n\n\nIndependent observations\n\n\nPopulation at least 10√ó sample size\n\n\n\nConservative Approach:\n\n\nUse \\(\\hat{p} = 0.5\\) for planning when true proportion unknown (maximizes margin of error)"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#interactive-ci-demo-confidence-intervals-for-proportions",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#interactive-ci-demo-confidence-intervals-for-proportions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Interactive CI Demo: Confidence Intervals for Proportions",
    "text": "Interactive CI Demo: Confidence Intervals for Proportions\n\n\n\nSample Size:  Confidence Level:  90% 95% 99%   Population p:  Generate New Sample & CI Simulate 100 CIs\n\n\n\nCurrent CI: Generate a sample to see CI Captures p? - | Sample Proportion: -"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-1-ci-for-mean",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-1-ci-for-mean",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Practice Problem 1: CI for Mean",
    "text": "Practice Problem 1: CI for Mean\n\nA random sample of 25 college students shows a mean daily screen time of 6.2 hours with a standard deviation of 1.8 hours. (a) Construct a 95% confidence interval for the mean daily screen time. (b) Interpret the confidence interval in context. (c) What would happen to the interval width if we used 99% confidence instead? Show Solution\n\nSolution. (a)\nGiven: \\(n = 25\\), \\(\\bar{x} = 6.2\\), \\(s = 1.8\\), 95% confidence\nFor \\(df = 24\\), \\(t^* = 2.064\\)\n\\(SE = \\frac{s}{\\sqrt{n}} = \\frac{1.8}{\\sqrt{25}} = 0.36\\)\n\\(CI = 6.2 \\pm 2.064 \\times 0.36 = 6.2 \\pm 0.743 = (5.46, 6.94)\\) hours\n(b)\nWe are 95% confident that the true mean daily screen time for all college students is between \\(5.46\\) and \\(6.94\\) hours.\n(c)\nFor 99% confidence, we use \\(t^* = 2.797\\), giving a wider interval: \\((5.19, 7.21)\\) hours."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-2-ci-for-proportion",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-2-ci-for-proportion",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Practice Problem 2: CI for Proportion",
    "text": "Practice Problem 2: CI for Proportion\n\nIn a survey of 400 voters, 240 support a particular candidate. (a) Construct a 90% confidence interval for the true proportion of supporters. (b) Check if the conditions for inference are met. (c) How large a sample would be needed for a margin of error of 0.03 with 95% confidence? Show Solution\n\nSolution. (a)\n\\(\\hat{p} = \\frac{240}{400} = 0.6\\), \\(n = 400\\), 90% confidence, \\(z^* = 1.645\\)\n\\(SE = \\sqrt{\\frac{0.6 \\times 0.4}{400}} = \\sqrt{\\frac{0.24}{400}} = 0.0245\\)\n\\(CI = 0.6 \\pm 1.645 \\times 0.0245 = 0.6 \\pm 0.0403 = (0.560, 0.640)\\)\n(b)\nCheck conditions: \\(n\\hat{p} = 400 \\times 0.6 = 240 \\geq 10\\) ‚úì\n\\(n(1-\\hat{p}) = 400 \\times 0.4 = 160 \\geq 10\\) ‚úì\n(c)\nSample size calculation:\n\\(n = \\frac{(z^*)^2 \\hat{p}(1-\\hat{p})}{ME^2} =\n\\frac{(1.96)^2 \\times 0.6 \\times 0.4}{(0.03)^2} =\n\\frac{0.9216}{0.0009} = 1024\\) people"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-3-sample-size-planning",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#practice-problem-3-sample-size-planning",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Practice Problem 3: Sample Size Planning",
    "text": "Practice Problem 3: Sample Size Planning\n\nA market researcher wants to estimate the average amount spent on coffee per week by college students. (a) How large a sample is needed for a 95% CI with margin of error $2 if \\(\\sigma\\) = $8? (b) If the budget only allows for 100 students, what confidence level gives a $2 margin of error? (c) What‚Äôs the trade-off between sample size, confidence level, and precision?\n\nShow Solution\n\n\nSolution. (a)\nFor means:\n\\(n = \\frac{(z^*)^2 \\sigma^2}{ME^2} =\n\\frac{(1.96)^2 \\times 8^2}{2^2} =\n\\frac{245.86}{4} = 62\\) students\n(b)\nWith \\(n = 100\\):\n\\(ME = z^* \\frac{\\sigma}{\\sqrt{n}} =\nz^* \\frac{8}{\\sqrt{100}} =\n0.8 z^*\\)\nFor \\(ME = 2\\):\n\\(z^* = \\frac{2}{0.8} = 2.5\\),\nwhich corresponds to about 98.8% confidence\n(c) Trade-offs:\n\nHigher confidence \\(\\rightarrow\\) wider intervals (less precision)\nLarger sample \\(\\rightarrow\\) narrower intervals (more precision)\nLower margin of error \\(\\rightarrow\\) need larger sample or lower confidence"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#common-mistakes-and-misconceptions",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#common-mistakes-and-misconceptions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Common Mistakes and Misconceptions",
    "text": "Common Mistakes and Misconceptions\n\n\nInterpretation Errors\n‚ùå Wrong: ‚Äú\\(95\\%\\) of the data falls in this interval‚Äù\n‚úÖ Right: ‚ÄúWe‚Äôre \\(95\\%\\) confident the parameter is in this interval‚Äù\n‚ùå Wrong: ‚ÄúThere‚Äôs a \\(95\\%\\) chance \\(\\mu\\) is in this interval‚Äù\n‚úÖ Right: ‚Äú\\(95\\%\\) of such intervals contain \\(\\mu\\)‚Äù\n\nTechnical Errors\n\nUsing \\(z*\\) when œÉ is unknown and \\(n &lt; 30\\)\nForgetting to check conditions\nConfusing standard error with standard deviation\nUsing wrong degrees of freedom for t-distribution\n\n\nRemember: The confidence level refers to the long-run proportion of intervals that capture the parameter!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#sample-size-and-margin-of-error-relationships",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#sample-size-and-margin-of-error-relationships",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Sample Size and Margin of Error Relationships",
    "text": "Sample Size and Margin of Error Relationships\n\n\nPopulation œÉ:  Confidence Level:  90% 95% 99%   Desired Margin of Error: \n\n\n\n\n\n\nSample Size vs Margin of Error\n\n\n\n\nRequired Sample Size: - | Resulting ME: -"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#types-of-sampling-methods",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#types-of-sampling-methods",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Types of Sampling Methods",
    "text": "Types of Sampling Methods\n\n\n\n\n\n\n\n\n\n\nMethod\nDescription\nAdvantages\nDisadvantages\n\n\n\n\nSimple Random\nEvery individual has equal chance\nUnbiased, simple\nMay not represent subgroups\n\n\nStratified\nSample from each subgroup\nEnsures representation\nMore complex\n\n\nCluster\nSample entire groups\nCost-effective for spread populations\nHigher variability\n\n\nSystematic\nEvery k-th individual\nSimple to implement\nCan miss patterns\n\n\nConvenience\nEasily accessible individuals\nQuick and cheap\nHighly biased\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nSampling Method Matters: Only probability sampling methods allow for valid statistical inference!"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#confidence-intervals-in-practice",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#confidence-intervals-in-practice",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Confidence Intervals in Practice",
    "text": "Confidence Intervals in Practice\n\n\n\nWhen to Use Each Type\nMeans: Continuous data (height, income, test scores)\nProportions: Categorical data (yes/no, success/failure)\nChoosing Confidence Level\n\n90%: Quick estimates, less critical decisions\n95%: Standard in most research\n99%: High-stakes decisions, medical trials\n\n\nReal-World Applications\n\nPolitical polls: Proportion confidence intervals\nQuality control: Mean confidence intervals\nMedical research: Both types with high confidence\nBusiness analytics: Varies by decision importance\n\nCommunication Tips\n\nAlways include the confidence level\nState what the interval estimates\nAcknowledge the uncertainty\nConsider practical significance"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#key-takeaways",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#key-takeaways",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\n\n\nMain Concepts\n\nSampling distributions follow predictable patterns\nConfidence intervals quantify uncertainty\nCentral Limit Theorem makes normal-based inference possible\nSample size directly affects precision\n\n\nPractical Guidelines Choose appropriate methods based on:\n\nData type (continuous vs categorical)\nSample size (use t when œÉ unknown)\nDesired precision (affects sample size)\nConfidence level (affects interval width)\n\nKey Principle Statistical inference allows us to make informed decisions about populations using sample data, while properly accounting for uncertainty."
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#looking-ahead",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#looking-ahead",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\nNext Lecture: Hypothesis Testing\nTopics we‚Äôll cover:\n\nNull and alternative hypotheses\nTest statistics and p-values\nType I and Type II errors\n\n\nConnection: Confidence intervals and hypothesis tests are two sides of the same statistical inference coin"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#questions",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#questions",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Questions?",
    "text": "Questions?\n\nOffice Hours: 11AM on Thursday (link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Hypothesis Testing and Statistical Significance"
  },
  {
    "objectID": "files/lecture_notes/lecture11/lecture11-interactive.html#resources",
    "href": "files/lecture_notes/lecture11/lecture11-interactive.html#resources",
    "title": "PSTAT 5A: Sampling and Confidence Intervals",
    "section": "Resources",
    "text": "Resources\n\n  \n    \n      \n      Read OpenIntro Statistics Chapter 5 sections 5.1-5.3\n    \n    \n      \n      Khan Academy - Confidence Intervals\n    \n    \n      \n      Seeing Theory - Frequentist Inference\n    \n    \n      \n      Confidence Intervals - Wikipedia\n    \n    \n      \n      Understanding Different Types of Intervals"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Get in Touch\n\nWe‚Äôre here to help you succeed in PSTAT 5A\n\n\n\n\n\n\nNM\n\n\nCourse Instructor\n\n\nNarjes Mathlouthi\n\n\n\n\nüìß\n\n\nnmathlouthi@ucsb.edu\n\n\n\n\nüè¢\n\n\nEllison Hall 5829\n\n\n\n\nüïê\n\n\nThursdays 11:00 AM‚Äì12:00 PM\n\n\n\n\nüíª\n\n\nVia Zoom or by appointment\n\n\n\n\n\n\nSL\n\n\nTeaching Assistant\n\n\nSummer Le\n\n\n\n\nüìß\n\n\nsle@ucsb.edu\n\n\n\n\nüïê\n\n\nFriday 1:00 PM ‚Äì 2:00 PM\n\n\n\n\nüíª\n\n\nVia Zoom (links on Canvas)\n\n\n\n\n\n\n\nMH\n\n\nTeaching Assistant\n\n\nMingzhu He\n\n\n\n\nüìß\n\n\nmingzhuhe@ucsb.edu\n\n\n\n\nüïê\n\n\nTuesday 11:00 AM ‚Äì 12:00 PM\n\n\n\n\nüíª\n\n\nVia Zoom (links on Canvas)\n\n\n\n\n\n\n\nInstructor Office Hours\n\n\nThursdays 11:00 AM ‚Äì 12:00 PM\n\n\nAvailable via Zoom or by appointment  Zoom links posted on Canvas\n\n\n\n\n\nCommunication Guidelines\n\n\n\n1\n\n\nSubject Line: Always include [PSTAT 5A] in your email subject for faster response\n\n\n\n\n2\n\n\nResponse Time: Allow 24‚Äì48 hours for replies (avoid sending on weekends)\n\n\n\n\n3\n\n\nUse UCSB Email: Always email from your UCSB account for verification\n\n\n\n\n4\n\n\nOffice Hours: Use office hours for complex questions or detailed help\n\n\n\n\n5\n\n\nUrgent Matters: For time-sensitive issues, mention ‚ÄúURGENT‚Äù in the subject line\n\n\n\n\n\n\nEmergency Contacts\n\n\nFor campus emergencies: 911 ‚Ä¢ For student crisis support: CAPS 24/7 line (805) 893-4411"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#important-announcements",
    "href": "files/lecture_notes/lecture10/lecture10.html#important-announcements",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "üì¢ Important Announcements",
    "text": "üì¢ Important Announcements\n\n\nüìù Quiz 2 Details\nWhen:\n- üìÖ Date: Friday, July 25\n- ‚è∞ Window: 7 AM ‚Äì 12 AM\n- ‚è≥ Duration: 1 hour once started\nWhere: üíª Online via Canvas\nCovers: Material from Weeks 3-4\n\nüìö What to Expect\n\nDiscrete & continuous distributions\nProbability calculations\nExpected value & variance\nNormal distribution applications\nNote: Upload photos of written work for calculation problems"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#todays-learning-journey",
    "href": "files/lecture_notes/lecture10/lecture10.html#todays-learning-journey",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Today‚Äôs Learning Journey üéØ",
    "text": "Today‚Äôs Learning Journey üéØ\n\n\nüß† Big Ideas We‚Äôll Explore\n\nWhy sampling? The power and necessity of statistical inference\nSample behavior - How sample means form predictable patterns\nUncertainty quantification - From point estimates to intervals\nThe CLT magic - Why normal distributions appear everywhere\nConfidence intervals - Our bridge from samples to populations\n\n\nüõ†Ô∏è Skills You‚Äôll Master\n\nDesign effective sampling strategies\nCalculate and interpret standard errors\nApply the Central Limit Theorem\nConstruct and interpret confidence intervals\nChoose appropriate sample sizes for desired precision\nRecognize and avoid sampling bias"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#the-foundation-why-do-we-sample",
    "href": "files/lecture_notes/lecture10/lecture10.html#the-foundation-why-do-we-sample",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "The Foundation: Why Do We Sample? ü§î",
    "text": "The Foundation: Why Do We Sample? ü§î\n\n\nüåç Real-World Constraints\nPopulation vs.¬†Sample Realities:\n\nTime: Surveying 40,000 UCSB students takes months\nCost: Each measurement costs money and resources\nLogistics: Some populations are impossible to reach entirely\nFeasibility: Testing every light bulb would destroy the product\n\nüí° The Statistical Solution\nUse a representative sample to make valid inferences about the entire population"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#study-design-the-foundation-of-good-inference",
    "href": "files/lecture_notes/lecture10/lecture10.html#study-design-the-foundation-of-good-inference",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Study Design: The Foundation of Good Inference",
    "text": "Study Design: The Foundation of Good Inference\n\n\n                            \n                                            \n\n\n\n\nüîç Observational Studies: - Observe what naturally occurs - Good for identifying associations - ‚ö†Ô∏è Cannot establish causation due to confounding\n\nüß™ Randomized Experiments: - Actively assign treatments randomly - Controls for confounding variables - ‚úÖ Can establish causal relationships"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#types-of-sampling-methods",
    "href": "files/lecture_notes/lecture10/lecture10.html#types-of-sampling-methods",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Types of Sampling Methods üéØ",
    "text": "Types of Sampling Methods üéØ\n\nüìã Probability Sampling Methods\n\n1. Simple Random Sampling (SRS)\nEvery individual has equal chance of selection\nGold standard for inference\n2. Stratified Sampling\nDivide population into groups (strata)\nSample randomly within each group\nEnsures representation of subgroups\n\n3. Cluster Sampling\nDivide into clusters, randomly select clusters\nSample all/some individuals within chosen clusters\nCost-effective for large populations\n4. Systematic Sampling\nSelect every \\(kth\\) individual from ordered list\nSimple but can introduce bias if pattern exists"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#sampling-bias-what-can-go-wrong",
    "href": "files/lecture_notes/lecture10/lecture10.html#sampling-bias-what-can-go-wrong",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Sampling Bias: What Can Go Wrong? ‚ö†Ô∏è",
    "text": "Sampling Bias: What Can Go Wrong? ‚ö†Ô∏è\n\n\nüö® Common Types of Bias\nSelection Bias - Systematic exclusion of certain groups - Example: Online surveys miss non-internet users\nResponse Bias\n- Who chooses to respond affects results - Example: Satisfaction surveys - unhappy customers more likely to respond\nNonresponse Bias - Missing data isn‚Äôt random - Example: Wealthy people less likely to disclose income\nConvenience Sampling - Sampling whoever is easiest to reach - Example: Surveying only students in your dorm\n\n\n\n                            \n                                            \n\n\nüí° Key Insight: Bias can‚Äôt be fixed by increasing sample size!"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#the-magic-of-sample-means-from-chaos-to-order",
    "href": "files/lecture_notes/lecture10/lecture10.html#the-magic-of-sample-means-from-chaos-to-order",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "The Magic of Sample Means: From Chaos to Order",
    "text": "The Magic of Sample Means: From Chaos to Order\n\n\nüé≤ The Setup:\n\nTake many samples from the same population\nCalculate the mean of each sample\nPlot all these sample means\nObserve the magic!\n\nüéØ What We Discover:\n\nSample means cluster around the true population mean\nThey form a predictable pattern (normal distribution!)\nLarger samples give more consistent results"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#the-central-limit-theorem",
    "href": "files/lecture_notes/lecture10/lecture10.html#the-central-limit-theorem",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "The Central Limit Theorem üåü",
    "text": "The Central Limit Theorem üåü\n\n\nüìê The Statement\nFor a population with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), when sample size \\(n\\) is large enough:\n\\[\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\]\nOr equivalently: \\[Z = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)\\]\n‚ú® The Magic Rules\n\nRule of Thumb: \\(n \\geq 30\\) usually works\nShape doesn‚Äôt matter: Works for ANY population distribution\n\nLarger \\(n\\) = Better approximation"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#standard-error-measuring-our-uncertainty",
    "href": "files/lecture_notes/lecture10/lecture10.html#standard-error-measuring-our-uncertainty",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Standard Error: Measuring Our Uncertainty üìè",
    "text": "Standard Error: Measuring Our Uncertainty üìè\n\n\nüéØ What is Standard Error?\nStandard Error (SE) measures how much sample means vary from sample to sample.\n\\[SE = \\frac{\\sigma}{\\sqrt{n}} \\text{ (when } \\sigma \\text{ is known)}\\]\n\\[SE = \\frac{s}{\\sqrt{n}} \\text{ (usual case, } \\sigma \\text{ unknown)}\\]\nüîç Key Insights\n\nSmaller SE = More precise estimates\nSE decreases as sample size increases\nRate of decrease: \\(SE \\propto 1/\\sqrt{n}\\)\n4√ó larger sample = ¬Ω the uncertainty!"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#confidence-intervals-our-bridge-to-the-population",
    "href": "files/lecture_notes/lecture10/lecture10.html#confidence-intervals-our-bridge-to-the-population",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Confidence Intervals: Our Bridge to the Population üåâ",
    "text": "Confidence Intervals: Our Bridge to the Population üåâ\n\n\nüéØ What Are Confidence Intervals?\nA confidence interval gives us a range of plausible values for the population parameter.\nFor a population mean: \\[\\bar{x} \\pm z^* \\cdot \\frac{s}{\\sqrt{n}}\\]\nüî¢ Common Confidence Levels\n\n90% CI: \\(z^* = 1.645\\)\n95% CI: \\(z^* = 1.96\\)\n99% CI: \\(z^* = 2.576\\)\n\nüí≠ Correct Interpretation\n‚ÄúWe are 95% confident that the true population mean lies between [lower bound] and [upper bound]‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#sample-size-planning-getting-it-right",
    "href": "files/lecture_notes/lecture10/lecture10.html#sample-size-planning-getting-it-right",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Sample Size Planning: Getting It Right üéØ",
    "text": "Sample Size Planning: Getting It Right üéØ\n\n\nüìê The Formula\nTo achieve margin of error \\(E\\) with confidence level \\((1-\\alpha)\\):\n\\[n = \\left(\\frac{z^*\\sigma}{E}\\right)^2\\]\nüéØ Key Considerations\nMargin of Error Trade-offs: - Smaller \\(E\\) requires larger \\(n\\) - Higher confidence requires larger \\(n\\)\n- More variable population requires larger \\(n\\)\nPractical Constraints: - Budget limitations - Time constraints\n- Availability of participants"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#putting-it-all-together-a-real-example",
    "href": "files/lecture_notes/lecture10/lecture10.html#putting-it-all-together-a-real-example",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Putting It All Together: A Real Example üìä",
    "text": "Putting It All Together: A Real Example üìä\n\n\nüéØ Research Question\n‚ÄúWhat is the average height of UCSB students?‚Äù\nOur Approach:\n\nPopulation: All 26,000 UCSB students\nSample: Random sample of 100 students\nMeasurement: Height in inches\nGoal: 95% confidence interval for population mean\n\nResults:\n\nSample mean: \\(\\bar{x} = 68.2\\) inches\nSample std dev: \\(s = 4.1\\) inches\nSample size: \\(n = 100\\)\n\n\n\n\n                            \n                                            \n\n\nüéØ Interpretation: We are 95% confident that the true average height of UCSB students is between 67.40 and 69.00 inches."
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#key-takeaways-your-statistical-toolkit",
    "href": "files/lecture_notes/lecture10/lecture10.html#key-takeaways-your-statistical-toolkit",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Key Takeaways: Your Statistical Toolkit üéØ",
    "text": "Key Takeaways: Your Statistical Toolkit üéØ\n\n\nüß† Fundamental Concepts\n1. Sampling Wisdom\n\nRepresentative samples beat large biased samples\nRandomization is your best friend\nBias can‚Äôt be fixed with larger samples\n\n2. The CLT Magic\n\nSample means are approximately normal (\\(n ‚â• 30\\))\nWorks for ANY population distribution\nEnables powerful statistical inference\n\n3. Standard Error\n\nMeasures precision of our estimates\nDecreases with \\(\\sqrt{n}\\), not \\(n\\)\nKey ingredient in confidence intervals\n\n\nüõ†Ô∏è Practical Skills\n4. Confidence Intervals\n\nQuantify uncertainty in our estimates\nCorrect interpretation is crucial\nWidth depends on confidence level and sample size\n\n5. Sample Size Planning\n\nBalance precision needs with resources\nConsider margin of error requirements\nAccount for practical constraints\n\n6. Quality Control\n\nAlways check for potential bias\nVerify assumptions (normality, independence)\nConsider the broader context"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#common-misconceptions-to-avoid",
    "href": "files/lecture_notes/lecture10/lecture10.html#common-misconceptions-to-avoid",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Common Misconceptions to Avoid ‚ö†Ô∏è",
    "text": "Common Misconceptions to Avoid ‚ö†Ô∏è"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#interactive-practice-test-your-understanding",
    "href": "files/lecture_notes/lecture10/lecture10.html#interactive-practice-test-your-understanding",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Interactive Practice: Test Your Understanding üß™",
    "text": "Interactive Practice: Test Your Understanding üß™\n\n\nü§î Check Questions\n1. Sample Size Question: If we want to halve our margin of error, by what factor should we increase our sample size?\n2. CLT Application:\nA population has a right-skewed distribution. What can we say about the distribution of sample means when n = 50?\n3. CI Interpretation: We calculated a 95% CI as (45, 55). What does this mean?\n4. Bias Detection: An online survey about internet usage gets 10,000 responses. What type of bias might be present?\n\n‚úÖ Answers\n1. Increase by factor of 4 (since \\(SE \\propto \\frac{1}{\\sqrt{n}}\\))\n2. Sample means will be approximately normal regardless of population shape\n3. We‚Äôre 95% confident the true population parameter is between 45 and 55\n4. Selection bias - excludes people without internet access"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#comprehensive-resources",
    "href": "files/lecture_notes/lecture10/lecture10.html#comprehensive-resources",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Comprehensive Resources üìö",
    "text": "Comprehensive Resources üìö\n\n\nüìñ Required Reading\n\nOpenIntro Statistics\n\nSection 1.3: Sampling principles and strategies\nSection 3.3: Confidence intervals for a mean\nSection 4.1: Central Limit Theorem\n\n\nüé• Video Resources\n\nKhan Academy: Central Limit Theorem\nStatQuest: Confidence Intervals Explained\n3Blue1Brown: Central Limit Theorem Visualization\n\n\nüíª Interactive Tools\n\nSeeing Theory: Probability Visualizations\nRossman & Chance Applets: Sampling Distributions\nCentral Limit Theorem Simulator\n\nü§ù Getting Help\n\nOffice Hours: Thursday 11 AM-12 PM (Zoom link on Canvas)\nEmail: nmathlouthi@ucsb.edu\n\nüéØ What‚Äôs Next?\nNext Lecture: Hypothesis Testing and p-values"
  },
  {
    "objectID": "files/lecture_notes/lecture10/lecture10.html#questions-discussion",
    "href": "files/lecture_notes/lecture10/lecture10.html#questions-discussion",
    "title": "PSTAT 5A: Sampling Principles and Strategies",
    "section": "Questions & Discussion ü§î",
    "text": "Questions & Discussion ü§î\n\n\nüí≠ Think About This‚Ä¶\n‚ÄúThe goal is not to eliminate uncertainty, but to understand and quantify it intelligently‚Äù\nKey Questions for Reflection:\n\nHow do we balance precision with practicality?\nWhen might a larger sample actually be worse?\nWhat makes a ‚Äúgood‚Äù confidence interval?\nHow do we communicate uncertainty to non-statisticians?\n\n\nüéØ Prepare for Next Class\nComing Up: Hypothesis Testing\n\nWhat are null and alternative hypotheses?\nHow do we make decisions with data?\nWhat does a p-value really mean?\n\nRecommended Prep:\n\nReview today‚Äôs confidence interval concepts\nThink about yes/no questions you‚Äôd test with data\nConsider what ‚Äústatistical significance‚Äù means to you"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sec-objectives",
    "href": "files/lecture_notes/lecture4/lecture4.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sec-prob",
    "href": "files/lecture_notes/lecture4/lecture4.html#sec-prob",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is Probability?",
    "text": "What is Probability?\n\nüéØ Definition\nProbability is a measure of the likelihood that an event will occur"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-range",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-range",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Range",
    "text": "Probability Range\n\n\n\nRanges from 0 to 1 (or 0% to 100%)\n0: Event will never occur (impossible)\n1: Event will certainly occur (certain)\n0.5: Event has equal chance of occurring or not"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#three-ways-to-express-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#three-ways-to-express-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Three Ways to Express Probability",
    "text": "Three Ways to Express Probability\n\nFraction: \\(\\frac{1}{2}\\), \\(\\frac{3}{4}\\), \\(\\frac{2}{6}\\)\nDecimal: 0.5, 0.75, 0.33\nPercentage: 50%, 75%, 33%"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#example",
    "href": "files/lecture_notes/lecture4/lecture4.html#example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example",
    "text": "Example\nWhen we roll a die, there are six possible outcomes:\n1, 2, 3, 4, 5, 6.\nThe probability of any of them turning up is 1/6 or 16%."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#why-study-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#why-study-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Why Study Probability?",
    "text": "Why Study Probability?\nProbability helps us:\n\nMake decisions under uncertainty\nUnderstand random processes\nAnalyze data and draw conclusions\nModel real-world phenomena\nAssess risk and likelihood\n\n\n\nApplications: Weather forecasting, medical diagnosis, finance, quality control, gaming, insurance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#random-experiments",
    "href": "files/lecture_notes/lecture4/lecture4.html#random-experiments",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Random Experiments",
    "text": "Random Experiments\nA random experiment is a process that:\n\nCan be repeated under similar conditions\nHas multiple possible outcomes\nThe outcome cannot be predicted with certainty\n\n\n\nExamples\n\nü™ô Flipping a coin\nüé≤ Rolling a die\nüÉè Drawing a card from a deck\nüí° Measuring the lifetime of a light bulb"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sample-space",
    "href": "files/lecture_notes/lecture4/lecture4.html#sample-space",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space",
    "text": "Sample Space\n\nüéØ Definition The sample space (denoted \\(S\\) or \\(\\Omega\\)) is the set of all possible outcomes of a random experiment"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sample-space-examples",
    "href": "files/lecture_notes/lecture4/lecture4.html#sample-space-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space Examples",
    "text": "Sample Space Examples\n\nCoin flip: \\(S = \\{H, T\\}\\)\nTwo coin flips: \\(S = \\{HH, HT, TH, TT\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#types-of-sample-spaces",
    "href": "files/lecture_notes/lecture4/lecture4.html#types-of-sample-spaces",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Types of Sample Spaces",
    "text": "Types of Sample Spaces\n\n\nFinite Sample Space\n\nLimited number of outcomes\n\nExample: Rolling a die\n\n\n\n\n\n\n\n\n\n\n\nInfinite Sample Space\n\nUnlimited outcomes (countable or uncountable)\n\nExample: Measuring exact height of students"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#events",
    "href": "files/lecture_notes/lecture4/lecture4.html#events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Events",
    "text": "Events\n\nüéØ Definition An event is a subset of the sample space\n\nSimple event: Contains exactly one outcome (Ex: \\(A = \\{3\\}\\) (rolling a 3))\nCompound event: Contains multiple outcomes (Ex: \\(B = \\{2, 4, 6\\}\\) (rolling an even number))"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#event-notation",
    "href": "files/lecture_notes/lecture4/lecture4.html#event-notation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Event Notation",
    "text": "Event Notation\nFor a die roll with \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (rolling an odd number)\n\\(B = \\{4, 5, 6\\}\\) (rolling 4 or higher)\n\\(C = \\{6\\}\\) (rolling a six)\n\n\n\nWe can describe events in words or using set notation"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#set-operations-overview",
    "href": "files/lecture_notes/lecture4/lecture4.html#set-operations-overview",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Set Operations Overview",
    "text": "Set Operations Overview\n\n\n\n\nüéØ Definition:\n\nSet: Collection of distinct objects\nUnion: A OR B occurs\n\nIntersection: A AND B occurs\nComplement: A does NOT occur\nSample Space: All possible outcomes"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#what-is-a-set",
    "href": "files/lecture_notes/lecture4/lecture4.html#what-is-a-set",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is a Set?",
    "text": "What is a Set?\n\n\n\n\nüéØ Definition: A collection of things that share common characteristics. They can be elements, members, objects or similar terms.\nExamples:\n\nSet of even numbers:\n\n{2, 4, 6, 8, ‚Ä¶}\n\nSet of vowels: {a, e, i, o, u}"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#union-a-b",
    "href": "files/lecture_notes/lecture4/lecture4.html#union-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Union: A ‚à™ B",
    "text": "Union: A ‚à™ B\n\n\n\n\nüéØ Definition: Contains all set elements, including intersections.\nIn Probability: The event that A OR B occurs (or both).\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#intersection-a-b",
    "href": "files/lecture_notes/lecture4/lecture4.html#intersection-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Intersection: A ‚à© B",
    "text": "Intersection: A ‚à© B\n\n\n\n\nüéØ Definition: Area where two or more sets overlap.\nIn Probability: The event that A AND B occurs.\nProperties:\n\nAlways smaller than or equal to individual sets\nCan be empty (disjoint sets)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#absolute-complement-ac",
    "href": "files/lecture_notes/lecture4/lecture4.html#absolute-complement-ac",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Absolute Complement: \\(A^c\\)",
    "text": "Absolute Complement: \\(A^c\\)\n\n\n\nüéØ Definition: All elements that do not belong to the set.\nIn Probability: The event that A does NOT occur.\n\n\\(P(A^c) = 1 - P(A)\\)\n\n\nKey Property:\n\\(A \\cup A^c = S\\) (Sample Space)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#summary-table",
    "href": "files/lecture_notes/lecture4/lecture4.html#summary-table",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Summary Table",
    "text": "Summary Table\n\n\n\n\n\n\n\n\n\nOperation\nSymbol\nMeaning\nProbability\n\n\n\n\nUnion\n\\(A \\cup B\\)\nOccurs if \\(A\\) or \\(B\\)\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\nIntersection\n\\(A \\cap B\\)\nOccurs if \\(A\\) and \\(B\\)\n\\(P(A \\cap B)\\)\n\n\nComplement\n\\(A^c\\)\nOccurs if \\(A\\) does not occur\n\\(P(A^c) = 1 - P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-commutative",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-commutative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Commutative",
    "text": "Probability Axioms: Commutative\n\nCommutative\n\\(A \\cup B = B \\cup A\\)\n\\(A \\cap B = B \\cap A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-associative",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-associative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Associative",
    "text": "Probability Axioms: Associative\n\nAssociative\n\\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\)\n\\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-distributive",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-distributive",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Distributive",
    "text": "Probability Axioms: Distributive\n\nDistributive\n\\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\n\\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-de-morgans-laws",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-de-morgans-laws",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: De Morgan‚Äôs Laws",
    "text": "Probability Axioms: De Morgan‚Äôs Laws\n\nDe Morgan‚Äôs Laws\n\\((A \\cup B)^c = A^c \\cap B^c\\)\n\\((A \\cap B)^c = A^c \\cup B^c\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-examples",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Examples",
    "text": "Practice Examples\n\nExample 1: In a class of students:\n\nSet A = Students who like Math\nSet B = Students who like Science\n\nQ: What does A ‚à™ B represent?\n\n\n\nSolution. Students who like Math OR Science (or both)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#example-set-operations",
    "href": "files/lecture_notes/lecture4/lecture4.html#example-set-operations",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example: Set Operations",
    "text": "Example: Set Operations\n\n\nFor die roll \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (odd numbers)\n\\(B = \\{4, 5, 6\\}\\) (4 or higher)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind:\n\n\\(A \\cup B\\)\n\\(A \\cap B\\)\n\\(A^c\\)\n\n\n\n\n\nSolution. \n\n\\(A \\cup B = \\{1, 3, 4, 5, 6\\}\\)\n\\(A \\cap B = \\{5\\}\\)\n\\(A^c = \\{2, 4, 6\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-events",
    "href": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive Events",
    "text": "Mutually Exclusive Events\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive (or disjoint) if they cannot occur simultaneously\n\\[A \\cap B = \\emptyset\\]\n\n\n\n\n\n\n\n\n\n\n\n\nWhen rolling a die\n\n\\(A = \\{1, 3, 5\\}\\) (odd)\n\\(B = \\{2, 4, 6\\}\\) (even)\n\n\\(A\\) and \\(B\\) are mutually exclusive"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-classical-definition-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-classical-definition-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Classical Definition of Probability",
    "text": "The Classical Definition of Probability\n\nüéØ Definition: For equally likely outcomes:\n\\[P(A) = \\frac{\\text{Number of outcomes in } A}{\\text{Total number of outcomes in } S}\\]\n\n\nProbability of rolling an even number on a fair die\n\n\n\\[P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#properties-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#properties-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Properties of Probability",
    "text": "Properties of Probability\n\nNon-negativity: \\(P(A) \\geq 0\\) for any event \\(A\\)\nNormalization: \\(P(S) = 1\\)\nAdditivity: If \\(A\\) and \\(B\\) are mutually exclusive, then\n\n\n\\[P(A \\cup B) = P(A) + P(B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-complement-rule",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-complement-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Complement Rule",
    "text": "The Complement Rule\n\n\\[P(A) + P(A^c) = 1\\]\n\\[P(A^c) = 1 - P(A)\\]\n\n\n\nIf the probability of rain is 0.3, what‚Äôs the probability of no rain?\n\n\n\n\nSolution. \\[P(\\text{no rain}) = 1 - P(\\text{rain}) = 1 - 0.3 = 0.7\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#questions",
    "href": "files/lecture_notes/lecture4/lecture4.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday‚Äôs 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Conditional Probabilities & Independence"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#resources",
    "href": "files/lecture_notes/lecture4/lecture4.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms\nProbability Animations"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#problem-statement",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#problem-statement",
    "title": "Linear Transformation Properties",
    "section": "Problem Statement",
    "text": "Problem Statement\n\nGiven: Let \\(X = \\{x_i\\}_{i=1}^{n}\\) and define \\(Y = \\{y_i\\}_{i=1}^{n}\\) by \\(y_i = a x_i\\) for some fixed constant \\(a \\neq 0\\).\nProve the following relationships:\n\\[\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i, \\quad \\bar{Y} = a \\bar{X}, \\quad S_Y^2 = a^2 S_X^2\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#understanding-the-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#understanding-the-notation",
    "title": "Linear Transformation Properties",
    "section": "Understanding the Notation",
    "text": "Understanding the Notation\nSet Notation\n\n\\(X = \\{x_i\\}_{i=1}^{n}\\) means:\n\n\\(X\\) is a dataset containing \\(n\\) observations\nThe observations are labeled \\(x_1, x_2, x_3, \\ldots, x_n\\)\n\\(i\\) is an index that runs from 1 to \\(n\\)\nThis is read as: ‚ÄúX is the set of \\(x_i\\) for \\(i\\) from 1 to \\(n\\)‚Äù\n\n\nExamples:\n\nIf \\(n = 5\\): \\(X = \\{x_1, x_2, x_3, x_4, x_5\\}\\)\nIf \\(X = \\{2, 4, 6, 8, 10\\}\\), then \\(x_1 = 2, x_2 = 4, x_3 = 6, x_4 = 8, x_5 = 10\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#summation-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#summation-notation",
    "title": "Linear Transformation Properties",
    "section": "Summation Notation",
    "text": "Summation Notation\n\n\\(\\sum_{i=1}^{n} x_i\\) means:\n\nAdd up all the \\(x_i\\) values\nStart with \\(i = 1\\) and go up to \\(i = n\\)\nThis equals: \\(x_1 + x_2 + x_3 + \\cdots + x_n\\)\n\n\nExample:\nIf \\(X = \\{2, 4, 6, 8, 10\\}\\), then: \\[\\sum_{i=1}^{5} x_i = x_1 + x_2 + x_3 + x_4 + x_5 = 2 + 4 + 6 + 8 + 10 = 30\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#linear-transformation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#linear-transformation",
    "title": "Linear Transformation Properties",
    "section": "Linear Transformation",
    "text": "Linear Transformation\n\n\\(Y = \\{y_i\\}_{i=1}^{n}\\) where \\(y_i = a x_i\\) means:\n\nEach element of \\(Y\\) is obtained by multiplying the corresponding element of \\(X\\) by the constant \\(a\\)\nThis is called a linear transformation\n\\(a\\) is called the scaling factor\n\n\nExample:\nIf \\(X = \\{2, 4, 6, 8, 10\\}\\) and \\(a = 3\\), then:\n\n\\(y_1 = 3 \\times 2 = 6\\)\n\\(y_2 = 3 \\times 4 = 12\\)\n\\(y_3 = 3 \\times 6 = 18\\)\n\\(y_4 = 3 \\times 8 = 24\\)\n\\(y_5 = 3 \\times 10 = 30\\)\n\nSo \\(Y = \\{6, 12, 18, 24, 30\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#sample-mean-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#sample-mean-notation",
    "title": "Linear Transformation Properties",
    "section": "Sample Mean Notation",
    "text": "Sample Mean Notation\n\nSample Mean: \\(\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\\)\nThis means:\n\nAdd up all observations: \\(\\sum_{i=1}^{n} x_i\\)\nDivide by the number of observations: \\(n\\)\nThe ‚Äúbar‚Äù over \\(X\\) indicates the mean\n\n\nExample:\nFor \\(X = \\{2, 4, 6, 8, 10\\}\\): \\[\\bar{X} = \\frac{1}{5}(2 + 4 + 6 + 8 + 10) = \\frac{30}{5} = 6\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#sample-variance-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#sample-variance-notation",
    "title": "Linear Transformation Properties",
    "section": "Sample Variance Notation",
    "text": "Sample Variance Notation\n\nSample Variance: \\(S_X^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2\\)\nThis means:\n\nFor each observation, find its deviation from the mean: \\((x_i - \\bar{X})\\)\nSquare each deviation: \\((x_i - \\bar{X})^2\\)\nAdd up all squared deviations: \\(\\sum_{i=1}^{n} (x_i - \\bar{X})^2\\)\nDivide by \\((n-1)\\): This gives the sample variance"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-1",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-1",
    "title": "Linear Transformation Properties",
    "section": "Proof 1: Sum Relationship",
    "text": "Proof 1: Sum Relationship\n\nStep 1: Start with the definition of \\(y_i\\) \\[y_i = a x_i \\text{ for all } i = 1, 2, \\ldots, n\\]\nStep 2: Write out the sum of all \\(y_i\\) \\[\\sum_{i=1}^{n} y_i = y_1 + y_2 + y_3 + \\cdots + y_n\\]\nStep 3: Substitute the definition \\(y_i = a x_i\\) \\[\\sum_{i=1}^{n} y_i = a x_1 + a x_2 + a x_3 + \\cdots + a x_n\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-continued",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-continued",
    "title": "Linear Transformation Properties",
    "section": "Proof 1: Sum Relationship (continued)",
    "text": "Proof 1: Sum Relationship (continued)\n\n\n\nStep 4: Factor out the constant \\(a\\) \\[\\sum_{i=1}^{n} y_i = a(x_1 + x_2 + x_3 + \\cdots + x_n)\\]\nStep 5: Recognize the sum notation \\[\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\]\nTherefore: \\(\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\) ‚úì\n\n\n\nKey Property Used: Constants can be factored out of sums \\[\\sum_{i=1}^{n} (c \\cdot x_i) = c \\sum_{i=1}^{n} x_i\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#example-sum-relationship",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#example-sum-relationship",
    "title": "Linear Transformation Properties",
    "section": "Example: Sum Relationship",
    "text": "Example: Sum Relationship\n\nGiven: \\(X = \\{2, 4, 6\\}\\) and \\(a = 5\\)\nThen: \\(Y = \\{10, 20, 30\\}\\) (since \\(y_i = 5x_i\\))\nCheck our formula:\n\n\\(\\sum_{i=1}^{3} x_i = 2 + 4 + 6 = 12\\)\n\\(\\sum_{i=1}^{3} y_i = 10 + 20 + 30 = 60\\)\n\\(a \\sum_{i=1}^{3} x_i = 5 \\times 12 = 60\\) ‚úì\n\nVerification: \\(60 = 60\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-1",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-1",
    "title": "Linear Transformation Properties",
    "section": "Proof 2: Sample Mean Relationship",
    "text": "Proof 2: Sample Mean Relationship\n\nStep 1: Start with the definition of sample mean \\[\\bar{Y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i\\]\nStep 2: Use our result from Proof 1 We proved that \\(\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\)\nStep 3: Substitute this result \\[\\bar{Y} = \\frac{1}{n} \\cdot a \\sum_{i=1}^{n} x_i\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-continued",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-continued",
    "title": "Linear Transformation Properties",
    "section": "Proof 2: Sample Mean Relationship (continued)",
    "text": "Proof 2: Sample Mean Relationship (continued)\n\n\n\nStep 4: Rearrange the constants \\[\\bar{Y} = a \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]\nStep 5: Recognize the definition of \\(\\bar{X}\\) \\[\\bar{Y} = a \\bar{X}\\]\nTherefore: \\(\\bar{Y} = a \\bar{X}\\) ‚úì\n\n\n\nKey Property Used: Constants can be moved outside of fractions \\[\\frac{1}{n} \\cdot a \\sum_{i=1}^{n} x_i = a \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-mean-relationship",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-mean-relationship",
    "title": "Linear Transformation Properties",
    "section": "Example: Sample Mean Relationship",
    "text": "Example: Sample Mean Relationship\n\nGiven: \\(X = \\{2, 4, 6\\}\\) and \\(a = 5\\)\nThen: \\(Y = \\{10, 20, 30\\}\\)\nCheck our formula:\n\n\\(\\bar{X} = \\frac{1}{3}(2 + 4 + 6) = \\frac{12}{3} = 4\\)\n\\(\\bar{Y} = \\frac{1}{3}(10 + 20 + 30) = \\frac{60}{3} = 20\\)\n\\(a \\bar{X} = 5 \\times 4 = 20\\) ‚úì\n\nVerification: \\(20 = 20\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-1",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-1",
    "title": "Linear Transformation Properties",
    "section": "Proof 3: Sample Variance Relationship",
    "text": "Proof 3: Sample Variance Relationship\n\nStep 1: Start with the definition of sample variance \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\bar{Y})^2\\]\nStep 2: Substitute \\(y_i = a x_i\\) and \\(\\bar{Y} = a \\bar{X}\\) \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (a x_i - a \\bar{X})^2\\]\nStep 3: Factor out \\(a\\) from the parentheses \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} [a(x_i - \\bar{X})]^2\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-continued",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-continued",
    "title": "Linear Transformation Properties",
    "section": "Proof 3: Sample Variance Relationship (continued)",
    "text": "Proof 3: Sample Variance Relationship (continued)\n\nStep 4: Use the property \\((ab)^2 = a^2 b^2\\) \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} a^2 (x_i - \\bar{X})^2\\]\nStep 5: Factor out the constant \\(a^2\\) from the sum \\[S_Y^2 = \\frac{a^2}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2\\]\nStep 6: Recognize the definition of \\(S_X^2\\) \\[S_Y^2 = a^2 \\cdot \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2 = a^2 S_X^2\\]\nTherefore: \\(S_Y^2 = a^2 S_X^2\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#key-properties-used-in-variance-proof",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#key-properties-used-in-variance-proof",
    "title": "Linear Transformation Properties",
    "section": "Key Properties Used in Variance Proof",
    "text": "Key Properties Used in Variance Proof\n\nProperties Used:\n\nFactoring: \\(ax_i - a\\bar{X} = a(x_i - \\bar{X})\\)\nSquaring: \\([a(x_i - \\bar{X})]^2 = a^2(x_i - \\bar{X})^2\\)\nConstants in sums: \\(\\sum_{i=1}^{n} a^2 f(x_i) = a^2 \\sum_{i=1}^{n} f(x_i)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-variance-relationship",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-variance-relationship",
    "title": "Linear Transformation Properties",
    "section": "Example: Sample Variance Relationship",
    "text": "Example: Sample Variance Relationship\n\nGiven: \\(X = \\{1, 3, 5\\}\\) and \\(a = 2\\)\nCalculate \\(S_X^2\\):\n\n\\(\\bar{X} = \\frac{1+3+5}{3} = 3\\)\n\\(S_X^2 = \\frac{1}{2}[(1-3)^2 + (3-3)^2 + (5-3)^2] = \\frac{1}{2}[4 + 0 + 4] = 4\\)\n\nFor \\(Y = \\{2, 6, 10\\}\\): - \\(\\bar{Y} = \\frac{2+6+10}{3} = 6 = 2 \\times 3\\) ‚úì\n\n\\(S_Y^2 = \\frac{1}{2}[(2-6)^2 + (6-6)^2 + (10-6)^2] = \\frac{1}{2}[16 + 0 + 16] = 16\\)\n\nCheck: \\(a^2 S_X^2 = 2^2 \\times 4 = 16\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#complete-summary-of-results",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#complete-summary-of-results",
    "title": "Linear Transformation Properties",
    "section": "Complete Summary of Results",
    "text": "Complete Summary of Results\n\nFor the linear transformation \\(Y = \\{y_i\\}_{i=1}^{n}\\) where \\(y_i = a x_i\\):\n\nSum: \\(\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\)\nMean: \\(\\bar{Y} = a \\bar{X}\\)\nVariance: \\(S_Y^2 = a^2 S_X^2\\)\n\nNote: The standard deviation relationship is \\(S_Y = |a| S_X\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#practical-implications",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#practical-implications",
    "title": "Linear Transformation Properties",
    "section": "Practical Implications",
    "text": "Practical Implications\n\n\nScaling Up (a &gt; 1):\n\nSums and means increase by factor \\(a\\)\nVariance increases by factor \\(a^2\\)\nData becomes more spread out\n\nExample: Converting inches to feet\n\nIf \\(a = 12\\), variance increases by \\(12^2 = 144\\)\n\n\n\nScaling Down (0 &lt; a &lt; 1):\n\nSums and means decrease by factor \\(a\\)\nVariance decreases by factor \\(a^2\\)\nData becomes less spread out\n\nExample: Converting dollars to cents\n\nIf \\(a = 0.01\\), variance decreases by \\((0.01)^2 = 0.0001\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#real-world-applications",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#real-world-applications",
    "title": "Linear Transformation Properties",
    "section": "Real-World Applications",
    "text": "Real-World Applications\n\nTemperature Conversion:\n\nCelsius to Fahrenheit: \\(F = \\frac{9}{5}C + 32\\) (not linear!)\nCelsius to Kelvin: \\(K = C + 273.15\\) (not linear!)\nBut scaling: \\(C_{doubled} = 2C\\) is linear with \\(a = 2\\)\n\nUnit Conversions: - Meters to centimeters: \\(a = 100\\)\n\nDollars to cents: \\(a = 100\\)\nHours to minutes: \\(a = 60\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#why-these-properties-matter",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#why-these-properties-matter",
    "title": "Linear Transformation Properties",
    "section": "Why These Properties Matter",
    "text": "Why These Properties Matter\n\nStatistical Significance:\n\nStandardization: Converting to z-scores uses linear transformations\nUnit Changes: Results remain proportionally correct\nData Analysis: Understanding how transformations affect summary statistics\nModeling: Linear regression relies on these properties\n\nKey Insight: Linear transformations preserve the shape of the distribution while changing location and scale."
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#practice-problem",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#practice-problem",
    "title": "Linear Transformation Properties",
    "section": "Practice Problem",
    "text": "Practice Problem\n\nTry This: A dataset has mean \\(\\bar{X} = 15\\) and variance \\(S_X^2 = 9\\).\nIf we transform the data using \\(y_i = 3x_i - 2\\), what are the new mean and variance?\n\n\n\n\n\n\nTip\n\n\nHint: This is not a pure linear transformation! You need \\(y_i = 3x_i - 2 = 3(x_i - \\frac{2}{3})\\)\n\n\n\n\nAnswer:\n\nNew mean: \\(\\bar{Y} = 3(15) - 2 = 43\\)\nNew variance: \\(S_Y^2 = 3^2 \\times 9 = 81\\)\n(The constant \\(-2\\) doesn‚Äôt affect variance!)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#common-mistakes-to-avoid",
    "title": "Linear Transformation Properties",
    "section": "Common Mistakes to Avoid",
    "text": "Common Mistakes to Avoid\n\n‚ùå Wrong: \\(S_Y^2 = a S_X^2\\)\n‚úÖ Correct: \\(S_Y^2 = a^2 S_X^2\\)\nWhy: Variance involves squared deviations, so the scaling factor gets squared too.\n‚ùå Wrong: Adding constants affects variance\n‚úÖ Correct: Only multiplication affects variance; addition only shifts the mean"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#conclusion",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#conclusion",
    "title": "Linear Transformation Properties",
    "section": "Conclusion",
    "text": "Conclusion\n\nWhat We Proved:\nFor the linear transformation \\(y_i = ax_i\\) with constant \\(a \\neq 0\\):\n\nSums scale linearly: Factor of \\(a\\)\nMeans scale linearly: Factor of \\(a\\)\n\nVariances scale quadratically: Factor of \\(a^2\\)\n\nKey Takeaway: Understanding these relationships is fundamental for:\n\nData transformations\nStatistical modeling\nUnit conversions\nStandardization procedures"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#questions",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#questions",
    "title": "Linear Transformation Properties",
    "section": "Questions?",
    "text": "Questions?\nKey Concepts Covered:\n\nSummation notation and indexing\nLinear transformations\nProperties of means and variances\nStep-by-step mathematical proofs\n\nNext Steps:\n\nApply to real datasets\nExplore non-linear transformations\nPractice with different scaling factors"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#additional-practice",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#additional-practice",
    "title": "Linear Transformation Properties",
    "section": "Additional Practice",
    "text": "Additional Practice\n\nExercise 1: If \\(X = \\{10, 20, 30, 40\\}\\) and \\(Y = \\{-5, -10, -15, -20\\}\\), what is the value of \\(a\\)?\nExercise 2: A dataset has \\(\\bar{X} = 50\\) and \\(S_X = 10\\). After transformation \\(y_i = 0.5x_i\\), find \\(\\bar{Y}\\) and \\(S_Y\\).\nExercise 3: Prove that if \\(y_i = ax_i + b\\) (adding a constant), then \\(S_Y^2 = a^2 S_X^2\\) (the constant doesn‚Äôt affect variance)."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#learning-objectives",
    "href": "files/lecture_notes/lecture3/lecture3.html#learning-objectives",
    "title": "Descriptive Statistics Part II",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture, you will be able to:\n\nCalculate and interpret measures of variability (range, variance, standard deviation)\nUnderstand and compute measures of position (percentiles, quartiles, z-scores)\nAssess distribution shape using skewness and kurtosis\nCreate and interpret histograms with appropriate bin widths\nConstruct and analyze boxplots for data exploration\nIdentify trends, patterns, and outliers in data visualizations\nApply Python for comprehensive descriptive analysis and visualization"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#lecture-outline",
    "href": "files/lecture_notes/lecture3/lecture3.html#lecture-outline",
    "title": "Descriptive Statistics Part II",
    "section": "Lecture Outline",
    "text": "Lecture Outline\n\n\nPart I: Measures of Variability (25 min)\n\nRange, Variance, Standard Deviation\nCoefficient of Variation\nPython Implementation\n\nPart II: Measures of Position (20 min)\n\nPercentiles and Quartiles\nZ-scores and Standardization\n\n\n\nPart III: Distribution Shape (10 min)\n\nSkewness and Kurtosis\n\nPart IV: Data Visualization (20 min)\n\nHistograms and Bin Width Selection\nBoxplots and Interpretation\n\nPart V: Identifying Patterns (5 min)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-is-variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-is-variability",
    "title": "Descriptive Statistics Part II",
    "section": "What is Variability?",
    "text": "What is Variability?\n\nüéØ Definition: Variability (or dispersion) measures how spread out or scattered the data points are around the center.\n\nWhy Variability Matters\n\nTwo datasets can have the same mean but very different spreads\nVariability indicates consistency and predictability\nEssential for risk assessment and quality control\nHelps determine confidence in our central tendency measures"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#range",
    "href": "files/lecture_notes/lecture3/lecture3.html#range",
    "title": "Descriptive Statistics Part II",
    "section": "Range",
    "text": "Range\n\nRange = Maximum value - Minimum value\n\nExample\nData: 12, 15, 18, 22, 25, 30, 35\n\nRange = 35 - 12 = 23"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#when-to-use-range",
    "href": "files/lecture_notes/lecture3/lecture3.html#when-to-use-range",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Range",
    "text": "When to Use Range\n‚úÖ Use range when:\n\nNeed a quick, simple measure of spread\nWorking with small datasets\nCommunicating to non-technical audiences\n\n‚ùå Avoid range when:\n\nOutliers are present\nNeed detailed information about variability\nWorking with large datasets"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#variance-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#variance-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Variance Definition",
    "text": "Variance Definition\n\nüéØ Definition: Variance measures the average squared deviation from the mean."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#recall",
    "href": "files/lecture_notes/lecture3/lecture3.html#recall",
    "title": "Descriptive Statistics Part II",
    "section": "Recall",
    "text": "Recall"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#side-by-side-comparison",
    "href": "files/lecture_notes/lecture3/lecture3.html#side-by-side-comparison",
    "title": "Descriptive Statistics Part II",
    "section": "Side-by-Side Comparison",
    "text": "Side-by-Side Comparison\n\n\n\nPopulation Variance\n\n\n\\[\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\]\n\n\\(\\sigma^2\\) = population variance\n\\(x_i\\) = value of \\(i^{th}\\) element\n\\(\\mu\\) = population mean\n\\(N\\) = population size\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\]\n\n\\(s^2\\) = sample variance\n\\(x_i\\) = value of \\(i^{th}\\) element\n\\(\\bar{x}\\) = sample mean\n\\(n\\) = sample size"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#key-differences",
    "href": "files/lecture_notes/lecture3/lecture3.html#key-differences",
    "title": "Descriptive Statistics Part II",
    "section": "Key Differences",
    "text": "Key Differences\n\nKey Difference: Sample variance uses \\((n-1)\\) instead of \\(N\\) in the denominator\n\nWhy \\((n-1)\\)?\n\nWhen we use sample mean \\(\\bar{x}\\) to estimate population mean \\(\\mu\\)\nWe lose one degree of freedom\nCalled Bessel‚Äôs correction\nMakes sample variance an unbiased estimator"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#when-to-use-each-formula",
    "href": "files/lecture_notes/lecture3/lecture3.html#when-to-use-each-formula",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Each Formula",
    "text": "When to Use Each Formula\n\nPopulation Variance (\\(\\sigma^2\\))\n\nYou have data for the entire population\nYou know the true population mean \\(\\mu\\)\nExample: Test scores for all students in a small class\n\n\n\nSample Variance (\\(s^2\\))\n\nYou have data from a sample only\nWant to estimate population variance\nExample: Survey responses from 100 people out of 10,000"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#understanding-degrees-of-freedom",
    "href": "files/lecture_notes/lecture3/lecture3.html#understanding-degrees-of-freedom",
    "title": "Descriptive Statistics Part II",
    "section": "Understanding Degrees of Freedom",
    "text": "Understanding Degrees of Freedom\n\n\nüìä Population Case\nAll observations are independent\n\nWe know the true population mean \\(\\mu\\)\nEach of the \\(N\\) observations provides independent information\nNo constraints on the data\n\n\n\\[\\text{Degrees of Freedom} = N\\]\n\n\n\nüìà Sample Case\nConstraint introduced by sample mean\n\nWe must estimate \\(\\mu\\) using \\(\\bar{x}\\)\nOnce we know \\(\\bar{x}\\) and \\((n-1)\\) observations, the last one is determined\nWe ‚Äúlose‚Äù one degree of freedom\n\n\n\\[\\text{Degrees of Freedom} = n-1\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#section",
    "href": "files/lecture_notes/lecture3/lecture3.html#section",
    "title": "Descriptive Statistics Part II",
    "section": "",
    "text": "Sample Mean Constraint\n\\[\\bar{x} = \\frac{x_1 + x_2 + \\cdots + x_n}{n}\\]\nRearranging: \\[x_n = n\\bar{x} - (x_1 + x_2 + \\cdots + x_{n-1})\\]\nOnce we know \\(\\bar{x}\\) and the first \\((n-1)\\) values, \\(x_n\\) is completely determined!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#example-calculation",
    "href": "files/lecture_notes/lecture3/lecture3.html#example-calculation",
    "title": "Descriptive Statistics Part II",
    "section": "Example Calculation",
    "text": "Example Calculation\nData: 3, 7, 2, 8, 5\nIf this is the entire population:\n\n\\(\\mu = \\frac{3+7+2+8+5}{5} = 5\\)\n\\(\\sigma^2 = \\frac{(3-5)^2+(7-5)^2+(2-5)^2+(8-5)^2+(5-5)^2}{5} = \\frac{22}{5} = 4.4\\)\n\nIf this is a sample:\n\n\\(\\bar{x} = 5\\) (same calculation)\n\\(s^2 = \\frac{22}{5-1} = \\frac{22}{4} = 5.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#variance-properties",
    "href": "files/lecture_notes/lecture3/lecture3.html#variance-properties",
    "title": "Descriptive Statistics Part II",
    "section": "Variance Properties",
    "text": "Variance Properties\nVariance measures:\n\nAverage squared deviation from the mean\nAlways non-negative: \\(\\sigma^2 \\geq 0\\), \\(s^2 \\geq 0\\)\nUnits: (original units)¬≤\n\nStandard Deviation:\n\n\\(\\sigma = \\sqrt{\\sigma^2}\\) (population)\n\\(s = \\sqrt{s^2}\\) (sample)\nSame units as original data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#bias-and-unbiasedness",
    "href": "files/lecture_notes/lecture3/lecture3.html#bias-and-unbiasedness",
    "title": "Descriptive Statistics Part II",
    "section": "Bias and Unbiasedness",
    "text": "Bias and Unbiasedness\nPopulation variance:\n\nTrue parameter value\nNo estimation involved\n\nSample variance with \\((n-1)\\):\n\n\\(E[s^2] = \\sigma^2\\) (unbiased)\nOn average, equals population variance\n\nSample variance with \\(n\\):\n\n\\(E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n}\\right] = \\frac{n-1}{n}\\sigma^2\\) (biased)\nSystematically underestimates population variance"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#implementation",
    "href": "files/lecture_notes/lecture3/lecture3.html#implementation",
    "title": "Descriptive Statistics Part II",
    "section": "Implementation",
    "text": "Implementation\nCalculators:\n\nMost use \\((n-1)\\) by default for sample standard deviation\nCheck your calculator‚Äôs documentation\n\nSoftware:\n\nR: var() uses \\((n-1)\\), sd() uses \\((n-1)\\)\nExcel: VAR.S() uses \\((n-1)\\), VAR.P() uses \\(n\\)\nPython: np.var(ddof=1) uses \\((n-1)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practice-problem",
    "href": "files/lecture_notes/lecture3/lecture3.html#practice-problem",
    "title": "Descriptive Statistics Part II",
    "section": "Practice Problem",
    "text": "Practice Problem\nDataset: Number of hours studied by 6 students: 2, 4, 3, 5, 6, 4\nCalculate both:\n\nPopulation variance (assuming this is the entire population)\nSample variance (assuming this is a sample)\n\n\nSolution:\n\nMean: \\(\\bar{x} = \\frac{24}{6} = 4\\)\nPopulation variance: \\(\\sigma^2 = \\frac{10}{6} = 1.67\\)\nSample variance: \\(s^2 = \\frac{10}{5} = 2.0\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#summary",
    "href": "files/lecture_notes/lecture3/lecture3.html#summary",
    "title": "Descriptive Statistics Part II",
    "section": "Summary",
    "text": "Summary\n\nKey Takeaways\n\nPopulation variance uses \\(N\\) (entire population)\nSample variance uses \\((n-1)\\) (Bessel‚Äôs correction)\nSample variance is unbiased estimator of population variance\nDifference matters more for small samples\nAlways check which formula your software uses!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#example-1",
    "href": "files/lecture_notes/lecture3/lecture3.html#example-1",
    "title": "Descriptive Statistics Part II",
    "section": "Example",
    "text": "Example\n\n\nüìä Complete Population Data (Test Scores)\nWe have test scores from 100 students arranged in a grid:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nM\nN\nO\nP\nQ\nR\nS\nT\n\n\n\n\n1\n24\n96\n30\n69\n85\n60\n55\n18\n30\n66\n64\n99\n92\n95\n84\n55\n72\n38\n86\n32\n\n\n2\n53\n81\n30\n89\n42\n94\n31\n26\n53\n78\n38\n60\n93\n90\n82\n85\n89\n54\n30\n58\n\n\n3\n62\n67\n75\n47\n99\n25\n32\n63\n49\n45\n30\n97\n57\n32\n37\n62\n33\n16\n11\n41\n\n\n4\n95\n74\n28\n73\n82\n97\n65\n88\n56\n95\n85\n44\n70\n65\n34\n85\n58\n15\n64\n84\n\n\n5\n76\n46\n83\n56\n98\n16\n76\n77\n35\n19\n97\n42\n90\n79\n73\n28\n82\n92\n90\n22\n\n\n\n\n\n\nüéØ Random Sample Selection\nWe randomly select 5 scores from different positions in our population:\nOur Sample: 82, 95, 83, 60, 92"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#final-calculations",
    "href": "files/lecture_notes/lecture3/lecture3.html#final-calculations",
    "title": "Descriptive Statistics Part II",
    "section": "Final Calculations",
    "text": "Final Calculations\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum(x_i - \\bar{x})^2}{n-1}\\] \\[s^2 = \\frac{753.2}{5-1} = \\frac{753.2}{4} = 188.3\\]\n\n\n\n\nSample Standard Deviation\n\n\n\\[s = \\sqrt{s^2}\\] \\[s = \\sqrt{188.3} = 13.72\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#properties-of-standard-deviation",
    "href": "files/lecture_notes/lecture3/lecture3.html#properties-of-standard-deviation",
    "title": "Descriptive Statistics Part II",
    "section": "Properties of Standard Deviation",
    "text": "Properties of Standard Deviation\n\nSame units as the original data\nAlways non-negative\nZero only when all values are identical\nLarger values indicate more variability\nApproximately 68% of data within 1 SD of mean (for normal distributions)\nApproximately 95% of data within 2 SD of mean"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#empirical-rule-68-95-99.7-rule",
    "href": "files/lecture_notes/lecture3/lecture3.html#empirical-rule-68-95-99.7-rule",
    "title": "Descriptive Statistics Part II",
    "section": "Empirical Rule (68-95-99.7 Rule)",
    "text": "Empirical Rule (68-95-99.7 Rule)\nFor approximately normal distributions:\n\n68% of data falls within 1 standard deviation of the mean\n95% of data falls within 2 standard deviations of the mean\n99.7% of data falls within 3 standard deviations of the mean\n\nThis rule helps us understand what constitutes ‚Äútypical‚Äù vs ‚Äúunusual‚Äù values."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#definition-and-purpose",
    "href": "files/lecture_notes/lecture3/lecture3.html#definition-and-purpose",
    "title": "Descriptive Statistics Part II",
    "section": "Definition and Purpose",
    "text": "Definition and Purpose\n\nüéØ Definition: Coefficient of Variation (CV) = \\(\\frac{\\text{Standard Deviation}}{\\text{Mean}} \\times 100\\%\\)\n\n\nWhy Use CV?\n\nCompares variability across different units or scales\nRelative measure of variability\nUseful when means differ substantially"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-implementation---variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-implementation---variability",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Variability",
    "text": "Python Implementation - Variability\n\nCodeVisualization\n\n\n\nimport numpy as np\nimport pandas as pd\n\n# Sample data\ndata = [10, 12, 14, 16, 18, 22, 25]\n\n# Calculate measures of variability\nrange_val = np.max(data) - np.min(data)\nvariance_sample = np.var(data, ddof=1)  # Sample variance\nstd_sample = np.std(data, ddof=1)       # Sample standard deviation\ncv = (std_sample / np.mean(data)) * 100\n\nprint(f\"Range: {range_val}\")\nprint(f\"Variance: {variance_sample:.2f}\")\nprint(f\"Standard Deviation: {std_sample:.2f}\")\nprint(f\"Coefficient of Variation: {cv:.1f}%\")\n\nRange: 15\nVariance: 28.90\nStandard Deviation: 5.38\nCoefficient of Variation: 32.2%"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-are-measures-of-position",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-are-measures-of-position",
    "title": "Descriptive Statistics Part II",
    "section": "What are Measures of Position?",
    "text": "What are Measures of Position?\n\n\nMeasures of position tell us where a particular value stands relative to the rest of the data.\nThey answer questions like:\n\n‚ÄúWhat percentage of students scored below 85?‚Äù\n‚ÄúIs this value typical or unusual?‚Äù\n‚ÄúHow does this observation compare to others?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#percentiles-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#percentiles-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Percentiles Definition",
    "text": "Percentiles Definition\nThe k-th percentile is the value below which k% of the data falls.\nExamples:\n\n50th percentile = Median (50% of data below this value)\n90th percentile = 90% of data falls below this value\n25th percentile = 25% of data falls below this value"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#quartiles",
    "href": "files/lecture_notes/lecture3/lecture3.html#quartiles",
    "title": "Descriptive Statistics Part II",
    "section": "Quartiles",
    "text": "Quartiles\nQuartiles divide the data into four equal parts:\n\nQ1 (First Quartile) = 25th percentile\nQ2 (Second Quartile) = 50th percentile = Median\nQ3 (Third Quartile) = 75th percentile"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#interquartile-range-iqr",
    "href": "files/lecture_notes/lecture3/lecture3.html#interquartile-range-iqr",
    "title": "Descriptive Statistics Part II",
    "section": "Interquartile Range (IQR)",
    "text": "Interquartile Range (IQR)\nIQR = Q3 - Q1\n\n\n\n\nProperties of IQR:\n\nContains the middle 50% of the data\nResistant to outliers\nUsed in boxplot construction\nUseful for outlier detection"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#z-score-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#z-score-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Z-score Definition",
    "text": "Z-score Definition\n\n\n\nüéØ Definition\nZ-score tells us how many standard deviations a value is from the mean.\n\n\n\\[z = \\frac{x - \\mu}{\\sigma} \\text{ or } z = \\frac{x - \\bar{x}}{s}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#z-score-example",
    "href": "files/lecture_notes/lecture3/lecture3.html#z-score-example",
    "title": "Descriptive Statistics Part II",
    "section": "Z-score Example",
    "text": "Z-score Example\nStudent‚Äôs test score: 85 Class mean: 78, Class standard deviation: 6\n\n\\[z = \\frac{85 - 78}{6} = \\frac{7}{6} = 1.17\\]\n\nInterpretation: This student scored 1.17 standard deviations above the class average."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#benefits-of-standardization",
    "href": "files/lecture_notes/lecture3/lecture3.html#benefits-of-standardization",
    "title": "Descriptive Statistics Part II",
    "section": "Benefits of Standardization",
    "text": "Benefits of Standardization\n\nCompare across different scales (test scores vs income)\nIdentify outliers systematically\n\nCombine different variables meaningfully\nPrepare data for certain statistical methods"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#skewness",
    "href": "files/lecture_notes/lecture3/lecture3.html#skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Skewness",
    "text": "Skewness\nSkewness measures the asymmetry of a distribution.\nTypes of Skewness:\n\n\n\n\nSymmetric (Skewness ‚âà 0): Mean ‚âà Median ‚âà Mode\nRight-skewed (Positive skewness): Mean &gt; Median, long tail to the right\nLeft-skewed (Negative skewness): Mean &lt; Median, long tail to the left"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#examples-of-skewness",
    "href": "files/lecture_notes/lecture3/lecture3.html#examples-of-skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Examples of Skewness",
    "text": "Examples of Skewness\nRight-skewed (Income data):\n\nMost people earn moderate amounts\nFew people earn very high amounts\nMean &gt; Median\n\nLeft-skewed (Test scores with ceiling effect):\n\nMost students score high\nFew students score very low\nMean &lt; Median"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#kurtosis",
    "href": "files/lecture_notes/lecture3/lecture3.html#kurtosis",
    "title": "Descriptive Statistics Part II",
    "section": "Kurtosis",
    "text": "Kurtosis\nKurtosis measures the ‚Äútailedness‚Äù of a distribution. It measures the degree of peaked Ness or flatness of a distribution compared to the normal distribution.\nTypes:\n\nMesokurtic (Normal-like): Kurtosis ‚âà 3\nLeptokurtic (Heavy tails): Kurtosis &gt; 3, more peaked\nPlatykurtic (Light tails): Kurtosis &lt; 3, flatter\n\nExcess Kurtosis = Kurtosis - 3 (makes normal distributions have excess kurtosis of 0)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-implementation---position-shape",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-implementation---position-shape",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Position & Shape",
    "text": "Python Implementation - Position & Shape\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndata = [12, 15, 18, 22, 25, 28, 30, 35, 40, 45]\n\n# Percentiles and quartiles\nq1 = np.percentile(data, 25)\nmedian = np.percentile(data, 50)\nq3 = np.percentile(data, 75)\niqr = q3 - q1\n\n# Z-scores\nz_scores = stats.zscore(data)\n\n# Shape measures\nskewness = stats.skew(data)\nkurt = stats.kurtosis(data)\n\nprint(f\"Q1: {q1}, Median: {median}, Q3: {q3}\")\nprint(f\"IQR: {iqr}\")\nprint(f\"Skewness: {skewness:.3f}\")\nprint(f\"Kurtosis: {kurt:.3f}\")\n\nQ1: 19.0, Median: 26.5, Q3: 33.75\nIQR: 14.75\nSkewness: 0.243\nKurtosis: -1.023"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-is-a-histogram",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-is-a-histogram",
    "title": "Descriptive Statistics Part II",
    "section": "What is a Histogram?",
    "text": "What is a Histogram?\nA histogram displays the distribution of a continuous variable by dividing data into bins and showing the frequency of observations in each bin.\nKey Components:\n\nX-axis: Variable values (continuous)\nY-axis: Frequency or density\nBins: Intervals that group the data\nBars: Height represents frequency in each bin"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#choosing-bin-width-critical-decision",
    "href": "files/lecture_notes/lecture3/lecture3.html#choosing-bin-width-critical-decision",
    "title": "Descriptive Statistics Part II",
    "section": "Choosing Bin Width: Critical Decision",
    "text": "Choosing Bin Width: Critical Decision\nBin width dramatically affects histogram interpretation!\nToo Few Bins (Wide bins):\n\nOversmoothing - lose important details\nMay hide multimodality\nDistribution appears simpler than it is\n\nToo Many Bins (Narrow bins):\n\nUndersmoothing - too much noise\nMay create artificial gaps\nHard to see overall pattern"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#bin-width-guidelines",
    "href": "files/lecture_notes/lecture3/lecture3.html#bin-width-guidelines",
    "title": "Descriptive Statistics Part II",
    "section": "Bin Width Guidelines",
    "text": "Bin Width Guidelines\nRule of Thumb Methods:\n\nSquare Root Rule: Number of bins ‚âà \\(\\sqrt{n}\\)\nSturges‚Äô Rule: Number of bins = \\(1 + \\log_2(n)\\)\nScott‚Äôs Rule: Bin width = \\(\\frac{3.5 \\times \\text{SD}}{n^{1/3}}\\)\nFreedman-Diaconis Rule: Bin width = \\(\\frac{2 \\times \\text{IQR}}{n^{1/3}}\\)\n\nBest practice: Try multiple bin widths and choose based on the story your data tells!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-histogram-examples",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-histogram-examples",
    "title": "Descriptive Statistics Part II",
    "section": "Python Histogram Examples",
    "text": "Python Histogram Examples\n\nCodeVisualization\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate sample data\nnp.random.seed(42)\ndata = np.random.normal(100, 15, 1000)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#interpreting-histograms",
    "href": "files/lecture_notes/lecture3/lecture3.html#interpreting-histograms",
    "title": "Descriptive Statistics Part II",
    "section": "Interpreting Histograms",
    "text": "Interpreting Histograms\nWhat to Look For:\n\nShape: Normal, skewed, uniform, bimodal?\nCenter: Where is the ‚Äútypical‚Äù value?\nSpread: How variable is the data?\nOutliers: Any unusual values?\nGaps: Are there missing values in certain ranges?\nMultiple peaks: Suggests multiple subgroups"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#anatomy-of-a-boxplot",
    "href": "files/lecture_notes/lecture3/lecture3.html#anatomy-of-a-boxplot",
    "title": "Descriptive Statistics Part II",
    "section": "Anatomy of a Boxplot",
    "text": "Anatomy of a Boxplot"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#boxplot-components-explained",
    "href": "files/lecture_notes/lecture3/lecture3.html#boxplot-components-explained",
    "title": "Descriptive Statistics Part II",
    "section": "Boxplot Components Explained",
    "text": "Boxplot Components Explained\nThe Box:\n\nLeft edge: Q1 (25th percentile)\nMiddle line: Median (Q2, 50th percentile)\n\nRight edge: Q3 (75th percentile)\nBox width: IQR (contains middle 50% of data)\n\nThe Whiskers:\n\nExtend to: Most extreme values within 1.5 √ó IQR from box edges\nLower whisker: Minimum value within Q1 - 1.5√óIQR\nUpper whisker: Maximum value within Q3 + 1.5√óIQR"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-boxplots-tell-us",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-boxplots-tell-us",
    "title": "Descriptive Statistics Part II",
    "section": "What Boxplots Tell Us",
    "text": "What Boxplots Tell Us\nDistribution Shape:\n\nSymmetric: Median in center of box, whiskers equal length\nRight-skewed: Median closer to Q1, longer upper whisker\nLeft-skewed: Median closer to Q3, longer lower whisker\n\nVariability:\n\nWide box: High variability in middle 50%\nLong whiskers: High overall variability\nMany outliers: Extreme variability"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#comparing-groups-with-boxplots",
    "href": "files/lecture_notes/lecture3/lecture3.html#comparing-groups-with-boxplots",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Groups with Boxplots",
    "text": "Comparing Groups with Boxplots"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#advanced-boxplot-interpretations",
    "href": "files/lecture_notes/lecture3/lecture3.html#advanced-boxplot-interpretations",
    "title": "Descriptive Statistics Part II",
    "section": "Advanced Boxplot Interpretations",
    "text": "Advanced Boxplot Interpretations"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#comparing-boxplots",
    "href": "files/lecture_notes/lecture3/lecture3.html#comparing-boxplots",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Boxplots:",
    "text": "Comparing Boxplots:\n\nMedian differences: Which group has higher typical values?\nIQR differences: Which group is more consistent?\nOutlier patterns: Which group has more extreme values?\nOverlap: Do the groups have similar ranges?"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#business-applications",
    "href": "files/lecture_notes/lecture3/lecture3.html#business-applications",
    "title": "Descriptive Statistics Part II",
    "section": "Business Applications:",
    "text": "Business Applications:\n\nQuality control: Compare product batches\nPerformance analysis: Compare team/department performance\n\nCustomer segmentation: Compare customer groups"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#common-patterns-in-data",
    "href": "files/lecture_notes/lecture3/lecture3.html#common-patterns-in-data",
    "title": "Descriptive Statistics Part II",
    "section": "Common Patterns in Data",
    "text": "Common Patterns in Data\nDistribution Patterns:\n\nNormal/Bell-shaped: Symmetric, single peak\nUniform: All values equally likely\nBimodal: Two distinct peaks (suggests subgroups)\nMultimodal: Multiple peaks\nU-shaped: High values at extremes, low in middle\n\nOutlier Patterns:\n\nIndividual outliers: Data entry errors, measurement errors\nClustered outliers: Distinct subpopulation\nSystematic outliers: May indicate process changes"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#red-flags-in-data-visualization",
    "href": "files/lecture_notes/lecture3/lecture3.html#red-flags-in-data-visualization",
    "title": "Descriptive Statistics Part II",
    "section": "Red Flags in Data Visualization",
    "text": "Red Flags in Data Visualization\nWarning Signs:\n\nGaps in histograms: Missing data or measurement limitations\nHeaping: Values cluster at round numbers (10, 50, 100)\nTruncation: Data cut off at certain values\nDigit preference: People prefer certain ending digits\nMultiple modes: Hidden subgroups in your data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#essential-concepts-to-remember",
    "href": "files/lecture_notes/lecture3/lecture3.html#essential-concepts-to-remember",
    "title": "Descriptive Statistics Part II",
    "section": "Essential Concepts to Remember",
    "text": "Essential Concepts to Remember\nVariability:\n\nStandard deviation is preferred over range for most analyses\nCV allows comparison across different scales\nIQR is resistant to outliers\n\nPosition:\n\nPercentiles and quartiles provide relative position\nZ-scores standardize across different distributions\nFive-number summary gives complete overview"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practical-guidelines",
    "href": "files/lecture_notes/lecture3/lecture3.html#practical-guidelines",
    "title": "Descriptive Statistics Part II",
    "section": "Practical Guidelines",
    "text": "Practical Guidelines\n\nAlways visualize before calculating statistics\nUse multiple measures - no single statistic tells the whole story\nConsider the context - what makes sense for your data?\nCheck for outliers - they can drastically affect your analysis\nCompare distributions using standardized measures when appropriate"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#try-these-exercises",
    "href": "files/lecture_notes/lecture3/lecture3.html#try-these-exercises",
    "title": "Descriptive Statistics Part II",
    "section": "Try These Exercises",
    "text": "Try These Exercises\n\nCalculate the five-number summary for: 12, 15, 18, 22, 25, 28, 30, 35, 40, 45\nCreate histograms with 5, 15, and 50 bins for the same dataset. What patterns do you observe?\nInterpret this scenario: Dataset A has mean=50, SD=5. Dataset B has mean=100, SD=10. Which is more variable?\nA student scores 85 on a test where the class mean is 78 and SD is 6. Calculate and interpret the z-score.\nDesign a boxplot comparison for three different customer segments in your business."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#additional-resources",
    "href": "files/lecture_notes/lecture3/lecture3.html#additional-resources",
    "title": "Descriptive Statistics Part II",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nMatplotlib Gallery: Histogram and Boxplot Examples\nExplore examples of histograms, boxplots, and other visualizations using Matplotlib.\nSeaborn Documentation: Statistical Visualizations\nFind examples and documentation for statistical visualizations, including distribution plots, categorical plots, and regression plots.\nNumPy Statistical Functions Reference\nOfficial reference for NumPy‚Äôs statistical functions such as mean, median, variance, and standard deviation.\nSciPy Statistical Functions Reference\nComprehensive documentation for statistical functions in scipy.stats, including probability distributions, hypothesis tests, and descriptive statistics.\nRecommended reading: Continue reading Chapter 2 in course textbook"
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#basic-probability",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#basic-probability",
    "title": "PSTAT 5A: Review Exercises",
    "section": "1. Basic Probability",
    "text": "1. Basic Probability\n\nA single fair six-sided die is rolled once.\n1.1 What is \\(P(\\text{roll is an even number})\\)?\n1.2 What is \\(P(\\text{roll is 5 or 6})\\)?"
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#basic-probability-answers",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#basic-probability-answers",
    "title": "PSTAT 5A: Review Exercises",
    "section": "1. Basic Probability: Answers",
    "text": "1. Basic Probability: Answers\n1.1. \\(P(\\text{even}) = 3/6 = \\tfrac{1}{2}\\)\n1.2. \\(P(5 \\text{ or } 6) = 2/6 = \\tfrac{1}{3}\\)"
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#joint-conditional-probability",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#joint-conditional-probability",
    "title": "PSTAT 5A: Review Exercises",
    "section": "2. Joint & Conditional Probability",
    "text": "2. Joint & Conditional Probability\n\nYou draw two cards without replacement from a standard 52-card deck.\n2.1. What is the probability that the first card is an Ace?\n2.2. Given that the first card is an Ace, what is the probability that the second card is also an Ace?\n2.3. Compute \\(P(\\text{both cards are Aces})\\):\n\nas a direct joint probability.\nusing conditional probability formula."
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#joint-conditional-probability-answers",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#joint-conditional-probability-answers",
    "title": "PSTAT 5A: Review Exercises",
    "section": "2. Joint & Conditional Probability: Answers",
    "text": "2. Joint & Conditional Probability: Answers\n\nSolution. 2.1. \\(4/52 = \\tfrac{1}{13}\\)\n2.2. \\(3/51 = \\tfrac{1}{17}\\)\n2.3.\n\n\\(4/52 \\times 3/51 = 1/221\\)\n\\((1/13)\\times(1/17) = 1/221\\)"
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#independence-vs.-mutual-exclusivity",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#independence-vs.-mutual-exclusivity",
    "title": "PSTAT 5A: Review Exercises",
    "section": "3. Independence vs.¬†Mutual Exclusivity",
    "text": "3. Independence vs.¬†Mutual Exclusivity\n\nFlip two fair coins in sequence. Define:\n\n\\(A =\\) first flip is Heads\n\n\\(B =\\) second flip is Heads\n\n\\(C =\\) both flips are Heads\n\n3.1 Are events \\(A\\) and \\(B\\) independent?\n3.2 Are events \\(A\\) and \\(C\\) mutually exclusive?\n3.3 Compute \\(P(A\\cap B)\\) and compare with \\(P(A)P(B)\\)."
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#independence-vs.-mutual-exclusivity-answers",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#independence-vs.-mutual-exclusivity-answers",
    "title": "PSTAT 5A: Review Exercises",
    "section": "3. Independence vs.¬†Mutual Exclusivity: Answers",
    "text": "3. Independence vs.¬†Mutual Exclusivity: Answers\n\nSolution. \n\nYes, independent: \\(P(B|A)=1/2 = P(B)\\)\nNo, not mutually exclusive: \\(A\\cap C \\neq \\varnothing\\).\n\n\\(P(A\\cap B)=1/4, \\;P(A)P(B)=1/4\\) ‚Üí matches (independence)."
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#bonus-challenge",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#bonus-challenge",
    "title": "PSTAT 5A: Review Exercises",
    "section": "4. Bonus Challenge",
    "text": "4. Bonus Challenge\n\nA bag contains 3 red balls and 2 blue balls. You draw one ball, replace it, then draw again.\n4.1 Are the two draws independent? Why or why not?\n4.2 Compute \\(P(\\text{red then blue})\\)."
  },
  {
    "objectID": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#bonus-challenge-answers",
    "href": "files/lecture_notes/review/Quiz1/q1_review_exercise.html#bonus-challenge-answers",
    "title": "PSTAT 5A: Review Exercises",
    "section": "4. Bonus Challenge: Answers",
    "text": "4. Bonus Challenge: Answers\n\nYes‚Äîthey‚Äôre independent because of replacement.\n\n\\((3/5)\\times(2/5) = 6/25\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#welcome-to-lecture-7-part-2",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#welcome-to-lecture-7-part-2",
    "title": "PSTAT 5A: Counting",
    "section": "Welcome to Lecture 7 (Part 2)",
    "text": "Welcome to Lecture 7 (Part 2)\nThe art and science of systematic enumeration"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#learning-objectives",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#learning-objectives",
    "title": "PSTAT 5A: Counting",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\n\n\n\n\n\n\n\nLearning Objectives\n\n\nBy the end of this lecture, you will be able to:\n\nCalculate combinations and understand when to use them (Section¬†3, Section¬†4)\nDistinguish between permutations and combinations (Section¬†7)\nUse counting techniques to solve probability problems (Section¬†12)\nApply the inclusion-exclusion principle (Section¬†17)\nSolve complex counting problems systematically (Section¬†21)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#sec-combinations",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#sec-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Combinations?",
    "text": "What Are Combinations?\n\n\n\n\n\n\n\n\n\nCombination\n\n\nA selection of objects where order does NOT matter\n\n\n\n\n\nCommittee Selection:\nABC, BAC, CAB ‚Üí Same committee!\nRace Results:\nABC, BAC, CAB ‚Üí Different outcomes!\n\n\n\n\n\n\nNote\n\n\nKey Point: Order doesn‚Äôt matter for combinations\n\n\n\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nAll combinations of 4 items taken 2 at a time:\n1. A, B\n2. A, C\n3. A, D\n4. B, C\n5. B, D\n6. C, D\n\n\n\n\nMore Examples: - Choosing committee members - Selecting pizza toppings - Forming study groups - Lottery number selection"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#sec-combinations-formula",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#sec-combinations-formula",
    "title": "PSTAT 5A: Counting",
    "section": "Combinations Formula",
    "text": "Combinations Formula\n\n\n\n\n\n\n\nKey Formula\n\n\n\\(C(n,r)\\) or \\(\\binom{n}{r}\\): Number of ways to choose \\(r\\) objects from \\(n\\) distinct objects (order doesn‚Äôt matter)\n\\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]\n\\(\\binom{n}{r}\\) reads ‚Äú\\(n\\) choose \\(r\\)‚Äù\n\n\n\n\n\nHow many ways can we choose 3 people from a group of 8 for a committee?\n\nSolution. \\(C(8,3) = \\frac{8!}{3!(8-3)!} = \\frac{8!}{3! \\times 5!} = \\frac{8 \\times 7 \\times 6}{3 \\times 2 \\times 1} = 56\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#permutations-vs-combinations",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#permutations-vs-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations vs Combinations",
    "text": "Permutations vs Combinations\n\n\n\n\n\n\n\n\n\nRelationship\n\n\n\n\\(P(n,r) = \\frac{n!}{(n-r)!} \\quad (1)\\)\n\nand,\n\n\\(C(n,r) = \\frac{n!}{(n-r)!} \\quad (2)\\)\n\nPlugging (2) into (1) and multiplying by \\(r\\) which represents the number of arrangements we get :\n\\(P(n,r) = C(n,r) \\times r!\\) (multiply by arrangements)\nWhy? For each combination of \\(r\\) objects, there are \\(r!\\) ways to arrange them\nSimilarly,\n\\(C(n,r) = P(n,r)/ r!\\) (divide out arrangements)\nWhy? diving by \\(r\\) removes the arrangements from our formula and leaves us with the number of selection possible from \\(n\\) objects.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nPermutations = Combinations √ó Arrangements\nCombinations answer: ‚ÄúHow many ways can I choose?‚Äù\nArrangements answer: ‚ÄúHow many ways can I order what I chose?‚Äù*\nPermutations answer: ‚ÄúHow many ways can I choose AND order?‚Äù\n\n\\(\\text{Choose} \\times \\text{Arrange} = \\text{Choose and Arrange}\\)\n\\[\n\\underbrace{\\binom{n}{r}}{\\substack{\\text{choose which}\\\\r\\text{ elements}}}\n\\;\\times\\;\n\\underbrace{r!}{\\substack{\\text{order those}\\\\r\\text{ elements}}}\n\\;=\\;\n\\frac{n!}{r!(n-r)!}\\;\\times\\;r!\n\\;=\\;\n\\frac{n!}{(n-r)!}\n\\;=\\;\nP(n,r).\n\\]\nThus,\n\\(C(n,r)√ór!= P(n,r)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#permutations-vs-combinations-example",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#permutations-vs-combinations-example",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations vs Combinations Example",
    "text": "Permutations vs Combinations Example\n\nSelect 3 people from a group of 5 for different purposes.\n\nFor a ranked competition (order matters):\n1st place, 2nd place, 3rd place matter\nUse permutations: \\(P(5,3) = \\frac{5!}{(5-3)!} = \\frac{5!}{2!} = \\frac{120}{2} = 60\\) ways\nFor a committee (order doesn‚Äôt matter):\nJust need 3 people, no specific roles\nUse combinations: \\(C(5,3) = \\frac{5!}{3!(5-3)!} = \\frac{5!}{3! \\cdot 2!} = \\frac{120}{6 \\cdot 2} = 10\\) ways\n\nVerifying the relationship:\n\\(P(5,3)=C(5,3)√ó3!\\)\n\\(60=10 \\times 6‚Äâ\\checkmark\\)\nFor each of the 10 combinations, there are \\(3! = 6\\) ways to arrange them, giving us the 60 permutations."
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#sec-permutation-vs-combination",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#sec-permutation-vs-combination",
    "title": "PSTAT 5A: Counting",
    "section": "Key Decision: Permutation or Combination?",
    "text": "Key Decision: Permutation or Combination?\n\n\n\n\n\n\n\n\n\nHow to Decide\n\n\nAsk yourself: Does order matter?\nOrder matters ‚Üí Use Permutations\n\nArrangements, sequences, rankings\n\nOrder doesn‚Äôt matter ‚Üí Use Combinations\n\nSelections, groups, subsets\n\n\n\n\n\n\n\n\nNote\n\n\n‚úÖ \\(P(n,r)\\) = counts both selection & arrangement ‚Üí grows faster\n‚úÖ \\(C(n,r)\\) = counts only selection ‚Üí grows slower\n‚úÖ The difference comes from \\(r!\\), which is big even for modest \\(r\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#practice-3",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#practice-3",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nFrom a class of 20 students:\n\nHow many ways to choose 5 students for a study group?\nHow many ways to choose a president, vice-president, and secretary?\n\n\n\nSolution. \n\n\\(C(20,5) = \\frac{20!}{5! \\times 15!} = 15,504\\) (order doesn‚Äôt matter)\n\\(P(20,3) = \\frac{20!}{17!} = 6,840\\) (order matters)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#properties-of-combinations",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#properties-of-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "Properties of Combinations",
    "text": "Properties of Combinations\n\n\n\n\n\n\n\nProperties\n\n\n\nSymmetry: \\(\\binom{n}{r} = \\binom{n}{n-r}\\)\nPascal‚Äôs Identity: \\(\\binom{n}{r} = \\binom{n-1}{r-1} + \\binom{n-1}{r}\\)\nBoundary conditions: \\(\\binom{n}{0} = \\binom{n}{n} = 1\\)\n\n\n\n\n\n\n\\(\\binom{8}{3} = \\binom{8}{5} = 56\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#pascals-triangle",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#pascals-triangle",
    "title": "PSTAT 5A: Counting",
    "section": "Pascal‚Äôs Triangle",
    "text": "Pascal‚Äôs Triangle\n\n\n\n\n\n\n\n\n\n\nPascal‚Äôs Triangle\n\n\n       1                    ‚Üê (x + y)‚Å∞\n     1   1                  ‚Üê (x + y)¬π\n   1   2   1                ‚Üê (x + y)¬≤\n 1   3   3   1              ‚Üê (x + y)¬≥\n1   4   6   4   1           ‚Üê (x + y)‚Å¥\n1  5  10  10  5  1          ‚Üê (x + y)‚Åµ\nEach number equals \\(\\binom{n}{r}\\) where \\(n\\) is the row number and \\(r\\) is the position from the left (starting at 0).\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nPattern: Each number is the sum of the two numbers above it.\nFormula: \\(\\binom{n}{r} = \\binom{n-1}{r-1} + \\binom{n-1}{r}\\)\nExample: \\(\\binom{4}{2} = 6\\) (row 4, position 2)\n\n\n\n\n\nRow 3:       1   3   3   1\n            ‚Üô ‚Üò ‚Üô ‚Üò ‚Üô ‚Üò ‚Üô ‚Üò\nRow 4:     1   4   6   4   1"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#binomial-theorem",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#binomial-theorem",
    "title": "PSTAT 5A: Counting",
    "section": "Binomial Theorem",
    "text": "Binomial Theorem\n\n\n\n\n\n\n\n\n\nKey Formula\n\n\n\\[(x + y)^n = \\sum_{r=0}^{n} \\binom{n}{r} x^{n-r} y^r\\]\nThis formula tells us how to expand \\((x + y)\\) raised to any positive integer power \\(n\\).\n\n\n\n\n\nEXAMPLE\n\\((x + y)^3 = \\binom{3}{0}x^3 + \\binom{3}{1}x^2y + \\binom{3}{2}xy^2 + \\binom{3}{3}y^3\\)\n\\(= x^3 + 3x^2y + 3xy^2 + y^3\\)\n\n\n\n\n\n\n\n\n\nKey Insights\n\n\nThe General Pattern\nPowers decrease and increase systematically:\n\nPowers of \\(x\\): \\(n, n-1, n-2, \\ldots, 1, 0\\)\nPowers of \\(y\\): \\(0, 1, 2, \\ldots, n-1, n\\)\nSum of powers in each term: always equals \\(n\\)\n\nCoefficients come from Pascal‚Äôs Triangle:\n\nCoefficient of \\(x^{n-r}y^r\\) is \\(\\binom{n}{r}\\)\nRead directly from row \\(n\\) of Pascal‚Äôs Triangle\n\nSymmetry in coefficients:\nFirst and last terms have coefficient 1 Coefficients are symmetric: \\(\\binom{n}{0} = \\binom{n}{n}\\), \\(\\binom{n}{1} = \\binom{n}{n-1}\\), etc."
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#sec-counting-probability",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#sec-counting-probability",
    "title": "PSTAT 5A: Counting",
    "section": "Counting and Probability",
    "text": "Counting and Probability\n\n\n\nA committee of 4 people is chosen from 7 women and 5 men. What‚Äôs the probability that exactly 2 are women?\n\nTotal ways to choose 4 from 12: \\(\\binom{12}{4} = 495\\)\nWays to choose 2 women from 7: \\(\\binom{7}{2} = 21\\)\nWays to choose 2 men from 5: \\(\\binom{5}{2} = 10\\)\n\n\n\nSolution. Favorable outcomes: \\(\\binom{7}{2} \\times \\binom{5}{2} = 21 \\times 10 = 210\\)\nProbability: \\(\\frac{210}{495} = \\frac{14}{33}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#practice-4",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#practice-4",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\n\n\n\nA standard deck has 52 cards. What‚Äôs the probability that a 5-card hand contains:\n\nExactly 3 aces? \\(P(\\text{exactly 3 aces in 5 cards})\\)\n\n\n\nAt least 1 ace? \\(P(\\text{at least one ace})\\)\n\n\n\n\n\nSolution. \n\nWays to pick 5 cards with zero aces All 5 come from the 48 non-aces: \\[\\binom{48}{5}\n= \\frac{48\\cdot47\\cdot46\\cdot45\\cdot44}{5\\cdot4\\cdot3\\cdot2\\cdot1}\n= \\frac{205{,}476{,}480}{120}\n= 1{,}712{,}304\\]\nProbability of no aces \\[\nP(\\text{no aces})\n= \\frac{\\binom{48}{5}}{\\binom{52}{5}}\n= \\frac{1{,}712{,}304}{2{,}598{,}960}\n\\approx 0.659 \\quad \\text{or} 65.9 \\% \\]\nSubtract from 1 \\[P(\\text{at least one ace})\n= 1 - P(\\text{no aces})\n= 1 - 0.659\n\\approx 0.341\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#practice-problem-4-continued",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#practice-problem-4-continued",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 4 (continued)",
    "text": "Practice Problem 4 (continued)\n\n\n\n\n\n\n\n\nTip\n\n\n\nHypergeometric formula: \\[\nP(\\text{exactly }k\\text{ successes})\n= \\frac{\\binom{K}{k}\\,\\binom{N-K}{n-k}}{\\binom{N}{n}} \\]\n\nwhere \\(N=52\\), \\(K=4\\) aces, \\(n=5\\) draws, and \\(k\\) is the number of aces you want.\n\nComplement trick: \\(\\;P(\\ge1\\text{ ace}) = 1 - P(0\\text{ aces})\\).\n\nThis structure makes it easy to plug in any ‚Äúnumber of successes‚Äù you need, or to use the complement when you want ‚Äúat least one.‚Äù\n\n\n\n\n\nHypergeometric in one formula\nFor part (a) you could also write directly:\n\\[P(k=3)\n= \\frac{\\binom{4}{3}\\,\\binom{48}{2}}{\\binom{52}{5}}\n= \\frac{4\\cdot1{,}128}{2{,}598{,}960}\n\\approx 0.001735\\]\nAnd for part (b):\n\\[\nP(\\ge1)\n= 1 - \\frac{\\binom{48}{5}}{\\binom{52}{5}}\n= 1 - 0.6590\n= 0.3410\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#permutations-with-restrictions",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#permutations-with-restrictions",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Restrictions",
    "text": "Permutations with Restrictions\n\nHow many 6-letter ‚Äúwords‚Äù can be formed from the letters A, B, C, D, E, F if:\n\nNo letter is repeated\nA and B must be adjacent\n\n\n\nSolution. Treat AB as a single unit\n\n5 units to arrange: (AB), C, D, E, F ‚Üí \\(5! = 120\\) ways\nA and B can be arranged within their unit: \\(2! = 2\\) ways\nTotal: \\(5! \\times 2! = 240\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#sec-inclusion-exclusion",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#sec-inclusion-exclusion",
    "title": "PSTAT 5A: Counting",
    "section": "The Inclusion-Exclusion Principle",
    "text": "The Inclusion-Exclusion Principle\n\n\n\nThe Principle of Inclusion‚ÄìExclusion lets you count (or find the probability of) the union of several sets by alternately adding and subtracting the sizes of their intersections.\n\n\nFor two sets \\(A\\) and \\(B\\): \\[|A \\cup B| = |A| + |B| - |A \\cap B|\\]\nFor three sets \\(A\\), \\(B\\), and \\(C\\): \\[|A \\cup B \\cup C| = |A| + |B| + |C| - |A \\cap B| \\\\\n- |A \\cap C| - |B \\cap C| + |A \\cap B \\cap C|\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#inclusion-exclusion-example",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#inclusion-exclusion-example",
    "title": "PSTAT 5A: Counting",
    "section": "Inclusion-Exclusion Example",
    "text": "Inclusion-Exclusion Example\n\nHow many integers from 1 to 100 are divisible by 2, 3, or 5?\n\nLet:\n\n\\(A\\) = divisible by 2: \\(|A| = 50\\)\n\\(B\\) = divisible by 3: \\(|B| = 33\\)\n\\(C\\) = divisible by 5: \\(|C| = 20\\)\n\n\n\n\n\n\n\nNote\n\n\n\\(|A \\cap B| = 16\\) (divisible by 6)\n\\(|A \\cap C| = 10\\) (divisible by 10)\n\\(|B \\cap C| = 6\\) (divisible by 15)\n\\(|A \\cap B \\cap C| = 3\\) (divisible by 30)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#inclusion-exclusion-solution",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#inclusion-exclusion-solution",
    "title": "PSTAT 5A: Counting",
    "section": "Inclusion-Exclusion Solution",
    "text": "Inclusion-Exclusion Solution\n\nSolution. \\[|A \\cup B \\cup C| = 50 + 33 + 20 - 16 - 10 - 6 + 3 = 74\\]\nAnswer: 74 integers from 1 to 100 are divisible by at least one of 2, 3, or 5"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#multinomial-coefficients",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#multinomial-coefficients",
    "title": "PSTAT 5A: Counting",
    "section": "Multinomial Coefficients",
    "text": "Multinomial Coefficients\n\n\n\n\n\n\n\nMultinomial Coefficient\n\n\nNumber of ways to divide \\(n\\) objects into groups of sizes \\(n_1, n_2, \\ldots, n_k\\):\n\\[\\binom{n}{n_1, n_2, \\ldots, n_k} = \\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\]\n\n\n\n\n\nHow many ways can 12 people be divided into 3 teams of 4?\n\\(\\binom{12}{4,4,4} = \\frac{12!}{4! \\times 4! \\times 4!} = 34,650\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#sec-problem-solving-strategy",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#sec-problem-solving-strategy",
    "title": "PSTAT 5A: Counting",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\n\n\n\n\n\nStrategy\n\n\n\nRead carefully: What exactly are we counting?\nIdentify the type: Permutation, combination, or other?\nCheck for restrictions: Are there constraints?\nDoes order matter?: This determines permutation vs combination\nBreak down complex problems: Use multiplication principle\nVerify your answer: Does it make sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#common-mistakes-to-avoid",
    "title": "PSTAT 5A: Counting",
    "section": "Common Mistakes to Avoid",
    "text": "Common Mistakes to Avoid\n\n\n\n\n\n\n\nCommon Mistakes\n\n\n\nConfusing permutations and combinations\n\nAlways ask: ‚ÄúDoes order matter?‚Äù\n\nForgetting about restrictions\n\nRead the problem carefully\n\nDouble counting\n\nMake sure you‚Äôre not counting the same arrangement twice\n\nNot considering the complement\n\nSometimes ‚Äúat least‚Äù problems are easier using complements"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#practice-6",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#practice-6",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\n\nA class has 15 students: 8 women and 7 men. How many ways can we:\n\nForm a committee of 5 people with exactly 3 women?\nArrange 6 people in a row with alternating genders (starting with a woman)?\n\n\n\nSolution. \n\n\\(\\binom{8}{3} \\times \\binom{7}{2} = 56 \\times 21 = 1,176\\)\nChoose 3 women from 8: \\(P(8,3) = 336\\) Choose 3 men from 7: \\(P(7,3) = 210\\) Total: \\(336 \\times 210 = 70,560\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#counting-in-computer-science",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#counting-in-computer-science",
    "title": "PSTAT 5A: Counting",
    "section": "Counting in Computer Science",
    "text": "Counting in Computer Science\n\nPassword Security:\n\n8-character password with letters, digits, symbols\n\\((26 + 26 + 10 + 32)^8 = 94^8 \\approx 6.1 \\times 10^{15}\\)\n\nHash Functions:\n\nDistributing data into buckets\nCollision probability calculations\n\nAlgorithm Analysis:\n\nCounting operations, comparisons\nBig O notation foundations"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#counting-in-genetics",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#counting-in-genetics",
    "title": "PSTAT 5A: Counting",
    "section": "Counting in Genetics",
    "text": "Counting in Genetics\n\nDNA Sequences:\n\n4 bases (A, T, G, C)\nGene of length \\(n\\): \\(4^n\\) possible sequences\n\nProtein Folding:\n\nNumber of possible conformations\nCombinatorial explosion\n\nPopulation Genetics:\n\nHardy-Weinberg calculations\nAllele combinations"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#real-world-applications",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#real-world-applications",
    "title": "PSTAT 5A: Counting",
    "section": "Real-World Applications",
    "text": "Real-World Applications\n\nLottery:\n\nPowerball: Choose 5 from 69, then 1 from 26\nOdds: \\(\\frac{1}{\\binom{69}{5} \\times 26} \\approx \\frac{1}{292,000,000}\\)\n\nCryptography:\n\nKey space size determines security\nRSA encryption relies on large number factorization\n\nSports Tournaments:\n\nMarch Madness bracket: \\(2^{63}\\) possible outcomes\nRound-robin tournaments: \\(\\binom{n}{2}\\) games"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#key-formulas-summary",
    "title": "PSTAT 5A: Counting",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\n\n\n\n\n\n\n\nSummary of Key Formulas\n\n\n\nPermutations: \\(P(n,r) = \\frac{n!}{(n-r)!}\\)\nCombinations: \\(C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\)\nWith repetition: \\(\\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\)\nInclusion-Exclusion: \\(|A \\cup B| = |A| + |B| - |A \\cap B|\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#technology-and-counting",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#technology-and-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Technology and Counting",
    "text": "Technology and Counting\n\n\n\n\n\n\n\nTools\n\n\nCalculators:\n\nUse nPr and nCr functions\nBe careful with large numbers\n\nSoftware:\n\nR: factorial(), choose(), combn()\nPython: math.factorial(), math.comb()\nExcel: FACT(), COMBIN(), PERMUT()\n\nOnline Tools:\n\nWolfram Alpha for complex calculations\nCombination/permutation calculators"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#practice-7",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#practice-7",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\n\nA standard deck of cards is shuffled. What‚Äôs the probability that:\n\nThe top 4 cards are all hearts?\nIn a 13-card hand, you get exactly one card from each rank?\n\n\n\nSolution. \n\n\\(\\frac{13}{52} \\times \\frac{12}{51} \\times \\frac{11}{50} \\times \\frac{10}{49} = \\frac{13 \\times 12 \\times 11 \\times 10}{52 \\times 51 \\times 50 \\times 49} \\approx 0.0026\\)\nChoose 1 card from each of 13 ranks: \\(4^{13}\\) Total 13-card hands: \\(\\binom{52}{13}\\) Probability: \\(\\frac{4^{13}}{\\binom{52}{13}} \\approx 6.3 \\times 10^{-6}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#extending-to-probability",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#extending-to-probability",
    "title": "PSTAT 5A: Counting",
    "section": "Extending to Probability",
    "text": "Extending to Probability\n\n\n\n\n\n\n\nDistributions\n\n\nHypergeometric Distribution:\n\nDrawing without replacement\nUses combinations: \\(P(X = k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}\\)\n\nBinomial Distribution:\n\nDrawing with replacement\nUses combinations: \\(P(X = k) = \\binom{n}{k}p^k(1-p)^{n-k}\\)\n\nWe‚Äôll explore these distributions in detail in future lectures"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#historical-note",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#historical-note",
    "title": "PSTAT 5A: Counting",
    "section": "Historical Note",
    "text": "Historical Note\n\n\n\n\n\n\n\nHistory\n\n\nBlaise Pascal (1623-1662) and Pierre de Fermat (1601-1665): - Founded probability theory through gambling problems - Pascal‚Äôs triangle and combinations\nLeonhard Euler (1707-1783): - Advanced combinatorics - Graph theory connections\nModern applications span computer science, biology, physics, and economics"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#common-student-questions",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#common-student-questions",
    "title": "PSTAT 5A: Counting",
    "section": "Common Student Questions",
    "text": "Common Student Questions\n\nQ: ‚ÄúWhen do I use permutations vs combinations?‚Äù\nA: Ask ‚ÄúDoes order matter?‚Äù Order matters ‚Üí permutation\nQ: ‚ÄúHow do I handle restrictions?‚Äù\nA: Break the problem into cases or use complementary counting\nQ: ‚ÄúWhat if objects are identical?‚Äù\nA: Use the formula for permutations with repetition\nQ: ‚ÄúHow do I check my answer?‚Äù\nA: Verify with small examples or use different methods"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#looking-ahead",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#looking-ahead",
    "title": "PSTAT 5A: Counting",
    "section": "Looking Ahead",
    "text": "Looking Ahead\n\n\n\n\n\n\n\nNext Lecture\n\n\nNext lecture: Discrete Probability Distributions - Binomial distribution (using combinations!)\n\nHypergeometric distribution\nGeometric distribution\nExpected value and variance\n\nConnection: Today‚Äôs counting techniques are essential for probability calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#study-tips",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#study-tips",
    "title": "PSTAT 5A: Counting",
    "section": "Study Tips",
    "text": "Study Tips\n\n\n\n\n\n\n\nTips\n\n\n\nPractice, practice, practice: Work through many examples\nIdentify patterns: Learn to recognize problem types\nStart simple: Build up to complex problems\nCheck your work: Use different approaches when possible\nUnderstand concepts: Don‚Äôt just memorize formulas"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#learning-summary",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#learning-summary",
    "title": "PSTAT 5A: Counting",
    "section": "Learning Objectives Summary",
    "text": "Learning Objectives Summary\n\n\n\n\n\n\n\nWhat We‚Äôve Covered\n\n\nIn this lecture, we‚Äôve addressed all the learning objectives:\n\n‚úÖ Calculate combinations and understand when to use them: Covered in Section¬†3 and Section¬†4\n‚úÖ Distinguish between permutations and combinations: Covered in Section¬†7\n‚úÖ Use counting techniques to solve probability problems: Covered in Section¬†12\n‚úÖ Apply the inclusion-exclusion principle: Covered in Section¬†17\n‚úÖ Solve complex counting problems systematically: Covered in Section¬†21"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#final-thoughts",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#final-thoughts",
    "title": "PSTAT 5A: Counting",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nCounting is fundamental to:\n\nProbability calculations\nStatistical inference\nComputer algorithms\nScientific modeling\n\n\n\n\n\n\n\n\nKnow the Basics\n\n\nPermutations and combinations are the building blocks for advanced statistical concepts"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part2.html#questions",
    "href": "files/lecture_notes/lecture6/lecture6-part2.html#questions",
    "title": "PSTAT 5A: Counting",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday‚Äôs 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Random Variables"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#welcome-to-lecture-7",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#welcome-to-lecture-7",
    "title": "PSTAT 5A: Counting",
    "section": "Welcome to Lecture 7",
    "text": "Welcome to Lecture 7\nThe art and science of systematic enumeration"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#learning-objectives",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#learning-objectives",
    "title": "PSTAT 5A: Counting",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\n\n\n\n\n\n\n\nLearning Objectives\n\n\nBy the end of this lecture, you will be able to:\n\nApply the fundamental counting principles (Section¬†0.4)\nCalculate permutations with and without repetition (Section¬†0.8, Section¬†0.11, Section¬†0.15)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#why-study-counting",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#why-study-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Why Study Counting?",
    "text": "Why Study Counting?\n\n\n\n\n\nCounting helps us:\n\nCalculate probabilities for complex events\n\nSolve optimization problems\n\nUnderstand combinations in genetics, computer science\n\nAnalyze algorithms and data structures\n\nMake decisions involving arrangements and selections\n\n\n\nReal-world applications of counting include:\n\nCryptography: Password strength and encryption key space\nGenetics: DNA sequence analysis and gene combinations\n\nTournament brackets: March Madness and sports competitions\nLottery odds: Probability calculations for games of chance\nPassword security: Character combinations and brute force protection"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-fundamental-counting",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-fundamental-counting",
    "title": "PSTAT 5A: Counting",
    "section": "The Fundamental Counting Principle",
    "text": "The Fundamental Counting Principle\n\n\n\n\n\n\n\n\n\nMultiplication Rule\n\n\nIf a procedure consists of \\(k\\) separate tasks where:\n\nTask 1 can be performed in \\(n_1\\) ways\nTask 2 can be performed in \\(n_2\\) ways\n‚Ä¶\nTask \\(k\\) can be performed in \\(n_k\\) ways\n\nThen, the entire procedure can be performed in \\(n_1 \\times n_2 \\times \\cdots \\times n_k\\) ways\n\n\n\n\n\n\n\n\n\n\n\n%%{init: {'flowchart': {'nodeSpacing': 20, 'rankSpacing': 50}}}%%\nflowchart TD\n    Start([üü¢ Start]) --&gt; T1[üìã Task 1&lt;br/&gt;n‚ÇÅ ways]\n    T1 --&gt; C1[Choice 1]\n    T1 --&gt; C2[Choice 2]\n    T1 --&gt; Cn1[Choice n‚ÇÅ]\n    \n    C1 --&gt; T2[üìã Task 2&lt;br/&gt;n‚ÇÇ ways]\n    C2 --&gt; T2\n    Cn1 --&gt; T2\n    \n    T2 --&gt; C21[Choice 1]\n    T2 --&gt; C22[Choice 2]\n    T2 --&gt; C2n[Choice n‚ÇÇ]\n    \n    C21 --&gt; Total[üéØ Total ways&lt;br/&gt;n‚ÇÅ √ó n‚ÇÇ √ó ... √ó n‚Çñ]\n    C22 --&gt; Total\n    C2n --&gt; Total\n    \n    classDef start fill:#d4edda,stroke:#155724,stroke-width:3px\n    classDef task fill:#d1ecf1,stroke:#0c5460,stroke-width:2px\n    classDef choice fill:#fff3cd,stroke:#856404,stroke-width:1px\n    classDef total fill:#f8d7da,stroke:#721c24,stroke-width:3px\n    \n    class Start start\n    class T1,T2 task\n    class C1,C2,Cn1,C21,C22,C2n choice\n    class Total total"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#simple-counting-example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#simple-counting-example",
    "title": "PSTAT 5A: Counting",
    "section": "Simple Counting Example",
    "text": "Simple Counting Example\n\n\n\nFormat: ABC-123\n\\[\n\\underbrace{A \\; B \\; \\_ \\; \\ - \\_ \\; \\_ \\; \\_}_{positions}\n\\]\n\nFirst position: 26 letters\nSecond position: 26 letters\nThird position: 26 letters\nFourth position: 10 digits\nFifth position: 10 digits\nSixth position: 10 digits\n\n\n\n\n\nSolution. Total possibilities: \\(26 \\times 26 \\times 26 \\times 10 \\times 10 \\times 10 = 26^3 \\times 10^3 = 17,576,000\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#restaurant-menu-example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#restaurant-menu-example",
    "title": "PSTAT 5A: Counting",
    "section": "Restaurant Menu Example",
    "text": "Restaurant Menu Example\n\nA restaurant offers:\nüç§ Appetizers: 4\nüç≤ Main Courses: 6\nüç∞ Desserts: 3\nHow many different three-course meals are possible?\n\n\nSolution. \\(4 \\times 6 \\times 3 = 72\\) different meals"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#practice-1",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#practice-1",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\nA password must contain:\n\nExactly 8 characters\nEach character is either a letter (26 possibilities) or digit (10 possibilities)\n\nHow many possible passwords are there?\n\n\n\n\n\n\n\nSolution. Each position has \\(26 + 10 = 36\\) choices.\nTotal: \\(36^8 = 2,821,109,907,456\\) passwords"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Permutations?",
    "text": "What Are Permutations?\n\n\n\n\n\n\n\n\n\nPermutation\n\n\nAn arrangement of objects where order matters\n\n\n\n\n\n\n\n\n\n\n\nOrder Matters\n\n\n\nRace finish positions (1st, 2nd, 3rd)\nSeating arrangements\nPasswords\nDNA sequences\n\n\n\n\n\n\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nAll permutations of ABC:\n1. ABC\n2. ACB\n3. BAC\n4. BCA\n5. CAB\n6. CBA"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-of-n-distinct-objects",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-of-n-distinct-objects",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(n\\) Distinct Objects",
    "text": "Permutations of \\(n\\) Distinct Objects\n\n\n\n\n\n\n\n\n\nKey Formula\n\n\nThe number of ways to arrange \\(n\\) distinct objects is:\n\\[n! = n \\times (n-1) \\times (n-2) \\times \\cdots \\times 2 \\times 1\\]\n\n\n\n\n\n\n\n\n\n\n\nSeating Process:\n1st position: 5 choices (Alice, Bob, Carol, David, Eve)\n2nd position: 4 choices (whoever is left)\n3rd position: 3 choices (whoever is left)\n4th position: 2 choices (whoever is left)\n5th position: 1 choice (last person)\nHow many ways can 5 people sit in a row?\n\n\nSolution. \\(5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#factorial-values",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#factorial-values",
    "title": "PSTAT 5A: Counting",
    "section": "Factorial Values",
    "text": "Factorial Values\n\n\n\n\n\n\\(n\\)\n\\(n!\\)\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n2\n2\n\n\n3\n6\n\n\n4\n24\n\n\n5\n120\n\n\n10\n3,628,800\n\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\n\nNote\n\n\n\\(0! = 1\\) by definition"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-r-from-n",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-r-from-n",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(r\\) Objects from \\(n\\)",
    "text": "Permutations of \\(r\\) Objects from \\(n\\)\n\n\n\n\n\n\n\n\n\nKey Formula\n\n\n\\(P(n,r)\\) or \\(_nP_r\\): Number of ways to arrange \\(r\\) objects selected from \\(n\\) distinct objects\n\\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\\[\nP_{k,n} =\n\\frac{n!}{(n-k)!}\n=\n\\]\n\\[\n= \\frac{\n  n(n-1)\\cdots(n-k+1)\\,\n  \\overbrace{(n-k)(n-k-1)\\cdots3\\cdot2\\cdot1}^{(n-k)!}\n}{\n  (n-k)!\n}\n\\]\n\\[\n= \\underbrace{\nn (n-1) (n-2) \\cdots (n-k+1)\n}_{k \\text{ terms}}\n\\]\nFill in \\(k\\) slots with no repetitions\n\\[\n\\underbrace{n \\; (n-1) \\; \\_ \\; \\_ \\; \\cdots}_{k}\n\\]\nNote that if we allowed repetitions we would get \\(n^k\\) \\[\n\\underbrace{n \\; n \\; n \\; \\cdots \\; n}_{k}\n\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#example",
    "title": "PSTAT 5A: Counting",
    "section": "Example",
    "text": "Example\n\nHow many ways can we select and arrange 3 people from a group of 8 for president, vice-president, and secretary? \n\n\nSolution. \\(P(8,3) = \\frac{8!}{(8-3)!} = \\frac{8!}{5!} = 8 \\times 7 \\times 6 = 336\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#understanding-pnr",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#understanding-pnr",
    "title": "PSTAT 5A: Counting",
    "section": "Understanding \\(P(n,r)\\)",
    "text": "Understanding \\(P(n,r)\\)\nWhy is \\(P(n,r) = \\frac{n!}{(n-r)!}\\)?\n\nFirst position: \\(n\\) choices\nSecond position: \\((n-1)\\) choices\n\nThird position: \\((n-2)\\) choices\n‚Ä¶\n\\(r\\)-th position: \\((n-r+1)\\) choices\n\n\nTotal: \\(n \\times (n-1) \\times (n-2) \\times \\cdots \\times (n-r+1) = \\frac{n!}{(n-r)!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#practice-2",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#practice-2",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\nA baseball team has 15 players. How many ways can the coach:\n\nArrange all 15 players in a line?\nChoose and arrange 9 players for the starting lineup (batting order matters)?\n\n\n\n\nSolution. \n\n\\(15! = 1,307,674,368,000\\)\n\\(P(15,9) = \\frac{15!}{6!} = 1,816,214,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-repetition",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#sec-permutations-repetition",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition",
    "text": "Permutations with Repetition\n\n\n\n\n\n\n\nPermutations with Repetition\n\n\nWhen some objects are identical, we have fewer distinct arrangements\nIf we have \\(n\\) objects where:\n\n\\(n_1\\) are of type 1\n\\(n_2\\) are of type 2\n‚Ä¶\n\\(n_k\\) are of type \\(k\\)\n\nNumber of distinct arrangements: \\(\\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-with-repetition-example",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#permutations-with-repetition-example",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition Example",
    "text": "Permutations with Repetition Example\n\n\n\nHow many distinct arrangements are there of the letters in ‚ÄúSTATISTICS‚Äù? \n\n\n\n\n\n\n\nTip\n\n\nS-T-A-T-I-S-T-I-C-S\n\nTotal letters: 10\nS appears 3 times\nT appears 3 times\nA appears 1 time\nI appears 2 times\nC appears 1 time\n\n\n\n\n\n\nSolution. \\(\\frac{10!}{3! \\times 3! \\times 1! \\times 2! \\times 1!} = \\frac{3,628,800}{6 \\times 6 \\times 1 \\times 2 \\times 1} = \\frac{3,628,800}{72} = 50,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#learning-summary",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#learning-summary",
    "title": "PSTAT 5A: Counting",
    "section": "Learning Objectives Summary",
    "text": "Learning Objectives Summary\n\n\n\n\n\n\n\nWhat We‚Äôve Covered\n\n\nIn this lecture, we‚Äôve addressed all the learning objectives:\n\n‚úÖ Apply the fundamental counting principles: Covered in Section¬†0.4\n‚úÖ Calculate permutations with and without repetition: Covered in Section¬†0.8, Section¬†0.11, and Section¬†0.15"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6-part1.html#questions",
    "href": "files/lecture_notes/lecture6/lecture6-part1.html#questions",
    "title": "PSTAT 5A: Counting",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday‚Äôs 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Counting continued"
  }
]