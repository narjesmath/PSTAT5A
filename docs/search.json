[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Class Schedule",
    "section": "",
    "text": "‚ö†Ô∏è\n\nImportant: This schedule is subject to change. Please check back regularly for updates and announcements.\n\n\n\n\n\n\nLabs & Worksheets\n\n\n\n\n\nQuizzes & Exams\n\n\n\n\n\nLecture Materials\n\n\n\n\n\nWeek 1: Introduction & Descriptive Statistics\n\n\n\n\n1\n\n\n6/23\n\n\nIntroduction\n\n\nLab 1\n\n\nWorksheet 1\n\n\n\n\n\n\n\n6/24\n\n\nNo class (lecture canceled)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n6/25\n\n\nDescriptive Statistics I\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n6/26\n\n\nDescriptive Statistics II\nLinear Transformations (Worksheet 1 Q3)\n\n\n\n\n\n\n\n‚Äî\n\n\n\n\n\n\nWeek 2: Probability Foundations\n\n\n\n\n2\n\n\n6/30\n\n\nDescriptive Statistics II (Continued)\n\n\nLab2 Lab2 Notebook\n\n\nWorksheet 2\n\n\n\n\n\n\n\n7/01\n\n\nIntro to Probability\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/02\n\n\nIntro to Probability (Continued)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/03\n\n\nConditional Probability\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 3: Random Variables & Inference\n\n\n\n\n3\n\n\n7/07\n\n\nRandom Variables\n\n\nLab 3\n\n\nWorksheet 3\n\n\n\n\n\n\n\n7/08\n\n\nIntroduction to Inference\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/09\n\n\nConfidence Intervals (Proportions)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/10\n\n\nConfidence Intervals (Means)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/11\n\n\nQuiz 1 (Weeks 1‚Äì2)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 4: Hypothesis Testing\n\n\n\n\n4\n\n\n7/14\n\n\nHypothesis Testing I\n\n\nLab 4\n\n\nWorksheet 4\n\n\n\n\n\n\n\n7/15\n\n\nHypothesis Testing II\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/16\n\n\nTwo‚ÄìSample t-Tests\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/17\n\n\nTwo‚ÄìSample t-Tests Continued\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 5: ANOVA & Statistical Modeling\n\n\n\n\n5\n\n\n7/21\n\n\nANOVA\n\n\nLab 5\n\n\nWorksheet 5\n\n\n\n\n\n\n\n7/22\n\n\nIntro to Statistical Modeling\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/23\n\n\nIntro to Statistical Modeling & Correlation\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/24\n\n\nQuiz 2 (Weeks 3‚Äì4)\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\nWeek 6: Regression & Course Wrap-Up\n\n\n\n\n6\n\n\n7/28\n\n\nRegression Analysis\n\n\nLab 6\n\n\nWorksheet 6\n\n\n\n\n\n\n\n7/29\n\n\nRegression Diagnostics, Sampling\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/30\n\n\nWrap-Up\n\n\n‚Äî\n\n\n‚Äî\n\n\n\n\n\n\n\n7/31\n\n\nQuiz 3 (Weeks 5‚Äì6)\n\n\n‚Äî\n\n\n‚Äî"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Download the full syllabus as a PDF\n\n\n\n\nüìö\n\n\nCourse Information\n\n\n\n\n\nLecture Time\n\n\nM/W/T/R 8:00 AM‚Äì9:30 AM\n\n\n\n\nLecture Hall\n\n\nHSSB 1173\n\n\n\n\nSections\n\n\nAs scheduled on GOLD (see Canvas for Zoom links)\n\n\n\n\nEmail\n\n\nnmathlouthi@ucsb.edu\n\n\n\n\nOffice\n\n\nEllison Hall 5829\n\n\n\n\nOffice Hours\n\n\nThursdays 11:00 AM‚Äì12:00 PM (via Zoom or by appointment)\n\n\n\n\n\nNote: Zoom links are posted on the Canvas page for the class.\n\n\n\n\n\n\nüë•\n\n\nTeaching Assistants\n\n\n\n\n\nSL\n\n\nSummer Le\n\n\nsle@ucsb.edu\n\n\n\n\nMH\n\n\nMingzhu He\n\n\nmingzhuhe@ucsb.edu\n\n\n\n\n\nEmail policy: Include [PSTAT 5A] in your subject. Allow 24‚Äì48 hours for a reply (avoid weekends).\n\n\n\n\n\n\nüéØ\n\n\nCourse Description\n\n\nThis introductory course covers the foundations of statistical thinking, including data description, probability, and inference. Students will learn how to summarize data, compute basic probabilities, and make informed decisions using statistical tools.\n\nStudent Learning Objectives\nBy the end of this course, you will be able to:\n\nSummarize data using descriptive statistics\nUnderstand fundamental probability rules and distributions\nConduct basic inferential procedures (confidence intervals, hypothesis tests)\nInterpret results and communicate findings\n\n\n\n\n\n\nüìñ\n\n\nCourse Materials\n\n\n\n\n\nCanvas\n\n\nAnnouncements, Zoom links, and grades (canvas.ucsb.edu)\n\n\n\n\nCalculator\n\n\nScientific calculator for in-class and quiz work\n\n\n\n\nComputer\n\n\nUse our JupyterHub instance\n\n\n\n\nRecommended Texts\n\n\nOpenIntro Statistics (free online)\nThink Stats by Allen Downey (free online)\n\n\n\n\n\n\n\nüìÖ\n\n\nClass Schedule\n\n\n\n\nNote: For the most up-to-date details, please visit the Class Schedule tab on our website: Class Schedule\n\n\n\n\n\n\nüìä\n\n\nGrading\n\n\n\n\nGrade Breakdown:\n\n\n\nLecture attendance: 5%\nSection attendance: 5%\nQuiz 1: 30%\nQuiz 2: 30%\nQuiz 3: 30%\n\n\n\nGrading Scale:\n\n\n\n\nA Grades\nB Grades\nC Grades\nD/F Grades\n\n\n\n\nA+: 97‚Äì100\nB+: 87‚Äì89\nC+: 77‚Äì79\nD+: 67‚Äì69\n\n\nA: 93‚Äì96\nB: 83‚Äì86\nC: 73‚Äì76\nD: 60‚Äì66\n\n\nA‚Äì: 90‚Äì92\nB‚Äì: 80‚Äì82\nC‚Äì: 70‚Äì72\nF: &lt; 60\n\n\n\n\n\n\nGrades round to the nearest whole number (e.g., 89.7 ‚Üí 90).\n\n\n\n\n\n\nüìù\n\n\nQuizzes\n\n\n\n\n\n1\n\n\n\nQuiz 1: Weeks 1‚Äì2\n\n\nJuly 10th\n\n\nCovers introduction and descriptive statistics\n\n\n\n\n\n2\n\n\n\nQuiz 2: Weeks 3‚Äì4\n\n\nJuly 24th\n\n\nCovers probability and hypothesis testing\n\n\n\n\n\n3\n\n\n\nQuiz 3: Weeks 5‚Äì6\n\n\nJuly 31st\n\n\nCovers ANOVA and regression analysis\n\n\n\n\n\n\nFormat: Multiple choice & short answer (open book)\nPlatform: Gradescope\nAvailability: Fridays 7 AM‚Äì12 AM (1‚Äëhour limit)\nMake‚Äëup policy: Notify within 48 h; documentation required.\n\n\n\n\n\n\nüéØ\n\n\nHow to Succeed\n\n\n\nAttend lectures & sections\nEngage actively & ask questions\nUse office hours for help\n\n\nClassroom Expectations\nRespect peers & TAs. Stay engaged. Seek support if needed.\n\n\nCommunication Guidelines\n\nUse UCSB email with clear subject\nAllow 24‚Äì48 h for replies\nUse office hours or appointments\n\n\n\n\n\n\nüõ°Ô∏è\n\n\nAcademic Integrity\n\n\nDo your own work. Cite sources properly. See:\n\nAcademic Integrity Policy\nStudent Conduct Code\n\n\n\n\n\nü§ù\n\n\nStudent Resources\n\n\n\n\nü¶Ω DSP & Accommodations Disability services and accommodations\n\n\nüìö CLAS Campus Learning Assistance Services\n\n\nüè• Student Health Health and wellness services\n\n\nüçé Basic Needs Food security and basic needs support\n\n\nüíö CAPS Counseling & Psychological Services\n\n\nüéì EOP Educational Opportunity Program\n\n\nüë• ONDAS First-Generation Support\n\n\nüìã Undocumented Services Support for undocumented students\n\n\nüîÑ Transfer Center Transfer student support\n\n\n\n\n\n\nüìÖ\n\n\nImportant Dates\n\n\n\n\n\nAdd w/o Code\n\n\nJune 29\n\n\n\n\nDrop w/ Refund\n\n\nJune 29\n\n\n\n\nAdd w/ Code\n\n\nJuly 3\n\n\n\n\nDrop Course\n\n\nJuly 9\n\n\n\n\nChange Grade Option\n\n\nAugust 1"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Course Resources",
    "section": "",
    "text": "üîç"
  },
  {
    "objectID": "resources.html#week-1-foundations-of-data-science",
    "href": "resources.html#week-1-foundations-of-data-science",
    "title": "Course Resources",
    "section": "Week 1: Foundations of Data Science",
    "text": "Week 1: Foundations of Data Science"
  },
  {
    "objectID": "resources.html#getting-started-with-data",
    "href": "resources.html#getting-started-with-data",
    "title": "Course Resources",
    "section": "Getting Started with Data",
    "text": "Getting Started with Data\nThis week introduces fundamental concepts in data science, including data types, basic statistics, and essential Python tools for data manipulation and analysis."
  },
  {
    "objectID": "resources.html#week-2-data-visualization",
    "href": "resources.html#week-2-data-visualization",
    "title": "Course Resources",
    "section": "Week 2: Data Visualization",
    "text": "Week 2: Data Visualization\n\n\nüöß\n\n\nResources Coming Soon!\nWeek 2 materials focusing on matplotlib, seaborn, and plotly will be available next week. Check back soon for visualization tutorials and interactive exercises."
  },
  {
    "objectID": "resources.html#week-3-statistical-analysis",
    "href": "resources.html#week-3-statistical-analysis",
    "title": "Course Resources",
    "section": "Week 3: Statistical Analysis",
    "text": "Week 3: Statistical Analysis\n\n\nüìä\n\n\nStatistical Inference & Confidence Intervals (CI‚Äôs)\nWeek 3 will cover statistical inference,and confidence intervals. Materials will be posted by week 3."
  },
  {
    "objectID": "resources.html#week-4-statistical-methods-testing",
    "href": "resources.html#week-4-statistical-methods-testing",
    "title": "Course Resources",
    "section": "Week 4: Statistical Methods & Testing",
    "text": "Week 4: Statistical Methods & Testing\n\n\nüî¨\n\n\nHypothesis Testing Fundamentals\nWeek 4 will cover hypothesis testing, and two sample t-Tests. Materials will be posted by week 4."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Get in Touch\n\nWe‚Äôre here to help you succeed in PSTAT 5A\n\n\n\n\n\n\nNM\n\n\nCourse Instructor\n\n\nNarjes Mathlouthi\n\n\n\n\nüìß\n\n\nnmathlouthi@ucsb.edu\n\n\n\n\nüè¢\n\n\nEllison Hall 5829\n\n\n\n\nüïê\n\n\nThursdays 11:00 AM‚Äì12:00 PM\n\n\n\n\nüíª\n\n\nVia Zoom or by appointment\n\n\n\n\n\n\nSL\n\n\nTeaching Assistant\n\n\nSummer Le\n\n\n\n\nüìß\n\n\nsle@ucsb.edu\n\n\n\n\nüïê\n\n\nFriday 1:00 PM ‚Äì 2:00 PM\n\n\n\n\nüíª\n\n\nVia Zoom (links on Canvas)\n\n\n\n\n\n\n\nMH\n\n\nTeaching Assistant\n\n\nMingzhu He\n\n\n\n\nüìß\n\n\nmingzhuhe@ucsb.edu\n\n\n\n\nüïê\n\n\nTuesday 11:00 AM ‚Äì 12:00 PM\n\n\n\n\nüíª\n\n\nVia Zoom (links on Canvas)\n\n\n\n\n\n\n\nInstructor Office Hours\n\n\nThursdays 11:00 AM ‚Äì 12:00 PM\n\n\nAvailable via Zoom or by appointment  Zoom links posted on Canvas\n\n\n\n\n\nCommunication Guidelines\n\n\n\n1\n\n\nSubject Line: Always include [PSTAT 5A] in your email subject for faster response\n\n\n\n\n2\n\n\nResponse Time: Allow 24‚Äì48 hours for replies (avoid sending on weekends)\n\n\n\n\n3\n\n\nUse UCSB Email: Always email from your UCSB account for verification\n\n\n\n\n4\n\n\nOffice Hours: Use office hours for complex questions or detailed help\n\n\n\n\n5\n\n\nUrgent Matters: For time-sensitive issues, mention ‚ÄúURGENT‚Äù in the subject line\n\n\n\n\n\n\nEmergency Contacts\n\n\nFor campus emergencies: 911 ‚Ä¢ For student crisis support: CAPS 24/7 line (805) 893-4411"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSTAT 5A: Understanding Data",
    "section": "",
    "text": "Learn the fundamentals of data science and statistical thinking\n\n\nSummer Session A 2025 ‚Ä¢ Taught by Narjes Mathlouthi\n\nGet Started ‚Üí"
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Course Overview",
    "text": "Course Overview\n\nTransform raw data into meaningful insights through hands-on learning and real-world applications"
  },
  {
    "objectID": "index.html#quick-navigation",
    "href": "index.html#quick-navigation",
    "title": "PSTAT 5A: Understanding Data",
    "section": "Quick Navigation",
    "text": "Quick Navigation\n\nEverything you need for the course, organized and accessible"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html",
    "href": "files/lecture_notes/lecture7/lecture7.html",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "",
    "text": "Discrete Random Variables\nFrom outcomes to numbers: quantifying randomness"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-7",
    "href": "files/lecture_notes/lecture7/lecture7.html#welcome-to-lecture-7",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "",
    "text": "Discrete Random Variables\nFrom outcomes to numbers: quantifying randomness"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture7/lecture7.html#todays-learning-objectives",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine random variables and distinguish discrete from continuous\nWork with probability mass functions (PMFs) and cumulative distribution functions (CDFs)\nCalculate expected values and variances for discrete random variables\nApply properties of expectation and variance\nWork with common discrete distributions (Bernoulli, Binomial, Geometric, Poisson)\nSolve real-world problems using discrete random variables\nUse technology to compute probabilities and parameters"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "href": "files/lecture_notes/lecture7/lecture7.html#what-is-a-random-variable",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "What is a Random Variable?",
    "text": "What is a Random Variable?\nA random variable is a function that assigns a numerical value to each outcome of a random experiment\nNotation: Usually denoted by capital letters \\(X\\), \\(Y\\), \\(Z\\)\nKey insight: Random variables transform outcomes into numbers, making mathematical analysis possible\n\nExample: Rolling a die - Outcomes: \\(\\{1, 2, 3, 4, 5, 6\\}\\) - Random variable \\(X\\): the number shown - \\(X\\) can take values \\(\\{1, 2, 3, 4, 5, 6\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#why-use-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Why Use Random Variables?",
    "text": "Why Use Random Variables?\nRandom variables allow us to:\n\nQuantify outcomes numerically\nCalculate means, variances, and other statistics\nModel real-world phenomena mathematically\nMake predictions and decisions\nCompare different random processes\n\n\nExamples: Height, test scores, number of defects, wait times, stock prices"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#types-of-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Types of Random Variables",
    "text": "Types of Random Variables\nDiscrete Random Variable: - Takes on a countable number of values - Can list all possible values - Examples: dice rolls, number of emails, quiz scores\nContinuous Random Variable: - Takes on uncountably many values (intervals) - Cannot list all possible values\n- Examples: height, weight, time, temperature\n\nToday we focus on discrete random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#examples-of-discrete-random-variables",
    "href": "files/lecture_notes/lecture7/lecture7.html#examples-of-discrete-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Examples of Discrete Random Variables",
    "text": "Examples of Discrete Random Variables\n\\(X\\) = Number of heads in 3 coin flips - Possible values: \\(\\{0, 1, 2, 3\\}\\)\n\\(Y\\) = Number of customers in an hour - Possible values: \\(\\{0, 1, 2, 3, \\ldots\\}\\)\n\\(Z\\) = Score on a 10-question quiz - Possible values: \\(\\{0, 1, 2, \\ldots, 10\\}\\)\n\nNotice: All values are integers with gaps between them"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "href": "files/lecture_notes/lecture7/lecture7.html#probability-mass-function-pmf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Probability Mass Function (PMF)",
    "text": "Probability Mass Function (PMF)\nThe probability mass function of a discrete random variable \\(X\\) is:\n\\[P(X = x) = \\text{probability that } X \\text{ takes the value } x\\]\nProperties of PMF: 1. \\(P(X = x) \\geq 0\\) for all \\(x\\) 2. \\(\\sum_{\\text{all } x} P(X = x) = 1\\)\n\nNotation: Sometimes written as \\(p(x)\\) or \\(f(x)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#pmf-example-fair-die",
    "href": "files/lecture_notes/lecture7/lecture7.html#pmf-example-fair-die",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "PMF Example: Fair Die",
    "text": "PMF Example: Fair Die\nLet \\(X\\) = outcome of rolling a fair six-sided die\n\\[P(X = x) = \\begin{cases}\n\\frac{1}{6} & \\text{if } x \\in \\{1, 2, 3, 4, 5, 6\\} \\\\\n0 & \\text{otherwise}\n\\end{cases}\\]\n\nVerification: - All probabilities ‚â• 0 ‚úì - Sum = \\(6 \\times \\frac{1}{6} = 1\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "href": "files/lecture_notes/lecture7/lecture7.html#pmf-example-two-coin-flips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "PMF Example: Two Coin Flips",
    "text": "PMF Example: Two Coin Flips\nLet \\(X\\) = number of heads in two coin flips\nSample space: \\(\\{HH, HT, TH, TT\\}\\)\n\n\n\n\n\\(x\\)\nOutcomes\n\\(P(X = x)\\)\n\n\n\n\n0\nTT\n1/4\n\n\n1\nHT, TH\n2/4 = 1/2\n\n\n2\nHH\n1/4\n\n\n\nVerification: \\(\\frac{1}{4} + \\frac{1}{2} + \\frac{1}{4} = 1\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-1",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\nA box contains 3 red balls and 2 blue balls. Two balls are drawn without replacement. Let \\(X\\) = number of red balls drawn.\nFind the PMF of \\(X\\).\n\nSolution: \\(X\\) can be 0, 1, or 2\n\\(P(X = 0) = \\frac{\\binom{3}{0}\\binom{2}{2}}{\\binom{5}{2}} = \\frac{1 \\times 1}{10} = \\frac{1}{10}\\)\n\\(P(X = 1) = \\frac{\\binom{3}{1}\\binom{2}{1}}{\\binom{5}{2}} = \\frac{3 \\times 2}{10} = \\frac{6}{10}\\)\n\\(P(X = 2) = \\frac{\\binom{3}{2}\\binom{2}{0}}{\\binom{5}{2}} = \\frac{3 \\times 1}{10} = \\frac{3}{10}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "href": "files/lecture_notes/lecture7/lecture7.html#cumulative-distribution-function-cdf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\nThe cumulative distribution function of a random variable \\(X\\) is:\n\\[F(x) = P(X \\leq x)\\]\nProperties of CDF: 1. \\(F(x)\\) is non-decreasing 2. \\(\\lim_{x \\to -\\infty} F(x) = 0\\) 3. \\(\\lim_{x \\to \\infty} F(x) = 1\\) 4. \\(F(x)\\) is right-continuous"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#cdf-example-two-coin-flips",
    "href": "files/lecture_notes/lecture7/lecture7.html#cdf-example-two-coin-flips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "CDF Example: Two Coin Flips",
    "text": "CDF Example: Two Coin Flips\nFrom our previous example where \\(X\\) = number of heads:\n\\[F(x) = \\begin{cases}\n0 & \\text{if } x &lt; 0 \\\\\n\\frac{1}{4} & \\text{if } 0 \\leq x &lt; 1 \\\\\n\\frac{3}{4} & \\text{if } 1 \\leq x &lt; 2 \\\\\n1 & \\text{if } x \\geq 2\n\\end{cases}\\]\n\nKey insight: CDF is a step function for discrete random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#relationship-between-pmf-and-cdf",
    "href": "files/lecture_notes/lecture7/lecture7.html#relationship-between-pmf-and-cdf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Relationship Between PMF and CDF",
    "text": "Relationship Between PMF and CDF\nFrom PMF to CDF: \\(F(x) = \\sum_{k \\leq x} P(X = k)\\)\nFrom CDF to PMF: \\(P(X = k) = F(k) - F(k^-)\\)\nwhere \\(F(k^-)\\) is the limit from the left\n\nUseful CDF Properties: - \\(P(X &gt; x) = 1 - F(x)\\) - \\(P(a &lt; X \\leq b) = F(b) - F(a)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-2",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\nUsing the red balls example from Problem 1, find:\n\n\\(F(0.5)\\)\n\\(F(1)\\)\n\n\\(P(X &gt; 1)\\)\n\\(P(0.5 &lt; X \\leq 1.5)\\)\n\n\nSolutions: a) \\(F(0.5) = P(X \\leq 0.5) = P(X = 0) = \\frac{1}{10}\\) b) \\(F(1) = P(X \\leq 1) = P(X = 0) + P(X = 1) = \\frac{1}{10} + \\frac{6}{10} = \\frac{7}{10}\\) c) \\(P(X &gt; 1) = 1 - F(1) = 1 - \\frac{7}{10} = \\frac{3}{10}\\) d) \\(P(0.5 &lt; X \\leq 1.5) = F(1.5) - F(0.5) = \\frac{7}{10} - \\frac{1}{10} = \\frac{6}{10}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#expected-value-mean",
    "href": "files/lecture_notes/lecture7/lecture7.html#expected-value-mean",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value (Mean)",
    "text": "Expected Value (Mean)\nThe expected value of a discrete random variable \\(X\\) is:\n\\[E[X] = \\mu = \\sum_{\\text{all } x} x \\cdot P(X = x)\\]\nInterpretation: The long-run average value if the experiment is repeated many times\n\nAlso called: Mean, expectation, average"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#expected-value-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#expected-value-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value Example",
    "text": "Expected Value Example\nFor two coin flips where \\(X\\) = number of heads:\n\\[E[X] = 0 \\cdot P(X = 0) + 1 \\cdot P(X = 1) + 2 \\cdot P(X = 2)\\]\n\\[= 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 0 + \\frac{1}{2} + \\frac{1}{2} = 1\\]\n\nMakes sense: On average, we expect 1 head in 2 coin flips"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-3",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\nFind the expected value for the red balls example (Problem 1).\n\nSolution: \\[E[X] = 0 \\cdot \\frac{1}{10} + 1 \\cdot \\frac{6}{10} + 2 \\cdot \\frac{3}{10}\\]\n\\[= 0 + \\frac{6}{10} + \\frac{6}{10} = \\frac{12}{10} = 1.2\\]\nOn average, we expect to draw 1.2 red balls"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "href": "files/lecture_notes/lecture7/lecture7.html#properties-of-expected-value",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Properties of Expected Value",
    "text": "Properties of Expected Value\nLinearity of Expectation: 1. \\(E[c] = c\\) (constant) 2. \\(E[cX] = c \\cdot E[X]\\) (scaling) 3. \\(E[X + Y] = E[X] + E[Y]\\) (additivity) 4. \\(E[aX + bY + c] = aE[X] + bE[Y] + c\\)\n\nImportant: Property 3 holds even if \\(X\\) and \\(Y\\) are dependent!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#expected-value-of-functions",
    "href": "files/lecture_notes/lecture7/lecture7.html#expected-value-of-functions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value of Functions",
    "text": "Expected Value of Functions\nFor a function \\(g(X)\\) of a random variable \\(X\\):\n\\[E[g(X)] = \\sum_{\\text{all } x} g(x) \\cdot P(X = x)\\]\n\nCommon example: \\(g(X) = X^2\\)\n\\[E[X^2] = \\sum_{\\text{all } x} x^2 \\cdot P(X = x)\\]\nNote: Generally \\(E[g(X)] \\neq g(E[X])\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#variance",
    "href": "files/lecture_notes/lecture7/lecture7.html#variance",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Variance",
    "text": "Variance\nThe variance of a random variable \\(X\\) measures spread around the mean:\n\\[\\text{Var}(X) = \\sigma^2 = E[(X - \\mu)^2]\\]\nAlternative formula (often easier to compute): \\[\\text{Var}(X) = E[X^2] - (E[X])^2\\]\nStandard deviation: \\(\\sigma = \\sqrt{\\text{Var}(X)}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#variance-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#variance-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Variance Example",
    "text": "Variance Example\nFor two coin flips where \\(X\\) = number of heads, \\(E[X] = 1\\):\nFirst, find \\(E[X^2]\\): \\[E[X^2] = 0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4} = 0 + \\frac{1}{2} + 1 = \\frac{3}{2}\\]\n\nThen: \\(\\text{Var}(X) = E[X^2] - (E[X])^2 = \\frac{3}{2} - 1^2 = \\frac{1}{2}\\)\nStandard deviation: \\(\\sigma = \\sqrt{\\frac{1}{2}} \\approx 0.707\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#properties-of-variance",
    "href": "files/lecture_notes/lecture7/lecture7.html#properties-of-variance",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Properties of Variance",
    "text": "Properties of Variance\n\n\\(\\text{Var}(c) = 0\\) (constants have no variability)\n\\(\\text{Var}(cX) = c^2 \\text{Var}(X)\\) (scaling by \\(c\\) scales variance by \\(c^2\\))\n\\(\\text{Var}(X + c) = \\text{Var}(X)\\) (shifting doesn‚Äôt change spread)\nIf \\(X\\) and \\(Y\\) are independent: \\(\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y)\\)\n\n\nNote: Property 4 requires independence, unlike expectation!"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-4",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-4",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\nFor the red balls example, find the variance and standard deviation.\nWe found \\(E[X] = 1.2\\). First find \\(E[X^2]\\):\n\n\\[E[X^2] = 0^2 \\cdot \\frac{1}{10} + 1^2 \\cdot \\frac{6}{10} + 2^2 \\cdot \\frac{3}{10}\\] \\[= 0 + \\frac{6}{10} + \\frac{12}{10} = \\frac{18}{10} = 1.8\\]\n\\[\\text{Var}(X) = 1.8 - (1.2)^2 = 1.8 - 1.44 = 0.36\\]\n\\[\\sigma = \\sqrt{0.36} = 0.6\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#bernoulli-distribution",
    "href": "files/lecture_notes/lecture7/lecture7.html#bernoulli-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\nA Bernoulli random variable models a single trial with two outcomes:\n\nSuccess (1) with probability \\(p\\)\nFailure (0) with probability \\(1-p\\)\n\nPMF: \\(P(X = x) = p^x(1-p)^{1-x}\\) for \\(x \\in \\{0, 1\\}\\)\nParameters: \\(p \\in [0, 1]\\)\n\nExamples: Coin flip, single exam question (pass/fail), defective item"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#bernoulli-properties",
    "href": "files/lecture_notes/lecture7/lecture7.html#bernoulli-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bernoulli Properties",
    "text": "Bernoulli Properties\nFor \\(X \\sim \\text{Bernoulli}(p)\\):\nMean: \\(E[X] = p\\)\nVariance: \\(\\text{Var}(X) = p(1-p)\\)\nStandard deviation: \\(\\sigma = \\sqrt{p(1-p)}\\)\n\nIntuition: - Mean \\(p\\) makes sense: probability of success - Variance maximized when \\(p = 0.5\\) (most uncertainty)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#binomial-distribution",
    "href": "files/lecture_notes/lecture7/lecture7.html#binomial-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\nA binomial random variable counts successes in \\(n\\) independent Bernoulli trials, each with success probability \\(p\\)\nPMF: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\) for \\(k = 0, 1, 2, \\ldots, n\\)\nParameters: \\(n\\) (number of trials), \\(p\\) (success probability)\nNotation: \\(X \\sim \\text{Binomial}(n, p)\\) or \\(X \\sim B(n, p)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#binomial-properties",
    "href": "files/lecture_notes/lecture7/lecture7.html#binomial-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Binomial Properties",
    "text": "Binomial Properties\nFor \\(X \\sim \\text{Binomial}(n, p)\\):\nMean: \\(E[X] = np\\)\nVariance: \\(\\text{Var}(X) = np(1-p)\\)\nStandard deviation: \\(\\sigma = \\sqrt{np(1-p)}\\)\n\nDerivation: Sum of \\(n\\) independent Bernoulli\\((p)\\) random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#binomial-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#binomial-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Binomial Example",
    "text": "Binomial Example\nA multiple choice quiz has 10 questions, each with 4 options. A student guesses randomly on each question. Let \\(X\\) = number of correct answers.\n\\(X \\sim \\text{Binomial}(10, 0.25)\\)\nWhat‚Äôs the probability of getting exactly 3 correct?\n\n\\[P(X = 3) = \\binom{10}{3} (0.25)^3 (0.75)^7\\] \\[= 120 \\times 0.015625 \\times 0.1335 \\approx 0.250\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-5",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-5",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 5",
    "text": "Practice Problem 5\nFor the quiz example:\n\nWhat‚Äôs the expected number of correct answers?\nWhat‚Äôs the standard deviation?\nWhat‚Äôs the probability of getting at least 4 correct?\n\n\nSolutions: a) \\(E[X] = np = 10 \\times 0.25 = 2.5\\) b) \\(\\sigma = \\sqrt{np(1-p)} = \\sqrt{10 \\times 0.25 \\times 0.75} = \\sqrt{1.875} \\approx 1.37\\) c) \\(P(X \\geq 4) = 1 - P(X \\leq 3) = 1 - [P(X=0) + P(X=1) + P(X=2) + P(X=3)]\\) Use binomial table or calculator: \\(P(X \\geq 4) \\approx 0.224\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#geometric-distribution",
    "href": "files/lecture_notes/lecture7/lecture7.html#geometric-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\nA geometric random variable counts the number of trials until the first success\nPMF: \\(P(X = k) = (1-p)^{k-1} p\\) for \\(k = 1, 2, 3, \\ldots\\)\nParameters: \\(p\\) (success probability per trial)\nNotation: \\(X \\sim \\text{Geometric}(p)\\)\n\nExamples: Number of coin flips until heads, number of shots until goal, number of calls until sale"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#geometric-properties",
    "href": "files/lecture_notes/lecture7/lecture7.html#geometric-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Geometric Properties",
    "text": "Geometric Properties\nFor \\(X \\sim \\text{Geometric}(p)\\):\nMean: \\(E[X] = \\frac{1}{p}\\)\nVariance: \\(\\text{Var}(X) = \\frac{1-p}{p^2}\\)\nMemoryless property: \\(P(X &gt; s + t | X &gt; s) = P(X &gt; t)\\)\n\nIntuition: If \\(p = 0.1\\), expect to wait \\(\\frac{1}{0.1} = 10\\) trials on average"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#geometric-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#geometric-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Geometric Example",
    "text": "Geometric Example\nA basketball player has a 60% free throw percentage. What‚Äôs the probability they make their first shot on the 3rd attempt?\n\\(X \\sim \\text{Geometric}(0.6)\\)\n\n\\[P(X = 3) = (1-0.6)^{3-1} \\times 0.6 = (0.4)^2 \\times 0.6 = 0.16 \\times 0.6 = 0.096\\]\nExpected number of attempts: \\(E[X] = \\frac{1}{0.6} \\approx 1.67\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-6",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-6",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\nA quality control inspector tests items until finding the first defective one. If 5% of items are defective:\n\nWhat‚Äôs the probability the first defective item is the 10th one tested?\nWhat‚Äôs the expected number of items tested?\nWhat‚Äôs the probability of testing more than 20 items?\n\n\nSolutions: a) \\(P(X = 10) = (0.95)^9 \\times 0.05 \\approx 0.0315\\) b) \\(E[X] = \\frac{1}{0.05} = 20\\) items c) \\(P(X &gt; 20) = (0.95)^{20} \\approx 0.358\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#poisson-distribution",
    "href": "files/lecture_notes/lecture7/lecture7.html#poisson-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution\nA Poisson random variable counts events occurring in a fixed interval when events happen at a constant average rate\nPMF: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\) for \\(k = 0, 1, 2, \\ldots\\)\nParameters: \\(\\lambda &gt; 0\\) (average rate)\nNotation: \\(X \\sim \\text{Poisson}(\\lambda)\\)\n\nExamples: Emails per hour, accidents per day, mutations per genome"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#poisson-properties",
    "href": "files/lecture_notes/lecture7/lecture7.html#poisson-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Poisson Properties",
    "text": "Poisson Properties\nFor \\(X \\sim \\text{Poisson}(\\lambda)\\):\nMean: \\(E[X] = \\lambda\\)\nVariance: \\(\\text{Var}(X) = \\lambda\\)\nStandard deviation: \\(\\sigma = \\sqrt{\\lambda}\\)\n\nUnique property: Mean equals variance!\nApproximation: Binomial\\((n, p)\\) ‚âà Poisson\\((np)\\) when \\(n\\) large, \\(p\\) small"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#poisson-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#poisson-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Poisson Example",
    "text": "Poisson Example\nA call center receives an average of 3 calls per minute. What‚Äôs the probability of receiving exactly 5 calls in the next minute?\n\\(X \\sim \\text{Poisson}(3)\\)\n\n\\[P(X = 5) = \\frac{3^5 e^{-3}}{5!} = \\frac{243 \\times e^{-3}}{120} \\approx \\frac{243 \\times 0.0498}{120} \\approx 0.101\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-7",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-7",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\nFor the call center example:\n\nWhat‚Äôs the probability of no calls in a minute?\nWhat‚Äôs the probability of at most 2 calls?\nIn a 2-minute period, what‚Äôs the expected number of calls?\n\n\nSolutions: a) \\(P(X = 0) = \\frac{3^0 e^{-3}}{0!} = e^{-3} \\approx 0.0498\\) b) \\(P(X \\leq 2) = P(X=0) + P(X=1) + P(X=2) \\approx 0.0498 + 0.1494 + 0.2240 = 0.423\\) c) For 2 minutes: \\(Y \\sim \\text{Poisson}(6)\\), so \\(E[Y] = 6\\) calls"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-distribution",
    "href": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Hypergeometric Distribution",
    "text": "Hypergeometric Distribution\nA hypergeometric random variable counts successes when sampling without replacement from a finite population\nSetup: Population of \\(N\\) items, \\(K\\) are successes, draw \\(n\\) items\nPMF: \\(P(X = k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}\\)\nNotation: \\(X \\sim \\text{Hypergeometric}(N, K, n)\\)\n\nExamples: Defective items in a batch, aces in a card hand, tagged fish in a sample"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-properties",
    "href": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Hypergeometric Properties",
    "text": "Hypergeometric Properties\nFor \\(X \\sim \\text{Hypergeometric}(N, K, n)\\):\nMean: \\(E[X] = n \\cdot \\frac{K}{N}\\)\nVariance: \\(\\text{Var}(X) = n \\cdot \\frac{K}{N} \\cdot \\frac{N-K}{N} \\cdot \\frac{N-n}{N-1}\\)\n\nConnection to Binomial: When \\(N\\) is large relative to \\(n\\), hypergeometric ‚âà binomial\\((n, K/N)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-example",
    "href": "files/lecture_notes/lecture7/lecture7.html#hypergeometric-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Hypergeometric Example",
    "text": "Hypergeometric Example\nA batch of 20 light bulbs contains 3 defective ones. If 5 bulbs are randomly selected, what‚Äôs the probability exactly 1 is defective?\n\\(X \\sim \\text{Hypergeometric}(20, 3, 5)\\)\n\n\\[P(X = 1) = \\frac{\\binom{3}{1}\\binom{17}{4}}{\\binom{20}{5}} = \\frac{3 \\times 2380}{15504} = \\frac{7140}{15504} \\approx 0.461\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-8",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-8",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 8",
    "text": "Practice Problem 8\nFor the light bulb example:\n\nWhat‚Äôs the expected number of defective bulbs in the sample?\nWhat‚Äôs the probability of no defective bulbs?\nWhat‚Äôs the probability of at least 2 defective bulbs?\n\n\nSolutions: a) \\(E[X] = 5 \\times \\frac{3}{20} = 0.75\\) bulbs b) \\(P(X = 0) = \\frac{\\binom{3}{0}\\binom{17}{5}}{\\binom{20}{5}} = \\frac{6188}{15504} \\approx 0.399\\) c) \\(P(X \\geq 2) = 1 - P(X = 0) - P(X = 1) \\approx 1 - 0.399 - 0.461 = 0.140\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#comparing-distributions",
    "href": "files/lecture_notes/lecture7/lecture7.html#comparing-distributions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Comparing Distributions",
    "text": "Comparing Distributions\n\n\n\n\n\n\n\n\n\n\nDistribution\nParameters\nMean\nVariance\nUse Case\n\n\n\n\nBernoulli\n\\(p\\)\n\\(p\\)\n\\(p(1-p)\\)\nSingle trial\n\n\nBinomial\n\\(n, p\\)\n\\(np\\)\n\\(np(1-p)\\)\nFixed trials\n\n\nGeometric\n\\(p\\)\n\\(1/p\\)\n\\((1-p)/p^2\\)\nWait for success\n\n\nPoisson\n\\(\\lambda\\)\n\\(\\lambda\\)\n\\(\\lambda\\)\nCount events\n\n\nHypergeometric\n\\(N, K, n\\)\n\\(n(K/N)\\)\nComplex\nSample w/o replacement"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#technology-and-software",
    "href": "files/lecture_notes/lecture7/lecture7.html#technology-and-software",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Technology and Software",
    "text": "Technology and Software\nCalculators: - Binomial: binompdf(), binomcdf() - Poisson: poissonpdf(), poissoncdf()\nR: - dbinom(), pbinom(), rbinom() - dpois(), ppois(), rpois() - dgeom(), pgeom(), rgeom()\nPython: - scipy.stats.binom, scipy.stats.poisson - numpy.random for simulation"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture7/lecture7.html#problem-solving-strategy",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\nIdentify the scenario: What type of process?\nCheck assumptions: Independence, constant probability, etc.\nChoose distribution: Match scenario to distribution\nIdentify parameters: \\(n\\), \\(p\\), \\(\\lambda\\), etc.\nCalculate probabilities: Use PMF, CDF, or technology\nInterpret results: Does the answer make sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#real-world-applications",
    "href": "files/lecture_notes/lecture7/lecture7.html#real-world-applications",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nQuality Control: - Binomial for defect rates - Hypergeometric for batch sampling\nReliability Engineering: - Geometric for time to failure - Poisson for system failures\nEpidemiology: - Binomial for disease spread - Poisson for rare events\nFinance: - Poisson for market events - Binomial for option pricing"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-9",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-9",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 9",
    "text": "Practice Problem 9\nA website receives an average of 2 orders per minute. Assuming orders follow a Poisson process:\n\nWhat‚Äôs the probability of exactly 3 orders in a minute?\nWhat‚Äôs the probability of no orders in 30 seconds?\nWhat‚Äôs the probability of more than 5 orders in 2 minutes?\n\n\nSolutions: a) \\(X \\sim \\text{Poisson}(2)\\): \\(P(X = 3) = \\frac{2^3 e^{-2}}{3!} \\approx 0.180\\) b) \\(Y \\sim \\text{Poisson}(1)\\): \\(P(Y = 0) = e^{-1} \\approx 0.368\\) c) \\(Z \\sim \\text{Poisson}(4)\\): \\(P(Z &gt; 5) = 1 - P(Z \\leq 5) \\approx 0.215\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#central-limit-theorem-preview",
    "href": "files/lecture_notes/lecture7/lecture7.html#central-limit-theorem-preview",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Central Limit Theorem Preview",
    "text": "Central Limit Theorem Preview\nFor large \\(n\\), many discrete distributions approach normal:\nBinomial: \\(X \\sim \\text{Binomial}(n, p)\\) ‚Üí \\(N(np, np(1-p))\\) when \\(np &gt; 5\\) and \\(n(1-p) &gt; 5\\)\nPoisson: \\(X \\sim \\text{Poisson}(\\lambda)\\) ‚Üí \\(N(\\lambda, \\lambda)\\) when \\(\\lambda &gt; 10\\)\n\nThis connection will be crucial for hypothesis testing and confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#common-mistakes",
    "href": "files/lecture_notes/lecture7/lecture7.html#common-mistakes",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Common Mistakes",
    "text": "Common Mistakes\n\nWrong distribution choice: Check assumptions carefully\nParameter confusion: Is it \\(n\\), \\(p\\), or \\(\\lambda\\)?\nInclusion errors: ‚ÄúAt least 3‚Äù vs ‚ÄúMore than 3‚Äù\nIndependence assumption: Sampling with/without replacement\nTechnology errors: pdf vs cdf functions"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#practice-problem-10",
    "href": "files/lecture_notes/lecture7/lecture7.html#practice-problem-10",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 10",
    "text": "Practice Problem 10\nA multiple choice test has 20 questions with 5 options each. A student knows the answers to 12 questions and guesses on the rest.\n\nWhat‚Äôs the expected score?\nWhat‚Äôs the probability of scoring at least 15?\nWhat‚Äôs the standard deviation of the score?\n\n\nSolution: Let \\(X\\) = known correct, \\(Y\\) = guessed correct - \\(X = 12\\) (deterministic) - \\(Y \\sim \\text{Binomial}(8, 0.2)\\) - Total score \\(S = X + Y = 12 + Y\\)\n\n\\(E[S] = 12 + E[Y] = 12 + 8(0.2) = 13.6\\)\n\\(P(S \\geq 15) = P(Y \\geq 3) \\approx 0.203\\)\n\n\\(\\sigma_S = \\sigma_Y = \\sqrt{8(0.2)(0.8)} = \\sqrt{1.28} \\approx 1.13\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#extensions-and-advanced-topics",
    "href": "files/lecture_notes/lecture7/lecture7.html#extensions-and-advanced-topics",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Extensions and Advanced Topics",
    "text": "Extensions and Advanced Topics\nNegative Binomial: Number of trials to get \\(r\\) successes\nMultinomial: Extension of binomial to more than 2 categories\nCompound Distributions: Sums of random variables\nGenerating Functions: Advanced technique for deriving properties\n\nThese topics appear in advanced probability courses"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#historical-context",
    "href": "files/lecture_notes/lecture7/lecture7.html#historical-context",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Historical Context",
    "text": "Historical Context\nJacob Bernoulli (1654-1705): Bernoulli trials and law of large numbers\nSim√©on Denis Poisson (1781-1840): Poisson distribution and approximation\nAbraham de Moivre (1667-1754): Normal approximation to binomial\nModern Applications: Computer science, machine learning, bioinformatics"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#common-student-questions",
    "href": "files/lecture_notes/lecture7/lecture7.html#common-student-questions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: ‚ÄúHow do I choose between binomial and hypergeometric?‚Äù A: Use binomial for sampling with replacement, hypergeometric without\nQ: ‚ÄúWhen can I use Poisson approximation?‚Äù A: When \\(n\\) is large, \\(p\\) is small, and \\(np\\) is moderate\nQ: ‚ÄúWhy does Poisson have mean = variance?‚Äù A: Mathematical property arising from its derivation as a limit\nQ: ‚ÄúHow do I know if trials are independent?‚Äù A: Check if outcome of one trial affects others"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture7/lecture7.html#key-formulas-summary",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\nExpected Value: \\(E[X] = \\sum x \\cdot P(X = x)\\)\nVariance: \\(\\text{Var}(X) = E[X^2] - (E[X])^2\\)\nBinomial: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\)\nGeometric: \\(P(X = k) = (1-p)^{k-1} p\\)\nPoisson: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "href": "files/lecture_notes/lecture7/lecture7.html#looking-ahead",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture: Continuous Random Variables - Probability density functions (PDFs) - Normal distribution - Exponential distribution\n- Central Limit Theorem applications\nConnection: Discrete distributions often approximate continuous ones, and vice versa"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#study-tips",
    "href": "files/lecture_notes/lecture7/lecture7.html#study-tips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Study Tips",
    "text": "Study Tips\n\nMaster the basics: PMF, CDF, expectation, variance\nLearn distribution characteristics: When to use each one\nPractice with technology: Get comfortable with calculators/software\nWork real problems: Apply distributions to actual scenarios\nCheck your intuition: Do answers make practical sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#final-thoughts",
    "href": "files/lecture_notes/lecture7/lecture7.html#final-thoughts",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nDiscrete random variables are fundamental to: - Modeling real-world phenomena - Making statistical inferences - Understanding probability theory - Building more complex models\n\nKey insight: Random variables transform unpredictable outcomes into predictable patterns"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#questions",
    "href": "files/lecture_notes/lecture7/lecture7.html#questions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: [Your office hours] Email: [Your email]\nNext Class: Continuous Random Variables\nRemember: Homework due [date]"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#bonus-law-of-large-numbers",
    "href": "files/lecture_notes/lecture7/lecture7.html#bonus-law-of-large-numbers",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bonus: Law of Large Numbers",
    "text": "Bonus: Law of Large Numbers\nAs \\(n\\) increases, the sample mean approaches the expected value:\n\\[\\bar{X}_n = \\frac{X_1 + X_2 + \\cdots + X_n}{n} \\to E[X]\\]\nExample: Flip a coin 1000 times - proportion of heads will be close to 0.5\nThis justifies our interpretation of expected value as ‚Äúlong-run average‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture7/lecture7.html#bonus-simulation",
    "href": "files/lecture_notes/lecture7/lecture7.html#bonus-simulation",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bonus: Simulation",
    "text": "Bonus: Simulation\nMonte Carlo Method: Use computer simulation to estimate probabilities\n# Simulate 10,000 binomial random variables\nX &lt;- rbinom(10000, size=10, prob=0.3)\nmean(X)  # Should be close to 10*0.3 = 3\nvar(X)   # Should be close to 10*0.3*0.7 = 2.1\nSimulation helps verify theoretical results and solve complex problems"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html",
    "href": "files/lecture_notes/lecture4/lecture4.html",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "",
    "text": "By the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#welcome-to-lecture-4",
    "href": "files/lecture_notes/lecture4/lecture4.html#welcome-to-lecture-4",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Welcome to Lecture 4",
    "text": "Welcome to Lecture 4\nIntroduction to Probability\nUnderstanding uncertainty through statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sec-objectives",
    "href": "files/lecture_notes/lecture4/lecture4.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sec-prob",
    "href": "files/lecture_notes/lecture4/lecture4.html#sec-prob",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is Probability?",
    "text": "What is Probability?\n\nüéØ Definition\nProbability is a measure of the likelihood that an event will occur"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-range",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-range",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Range",
    "text": "Probability Range\n\n\n\nRanges from 0 to 1 (or 0% to 100%)\n0: Event will never occur (impossible)\n1: Event will certainly occur (certain)\n0.5: Event has equal chance of occurring or not"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#three-ways-to-express-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#three-ways-to-express-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Three Ways to Express Probability",
    "text": "Three Ways to Express Probability\n\nFraction: \\(\\frac{1}{2}\\), \\(\\frac{3}{4}\\), \\(\\frac{2}{6}\\)\nDecimal: 0.5, 0.75, 0.33\nPercentage: 50%, 75%, 33%"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#example",
    "href": "files/lecture_notes/lecture4/lecture4.html#example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example",
    "text": "Example\nWhen we roll a die, there are six possible outcomes:\n1, 2, 3, 4, 5, 6.\nThe probability of any of them turning up is 1/6 or 16%."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#why-study-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#why-study-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Why Study Probability?",
    "text": "Why Study Probability?\nProbability helps us:\n\nMake decisions under uncertainty\nUnderstand random processes\nAnalyze data and draw conclusions\nModel real-world phenomena\nAssess risk and likelihood\n\n\n\nApplications: Weather forecasting, medical diagnosis, finance, quality control, gaming, insurance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#random-experiments",
    "href": "files/lecture_notes/lecture4/lecture4.html#random-experiments",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Random Experiments",
    "text": "Random Experiments\nA random experiment is a process that:\n\nCan be repeated under similar conditions\nHas multiple possible outcomes\nThe outcome cannot be predicted with certainty\n\n\n\nExamples\n\nü™ô Flipping a coin\nüé≤ Rolling a die\nüÉè Drawing a card from a deck\nüí° Measuring the lifetime of a light bulb"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sample-space",
    "href": "files/lecture_notes/lecture4/lecture4.html#sample-space",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space",
    "text": "Sample Space\n\nüéØ Definition The sample space (denoted \\(S\\) or \\(\\Omega\\)) is the set of all possible outcomes of a random experiment"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#sample-space-examples",
    "href": "files/lecture_notes/lecture4/lecture4.html#sample-space-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space Examples",
    "text": "Sample Space Examples\n\nCoin flip: \\(S = \\{H, T\\}\\)\nTwo coin flips: \\(S = \\{HH, HT, TH, TT\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#types-of-sample-spaces",
    "href": "files/lecture_notes/lecture4/lecture4.html#types-of-sample-spaces",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Types of Sample Spaces",
    "text": "Types of Sample Spaces\n\n\nFinite Sample Space\n\nLimited number of outcomes\n\nExample: Rolling a die\n\n\n\n\n\n\n\n\n\n\n\nInfinite Sample Space\n\nUnlimited outcomes (countable or uncountable)\n\nExample: Measuring exact height of students"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#events",
    "href": "files/lecture_notes/lecture4/lecture4.html#events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Events",
    "text": "Events\n\nüéØ Definition An event is a subset of the sample space\n\nSimple event: Contains exactly one outcome (Ex: \\(A = \\{3\\}\\) (rolling a 3))\nCompound event: Contains multiple outcomes (Ex: \\(B = \\{2, 4, 6\\}\\) (rolling an even number))"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#event-notation",
    "href": "files/lecture_notes/lecture4/lecture4.html#event-notation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Event Notation",
    "text": "Event Notation\nFor a die roll with \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (rolling an odd number)\n\\(B = \\{4, 5, 6\\}\\) (rolling 4 or higher)\n\\(C = \\{6\\}\\) (rolling a six)\n\n\n\nWe can describe events in words or using set notation"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#set-operations-overview",
    "href": "files/lecture_notes/lecture4/lecture4.html#set-operations-overview",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Set Operations Overview",
    "text": "Set Operations Overview\n\n\n\n\nüéØ Definition:\n\nSet: Collection of distinct objects\nUnion: A OR B occurs\n\nIntersection: A AND B occurs\nComplement: A does NOT occur\nSample Space: All possible outcomes"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#what-is-a-set",
    "href": "files/lecture_notes/lecture4/lecture4.html#what-is-a-set",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is a Set?",
    "text": "What is a Set?\n\n\n\n\nüéØ Definition: A collection of things that share common characteristics. They can be elements, members, objects or similar terms.\nExamples:\n\nSet of even numbers:\n\n{2, 4, 6, 8, ‚Ä¶}\n\nSet of vowels: {a, e, i, o, u}"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#union-a-b",
    "href": "files/lecture_notes/lecture4/lecture4.html#union-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Union: A ‚à™ B",
    "text": "Union: A ‚à™ B\n\n\n\n\nüéØ Definition: Contains all set elements, including intersections.\nIn Probability: The event that A OR B occurs (or both).\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#intersection-a-b",
    "href": "files/lecture_notes/lecture4/lecture4.html#intersection-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Intersection: A ‚à© B",
    "text": "Intersection: A ‚à© B\n\n\n\n\nüéØ Definition: Area where two or more sets overlap.\nIn Probability: The event that A AND B occurs.\nProperties:\n\nAlways smaller than or equal to individual sets\nCan be empty (disjoint sets)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#absolute-complement-ac",
    "href": "files/lecture_notes/lecture4/lecture4.html#absolute-complement-ac",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Absolute Complement: \\(A^c\\)",
    "text": "Absolute Complement: \\(A^c\\)\n\n\n\nüéØ Definition: All elements that do not belong to the set.\nIn Probability: The event that A does NOT occur.\n\n\\(P(A^c) = 1 - P(A)\\)\n\n\nKey Property:\n\\(A \\cup A^c = S\\) (Sample Space)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#summary-table",
    "href": "files/lecture_notes/lecture4/lecture4.html#summary-table",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Summary Table",
    "text": "Summary Table\n\n\n\n\n\n\n\n\n\nOperation\nSymbol\nMeaning\nProbability\n\n\n\n\nUnion\n\\(A \\cup B\\)\nOccurs if \\(A\\) or \\(B\\)\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\nIntersection\n\\(A \\cap B\\)\nOccurs if \\(A\\) and \\(B\\)\n\\(P(A \\cap B)\\)\n\n\nComplement\n\\(A^c\\)\nOccurs if \\(A\\) does not occur\n\\(P(A^c) = 1 - P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-commutative",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-commutative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Commutative",
    "text": "Probability Axioms: Commutative\n\nCommutative\n\\(A \\cup B = B \\cup A\\)\n\\(A \\cap B = B \\cap A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-associative",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-associative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Associative",
    "text": "Probability Axioms: Associative\n\nAssociative\n\\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\)\n\\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-distributive",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-distributive",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Distributive",
    "text": "Probability Axioms: Distributive\n\nDistributive\n\\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\n\\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-de-morgans-laws",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-axioms-de-morgans-laws",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: De Morgan‚Äôs Laws",
    "text": "Probability Axioms: De Morgan‚Äôs Laws\n\nDe Morgan‚Äôs Laws\n\\((A \\cup B)^c = A^c \\cap B^c\\)\n\\((A \\cap B)^c = A^c \\cup B^c\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-examples",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Examples",
    "text": "Practice Examples\n\nExample 1: In a class of students:\n\nSet A = Students who like Math\nSet B = Students who like Science\n\nQ: What does A ‚à™ B represent?\n\n\n\nSolution. Students who like Math OR Science (or both)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#example-set-operations",
    "href": "files/lecture_notes/lecture4/lecture4.html#example-set-operations",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example: Set Operations",
    "text": "Example: Set Operations\n\n\nFor die roll \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (odd numbers)\n\\(B = \\{4, 5, 6\\}\\) (4 or higher)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind:\n\n\\(A \\cup B\\)\n\\(A \\cap B\\)\n\\(A^c\\)\n\n\n\n\n\nSolution. \n\n\\(A \\cup B = \\{1, 3, 4, 5, 6\\}\\)\n\\(A \\cap B = \\{5\\}\\)\n\\(A^c = \\{2, 4, 6\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-events",
    "href": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive Events",
    "text": "Mutually Exclusive Events\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive (or disjoint) if they cannot occur simultaneously\n\\[A \\cap B = \\emptyset\\]\n\n\n\n\n\n\n\n\n\n\n\n\nWhen rolling a die\n\n\\(A = \\{1, 3, 5\\}\\) (odd)\n\\(B = \\{2, 4, 6\\}\\) (even)\n\n\\(A\\) and \\(B\\) are mutually exclusive"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-classical-definition-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-classical-definition-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Classical Definition of Probability",
    "text": "The Classical Definition of Probability\n\nüéØ Definition: For equally likely outcomes:\n\\[P(A) = \\frac{\\text{Number of outcomes in } A}{\\text{Total number of outcomes in } S}\\]\n\n\nProbability of rolling an even number on a fair die\n\n\n\\[P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#properties-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#properties-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Properties of Probability",
    "text": "Properties of Probability\n\nNon-negativity: \\(P(A) \\geq 0\\) for any event \\(A\\)\nNormalization: \\(P(S) = 1\\)\nAdditivity: If \\(A\\) and \\(B\\) are mutually exclusive, then\n\n\n\\[P(A \\cup B) = P(A) + P(B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-complement-rule",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-complement-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Complement Rule",
    "text": "The Complement Rule\n\n\\[P(A) + P(A^c) = 1\\]\n\\[P(A^c) = 1 - P(A)\\]\n\n\n\nIf the probability of rain is 0.3, what‚Äôs the probability of no rain?\n\n\n\n\nSolution. \\[P(\\text{no rain}) = 1 - P(\\text{rain}) = 1 - 0.3 = 0.7\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-problem-1",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-problem-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\n\n\n\nA standard deck has 52 cards. What is the probability of drawing:\n\nA heart \\(\\heartsuit\\)?\nA face card (Jack, Queen, King)?\nThe ace of spades \\(\\spadesuit\\)?\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{heart}) = \\frac{13}{52} = \\frac{1}{4}\\)\n\\(P(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\\)\n\\(P(\\text{ace of spades}) = \\frac{1}{52}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#the-addition-rule",
    "href": "files/lecture_notes/lecture4/lecture4.html#the-addition-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Addition Rule",
    "text": "The Addition Rule\nFor any two events \\(A\\) and \\(B\\):\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\n\nWhy subtract \\(P(A \\cap B)\\)?\n\n\n\nSolution. We don‚Äôt want to double-count outcomes that are in both events"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#addition-rule-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#addition-rule-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Addition Rule Example",
    "text": "Addition Rule Example\n\n\n\n\nDrawing from a standard deck:\n\n\\(A\\): Drawing a heart \\(\\heartsuit\\) (\\(P(A) = \\frac{13}{52}\\))\n\\(B\\): Drawing a face card (\\(P(B) = \\frac{12}{52}\\))\nWhat‚Äôs \\(P(A \\cup B)\\) (heart OR face card)?"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#conditional-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#conditional-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\n\n\n\nüéØConditional probability is the probability of event \\(A\\) given that event \\(B\\) has occurred\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nprovided \\(P(B) &gt; 0\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#conditional-probability-interpretation",
    "href": "files/lecture_notes/lecture4/lecture4.html#conditional-probability-interpretation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Interpretation",
    "text": "Conditional Probability Interpretation\n\\(P(A|B)\\) means:\n\nWe know event  \\(B\\) has occurred \nWhat‚Äôs the probability that \\(A\\) also occurred?\nWe ‚Äúrestrict‚Äù our sample space to only outcomes in \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#conditional-probability-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#conditional-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Example",
    "text": "Conditional Probability Example\n\n\n\nDrawing a card from a standard deck:\n\n\\(A\\): Card is a heart \\(\\heartsuit\\)\n\\(B\\): Card is red\nQ: Find \\(P(A|B)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution. \\(P(A \\cap B) = P(\\text{heart}) = \\frac{13}{52}\\)\n\\(P(B) = P(\\text{red}) = \\frac{26}{52}\\)\n\\(P(A|B) = \\frac{13/52}{26/52} = \\frac{13}{26} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#independence",
    "href": "files/lecture_notes/lecture4/lecture4.html#independence",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\nüéØ Definition Events \\(A\\) and \\(B\\) are independent if:\n\\[P(A|B) = P(A)\\]\nor equivalently:\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\n\n\nKnowing that \\(B\\) occurred doesn‚Äôt change the probability of \\(A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#independence-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#independence-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence Example",
    "text": "Independence Example\n\nTwo coin flips:\n\n\\(A\\): First flip is heads\n\\(B\\): Second flip is heads\n\nQ: Are \\(A\\) and \\(B\\) independent?\n\n\n\nSolution. \\(P(A) = \\frac{1}{2}\\), \\(P(B) = \\frac{1}{2}\\)\n\\(P(A \\cap B) = P(\\text{HH}) = \\frac{1}{4}\\)\n\\(P(A) \\times P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\)\nYes, they are independent!"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#multiplication-rule",
    "href": "files/lecture_notes/lecture4/lecture4.html#multiplication-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Multiplication Rule",
    "text": "Multiplication Rule\nGeneral case: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nIndependent events: \\(P(A \\cap B) = P(A) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-problem-2",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-problem-2",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\n\n\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement.\n\nWhat‚Äôs the probability both balls are red?\nWhat‚Äôs the probability the first is red and second is blue?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{both red}) = \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)\n\\(P(\\text{red then blue}) = \\frac{5}{8} \\times \\frac{3}{7} = \\frac{15}{56}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#law-of-total-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#law-of-total-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nüéØ Definition\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space, then:\n\\[P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \\cdots + P(A|B_n)P(B_n)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#law-of-total-probability-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\n\nA factory has two machines:\n\nMachine 1: Produces 60% of items, 5% defective\nMachine 2: Produces 40% of items, 3% defective\n\nQ: What‚Äôs the overall probability an item is defective?\n\n\n\nSolution. \\(P(\\text{defective}) = P(D|M_1)P(M_1) + P(D|M_2)P(M_2)\\)\n\\(= 0.05 \\times 0.6 + 0.03 \\times 0.4 = 0.03 + 0.012 = 0.042\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem",
    "href": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem",
    "text": "Bayes‚Äô Theorem\n\nüéØ Definition \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\nThis allows us to ‚Äúreverse‚Äù conditional probabilities\nNamed after Thomas Bayes (1701-1761)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-components",
    "href": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-components",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Components",
    "text": "Bayes‚Äô Theorem Components\n\n\\(A,B\\): Events\n\\(P(A|B)\\): Posterior probability - what we want to find\n\\(P(B|A)\\): Likelihood - given \\(A\\), probability of observing \\(B\\)\n\\(P(A)\\): Prior probability - initial probability of \\(A\\)\n\\(P(B)\\): Marginal probability - total probability of \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Example",
    "text": "Bayes‚Äô Theorem Example\n\n\n\nMedical test for a disease: 1\n\nDisease affects 1% of population\nTest is 95% accurate for sick people\nTest is 90% accurate for healthy people\n\nQ:If someone tests positive, what‚Äôs the probability they have the disease?\n\n\n\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n\\(P(\\neg D \\,\\wedge\\, \\text{Negative})\n\\;=\\;P(\\neg D)\\times P(\\text{Negative}\\mid \\neg D)\n\\;=\\;0.99\\times0.90\n\\;=\\;0.891\\;(89.1\\%)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-solution",
    "href": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-solution",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Solution",
    "text": "Bayes‚Äô Theorem Solution\nLet:\n\n\\(D\\): Person has disease\n\\(T^+\\): Test is positive\n\nGiven:\n\n\\(P(D) = 0.01\\)\n\\(P(T^+|D) = 0.95\\)\n\\(P(T^-|D^c) = 0.90\\), so \\(P(T^+|D^c) = 0.10\\)\n\n\n\nSolution. \\(P(T^+) = P(T^+|D)P(D) + P(T^+|D^c)P(D^c)\\)\n\\(= 0.95 \\times 0.01 + 0.10 \\times 0.99 = 0.1085\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-solution-cont.",
    "href": "files/lecture_notes/lecture4/lecture4.html#bayes-theorem-solution-cont.",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Solution (cont.)",
    "text": "Bayes‚Äô Theorem Solution (cont.)\n\\[P(D|T^+) = \\frac{P(T^+|D) \\times P(D)}{P(T^+)} = \\frac{0.95 \\times 0.01}{0.1085} \\approx 0.088\\]\n\n\n\n\n\n\n\n\n\n\n\nSurprising result: Even with a positive test, there‚Äôs only an 8.8% chance of having the disease!\nThis is due to the low base rate of the disease"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#common-probability-mistakes",
    "href": "files/lecture_notes/lecture4/lecture4.html#common-probability-mistakes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nConfusing \\(P(A|B)\\) with \\(P(B|A)\\)\n\n\nProsecutor‚Äôs fallacy is a specific error in interpreting conditional probabilities. Confusing\n\\(P(\\text{Evidence}\\mid\\text{Innocent})\n\\quad\\text{with}\\quad\nP(\\text{Innocent}\\mid\\text{Evidence})\\).\nEx: OJ Simpson Case 1\n\nthe DNA evidence in the O. J. Simpson trial are a classic example of the prosecutor‚Äôs fallacy. Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was ‚Äúone in 170 million,‚Äù then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#tree-diagrams",
    "href": "files/lecture_notes/lecture4/lecture4.html#tree-diagrams",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\n\nüéØ Definition Tree diagrams help visualize sequential events and calculate probabilities."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-problem-3",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-problem-3",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nTwo fair dice are rolled. Find:\n\n\\(P(\\text{sum} = 7)\\)\n\\(P(\\text{sum} = 7 | \\text{first die shows 3})\\)\nAre these events independent?\n\n\n\n\nSolution. \n\n6 ways out of 36: \\(P(\\text{sum} = 7) = \\frac{6}{36} = \\frac{1}{6}\\)\nGiven first die is 3, need second die to be 4: \\(P(\\text{sum} = 7 | \\text{first} = 3) = \\frac{1}{6}\\)\nYes, they‚Äôre independent since \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#counting-and-probability",
    "href": "files/lecture_notes/lecture4/lecture4.html#counting-and-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Counting and Probability",
    "text": "Counting and Probability\n\nSometimes we need to count outcomes:\n\nMultiplication Principle: If task 1 can be done in \\(m\\) ways and task 2 in \\(n\\) ways, both can be done in \\(m \\times n\\) ways\n\n\nPermutations: Arrangements where order matters \\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\n\nCombinations: Selections where order doesn‚Äôt matter \\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#counting-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#counting-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Counting Example",
    "text": "Counting Example\n\nQ: How many ways can you arrange 5 people in a row?\n\n\n\nSolution. This is a permutation: \\(P(5,5) = 5! = 120\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-with-counting",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-with-counting",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability with Counting",
    "text": "Probability with Counting\n\nExample: A committee of 3 people is chosen from 8 people (5 women, 3 men). What‚Äôs the probability all 3 are women?\n\n\n\nSolution. Total ways to choose 3 from 8: \\(\\binom{8}{3} = 56\\)\nWays to choose 3 women from 5: \\(\\binom{5}{3} = 10\\)\nProbability: \\(\\frac{10}{56} = \\frac{5}{28}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#probability-distributions-preview",
    "href": "files/lecture_notes/lecture4/lecture4.html#probability-distributions-preview",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Distributions Preview",
    "text": "Probability Distributions Preview\nA probability distribution assigns probabilities to all possible outcomes\nFor discrete random variables:\n\nProbability mass function (PMF)\nCumulative distribution function (CDF)\n\nWe‚Äôll explore this more in future lectures"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#common-discrete-distributions",
    "href": "files/lecture_notes/lecture4/lecture4.html#common-discrete-distributions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Discrete Distributions",
    "text": "Common Discrete Distributions\nUniform Distribution: All outcomes equally likely\nBinomial Distribution: Number of successes in fixed trials\nGeometric Distribution: Number of trials until first success\nExamples and details coming in later lectures"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#real-world-applications",
    "href": "files/lecture_notes/lecture4/lecture4.html#real-world-applications",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Diagnosis: Using Bayes‚Äô theorem for test interpretation\nQuality Control: Probability of defective items\nFinance: Risk assessment and portfolio theory\nSports: Probability of wins, fantasy sports\nInsurance: Calculating premiums based on risk"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture4/lecture4.html#key-formulas-summary",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\nBasic probability: \\(P(A) = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\\)\nComplement: \\(P(A^c) = 1 - P(A)\\)\nAddition: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nConditional: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nIndependence: \\(P(A \\cap B) = P(A) \\times P(B)\\)\nBayes‚Äô: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture4/lecture4.html#problem-solving-strategy",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\nIdentify the sample space and events\nDetermine if events are independent or mutually exclusive\nChoose the appropriate rule or formula\nCalculate step by step\nCheck if your answer makes sense"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-problem-4",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-problem-4",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\n\nA bag contains 4 red, 3 blue, and 2 green marbles. Three marbles are drawn without replacement.\nFind the probability that: a) All three are red b) No two are the same color c) At least one is blue"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#practice-problem-4-solutions",
    "href": "files/lecture_notes/lecture4/lecture4.html#practice-problem-4-solutions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 4 Solutions",
    "text": "Practice Problem 4 Solutions\n\nSolution. \n\nAll red: \\(\\frac{4}{9} \\times \\frac{3}{8} \\times \\frac{2}{7} = \\frac{24}{504} = \\frac{1}{21}\\)\nDifferent colors: \\(\\frac{4 \\times 3 \\times 2}{9 \\times 8 \\times 7} \\times 3! = \\frac{24 \\times 6}{504} = \\frac{144}{504} = \\frac{2}{7}\\)\nAt least one blue: \\(1 - P(\\text{no blue}) = 1 - \\frac{6 \\times 5 \\times 4}{9 \\times 8 \\times 7} = 1 - \\frac{120}{504} = \\frac{384}{504} = \\frac{16}{21}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#common-student-questions",
    "href": "files/lecture_notes/lecture4/lecture4.html#common-student-questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Student Questions",
    "text": "Common Student Questions\n\nQ: ‚ÄúWhy isn‚Äôt \\(P(A \\cup B) = P(A) + P(B)\\) always?‚Äù A: We‚Äôd double-count outcomes in both events\nQ: ‚ÄúHow do I know if events are independent?‚Äù A: Check if \\(P(A|B) = P(A)\\) or if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nQ: ‚ÄúWhen do I use Bayes‚Äô theorem?‚Äù A: When you want to ‚Äúreverse‚Äù a conditional probability"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#looking-ahead",
    "href": "files/lecture_notes/lecture4/lecture4.html#looking-ahead",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture:\n\nRandom Variables and Probability Distributions\nDiscrete vs.¬†continuous random variables\nExpected value and variance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#final-thoughts",
    "href": "files/lecture_notes/lecture4/lecture4.html#final-thoughts",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Final Thoughts",
    "text": "Final Thoughts\n\nProbability is the foundation of statistics:\n\nHelps us quantify uncertainty\nProvides tools for making decisions with incomplete information\nEssential for understanding statistical inference\n\n\n\nPractice: The key to mastering probability is working through many problems!"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#questions",
    "href": "files/lecture_notes/lecture4/lecture4.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday‚Äôs 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Conditional Probabilities & Independence"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#bonus-probability-paradoxes",
    "href": "files/lecture_notes/lecture4/lecture4.html#bonus-probability-paradoxes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bonus: Probability Paradoxes",
    "text": "Bonus: Probability Paradoxes\nMonty Hall Problem: Should you switch doors?\nBirthday Paradox: How many people needed for 50% chance of shared birthday?\nSimpson‚Äôs Paradox: When aggregate data reverses subgroup trends\nExplore these to deepen your probability intuition!"
  },
  {
    "objectID": "files/worksheets/worksheet2_sln.html",
    "href": "files/worksheets/worksheet2_sln.html",
    "title": "PSTAT 5A Practice Worksheet 2 Solutions",
    "section": "",
    "text": "Given:\n\n24 students: average = 74, standard deviation = 8.9\n1 makeup student: score = 64\n\n\n\nSolution: DECREASE\nSince 64 &lt; 74 (the current average), adding this score will pull the average down.\n\n\n\nSolution:\nNew average = (Sum of all 25 scores) / 25\nSum of first 24 scores = 24 √ó 74 = 1,776\nTotal sum = 1,776 + 64 = 1,840\nNew average = 1,840 / 25 = 73.6 points\n\n\n\nSolution: INCREASE\nThe score of 64 is more than one standard deviation below the original mean (74 - 8.9 = 65.1). This adds more variability to the dataset, increasing the standard deviation.\n\n\n\n\nGiven: - TV watching hours per week - Mean = 4.71 hours - Standard deviation = 4.18 hours\nQuestion: Is the distribution symmetric? What shape? Explain reasoning.\nSolution: NOT SYMMETRIC - RIGHT-SKEWED\nReasoning: 1. The standard deviation (4.18) is nearly as large as the mean (4.71)\n\nSince hours cannot be negative, there‚Äôs a natural lower bound at 0\nSome students likely watch much more TV than others, creating a long right tail\nThe large standard deviation relative to the mean suggests high variability\nIn a right-skewed distribution, a few high values (heavy TV watchers) pull the mean higher"
  },
  {
    "objectID": "files/worksheets/worksheet2_sln.html#problem-a1-mean-and-standard-deviation",
    "href": "files/worksheets/worksheet2_sln.html#problem-a1-mean-and-standard-deviation",
    "title": "PSTAT 5A Practice Worksheet 2 Solutions",
    "section": "",
    "text": "Given:\n\n24 students: average = 74, standard deviation = 8.9\n1 makeup student: score = 64\n\n\n\nSolution: DECREASE\nSince 64 &lt; 74 (the current average), adding this score will pull the average down.\n\n\n\nSolution:\nNew average = (Sum of all 25 scores) / 25\nSum of first 24 scores = 24 √ó 74 = 1,776\nTotal sum = 1,776 + 64 = 1,840\nNew average = 1,840 / 25 = 73.6 points\n\n\n\nSolution: INCREASE\nThe score of 64 is more than one standard deviation below the original mean (74 - 8.9 = 65.1). This adds more variability to the dataset, increasing the standard deviation."
  },
  {
    "objectID": "files/worksheets/worksheet2_sln.html#problem-a2-distribution-shape-analysis",
    "href": "files/worksheets/worksheet2_sln.html#problem-a2-distribution-shape-analysis",
    "title": "PSTAT 5A Practice Worksheet 2 Solutions",
    "section": "",
    "text": "Given: - TV watching hours per week - Mean = 4.71 hours - Standard deviation = 4.18 hours\nQuestion: Is the distribution symmetric? What shape? Explain reasoning.\nSolution: NOT SYMMETRIC - RIGHT-SKEWED\nReasoning: 1. The standard deviation (4.18) is nearly as large as the mean (4.71)\n\nSince hours cannot be negative, there‚Äôs a natural lower bound at 0\nSome students likely watch much more TV than others, creating a long right tail\nThe large standard deviation relative to the mean suggests high variability\nIn a right-skewed distribution, a few high values (heavy TV watchers) pull the mean higher"
  },
  {
    "objectID": "files/worksheets/worksheet2_sln.html#problem-b1-interpreting-histograms",
    "href": "files/worksheets/worksheet2_sln.html#problem-b1-interpreting-histograms",
    "title": "PSTAT 5A Practice Worksheet 2 Solutions",
    "section": "2.1 Problem B1: Interpreting Histograms",
    "text": "2.1 Problem B1: Interpreting Histograms\nContext: Infant mortality histogram shows right-skewed distribution with:\n\nHighest bar at 0-10 range (about 38% of countries)\nDecreasing bars: 10-20 (23%), 20-30 (11%)\nLong right tail with few countries having high rates\n\n\n2.1.1 Part (a): Estimate Q1, the median, and Q3 from the histogram.\nSolution: Looking at cumulative percentages:\n\nQ1 (25th percentile) ‚âà 8 deaths per 1,000 live births\nMedian (50th percentile) ‚âà 15 deaths per 1,000 live births\nQ3 (75th percentile) ‚âà 35 deaths per 1,000 live births\n\n\n\n2.1.2 Part (b): Would you expect the mean to be smaller or larger than the median? Explain.\nSolution: MEAN &gt; MEDIAN\nReasoning: - The distribution is right-skewed\n\nThe long right tail contains countries with very high infant mortality rates\nThese extreme values pull the mean higher than the median\nIn right-skewed distributions, the mean is always greater than the median\nThe median is resistant to outliers, but the mean is affected by them"
  },
  {
    "objectID": "files/worksheets/worksheet2_sln.html#problem-b2-comparing-distributions",
    "href": "files/worksheets/worksheet2_sln.html#problem-b2-comparing-distributions",
    "title": "PSTAT 5A Practice Worksheet 2 Solutions",
    "section": "2.2 Problem B2: Comparing Distributions",
    "text": "2.2 Problem B2: Comparing Distributions\nBased on the plots showing Gain vs No Gain counties:\n\n2.2.1 Center:\n\nGain group has higher median household income (~$55,000)\nNo Gain group has lower median household income (~$45,000)\n\n\n\n2.2.2 Variability:\n\nGain group shows less variability (tighter distribution)\nNo Gain group shows greater variability (wider spread)\n\n\n\n2.2.3 Shape:\n\nBoth groups are right-skewed\nShape is relatively consistent between groups\nBoth have longer right tails\n\n\n\n2.2.4 Modes:\n\nEach group has one prominent mode\nGain group: mode around $50,000-$55,000\nNo Gain group: mode around $40,000-$45,000"
  },
  {
    "objectID": "files/worksheets/worksheet2_sln.html#problem-c1-basic-variance-calculations",
    "href": "files/worksheets/worksheet2_sln.html#problem-c1-basic-variance-calculations",
    "title": "PSTAT 5A Practice Worksheet 2 Solutions",
    "section": "3.1 Problem C1: Basic Variance Calculations",
    "text": "3.1 Problem C1: Basic Variance Calculations\nData: 3, 7, 2, 8, 5, 6, 4, 9\n\n3.1.1 Part (a): Calculate the sample mean xÃÑ.\nSolution:\nxÃÑ = (3 + 7 + 2 + 8 + 5 + 6 + 4 + 9) / 8\nxÃÑ = 44 / 8 = 5.5\n\n\n3.1.2 Part (b): Calculate the sample variance s¬≤ using (n-1).\nSolution:\ns¬≤ = Œ£(xi - xÃÑ)¬≤ / (n-1)\n\nDeviations from mean:\n(3-5.5)¬≤ = (-2.5)¬≤ = 6.25\n(7-5.5)¬≤ = (1.5)¬≤ = 2.25  \n(2-5.5)¬≤ = (-3.5)¬≤ = 12.25\n(8-5.5)¬≤ = (2.5)¬≤ = 6.25\n(5-5.5)¬≤ = (-0.5)¬≤ = 0.25\n(6-5.5)¬≤ = (0.5)¬≤ = 0.25\n(4-5.5)¬≤ = (-1.5)¬≤ = 2.25\n(9-5.5)¬≤ = (3.5)¬≤ = 12.25\n\nSum = 6.25 + 2.25 + 12.25 + 6.25 + 0.25 + 0.25 + 2.25 + 12.25 = 42\n\ns¬≤ = 42 / (8-1) = 42 / 7 = 6.0\n\n\n3.1.3 Part (c): Calculate the sample standard deviation s.\nSolution:\ns = ‚àös¬≤ = ‚àö6 = 2.4495\n\n\n3.1.4 Part (d): Population variance œÉ¬≤ if treated as complete population.\nSolution:\nœÉ¬≤ = Œ£(xi - Œº)¬≤ / N\nœÉ¬≤ = 42 / 8 = 5.25\n\n\n3.1.5 Part (e): Why divide by (n-1) for sample variance instead of n?\nSolution: We use (n-1) because of degrees of freedom. When we use the sample mean xÃÑ to calculate deviations, we ‚Äúuse up‚Äù one degree of freedom. The sample mean constrains the data - if we know (n-1) deviations and the sample mean, the last deviation is determined. This makes s¬≤ an unbiased estimator of the population variance œÉ¬≤."
  },
  {
    "objectID": "files/worksheets/worksheet2_sln.html#problem-c2-comparing-variability",
    "href": "files/worksheets/worksheet2_sln.html#problem-c2-comparing-variability",
    "title": "PSTAT 5A Practice Worksheet 2 Solutions",
    "section": "3.2 Problem C2: Comparing Variability",
    "text": "3.2 Problem C2: Comparing Variability\nData Sets: - Set A: 10, 12, 14, 16, 18 - Set B: 5, 10, 14, 18, 23\n\n3.2.1 Part (a): Calculate the mean for each set.\nSolution:\nSet A: xÃÑ_A = (10 + 12 + 14 + 16 + 18) / 5 = 70 / 5 = 14\nSet B: xÃÑ_B = (5 + 10 + 14 + 18 + 23) / 5 = 70 / 5 = 14\n\n\n3.2.2 Part (b): Calculate the sample variance for each set.\nSolution:\nSet A:\nDeviations: (10-14)¬≤=16, (12-14)¬≤=4, (14-14)¬≤=0, (16-14)¬≤=4, (18-14)¬≤=16\nSum = 16 + 4 + 0 + 4 + 16 = 40\ns¬≤_A = 40 / (5-1) = 40 / 4 = 10\nSet B:\nDeviations: (5-14)¬≤=81, (10-14)¬≤=16, (14-14)¬≤=0, (18-14)¬≤=16, (23-14)¬≤=81  \nSum = 81 + 16 + 0 + 16 + 81 = 194\ns¬≤_B = 194 / (5-1) = 194 / 4 = 48.5\n\n\n3.2.3 Part (c): Which set has greater variability?\nSolution: SET B has greater variability\nSet B has variance = 48.5 vs Set A variance = 10\n\n\n3.2.4 Part (d): Calculate coefficient of variation for each set. Which has greater relative variability?\nSolution:\nCV_A = s_A / xÃÑ_A = ‚àö10 / 14 = 3.162 / 14 = 0.2259\nCV_B = s_B / xÃÑ_B = ‚àö48.5 / 14 = 6.964 / 14 = 0.4974\nSET B has greater relative variability (CV_B = 0.4974 &gt; CV_A = 0.2259)\nNote: The coefficient of variation measures variability relative to the mean, making it useful for comparing datasets with different units or scales."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#introduction",
    "href": "files/labs/lab2/lab2_sln.html#introduction",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis document contains the complete solutions to Lab 2: Data Classes and Programming Fundamentals. Each task is solved with explanations to help you understand the concepts."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#lists",
    "href": "files/labs/lab2/lab2_sln.html#lists",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "2 Lists",
    "text": "2 Lists\n\n2.1 Task 1 Solution\nCreate a list containing the elements 1, \"hi\", 3.4, and \"PSTAT 5A\". Assign this list to a variable called list1.\n\n# Solution\nlist1 = [1, \"hi\", 3.4, \"PSTAT 5A\"]\nprint(list1)\n\n[1, 'hi', 3.4, 'PSTAT 5A']\n\n\n\n\n2.2 Task 1 (cont‚Äôd) Solution\nRun the code type(list1).\n\n# Solution\nprint(type(list1))\n\n&lt;class 'list'&gt;\n\n\nExplanation: The output shows &lt;class 'list'&gt;, confirming that list1 is indeed a list object."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#indexing",
    "href": "files/labs/lab2/lab2_sln.html#indexing",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "3 Indexing",
    "text": "3 Indexing\n\n3.1 Task 2 Solution\nCreate a list with the numbers 1 through 10, inclusive, and assign this to a variable called x.\n\n# Solution\nx = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n# Alternative using range:\n# x = list(range(1, 11))\nprint(x)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n\nRun the code x[1].\n\n# Solution\nprint(x[1])\n\n2\n\n\nRun the code x[0].\n\n# Solution\nprint(x[0])\n\n1\n\n\nExplanation: - x[1] returns 2 (the second element, since indexing starts at 0) - x[0] returns 1 (the first element)\n\n\n3.2 Task 3 Solution\nCreate a list called x that contains the elements 1, \"two\", 3.5, \"four\", and \"five five\". Answer the questions and verify.\n\n# Create the list\nx = [1, \"two\", 3.5, \"four\", \"five five\"]\n\n# Predictions as comments:\n# 1. type(x) would output: &lt;class 'list'&gt;\n# 2. type(x[1]) would output: &lt;class 'str'&gt;\n# 3. x[0] would output: 1\n\nNow verify the answers:\n\n# Verify answers\nprint(\"1. type(x):\", type(x))\nprint(\"2. type(x[1]):\", type(x[1]))\nprint(\"3. x[0]:\", x[0])\n\n1. type(x): &lt;class 'list'&gt;\n2. type(x[1]): &lt;class 'str'&gt;\n3. x[0]: 1\n\n\nExplanation: 1. type(x) returns &lt;class 'list'&gt; because x is a list 2. type(x[1]) returns &lt;class 'str'&gt; because x[1] is ‚Äútwo‚Äù, which is a string 3. x[0] returns 1, the first element of the list"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#tables",
    "href": "files/labs/lab2/lab2_sln.html#tables",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "4 Tables",
    "text": "4 Tables\nFirst, let‚Äôs install and import the datascience module:\n\n# Install datascience if needed (uncomment if necessary)\n# !pip install datascience\nfrom datascience import *\n\n/Users/narjesmathlouthi/Desktop/PSTAT5A/web/PSTAT5A/.venv/lib/python3.13/site-packages/datascience/maps.py:13: UserWarning:\n\npkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n\n\n\n\n4.1 Task 4 Solution\nRead the list of methods for Table objects and write down three different methods:\n\n# Three Table methods with descriptions:\n# .with_columns(): adds specified columns to a table\n# .select(): selects specific columns from a table and returns a new table\n# .where(): filters rows based on a condition and returns a new table with matching rows\n# .num_rows: returns the number of rows in the table\n# .num_columns: returns the number of columns in the table\n\n\n\n4.2 Task 5 Solution\nCreate the professor table:\n\n# Solution\nprofs = Table().with_columns(\n    \"Professor\", [\"Dr. Swenson\", \"Dr. Wainwright\", \"Dr. Mouti\"],\n    \"Office\", [\"South Hall\", \"Old Gym\", \"Old Gym\"],\n    \"Course\", [\"PSTAT 130\", \"PSTAT 120A\", \"PSTAT 126\"]\n)\n\nprofs\n\n\n\n\nProfessor\nOffice\nCourse\n\n\n\n\nDr. Swenson\nSouth Hall\nPSTAT 130\n\n\nDr. Wainwright\nOld Gym\nPSTAT 120A\n\n\nDr. Mouti\nOld Gym\nPSTAT 126\n\n\n\n\n\nSelect the column called Course from profs:\n\n# Solution\nprofs.select(\"Course\")\n\n\n\n\nCourse\n\n\n\n\nPSTAT 130\n\n\nPSTAT 120A\n\n\nPSTAT 126\n\n\n\n\n\nCreate a new table called profs_new with an additional row:\n\n# Solution\nprofs_new = profs.with_row([\"Dr. Ravat\", \"South Hall\", \"PSTAT 120B\"])\nprofs_new\n\n\n\n\nProfessor\nOffice\nCourse\n\n\n\n\nDr. Swenson\nSouth Hall\nPSTAT 130\n\n\nDr. Wainwright\nOld Gym\nPSTAT 120A\n\n\nDr. Mouti\nOld Gym\nPSTAT 126\n\n\nDr. Ravat\nSouth Hall\nPSTAT 120B\n\n\n\n\n\nExplanation: The .with_row() method adds a new row to the existing table. We provide the values in the same order as the columns.\n\n\n4.3 Filtering Tables Example\n\n# Create example table for filtering\ntable1 = Table().with_columns(\n    \"Course\", [\"PSTAT 5A\", \"PSTAT 120A\", \"PSTAT 130\"],\n    \"Units\", [4, 4, 4],\n    \"Instructor\", [\"Mathlouthi\", \"Johnson\", \"Smith\"]\n)\n\n# Filter for courses taught by Mathlouthi\ntable1.where(\"Instructor\", \"Mathlouthi\")\n\n\n\n\nCourse\nUnits\nInstructor\n\n\n\n\nPSTAT 5A\n4\nMathlouthi\n\n\n\n\n\n\n# Try filtering for an instructor that doesn't exist\ntable1.where(\"Instructor\", \"Wilson\")\n\n\n\n\nCourse\nUnits\nInstructor"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#arrays",
    "href": "files/labs/lab2/lab2_sln.html#arrays",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "5 Arrays",
    "text": "5 Arrays\n\n5.1 Task 6 Solution\nMake a list and array with the same elements and compare operations:\n\n# Create list and array\nmy_list = [1, 2, 3]\nmy_array = make_array(1, 2, 3)\n\nprint(\"List:\", my_list)\nprint(\"Array:\", my_array)\n\nList: [1, 2, 3]\nArray: [1 2 3]\n\n\n\n# Sum operations\nprint(\"sum(my_list):\", sum(my_list))\nprint(\"sum(my_array):\", sum(my_array))\n\nsum(my_list): 6\nsum(my_array): 6\n\n\n\n# Addition with scalar - this will cause an error for lists\ntry:\n    result = my_list + 2\n    print(\"my_list + 2:\", result)\nexcept TypeError as e:\n    print(\"Error with my_list + 2:\", e)\n\nError with my_list + 2: can only concatenate list (not \"int\") to list\n\n\n\n# Addition with scalar works for arrays\nprint(\"my_array + 2:\", my_array + 2)\n\nmy_array + 2: [3 4 5]\n\n\nExplanation: Arrays support element-wise operations (like adding 2 to each element), while lists do not. Lists use + for concatenation, not arithmetic."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#comparisons",
    "href": "files/labs/lab2/lab2_sln.html#comparisons",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "6 Comparisons",
    "text": "6 Comparisons\n\n6.1 Task 7 Solution\nCompare \"statistics\" and \"Statistics\":\n\n# Solution\nprint('\"statistics\" &lt; \"Statistics\":', \"statistics\" &lt; \"Statistics\")\nprint('\"Statistics\" &lt; \"statistics\":', \"Statistics\" &lt; \"statistics\")\n\n# Additional comparisons to understand the pattern\nprint('ord(\"S\"):', ord(\"S\"))\nprint('ord(\"s\"):', ord(\"s\"))\n\n\"statistics\" &lt; \"Statistics\": False\n\"Statistics\" &lt; \"statistics\": True\nord(\"S\"): 83\nord(\"s\"): 115\n\n\nAnswer: When Python compares strings, capital letters are given precedence (they have ‚Äúlower‚Äù ASCII values). Capital letters come before lowercase letters in ASCII ordering, so \"Statistics\" &lt; \"statistics\" returns True.\n\n\n6.2 Task 8 Solution\nCreate arrays and compare element-wise:\n\n# Solution\nx = make_array(1, 2, 3)\ny = make_array(2, 3, 1)\n\nprint(\"x:\", x)\nprint(\"y:\", y)\nprint(\"x &lt; y:\", x &lt; y)\n\nx: [1 2 3]\ny: [2 3 1]\nx &lt; y: [ True  True False]\n\n\nExplanation: Python compares arrays element-wise, returning an array of boolean values: - 1 &lt; 2 ‚Üí True - 2 &lt; 3 ‚Üí True\n- 3 &lt; 1 ‚Üí False"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#conditionals",
    "href": "files/labs/lab2/lab2_sln.html#conditionals",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "7 Conditionals",
    "text": "7 Conditionals\n\n7.1 Task 9 Solution\nPredict and verify the conditional statement:\n\n# Prediction: x will be \"goodbye\"\n# Reasoning: x = 2, so x &lt; 2 is False, but x &lt; 3 is True\n\n# Run the code:\nx = 2\n\nif x &lt; 2:\n    x = \"hello\"\nelif x &lt; 3:\n    x = \"goodbye\"\nelse:\n    x = \"take care\"\n\nprint(\"Result:\", x)\n\nResult: goodbye\n\n\nExplanation: Since x = 2: - x &lt; 2 is False (2 is not less than 2) - x &lt; 3 is True (2 is less than 3) - So the elif condition executes, setting x = \"goodbye\""
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#functions",
    "href": "files/labs/lab2/lab2_sln.html#functions",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "8 Functions",
    "text": "8 Functions\n\n8.1 Task 10 Solution\nThree functions we‚Äôve used in this Lab:\n# Three functions used in this lab:\n# 1. type() - returns the data type of an object\n# 2. print() - displays output to the screen\n# 3. make_array() - creates an array from the given elements\n# Additional: sum(), len(), range()\n\n\n8.2 Task 11 Solution\nWrite a Celsius to Fahrenheit conversion function:\n\n# Solution\ndef cent_to_far(c):\n    \"\"\"Convert Celsius to Fahrenheit using the formula F = (9/5) * C + 32\"\"\"\n    fahrenheit = (9/5) * c + 32\n    return fahrenheit\n\n# Test the function\nprint(\"cent_to_far(0):\", cent_to_far(0))    # Should return 32\nprint(\"cent_to_far(20):\", cent_to_far(20))  # Should return 68\n\ncent_to_far(0): 32.0\ncent_to_far(20): 68.0\n\n\nExplanation: The conversion formula is F = (9/5) √ó C + 32. Our function correctly implements this formula.\n\n\n8.3 Task 12 Solution\nWrite a parity function to determine if a number is even or odd:\n\n# Solution\ndef parity(x):\n    \"\"\"Returns 'even' if x is even, 'odd' if x is odd\"\"\"\n    if x % 2 == 0:\n        return \"even\"\n    else:\n        return \"odd\"\n\n# Test the function\nprint(\"parity(2):\", parity(2))  # Should return 'even'\nprint(\"parity(3):\", parity(3))  # Should return 'odd'\n\n# Additional tests\nprint(\"parity(10):\", parity(10))\nprint(\"parity(15):\", parity(15))\n\nparity(2): even\nparity(3): odd\nparity(10): even\nparity(15): odd\n\n\nExplanation: The modulus operator % returns the remainder of division. If x % 2 == 0, then x is divisible by 2 (even). Otherwise, it‚Äôs odd."
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#complete-examples-and-additional-practice",
    "href": "files/labs/lab2/lab2_sln.html#complete-examples-and-additional-practice",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "9 Complete Examples and Additional Practice",
    "text": "9 Complete Examples and Additional Practice\nHere are some additional examples that demonstrate the concepts:\n\n9.1 Advanced List Operations\n\n# List slicing examples\nnumbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nprint(\"First 5 elements:\", numbers[:5])\nprint(\"Last 3 elements:\", numbers[-3:])\nprint(\"Every other element:\", numbers[::2])\n\nFirst 5 elements: [0, 1, 2, 3, 4]\nLast 3 elements: [7, 8, 9]\nEvery other element: [0, 2, 4, 6, 8]\n\n\n\n\n9.2 Table Operations\n\n# More complex table operations\nstudents = Table().with_columns(\n    \"Name\", [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"],\n    \"Grade\", [85, 92, 78, 96],\n    \"Year\", [\"Sophomore\", \"Junior\", \"Freshman\", \"Senior\"]\n)\n\n# Multiple operations\nhigh_performers = students.where(\"Grade\", are.above(90))\nprint(\"High performers:\")\nhigh_performers.show()\n\n# Sort by grade\nsorted_students = students.sort(\"Grade\", descending=True)\nprint(\"\\nStudents sorted by grade:\")\nsorted_students.show()\n\nHigh performers:\n\n\n\n\n\nName\nGrade\nYear\n\n\n\n\nBob\n92\nJunior\n\n\nDiana\n96\nSenior\n\n\n\n\n\n\nStudents sorted by grade:\n\n\n\n\n\nName\nGrade\nYear\n\n\n\n\nDiana\n96\nSenior\n\n\nBob\n92\nJunior\n\n\nAlice\n85\nSophomore\n\n\nCharlie\n78\nFreshman\n\n\n\n\n\n\n\n9.3 Array Operations\n\nimport numpy as np\n\n# Array mathematical operations\nscores = make_array(85, 92, 78, 96, 89)\nprint(\"Original scores:\", scores)\nprint(\"Curved scores (+5):\", scores + 5)\nprint(\"Squared scores:\", scores ** 2)\nprint(\"Average score:\", np.mean(scores))\n\nOriginal scores: [85 92 78 96 89]\nCurved scores (+5): [ 90  97  83 101  94]\nSquared scores: [7225 8464 6084 9216 7921]\nAverage score: 88.0"
  },
  {
    "objectID": "files/labs/lab2/lab2_sln.html#summary",
    "href": "files/labs/lab2/lab2_sln.html#summary",
    "title": "Lab 2 Solutions: Data Classes and Programming Fundamentals",
    "section": "10 Summary",
    "text": "10 Summary\nThis lab covered fundamental Python data structures and programming concepts:\n\nLists: Mutable, mixed-type collections with zero-based indexing\nTables: Structured data with named columns for data analysis\nArrays: Homogeneous collections supporting element-wise operations\nComparisons: Boolean logic and various comparison operators\nConditionals: Decision-making with if/elif/else statements\nFunctions: Creating reusable code blocks with proper documentation\n\nThese concepts form the foundation for data analysis and programming in Python!"
  },
  {
    "objectID": "files/worksheets/worksheet3.html",
    "href": "files/worksheets/worksheet3.html",
    "title": "PSTAT 5A Practice Worksheet",
    "section": "",
    "text": "‚è∞ Time Allocation: - Section A (Warm-up): 15 minutes\n\nSection B (Intermediate): 25 minutes\nSection C (Advanced): 20 minutes\nSection D (Variance Practice): 20 minutes\nTotal: 60 minutes\n\n\n\nüìù Important Instructions:\n\nShow all work clearly for full credit\nPartial credit awarded for correct methodology\nRound final answers to 4 decimal places unless otherwise specified\nIdentify your approach before calculating\nUse calculator and probability tables as needed\n\n\n\nüìö Key Formulas Reference:\nBasic Probability:\n\nConditional Probability: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nBayes‚Äô Theorem: \\(P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\\)\nLaw of Total Probability: \\(P(A) = \\sum P(A|B_i) \\cdot P(B_i)\\)\n\nCounting:\n\nPermutations: \\(P(n,r) = \\frac{n!}{(n-r)!}\\)\nCombinations: \\(C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\)\n\nDiscrete Random Variables:\n\nBinomial PMF: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\)\nPoisson PMF: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\)\nExpected Value: \\(E[X] = \\sum x \\cdot P(X = x)\\)\nVariance: \\(\\text{Var}(X) = E[X^2] - (E[X])^2\\)\n\nVariance Formulas:\n\nPopulation Variance: \\(\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\)\nSample Variance: \\(s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\)\nVariance of Sample Mean: \\(\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\)\nStandard Error: \\(SE(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\\)"
  },
  {
    "objectID": "files/worksheets/worksheet3.html#understanding-variance-population-vs-sample",
    "href": "files/worksheets/worksheet3.html#understanding-variance-population-vs-sample",
    "title": "PSTAT 5A Practice Worksheet",
    "section": "5.1 Understanding Variance: Population vs Sample",
    "text": "5.1 Understanding Variance: Population vs Sample\n\nüéØ Key Variance Concepts:\nPopulation Variance (when you have ALL data): \\[\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\]\nSample Variance (when you have a sample): \\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\]\nWhy (n-1)? Using the sample mean to estimate deviations ‚Äúuses up‚Äù one degree of freedom.\nVariance of Sample Mean: \\[\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}\\]\nStandard Error (Standard Deviation of Sample Mean): \\[SE(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\\]\n\n\nProblem D1: Basic Variance Calculations (6 points)\nThe following data represents the number of customer complaints per day for a small business over 8 days:\nData: 3, 7, 2, 8, 5, 6, 4, 9\nPart (a) [1 point]: Calculate the sample mean \\(\\bar{x}\\).\nPart (b) [2 points]: Calculate the sample variance \\(s^2\\) using the formula with \\((n-1)\\) in the denominator.\nPart (c) [1 point]: Calculate the sample standard deviation \\(s\\).\nPart (d) [1 point]: If this were treated as a complete population, what would the population variance \\(\\sigma^2\\) be?\nPart (e) [1 point]: Explain why we divide by \\((n-1)\\) for sample variance instead of \\(n\\).\nWork Space:\n\n\n\nProblem D2: Sample Mean Distribution (8 points)\nA factory produces bolts with a mean length of 5.0 cm and standard deviation of 0.2 cm. Quality control takes random samples to monitor production.\nPart (a) [1 point]: If a sample of 16 bolts is taken, what is the expected value of the sample mean \\(\\bar{X}\\)?\nPart (b) [1.5 points]: What is the variance of the sample mean \\(\\text{Var}(\\bar{X})\\)?\nPart (c) [1 point]: What is the standard error of the sample mean?\nPart (d) [1.5 points]: If the sample size is increased to 64 bolts, how does this change the standard error?\nPart (e) [1.5 points - Conceptual]: Explain why the variance of the sample mean decreases as sample size increases.\nPart (f) [1.5 points - Application]: What sample size would be needed to reduce the standard error to 0.025 cm?\nWork Space:\n\n\n\nProblem D3: Variance Properties with Random Variables (6 points)\nConsider two independent random variables: - \\(X \\sim \\text{Binomial}(20, 0.3)\\)\n- \\(Y \\sim \\text{Poisson}(4)\\)\nDefine \\(Z = 2X + 3Y - 5\\).\nPart (a) [2 points]: Find \\(E[X]\\), \\(\\text{Var}(X)\\), \\(E[Y]\\), and \\(\\text{Var}(Y)\\).\nPart (b) [1.5 points]: Calculate \\(E[Z]\\) using properties of expectation.\nPart (c) [2 points]: Calculate \\(\\text{Var}(Z)\\) using properties of variance.\nPart (d) [0.5 points]: What is the standard deviation of \\(Z\\)?\nWork Space:\n\n\n\nProblem D4: Real-World Variance Application (7 points)\nA pharmaceutical company tests the effectiveness of a new drug. They measure the reduction in symptoms (in points) for patients taking the drug. Historical data shows that symptom reduction follows a distribution with mean Œº = 12 points and standard deviation œÉ = 4 points.\nPart (a) [1 point]: If they test the drug on a sample of 25 patients, what is the expected value of the average symptom reduction?\nPart (b) [1.5 points]: What is the standard error of the sample mean?\nPart (c) [1.5 points]: The company wants the standard error to be no more than 0.5 points. What minimum sample size is required?\nPart (d) [2 points - Practical Interpretation]: If the company observes a sample mean of 13.2 points from 25 patients, calculate how many standard errors this is above the expected value. Is this result likely due to random variation?\nPart (e) [1 point - Study Design]: The company is designing a larger study. If they want to detect a true difference of 1 point from the historical mean with a standard error of 0.3, what sample size should they use?\nWork Space:"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html",
    "href": "files/lecture_notes/lecture5/lecture5.html",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "",
    "text": "By the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#welcome-to-lecture-5",
    "href": "files/lecture_notes/lecture5/lecture5.html#welcome-to-lecture-5",
    "title": "PSTAT 5A: Counting",
    "section": "",
    "text": "Counting\nThe art and science of systematic enumeration"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture5/lecture5.html#todays-learning-objectives",
    "title": "PSTAT 5A: Counting",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nApply the fundamental counting principles\nCalculate permutations with and without repetition\nCalculate combinations and understand when to use them\nDistinguish between permutations and combinations\nUse counting techniques to solve probability problems\nApply the inclusion-exclusion principle\nSolve complex counting problems systematically"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#why-study-counting",
    "href": "files/lecture_notes/lecture5/lecture5.html#why-study-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Why Study Counting?",
    "text": "Why Study Counting?\nCounting helps us:\n\nCalculate probabilities for complex events\nSolve optimization problems\nUnderstand combinations in genetics, computer science\nAnalyze algorithms and data structures\nMake decisions involving arrangements and selections\n\n\nApplications: Cryptography, genetics, tournament brackets, lottery odds, password security"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#the-fundamental-counting-principle",
    "href": "files/lecture_notes/lecture5/lecture5.html#the-fundamental-counting-principle",
    "title": "PSTAT 5A: Counting",
    "section": "The Fundamental Counting Principle",
    "text": "The Fundamental Counting Principle\nMultiplication Rule: If a procedure consists of \\(k\\) separate tasks where: - Task 1 can be performed in \\(n_1\\) ways - Task 2 can be performed in \\(n_2\\) ways - ‚Ä¶ - Task \\(k\\) can be performed in \\(n_k\\) ways\nThen the entire procedure can be performed in \\(n_1 \\times n_2 \\times \\cdots \\times n_k\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#simple-counting-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#simple-counting-example",
    "title": "PSTAT 5A: Counting",
    "section": "Simple Counting Example",
    "text": "Simple Counting Example\nLicense Plates: Format ABC-123 - First position: 26 letters - Second position: 26 letters\n- Third position: 26 letters - Fourth position: 10 digits - Fifth position: 10 digits - Sixth position: 10 digits\n\nTotal possibilities: \\(26 \\times 26 \\times 26 \\times 10 \\times 10 \\times 10 = 26^3 \\times 10^3 = 17,576,000\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#restaurant-menu-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#restaurant-menu-example",
    "title": "PSTAT 5A: Counting",
    "section": "Restaurant Menu Example",
    "text": "Restaurant Menu Example\nA restaurant offers: - 4 appetizers - 6 main courses\n- 3 desserts\nHow many different three-course meals are possible?\n\nSolution: \\(4 \\times 6 \\times 3 = 72\\) different meals"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-1",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\n\n\n\nA standard deck has 52 cards. What is the probability of drawing:\n\nA heart \\(\\heartsuit\\)?\nA face card (Jack, Queen, King)?\nThe ace of spades \\(\\spadesuit\\)?\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{heart}) = \\frac{13}{52} = \\frac{1}{4}\\)\n\\(P(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\\)\n\\(P(\\text{ace of spades}) = \\frac{1}{52}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#what-are-permutations",
    "href": "files/lecture_notes/lecture5/lecture5.html#what-are-permutations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Permutations?",
    "text": "What Are Permutations?\nPermutation: An arrangement of objects where order matters\n\nExamples where order matters: - Race finish positions (1st, 2nd, 3rd) - Seating arrangements - Passwords - DNA sequences"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#permutations-of-n-distinct-objects",
    "href": "files/lecture_notes/lecture5/lecture5.html#permutations-of-n-distinct-objects",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(n\\) Distinct Objects",
    "text": "Permutations of \\(n\\) Distinct Objects\nThe number of ways to arrange \\(n\\) distinct objects is:\n\\[n! = n \\times (n-1) \\times (n-2) \\times \\cdots \\times 2 \\times 1\\]\n\nExample: How many ways can 5 people sit in a row?\n\\(5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#factorial-values",
    "href": "files/lecture_notes/lecture5/lecture5.html#factorial-values",
    "title": "PSTAT 5A: Counting",
    "section": "Factorial Values",
    "text": "Factorial Values\n\n\n\n\\(n\\)\n\\(n!\\)\n\n\n\n\n0\n1\n\n\n1\n1\n\n\n2\n2\n\n\n3\n6\n\n\n4\n24\n\n\n5\n120\n\n\n10\n3,628,800\n\n\n\n\nNote: \\(0! = 1\\) by definition"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#permutations-of-r-objects-from-n",
    "href": "files/lecture_notes/lecture5/lecture5.html#permutations-of-r-objects-from-n",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations of \\(r\\) Objects from \\(n\\)",
    "text": "Permutations of \\(r\\) Objects from \\(n\\)\n\\(P(n,r)\\) or \\(_nP_r\\): Number of ways to arrange \\(r\\) objects selected from \\(n\\) distinct objects\n\\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\nExample: How many ways can we select and arrange 3 people from a group of 8 for president, vice-president, and secretary?\n\\(P(8,3) = \\frac{8!}{(8-3)!} = \\frac{8!}{5!} = 8 \\times 7 \\times 6 = 336\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#understanding-pnr",
    "href": "files/lecture_notes/lecture5/lecture5.html#understanding-pnr",
    "title": "PSTAT 5A: Counting",
    "section": "Understanding \\(P(n,r)\\)",
    "text": "Understanding \\(P(n,r)\\)\nWhy is \\(P(n,r) = \\frac{n!}{(n-r)!}\\)?\n\nFirst position: \\(n\\) choices\nSecond position: \\((n-1)\\) choices\n\nThird position: \\((n-2)\\) choices\n‚Ä¶\n\\(r\\)-th position: \\((n-r+1)\\) choices\n\n\nTotal: \\(n \\times (n-1) \\times (n-2) \\times \\cdots \\times (n-r+1) = \\frac{n!}{(n-r)!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-2",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-2",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\nA baseball team has 15 players. How many ways can the coach:\n\nArrange all 15 players in a line?\nChoose and arrange 9 players for the starting lineup (batting order matters)?\n\n\nSolutions: a) \\(15! = 1,307,674,368,000\\) b) \\(P(15,9) = \\frac{15!}{6!} = 1,816,214,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#permutations-with-repetition",
    "href": "files/lecture_notes/lecture5/lecture5.html#permutations-with-repetition",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition",
    "text": "Permutations with Repetition\nWhen some objects are identical, we have fewer distinct arrangements\nIf we have \\(n\\) objects where: - \\(n_1\\) are of type 1 - \\(n_2\\) are of type 2\n- ‚Ä¶ - \\(n_k\\) are of type \\(k\\)\nNumber of distinct arrangements: \\(\\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#permutations-with-repetition-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#permutations-with-repetition-example",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Repetition Example",
    "text": "Permutations with Repetition Example\nHow many distinct arrangements are there of the letters in ‚ÄúSTATISTICS‚Äù?\nS-T-A-T-I-S-T-I-C-S - Total letters: 10 - S appears 3 times - T appears 3 times\n- A appears 1 time - I appears 2 times - C appears 1 time\n\n\\(\\frac{10!}{3! \\times 3! \\times 1! \\times 2! \\times 1!} = \\frac{3,628,800}{6 \\times 6 \\times 1 \\times 2 \\times 1} = \\frac{3,628,800}{72} = 50,400\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#what-are-combinations",
    "href": "files/lecture_notes/lecture5/lecture5.html#what-are-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "What Are Combinations?",
    "text": "What Are Combinations?\nCombination: A selection of objects where order does NOT matter\n\nExamples where order doesn‚Äôt matter: - Choosing committee members - Selecting pizza toppings - Forming study groups - Lottery number selection"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#combinations-formula",
    "href": "files/lecture_notes/lecture5/lecture5.html#combinations-formula",
    "title": "PSTAT 5A: Counting",
    "section": "Combinations Formula",
    "text": "Combinations Formula\n\\(C(n,r)\\) or \\(\\binom{n}{r}\\): Number of ways to choose \\(r\\) objects from \\(n\\) distinct objects (order doesn‚Äôt matter)\n\\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]\n\nExample: How many ways can we choose 3 people from a group of 8 for a committee?\n\\(C(8,3) = \\frac{8!}{3!(8-3)!} = \\frac{8!}{3! \\times 5!} = \\frac{8 \\times 7 \\times 6}{3 \\times 2 \\times 1} = 56\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#relationship-permutations-vs-combinations",
    "href": "files/lecture_notes/lecture5/lecture5.html#relationship-permutations-vs-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "Relationship: Permutations vs Combinations",
    "text": "Relationship: Permutations vs Combinations\n\\[P(n,r) = C(n,r) \\times r!\\]\nWhy? For each combination of \\(r\\) objects, there are \\(r!\\) ways to arrange them\n\nExample: \\(P(8,3) = C(8,3) \\times 3! = 56 \\times 6 = 336\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#key-decision-permutation-or-combination",
    "href": "files/lecture_notes/lecture5/lecture5.html#key-decision-permutation-or-combination",
    "title": "PSTAT 5A: Counting",
    "section": "Key Decision: Permutation or Combination?",
    "text": "Key Decision: Permutation or Combination?\nAsk yourself: Does order matter?\nOrder matters ‚Üí Use Permutations - Arrangements, sequences, rankings\nOrder doesn‚Äôt matter ‚Üí Use Combinations\n- Selections, groups, subsets"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-3",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-3",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\nFrom a class of 20 students:\n\nHow many ways to choose 5 students for a study group?\nHow many ways to choose a president, vice-president, and secretary?\nHow many ways to arrange all 20 students in a circle?\n\n\nSolutions: a) \\(C(20,5) = \\frac{20!}{5! \\times 15!} = 15,504\\) (order doesn‚Äôt matter) b) \\(P(20,3) = \\frac{20!}{17!} = 6,840\\) (order matters) c) \\((20-1)! = 19!\\) (circular permutation)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#properties-of-combinations",
    "href": "files/lecture_notes/lecture5/lecture5.html#properties-of-combinations",
    "title": "PSTAT 5A: Counting",
    "section": "Properties of Combinations",
    "text": "Properties of Combinations\n\nSymmetry: \\(\\binom{n}{r} = \\binom{n}{n-r}\\)\nPascal‚Äôs Identity: \\(\\binom{n}{r} = \\binom{n-1}{r-1} + \\binom{n-1}{r}\\)\nBoundary conditions: \\(\\binom{n}{0} = \\binom{n}{n} = 1\\)\n\n\nExample: \\(\\binom{8}{3} = \\binom{8}{5} = 56\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#pascals-triangle",
    "href": "files/lecture_notes/lecture5/lecture5.html#pascals-triangle",
    "title": "PSTAT 5A: Counting",
    "section": "Pascal‚Äôs Triangle",
    "text": "Pascal‚Äôs Triangle\n           1\n         1   1\n       1   2   1\n     1   3   3   1\n   1   4   6   4   1\n 1   5  10  10   5   1\n1   6  15  20  15   6   1\nEach number is \\(\\binom{n}{r}\\) where \\(n\\) is the row and \\(r\\) is the position"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#binomial-theorem",
    "href": "files/lecture_notes/lecture5/lecture5.html#binomial-theorem",
    "title": "PSTAT 5A: Counting",
    "section": "Binomial Theorem",
    "text": "Binomial Theorem\n\\[(x + y)^n = \\sum_{r=0}^{n} \\binom{n}{r} x^{n-r} y^r\\]\n\nExample: \\((x + y)^3 = \\binom{3}{0}x^3 + \\binom{3}{1}x^2y + \\binom{3}{2}xy^2 + \\binom{3}{3}y^3\\)\n\\(= x^3 + 3x^2y + 3xy^2 + y^3\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#counting-and-probability",
    "href": "files/lecture_notes/lecture5/lecture5.html#counting-and-probability",
    "title": "PSTAT 5A: Counting",
    "section": "Counting and Probability",
    "text": "Counting and Probability\nExample: A committee of 4 people is chosen from 7 women and 5 men. What‚Äôs the probability that exactly 2 are women?\nTotal ways to choose 4 from 12: \\(\\binom{12}{4} = 495\\)\nWays to choose 2 women from 7: \\(\\binom{7}{2} = 21\\) Ways to choose 2 men from 5: \\(\\binom{5}{2} = 10\\)\n\nFavorable outcomes: \\(\\binom{7}{2} \\times \\binom{5}{2} = 21 \\times 10 = 210\\)\nProbability: \\(\\frac{210}{495} = \\frac{14}{33}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-4",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-4",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\nA standard deck has 52 cards. What‚Äôs the probability that a 5-card hand contains:\n\nExactly 3 aces?\nAt least 1 ace?\n\n\n\nWays to get 3 aces from 4: \\(\\binom{4}{3} = 4\\) Ways to get 2 non-aces from 48: \\(\\binom{48}{2} = 1,128\\) Total 5-card hands: \\(\\binom{52}{5} = 2,598,960\\)\nProbability: \\(\\frac{4 \\times 1,128}{2,598,960} = \\frac{4,512}{2,598,960} \\approx 0.00174\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-4-continued",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-4-continued",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 4 (continued)",
    "text": "Practice Problem 4 (continued)\n\nAt least 1 ace = 1 - (no aces)\n\nWays to choose 5 cards with no aces: \\(\\binom{48}{5} = 1,712,304\\)\n\n\\(P(\\text{at least 1 ace}) = 1 - \\frac{\\binom{48}{5}}{\\binom{52}{5}} = 1 - \\frac{1,712,304}{2,598,960} \\approx 0.341\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#circular-permutations",
    "href": "files/lecture_notes/lecture5/lecture5.html#circular-permutations",
    "title": "PSTAT 5A: Counting",
    "section": "Circular Permutations",
    "text": "Circular Permutations\nWhen arranging objects in a circle, we fix one object to eliminate rotational symmetry\nNumber of circular permutations of \\(n\\) objects: \\((n-1)!\\)\n\nExample: How many ways can 6 people sit around a circular table?\n\\((6-1)! = 5! = 120\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#permutations-with-restrictions",
    "href": "files/lecture_notes/lecture5/lecture5.html#permutations-with-restrictions",
    "title": "PSTAT 5A: Counting",
    "section": "Permutations with Restrictions",
    "text": "Permutations with Restrictions\nExample: How many 6-letter ‚Äúwords‚Äù can be formed from the letters A, B, C, D, E, F if: - No letter is repeated - A and B must be adjacent\n\nSolution: Treat AB as a single unit - 5 units to arrange: (AB), C, D, E, F ‚Üí \\(5! = 120\\) ways - A and B can be arranged within their unit: \\(2! = 2\\) ways - Total: \\(5! \\times 2! = 240\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#the-inclusion-exclusion-principle",
    "href": "files/lecture_notes/lecture5/lecture5.html#the-inclusion-exclusion-principle",
    "title": "PSTAT 5A: Counting",
    "section": "The Inclusion-Exclusion Principle",
    "text": "The Inclusion-Exclusion Principle\nFor two sets \\(A\\) and \\(B\\): \\[|A \\cup B| = |A| + |B| - |A \\cap B|\\]\nFor three sets \\(A\\), \\(B\\), and \\(C\\): \\[|A \\cup B \\cup C| = |A| + |B| + |C| - |A \\cap B| - |A \\cap C| - |B \\cap C| + |A \\cap B \\cap C|\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#inclusion-exclusion-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#inclusion-exclusion-example",
    "title": "PSTAT 5A: Counting",
    "section": "Inclusion-Exclusion Example",
    "text": "Inclusion-Exclusion Example\nHow many integers from 1 to 100 are divisible by 2, 3, or 5?\nLet: - \\(A\\) = divisible by 2: \\(|A| = 50\\) - \\(B\\) = divisible by 3: \\(|B| = 33\\)\n- \\(C\\) = divisible by 5: \\(|C| = 20\\)\n\n\\(|A \\cap B| = 16\\) (divisible by 6) \\(|A \\cap C| = 10\\) (divisible by 10) \\(|B \\cap C| = 6\\) (divisible by 15) \\(|A \\cap B \\cap C| = 3\\) (divisible by 30)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#inclusion-exclusion-solution",
    "href": "files/lecture_notes/lecture5/lecture5.html#inclusion-exclusion-solution",
    "title": "PSTAT 5A: Counting",
    "section": "Inclusion-Exclusion Solution",
    "text": "Inclusion-Exclusion Solution\n\\[|A \\cup B \\cup C| = 50 + 33 + 20 - 16 - 10 - 6 + 3 = 74\\]\n\nAnswer: 74 integers from 1 to 100 are divisible by at least one of 2, 3, or 5"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#derangements",
    "href": "files/lecture_notes/lecture5/lecture5.html#derangements",
    "title": "PSTAT 5A: Counting",
    "section": "Derangements",
    "text": "Derangements\nA derangement is a permutation where no object appears in its original position\nNumber of derangements of \\(n\\) objects: \\[D_n = n! \\sum_{k=0}^{n} \\frac{(-1)^k}{k!} \\approx \\frac{n!}{e}\\]\n\nExample: How many ways can 4 people return hats to the wrong owners?\n\\(D_4 = 4! \\left(\\frac{1}{0!} - \\frac{1}{1!} + \\frac{1}{2!} - \\frac{1}{3!} + \\frac{1}{4!}\\right) = 24 \\times \\frac{9}{24} = 9\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#multinomial-coefficients",
    "href": "files/lecture_notes/lecture5/lecture5.html#multinomial-coefficients",
    "title": "PSTAT 5A: Counting",
    "section": "Multinomial Coefficients",
    "text": "Multinomial Coefficients\nNumber of ways to divide \\(n\\) objects into groups of sizes \\(n_1, n_2, \\ldots, n_k\\):\n\\[\\binom{n}{n_1, n_2, \\ldots, n_k} = \\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\]\n\nExample: How many ways can 12 people be divided into 3 teams of 4?\n\\(\\binom{12}{4,4,4} = \\frac{12!}{4! \\times 4! \\times 4!} = 34,650\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#stars-and-bars",
    "href": "files/lecture_notes/lecture5/lecture5.html#stars-and-bars",
    "title": "PSTAT 5A: Counting",
    "section": "Stars and Bars",
    "text": "Stars and Bars\nProblem: Number of ways to distribute \\(n\\) identical objects into \\(k\\) distinct bins\nSolution: \\(\\binom{n+k-1}{k-1}\\) or \\(\\binom{n+k-1}{n}\\)\n\nExample: How many ways can you distribute 10 identical candies to 4 children?\n\\(\\binom{10+4-1}{4-1} = \\binom{13}{3} = 286\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-5",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-5",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 5",
    "text": "Practice Problem 5\nA pizza shop offers 12 toppings. How many different pizzas can you order if:\n\nYou want exactly 4 toppings?\nYou want at most 3 toppings?\nYou want at least 1 topping?\n\n\nSolutions: a) \\(\\binom{12}{4} = 495\\) b) \\(\\binom{12}{0} + \\binom{12}{1} + \\binom{12}{2} + \\binom{12}{3} = 1 + 12 + 66 + 220 = 299\\) c) \\(2^{12} - 1 = 4,095\\) (all subsets except empty set)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#advanced-counting-stirling-numbers",
    "href": "files/lecture_notes/lecture5/lecture5.html#advanced-counting-stirling-numbers",
    "title": "PSTAT 5A: Counting",
    "section": "Advanced Counting: Stirling Numbers",
    "text": "Advanced Counting: Stirling Numbers\nStirling numbers of the second kind \\(S(n,k)\\): Number of ways to partition \\(n\\) objects into \\(k\\) non-empty subsets\nBell numbers \\(B_n\\): Total number of ways to partition \\(n\\) objects \\[B_n = \\sum_{k=0}^{n} S(n,k)\\]\nThese are advanced topics for further study"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture5/lecture5.html#problem-solving-strategy",
    "title": "PSTAT 5A: Counting",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\nRead carefully: What exactly are we counting?\nIdentify the type: Permutation, combination, or other?\nCheck for restrictions: Are there constraints?\nDoes order matter?: This determines permutation vs combination\nBreak down complex problems: Use multiplication principle\nVerify your answer: Does it make sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-mistakes-to-avoid",
    "title": "PSTAT 5A: Counting",
    "section": "Common Mistakes to Avoid",
    "text": "Common Mistakes to Avoid\n\nConfusing permutations and combinations\n\nAlways ask: ‚ÄúDoes order matter?‚Äù\n\nForgetting about restrictions\n\nRead the problem carefully\n\nDouble counting\n\nMake sure you‚Äôre not counting the same arrangement twice\n\nNot considering the complement\n\nSometimes ‚Äúat least‚Äù problems are easier using complements"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-6",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-6",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\nA class has 15 students: 8 women and 7 men. How many ways can we:\n\nForm a committee of 5 people with exactly 3 women?\nArrange 6 people in a row with alternating genders (starting with a woman)?\n\n\nSolutions: a) \\(\\binom{8}{3} \\times \\binom{7}{2} = 56 \\times 21 = 1,176\\) b) Choose 3 women from 8: \\(P(8,3) = 336\\) Choose 3 men from 7: \\(P(7,3) = 210\\) Total: \\(336 \\times 210 = 70,560\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#counting-in-computer-science",
    "href": "files/lecture_notes/lecture5/lecture5.html#counting-in-computer-science",
    "title": "PSTAT 5A: Counting",
    "section": "Counting in Computer Science",
    "text": "Counting in Computer Science\nPassword Security: - 8-character password with letters, digits, symbols - \\((26 + 26 + 10 + 32)^8 = 94^8 \\approx 6.1 \\times 10^{15}\\)\nHash Functions: - Distributing data into buckets - Collision probability calculations\nAlgorithm Analysis: - Counting operations, comparisons - Big O notation foundations"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#counting-in-genetics",
    "href": "files/lecture_notes/lecture5/lecture5.html#counting-in-genetics",
    "title": "PSTAT 5A: Counting",
    "section": "Counting in Genetics",
    "text": "Counting in Genetics\nDNA Sequences: - 4 bases (A, T, G, C) - Gene of length \\(n\\): \\(4^n\\) possible sequences\nProtein Folding: - Number of possible conformations - Combinatorial explosion\nPopulation Genetics: - Hardy-Weinberg calculations - Allele combinations"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#real-world-applications",
    "href": "files/lecture_notes/lecture5/lecture5.html#real-world-applications",
    "title": "PSTAT 5A: Counting",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nLottery: - Powerball: Choose 5 from 69, then 1 from 26 - Odds: \\(\\frac{1}{\\binom{69}{5} \\times 26} \\approx \\frac{1}{292,000,000}\\)\nCryptography: - Key space size determines security - RSA encryption relies on large number factorization\nSports Tournaments: - March Madness bracket: \\(2^{63}\\) possible outcomes - Round-robin tournaments: \\(\\binom{n}{2}\\) games"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture5/lecture5.html#key-formulas-summary",
    "title": "PSTAT 5A: Counting",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\nPermutations: \\(P(n,r) = \\frac{n!}{(n-r)!}\\)\nCombinations: \\(C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\)\nWith repetition: \\(\\frac{n!}{n_1! \\times n_2! \\times \\cdots \\times n_k!}\\)\nCircular: \\((n-1)!\\)\nInclusion-Exclusion: \\(|A \\cup B| = |A| + |B| - |A \\cap B|\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#technology-and-counting",
    "href": "files/lecture_notes/lecture5/lecture5.html#technology-and-counting",
    "title": "PSTAT 5A: Counting",
    "section": "Technology and Counting",
    "text": "Technology and Counting\nCalculators: - Use nPr and nCr functions - Be careful with large numbers\nSoftware: - R: factorial(), choose(), combn() - Python: math.factorial(), math.comb() - Excel: FACT(), COMBIN(), PERMUT()\nOnline Tools: - Wolfram Alpha for complex calculations - Combination/permutation calculators"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#practice-problem-7",
    "href": "files/lecture_notes/lecture5/lecture5.html#practice-problem-7",
    "title": "PSTAT 5A: Counting",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\nA standard deck of cards is shuffled. What‚Äôs the probability that:\n\nThe top 4 cards are all hearts?\nIn a 13-card hand, you get exactly one card from each rank?\n\n\nSolutions: a) \\(\\frac{13}{52} \\times \\frac{12}{51} \\times \\frac{11}{50} \\times \\frac{10}{49} = \\frac{13 \\times 12 \\times 11 \\times 10}{52 \\times 51 \\times 50 \\times 49} \\approx 0.0026\\)\n\nChoose 1 card from each of 13 ranks: \\(4^{13}\\) Total 13-card hands: \\(\\binom{52}{13}\\) Probability: \\(\\frac{4^{13}}{\\binom{52}{13}} \\approx 6.3 \\times 10^{-6}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#extending-to-probability",
    "href": "files/lecture_notes/lecture5/lecture5.html#extending-to-probability",
    "title": "PSTAT 5A: Counting",
    "section": "Extending to Probability",
    "text": "Extending to Probability\nHypergeometric Distribution: - Drawing without replacement - Uses combinations: \\(P(X = k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}\\)\nBinomial Distribution: - Drawing with replacement\n- Uses combinations: \\(P(X = k) = \\binom{n}{k}p^k(1-p)^{n-k}\\)\nWe‚Äôll explore these distributions in detail in future lectures"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#historical-note",
    "href": "files/lecture_notes/lecture5/lecture5.html#historical-note",
    "title": "PSTAT 5A: Counting",
    "section": "Historical Note",
    "text": "Historical Note\nBlaise Pascal (1623-1662) and Pierre de Fermat (1601-1665): - Founded probability theory through gambling problems - Pascal‚Äôs triangle and combinations\nLeonhard Euler (1707-1783): - Advanced combinatorics - Graph theory connections\nModern applications span computer science, biology, physics, and economics"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#common-student-questions",
    "href": "files/lecture_notes/lecture5/lecture5.html#common-student-questions",
    "title": "PSTAT 5A: Counting",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: ‚ÄúWhen do I use permutations vs combinations?‚Äù A: Ask ‚ÄúDoes order matter?‚Äù Order matters ‚Üí permutation\nQ: ‚ÄúHow do I handle restrictions?‚Äù A: Break the problem into cases or use complementary counting\nQ: ‚ÄúWhat if objects are identical?‚Äù A: Use the formula for permutations with repetition\nQ: ‚ÄúHow do I check my answer?‚Äù A: Verify with small examples or use different methods"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#looking-ahead",
    "href": "files/lecture_notes/lecture5/lecture5.html#looking-ahead",
    "title": "PSTAT 5A: Counting",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture: Discrete Probability Distributions - Binomial distribution (using combinations!) - Hypergeometric distribution\n- Geometric distribution - Expected value and variance\nConnection: Today‚Äôs counting techniques are essential for probability calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#study-tips",
    "href": "files/lecture_notes/lecture5/lecture5.html#study-tips",
    "title": "PSTAT 5A: Counting",
    "section": "Study Tips",
    "text": "Study Tips\n\nPractice, practice, practice: Work through many examples\nIdentify patterns: Learn to recognize problem types\nStart simple: Build up to complex problems\nCheck your work: Use different approaches when possible\nUnderstand concepts: Don‚Äôt just memorize formulas"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#final-thoughts",
    "href": "files/lecture_notes/lecture5/lecture5.html#final-thoughts",
    "title": "PSTAT 5A: Counting",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nCounting is fundamental to: - Probability calculations - Statistical inference\n- Computer algorithms - Scientific modeling\n\nMaster the basics: Permutations and combinations are the building blocks for advanced statistical concepts"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#questions",
    "href": "files/lecture_notes/lecture5/lecture5.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday‚Äôs 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Conditional Probability & Bayes Theorem"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#bonus-large-number-approximations",
    "href": "files/lecture_notes/lecture5/lecture5.html#bonus-large-number-approximations",
    "title": "PSTAT 5A: Counting",
    "section": "Bonus: Large Number Approximations",
    "text": "Bonus: Large Number Approximations\nStirling‚Äôs Approximation: \\(n! \\approx \\sqrt{2\\pi n} \\left(\\frac{n}{e}\\right)^n\\)\nNormal Approximation: For large \\(n\\), \\(\\binom{n}{k} \\approx \\frac{1}{\\sqrt{2\\pi n p(1-p)}} \\exp\\left(-\\frac{(k-np)^2}{2np(1-p)}\\right)\\)\nUseful for computational purposes when exact values are too large"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html",
    "href": "files/lecture_notes/lecture6/lecture6.html",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "",
    "text": "Conditional Probabilities\nUnderstanding probability when information changes the game"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#welcome-to-lecture-6",
    "href": "files/lecture_notes/lecture6/lecture6.html#welcome-to-lecture-6",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "",
    "text": "Conditional Probabilities\nUnderstanding probability when information changes the game"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture6/lecture6.html#todays-learning-objectives",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine and calculate conditional probabilities\nApply the multiplication rule for dependent events\nUse tree diagrams to solve multi-stage problems\nApply the law of total probability\nUse Bayes‚Äô theorem to solve real-world problems\nDistinguish between independence and conditional independence\nRecognize and avoid common conditional probability fallacies"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#motivation-why-conditional-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#motivation-why-conditional-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Motivation: Why Conditional Probability?",
    "text": "Motivation: Why Conditional Probability?\nIn real life, we rarely make decisions with no information\nExamples: - Medical diagnosis with test results - Weather forecast with current conditions\n- Investment decisions with market data - Sports betting with team statistics - Insurance premiums based on risk factors\n\nConditional probability helps us update our beliefs when we gain new information"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#what-is-conditional-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#what-is-conditional-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "What is Conditional Probability?",
    "text": "What is Conditional Probability?\nConditional Probability is the probability of an event occurring, given that another event has already occurred\nNotation: \\(P(A|B)\\) read as ‚Äúprobability of A given B‚Äù\n\nKey insight: When we know B has occurred, our sample space effectively ‚Äúshrinks‚Äù to only outcomes where B is true"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#intuitive-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#intuitive-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Intuitive Example",
    "text": "Intuitive Example\nYou roll a fair six-sided die, but before revealing the result, someone tells you ‚Äúthe number is even‚Äù\nWhat‚Äôs the probability it‚Äôs a 4?\n\nWithout information: \\(P(\\text{rolling 4}) = \\frac{1}{6}\\)\nWith information: \\(P(\\text{4 | even}) = ?\\)\nGiven it‚Äôs even, possible outcomes: \\(\\{2, 4, 6\\}\\) So \\(P(\\text{4 | even}) = \\frac{1}{3}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#formal-definition",
    "href": "files/lecture_notes/lecture6/lecture6.html#formal-definition",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Formal Definition",
    "text": "Formal Definition\nFor events A and B where \\(P(B) &gt; 0\\):\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\n\nInterpretation: - Numerator: Outcomes where both A and B occur - Denominator: All outcomes where B occurs\n- Ratio: Fraction of B-outcomes where A also occurs"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#understanding-the-formula",
    "href": "files/lecture_notes/lecture6/lecture6.html#understanding-the-formula",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Understanding the Formula",
    "text": "Understanding the Formula\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nWhy this formula makes sense: - We restrict our attention to outcomes where B occurs - Among those outcomes, what fraction also have A? - This is exactly \\(\\frac{P(A \\cap B)}{P(B)}\\)\n\nRearranging: \\(P(A \\cap B) = P(A|B) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-1",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-1",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\nA card is drawn from a standard 52-card deck. Find:\n\n\\(P(\\text{King | Face card})\\)\n\\(P(\\text{Heart | Red card})\\)\n\n\\(P(\\text{Ace | Black card})\\)\n\n\nSolutions: a) \\(P(\\text{King | Face}) = \\frac{4}{12} = \\frac{1}{3}\\) (4 kings among 12 face cards) b) \\(P(\\text{Heart | Red}) = \\frac{13}{26} = \\frac{1}{2}\\) (13 hearts among 26 red cards) c) \\(P(\\text{Ace | Black}) = \\frac{2}{26} = \\frac{1}{13}\\) (2 black aces among 26 black cards)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#two-way-tables",
    "href": "files/lecture_notes/lecture6/lecture6.html#two-way-tables",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Two-Way Tables",
    "text": "Two-Way Tables\nTwo-way tables are excellent for conditional probability problems\nExample: Survey of 1000 people about coffee preference\n\n\n\n\nCoffee\nNo Coffee\nTotal\n\n\n\n\nMorning\n350\n150\n500\n\n\nEvening\n200\n300\n500\n\n\nTotal\n550\n450\n1000"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#using-two-way-tables",
    "href": "files/lecture_notes/lecture6/lecture6.html#using-two-way-tables",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Using Two-Way Tables",
    "text": "Using Two-Way Tables\nFind: \\(P(\\text{Coffee | Morning person})\\)\nFrom the table: - Morning people: 500 - Morning people who drink coffee: 350\n\n\\(P(\\text{Coffee | Morning}) = \\frac{350}{500} = 0.7\\)\nCompare to: \\(P(\\text{Coffee}) = \\frac{550}{1000} = 0.55\\)\nBeing a morning person increases coffee probability!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-2",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-2",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\nUsing the coffee table, find:\n\n\\(P(\\text{Morning | Coffee drinker})\\)\n\\(P(\\text{No Coffee | Evening person})\\)\n\\(P(\\text{Evening | No Coffee})\\)\n\n\nSolutions: a) \\(P(\\text{Morning | Coffee}) = \\frac{350}{550} = \\frac{7}{11} \\approx 0.636\\) b) \\(P(\\text{No Coffee | Evening}) = \\frac{300}{500} = 0.6\\)\nc) \\(P(\\text{Evening | No Coffee}) = \\frac{300}{450} = \\frac{2}{3} \\approx 0.667\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#independence-revisited",
    "href": "files/lecture_notes/lecture6/lecture6.html#independence-revisited",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Independence Revisited",
    "text": "Independence Revisited\nEvents A and B are independent if knowing that B occurred doesn‚Äôt change the probability of A\n\\[P(A|B) = P(A)\\]\nEquivalently: \\[P(A \\cap B) = P(A) \\times P(B)\\]\n\nExample: Two coin flips are independent because \\(P(\\text{H}_2 | \\text{H}_1) = P(\\text{H}_2) = 0.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#testing-for-independence",
    "href": "files/lecture_notes/lecture6/lecture6.html#testing-for-independence",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Testing for Independence",
    "text": "Testing for Independence\nMethod 1: Check if \\(P(A|B) = P(A)\\) Method 2: Check if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nMethod 3: Check if \\(P(B|A) = P(B)\\)\n\nCoffee Example: Are coffee preference and time preference independent?\n\\(P(\\text{Coffee}) = 0.55\\) \\(P(\\text{Coffee | Morning}) = 0.7\\)\nSince \\(0.7 \\neq 0.55\\), they are not independent"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#the-multiplication-rule",
    "href": "files/lecture_notes/lecture6/lecture6.html#the-multiplication-rule",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "The Multiplication Rule",
    "text": "The Multiplication Rule\nGeneral Multiplication Rule: \\[P(A \\cap B) = P(A) \\times P(B|A) = P(B) \\times P(A|B)\\]\nFor Independent Events: \\[P(A \\cap B) = P(A) \\times P(B)\\]\n\nExtension to Multiple Events: \\[P(A_1 \\cap A_2 \\cap A_3) = P(A_1) \\times P(A_2|A_1) \\times P(A_3|A_1 \\cap A_2)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#multiplication-rule-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#multiplication-rule-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Multiplication Rule Example",
    "text": "Multiplication Rule Example\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement. What‚Äôs the probability both are red?\n\nLet \\(R_1\\) = first ball is red, \\(R_2\\) = second ball is red\n\\(P(R_1 \\cap R_2) = P(R_1) \\times P(R_2|R_1)\\)\n\\(= \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-3",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-3",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\nA box contains 4 defective and 6 working items. Three items are selected without replacement. Find the probability that:\n\nAll three work\nThe first two work and the third is defective\nExactly two work\n\n\nSolutions: a) \\(P(\\text{WWW}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}\\)\n\n\\(P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-3-continued",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-3-continued",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 3 (continued)",
    "text": "Practice Problem 3 (continued)\n\nExactly two work (three scenarios: WWD, WDW, DWW)\n\n\\(P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{1}{6}\\)\n\\(P(\\text{WDW}) = \\frac{6}{10} \\times \\frac{4}{9} \\times \\frac{5}{8} = \\frac{1}{6}\\)\n\\(P(\\text{DWW}) = \\frac{4}{10} \\times \\frac{6}{9} \\times \\frac{5}{8} = \\frac{1}{6}\\)\n\nTotal: \\(\\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#tree-diagrams",
    "href": "files/lecture_notes/lecture6/lecture6.html#tree-diagrams",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\nTree diagrams help visualize sequential events and conditional probabilities\n                    0.5   Red\n            0.6 ‚îÄ‚îÄ‚îê\n                    0.5   Blue\nBall 1      \n                    0.4   Red  \n            0.4 ‚îÄ‚îÄ‚îê\n                    0.6   Blue\nEach branch shows conditional probabilities"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#tree-diagram-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#tree-diagram-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagram Example",
    "text": "Tree Diagram Example\nMedical test scenario: - 2% of population has disease - Test is 95% accurate for sick people\n- Test is 90% accurate for healthy people\nWhat‚Äôs the probability of testing positive?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#tree-diagram-solution",
    "href": "files/lecture_notes/lecture6/lecture6.html#tree-diagram-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagram Solution",
    "text": "Tree Diagram Solution\n                    0.95   Test +\n            0.02 ‚îÄ‚îÄ‚îê\n                    0.05   Test -\nDisease?    \n                    0.10   Test +\n            0.98 ‚îÄ‚îÄ‚îê\n                    0.90   Test -\n\n\\(P(\\text{Test+}) = P(\\text{Test+|Disease}) \\times P(\\text{Disease}) + P(\\text{Test+|Healthy}) \\times P(\\text{Healthy})\\)\n\\(= 0.95 \\times 0.02 + 0.10 \\times 0.98 = 0.019 + 0.098 = 0.117\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#law-of-total-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#law-of-total-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space (mutually exclusive and exhaustive), then:\n\\[P(A) = \\sum_{i=1}^{n} P(A|B_i) \\times P(B_i)\\]\n\nPartition means: - \\(B_i \\cap B_j = \\emptyset\\) for \\(i \\neq j\\) (mutually exclusive) - \\(\\bigcup_{i=1}^{n} B_i = S\\) (exhaustive)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#law-of-total-probability-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\nA factory has three machines: - Machine A: 50% of production, 1% defective - Machine B: 30% of production, 2% defective\n- Machine C: 20% of production, 3% defective\nWhat‚Äôs the overall defect rate?\n\n\\(P(\\text{Defective}) = P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)\\)\n\\(= 0.01 \\times 0.5 + 0.02 \\times 0.3 + 0.03 \\times 0.2\\)\n\\(= 0.005 + 0.006 + 0.006 = 0.017 = 1.7\\%\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-4",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-4",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\nA student studies for an exam with three possible outcomes based on study time: - Studies hard (40%): 90% chance of passing - Studies moderately (35%): 70% chance of passing\n- Doesn‚Äôt study (25%): 30% chance of passing\nWhat‚Äôs the overall probability of passing?\n\n\\(P(\\text{Pass}) = 0.9 \\times 0.4 + 0.7 \\times 0.35 + 0.3 \\times 0.25\\)\n\\(= 0.36 + 0.245 + 0.075 = 0.68\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem",
    "href": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem",
    "text": "Bayes‚Äô Theorem\nThe Foundation: We often want to ‚Äúreverse‚Äù conditional probabilities\nGiven: \\(P(B|A)\\), \\(P(A)\\), \\(P(B)\\) Want: \\(P(A|B)\\)\nBayes‚Äô Theorem: \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem-components",
    "href": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem-components",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem Components",
    "text": "Bayes‚Äô Theorem Components\n\\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\n\n\\(P(A|B)\\): Posterior probability (what we want)\n\\(P(B|A)\\): Likelihood (what we observe)\n\n\\(P(A)\\): Prior probability (initial belief)\n\\(P(B)\\): Evidence (marginal probability)\n\n\n‚ÄúIn light of evidence B, how should we update our belief in A?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem-with-total-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#bayes-theorem-with-total-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem with Total Probability",
    "text": "Bayes‚Äô Theorem with Total Probability\nWhen we need to find \\(P(B)\\):\n\\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B|A) \\times P(A) + P(B|A^c) \\times P(A^c)}\\]\nThis is the most common form for applications"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#medical-diagnosis-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#medical-diagnosis-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Medical Diagnosis Example",
    "text": "Medical Diagnosis Example\nRevisiting our medical test: - 2% of population has disease (prior) - Test positive (evidence)\n- Test is 95% accurate for sick, 90% accurate for healthy\nGiven a positive test, what‚Äôs the probability of having the disease?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#medical-diagnosis-solution",
    "href": "files/lecture_notes/lecture6/lecture6.html#medical-diagnosis-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Medical Diagnosis Solution",
    "text": "Medical Diagnosis Solution\nLet D = disease, T+ = positive test\n\\[P(D|T+) = \\frac{P(T+|D) \\times P(D)}{P(T+|D) \\times P(D) + P(T+|D^c) \\times P(D^c)}\\]\n\\[= \\frac{0.95 \\times 0.02}{0.95 \\times 0.02 + 0.10 \\times 0.98}\\]\n\\[= \\frac{0.019}{0.019 + 0.098} = \\frac{0.019}{0.117} \\approx 0.162\\]\n\nSurprising: Only 16.2% chance of disease despite positive test!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#why-the-low-probability",
    "href": "files/lecture_notes/lecture6/lecture6.html#why-the-low-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Why the Low Probability?",
    "text": "Why the Low Probability?\nBase Rate Fallacy: When disease is rare (2%), most positive tests are false positives\nIntuition: Out of 10,000 people: - 200 have disease ‚Üí 190 test positive\n- 9,800 healthy ‚Üí 980 test positive - Total positive tests: 1,170 - True positives: 190\n\\(P(\\text{Disease | Positive}) = \\frac{190}{1,170} \\approx 0.162\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-5",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-5",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 5",
    "text": "Practice Problem 5\nEmail spam filter: - 60% of emails are spam - Filter catches 95% of spam - Filter incorrectly flags 8% of legitimate emails\nIf an email is flagged as spam, what‚Äôs the probability it‚Äôs actually spam?\n\n\\(P(\\text{Spam | Flagged}) = \\frac{0.95 \\times 0.6}{0.95 \\times 0.6 + 0.08 \\times 0.4}\\)\n\\(= \\frac{0.57}{0.57 + 0.032} = \\frac{0.57}{0.602} \\approx 0.947\\)\nThe filter is quite reliable!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#multiple-events-and-bayes",
    "href": "files/lecture_notes/lecture6/lecture6.html#multiple-events-and-bayes",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Multiple Events and Bayes‚Äô",
    "text": "Multiple Events and Bayes‚Äô\nExtended Bayes‚Äô Theorem: If \\(A_1, A_2, \\ldots, A_n\\) partition the sample space:\n\\[P(A_i|B) = \\frac{P(B|A_i) \\times P(A_i)}{\\sum_{j=1}^{n} P(B|A_j) \\times P(A_j)}\\]\nThis allows us to update probabilities for multiple hypotheses"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#three-machine-example-revisited",
    "href": "files/lecture_notes/lecture6/lecture6.html#three-machine-example-revisited",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Three Machine Example Revisited",
    "text": "Three Machine Example Revisited\nA defective item is found. Which machine most likely produced it?\nFrom before: - Machine A: 50% production, 1% defective\n- Machine B: 30% production, 2% defective - Machine C: 20% production, 3% defective - Overall defect rate: 1.7%"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#three-machine-solution",
    "href": "files/lecture_notes/lecture6/lecture6.html#three-machine-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Three Machine Solution",
    "text": "Three Machine Solution\n\\[P(A|\\text{Defective}) = \\frac{0.01 \\times 0.5}{0.017} = \\frac{0.005}{0.017} \\approx 0.294\\]\n\\[P(B|\\text{Defective}) = \\frac{0.02 \\times 0.3}{0.017} = \\frac{0.006}{0.017} \\approx 0.353\\]\n\\[P(C|\\text{Defective}) = \\frac{0.03 \\times 0.2}{0.017} = \\frac{0.006}{0.017} \\approx 0.353\\]\n\nMachine B or C are most likely sources of the defective item"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-6",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-6",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\nThree boxes contain colored balls: - Box 1: 3 red, 2 blue (chosen 40% of time) - Box 2: 2 red, 3 blue (chosen 35% of time)\n- Box 3: 1 red, 4 blue (chosen 25% of time)\nA red ball is drawn. Which box was it most likely from?\n\n\\(P(\\text{Red}) = \\frac{3}{5} \\times 0.4 + \\frac{2}{5} \\times 0.35 + \\frac{1}{5} \\times 0.25 = 0.24 + 0.14 + 0.05 = 0.43\\)\n\\(P(\\text{Box 1 | Red}) = \\frac{0.6 \\times 0.4}{0.43} \\approx 0.558\\) \\(P(\\text{Box 2 | Red}) = \\frac{0.4 \\times 0.35}{0.43} \\approx 0.326\\)\n\\(P(\\text{Box 3 | Red}) = \\frac{0.2 \\times 0.25}{0.43} \\approx 0.116\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#conditional-independence",
    "href": "files/lecture_notes/lecture6/lecture6.html#conditional-independence",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Conditional Independence",
    "text": "Conditional Independence\nEvents A and B are conditionally independent given C if:\n\\[P(A \\cap B | C) = P(A|C) \\times P(B|C)\\]\nImportant: Conditional independence doesn‚Äôt imply independence!\n\nExample: Weather in two cities may be independent normally, but conditionally dependent given a major weather system"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#simpsons-paradox",
    "href": "files/lecture_notes/lecture6/lecture6.html#simpsons-paradox",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Simpson‚Äôs Paradox",
    "text": "Simpson‚Äôs Paradox\nSimpson‚Äôs Paradox: A trend in subgroups can reverse when groups are combined\nClassic Example: University admissions by gender\n\n\n\n\nMen\nWomen\n\n\n\n\nDept A\n62% (825/1327)\n82% (108/131)\n\n\nDept B\n63% (560/893)\n68% (25/37)\n\n\nOverall\n44% (1385/2220)\n30% (133/168)\n\n\n\nWomen have higher rates in each department but lower overall!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#common-fallacies",
    "href": "files/lecture_notes/lecture6/lecture6.html#common-fallacies",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Common Fallacies",
    "text": "Common Fallacies\n1. Confusion of the Inverse - Confusing \\(P(A|B)\\) with \\(P(B|A)\\) - ‚ÄúIf it rains, the ground is wet‚Äù ‚â† ‚ÄúIf the ground is wet, it rained‚Äù\n2. Base Rate Neglect\n- Ignoring prior probabilities - Medical test example\n3. Prosecutor‚Äôs Fallacy - \\(P(\\text{Evidence | Innocent}) \\neq P(\\text{Innocent | Evidence})\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#prosecutors-fallacy-example",
    "href": "files/lecture_notes/lecture6/lecture6.html#prosecutors-fallacy-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Prosecutor‚Äôs Fallacy Example",
    "text": "Prosecutor‚Äôs Fallacy Example\nDNA evidence matches defendant with probability 1 in a million for random person\nWrong reasoning: ‚ÄúProbability of innocence is 1 in a million‚Äù\nCorrect reasoning: Need to consider: - How many people could have committed the crime? - What‚Äôs the prior probability of guilt? - Possibility of lab error, planted evidence, etc."
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-7",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-7",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\nQuality control: 5% of items are defective. A test detects 96% of defective items but has a 4% false positive rate.\n\nWhat‚Äôs the probability an item testing positive is actually defective?\nWhat‚Äôs the probability an item testing negative is actually good?\n\n\n\n\\(P(\\text{Defective | Positive}) = \\frac{0.96 \\times 0.05}{0.96 \\times 0.05 + 0.04 \\times 0.95} = \\frac{0.048}{0.086} \\approx 0.558\\)\n\\(P(\\text{Good | Negative}) = \\frac{0.96 \\times 0.95}{0.96 \\times 0.95 + 0.04 \\times 0.05} = \\frac{0.912}{0.914} \\approx 0.998\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#real-world-applications",
    "href": "files/lecture_notes/lecture6/lecture6.html#real-world-applications",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Screening: - Mammograms, COVID tests - Balancing sensitivity vs specificity\nMachine Learning: - Naive Bayes classifiers - Spam detection, recommendation systems\nFinance: - Credit scoring - Fraud detection\nLegal System: - DNA evidence interpretation - Probability of guilt/innocence"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#technology-and-tools",
    "href": "files/lecture_notes/lecture6/lecture6.html#technology-and-tools",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Technology and Tools",
    "text": "Technology and Tools\nCalculators: - Basic probability calculations - Watch for rounding errors\nSoftware: - R: conditional probability tables - Python: pandas for two-way tables - Excel: pivot tables for conditional analysis\nVisualization: - Tree diagrams\n- Contingency tables - Bayes networks"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#diagnostic-thinking",
    "href": "files/lecture_notes/lecture6/lecture6.html#diagnostic-thinking",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Diagnostic Thinking",
    "text": "Diagnostic Thinking\nQuestions to ask: 1. What information am I conditioning on? 2. How does this information change the probability? 3. What‚Äôs the base rate or prior probability? 4. Am I confusing \\(P(A|B)\\) with \\(P(B|A)\\)? 5. Are the events independent?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture6/lecture6.html#problem-solving-strategy",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\nIdentify the type: Direct conditional, Bayes‚Äô, or law of total probability?\nDefine events clearly: Use precise notation\nOrganize information: Two-way tables or tree diagrams\nCheck for independence: Does additional info matter?\nApply appropriate formula: Don‚Äôt forget denominators!\nVerify answer: Does it make intuitive sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-8",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-8",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 8",
    "text": "Practice Problem 8\nA survey shows: - 70% of people like pizza - 60% of people like movies\n- 40% like both pizza and movies\n\nAre liking pizza and movies independent?\nWhat‚Äôs \\(P(\\text{Pizza | Movies})\\)?\nWhat‚Äôs \\(P(\\text{Movies | Pizza})\\)?"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#practice-problem-8-solutions",
    "href": "files/lecture_notes/lecture6/lecture6.html#practice-problem-8-solutions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 8 Solutions",
    "text": "Practice Problem 8 Solutions\n\nCheck independence: \\(P(\\text{Pizza}) \\times P(\\text{Movies}) = 0.7 \\times 0.6 = 0.42 \\neq 0.4\\) Not independent!\n\\(P(\\text{Pizza | Movies}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Movies})} = \\frac{0.4}{0.6} = \\frac{2}{3}\\)\n\\(P(\\text{Movies | Pizza}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Pizza})} = \\frac{0.4}{0.7} = \\frac{4}{7}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#advanced-topics-preview",
    "href": "files/lecture_notes/lecture6/lecture6.html#advanced-topics-preview",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Advanced Topics Preview",
    "text": "Advanced Topics Preview\nMarkov Chains: - Sequences where future depends only on present - \\(P(X_{n+1} | X_n, X_{n-1}, \\ldots, X_1) = P(X_{n+1} | X_n)\\)\nBayesian Statistics: - Using Bayes‚Äô theorem for statistical inference - Updating beliefs with data\nInformation Theory: - Conditional entropy - Mutual information"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#historical-context",
    "href": "files/lecture_notes/lecture6/lecture6.html#historical-context",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Historical Context",
    "text": "Historical Context\nThomas Bayes (1701-1761): - Presbyterian minister and mathematician - Bayes‚Äô theorem published posthumously\nPierre-Simon Laplace (1749-1827): - Developed and popularized Bayesian methods - ‚ÄúProbability is nothing but common sense reduced to calculation‚Äù\nModern Applications: AI, machine learning, medical diagnosis, finance"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#common-student-questions",
    "href": "files/lecture_notes/lecture6/lecture6.html#common-student-questions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: ‚ÄúHow do I know when to use Bayes‚Äô theorem?‚Äù A: When you want to ‚Äúreverse‚Äù a conditional probability\nQ: ‚ÄúWhy are medical test problems so counterintuitive?‚Äù\nA: Base rates matter more than we intuitively expect\nQ: ‚ÄúWhat‚Äôs the difference between independence and conditional independence?‚Äù A: Independence means no relationship; conditional independence means no relationship given specific information"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture6/lecture6.html#key-formulas-summary",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\nConditional Probability: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nMultiplication Rule: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nLaw of Total Probability: \\(P(A) = \\sum P(A|B_i) \\times P(B_i)\\)\nBayes‚Äô Theorem: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)\nIndependence: \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#looking-ahead",
    "href": "files/lecture_notes/lecture6/lecture6.html#looking-ahead",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture: Discrete Random Variables - Random variables as functions - Probability mass functions - Expected value and variance - Common discrete distributions (binomial, geometric, Poisson)\nConnection: Conditional probability is essential for understanding dependence in random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#study-tips",
    "href": "files/lecture_notes/lecture6/lecture6.html#study-tips",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Study Tips",
    "text": "Study Tips\n\nPractice with real scenarios: Medical tests, quality control\nDraw diagrams: Tree diagrams and two-way tables\nCheck your intuition: Do answers make sense?\nMaster the basics: Conditional probability formula\nWatch for fallacies: Don‚Äôt confuse \\(P(A|B)\\) and \\(P(B|A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#final-thoughts",
    "href": "files/lecture_notes/lecture6/lecture6.html#final-thoughts",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nConditional probability is everywhere: - Updates beliefs with new information - Foundation of Bayesian thinking - Critical for proper statistical reasoning - Essential for machine learning and AI\n\nKey insight: Information changes probability - embrace this uncertainty!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#questions",
    "href": "files/lecture_notes/lecture6/lecture6.html#questions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: [Your office hours] Email: [Your email]\nNext Class: Discrete Random Variables\nRemember: Homework due [date]"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#bonus-monty-hall-problem",
    "href": "files/lecture_notes/lecture6/lecture6.html#bonus-monty-hall-problem",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bonus: Monty Hall Problem",
    "text": "Bonus: Monty Hall Problem\nThree doors: one has a car, two have goats 1. You choose a door 2. Host opens a door with a goat 3. Do you switch?\n\nAnswer: Yes! Switch! - \\(P(\\text{Car behind your door}) = \\frac{1}{3}\\) - \\(P(\\text{Car behind other remaining door}) = \\frac{2}{3}\\)\nConditional probability in action!"
  },
  {
    "objectID": "files/lecture_notes/lecture6/lecture6.html#bonus-birthday-paradox-connection",
    "href": "files/lecture_notes/lecture6/lecture6.html#bonus-birthday-paradox-connection",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bonus: Birthday Paradox Connection",
    "text": "Bonus: Birthday Paradox Connection\nIn a room of 23 people, probability of shared birthday ‚âà 50%\nConditional approach: What‚Äôs \\(P(\\text{no match | first $k$ people have different birthdays})\\)?\nThis helps build intuition for why the probability grows so quickly!\nSurprising results often involve conditional probability!"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "href": "files/lecture_notes/lecture2/lecture2.html#todays-agenda",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Today‚Äôs Agenda",
    "text": "Today‚Äôs Agenda\n\nIntroduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\nWhy it matters before any modeling\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset they‚Äôve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "href": "files/lecture_notes/lecture2/lecture2.html#learning-objectives-los",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Learning Objectives (LOs)",
    "text": "Learning Objectives (LOs)\nBy the end of this lecture you should be able to:\n\nDefine descriptive statistics and explain its importance in data analysis (Section¬†1)\nDistinguish between different types of data and measurement scales (Section¬†2)\nCalculate and interpret measures of central tendency (mean, median, mode)(Section¬†3)\nUnderstand when to use each measure of central tendency\nApply Python to compute descriptive statistics(Section¬†9)\nInterpret basic descriptive statistics in real-world contexts(Section¬†10)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Statistics",
    "text": "Statistics\n\nFacts are stubborn, but statistics are more pliable.\nMark Twain\n\nStatistics refers to the mathematics and techniques with which we understand data. 1\n\n\n\n(source)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-are-descriptive-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What are Descriptive Statistics?",
    "text": "What are Descriptive Statistics?\n\nDescriptive statistics are numerical and graphical methods used to summarize, organize, and describe data in a meaningful way.\n\nPurpose of Descriptive Statistics\n\nSummarize large datasets into manageable information\nIdentify patterns and trends in data\nCommunicate findings clearly to others\nPrepare data for further analysis\nMake initial assessments about data quality"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs.¬†Inferential Statistics",
    "text": "Descriptive vs.¬†Inferential Statistics\n\n\n\n\n\n\n\nDescriptive Statistics\nInferential Statistics\n\n\n\n\nDescribes what the data shows\nMakes predictions about populations\n\n\nSummarizes sample data\nUses sample data to make generalizations\n\n\nNo conclusions beyond the data\nDraws conclusions beyond the immediate data\n\n\nExamples: mean, median, graphs\nExamples: hypothesis testing, confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#descriptive-vs.-inferential-statistics-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Descriptive vs.¬†Inferential Statistics",
    "text": "Descriptive vs.¬†Inferential Statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "href": "files/lecture_notes/lecture2/lecture2.html#why-data-types-matter",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Why Data Types Matter",
    "text": "Why Data Types Matter\nUnderstanding data types is crucial because:\n\n\nDifferent statistics are appropriate for different data types\nStatistical methods depend on the level of measurement\nMisapplying statistics can lead to incorrect conclusions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-data",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Data",
    "text": "Types of Data\n\n\n\n\n\ngraph TD\n    A[Variable Types]\n    A --&gt; B[Categorical]\n    A --&gt; C[Numerical]\n    B --&gt; B1[\"Nominal&lt;br/&gt;e.g., gender, major\"]\n    B --&gt; B2[\"Ordinal&lt;br/&gt;e.g., rating, education level\"]\n    C --&gt; C1[\"Discrete&lt;br/&gt;e.g., count (# of students)\"]\n    C --&gt; C2[\"Continuous&lt;br/&gt;e.g., measurements like height, weight\"]\n    \n    classDef root fill:#e1f5fe,stroke:#01579b,stroke-width:3px\n    classDef categorical fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef numerical fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px\n    classDef nominal fill:#fce4ec,stroke:#880e4f,stroke-width:2px\n    classDef ordinal fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef discrete fill:#e0f2f1,stroke:#00695c,stroke-width:2px\n    classDef continuous fill:#f1f8e9,stroke:#33691e,stroke-width:2px\n    \n    class A root\n    class B categorical\n    class C numerical\n    class B1 nominal\n    class B2 ordinal\n    class C1 discrete\n    class C2 continuous\n\n\n\n\n\n\n\nPrompt: Which summary stat would you pick for ‚Äúmajor‚Äù? For ‚Äúgpa‚Äù?"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#categorical-data-qualitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Categorical Data (Qualitative)",
    "text": "Categorical Data (Qualitative)\n\n\nNominal Data\n\nCategories with no natural order\nExamples: gender, color, brand names, marital status\nAppropriate statistics: mode, frequency counts, proportions\n\n\nOrdinal Data\n\nCategories with a natural order or ranking\nExamples: education level, satisfaction ratings, letter grades\nAppropriate statistics: mode, median, percentiles"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "href": "files/lecture_notes/lecture2/lecture2.html#numerical-data-quantitative",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Numerical Data (Quantitative)",
    "text": "Numerical Data (Quantitative)\n\nDiscrete Data\n\nCountable values, often integers\nExamples: number of children, cars sold, defective items\nCan take on finite or countably infinite values\n\n\n\nContinuous Data\n\nCan take any value within a range\nExamples: height, weight, temperature, time\nMeasured rather than counted"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "href": "files/lecture_notes/lecture2/lecture2.html#measurement-scales-summary",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Measurement Scales Summary",
    "text": "Measurement Scales Summary\n\n\n\n\n\n\n\n\n\n\nScale\nType\nProperties\nExamples\nAppropriate Statistics\n\n\n\n\nNominal\nCategorical\nCategories only\nGender, Color\nMode, Frequency\n\n\nOrdinal\nCategorical\nOrder matters\nRankings, Grades\nMode, Median\n\n\nInterval\nNumerical\nEqual intervals, no true zero\nTemperature (¬∞C)\nMean, Median, Mode\n\n\nRatio\nNumerical\nEqual intervals, true zero\nHeight, Weight, Income\nAll statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#what-is-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "What is Central Tendency?",
    "text": "What is Central Tendency?\nCentral tendency describes the center or typical value of a dataset.\nIt answers the question: ‚ÄúWhat is a representative value for this data?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-and-formula",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition and Formula",
    "text": "Definition and Formula\n\nüéØ Definition: The mean is the sum of all values divided by the number of values.\n\n\nFormula\n\nFor a sample: \\(\\bar{x} = \\frac{\\sum x}{n}\\)\nFor a population: \\(\\mu = \\frac{\\sum x}{N}\\)\n\nWhere:\n\n\\(\\bar{x}\\) (x-bar) = sample mean\n\\(\\mu\\) (mu) = population mean\n\\(\\sum x\\) = sum of all values\n\\(n\\) = sample size, \\(N\\) = population size"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-calculation",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example Calculation",
    "text": "Example Calculation\nStudent test scores: 85, 90, 78, 92, 88\n\nMean = \\(\\frac{85 + 90 + 78 + 92 + 88}{5} = \\frac{433}{5} = 86.6\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mean",
    "text": "Properties of the Mean\n\nUses all data points - every value affects the mean\nSensitive to outliers - extreme values can distort the mean\nUnique - there is only one mean for a dataset\nCan be calculated for interval and ratio data\nBalancing point - sum of deviations from mean equals zero"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mean",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mean",
    "text": "When to Use the Mean\n‚úÖ Use the mean when:\n\nData is approximately symmetric\nNo extreme outliers present\nWorking with interval or ratio data\nNeed to use the value in further calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "href": "files/lecture_notes/lecture2/lecture2.html#advantages-and-disadvantages",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Advantages and Disadvantages",
    "text": "Advantages and Disadvantages\n\n\nAdvantages\n\nUses all information in the dataset\nAlgebraically defined and mathematically tractable\nWidely understood and accepted\n\n\nDisadvantages\n\nAffected by outliers and skewed distributions\nMay not represent a typical value in skewed data\nCannot be used with nominal or ordinal data"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\n\nüéØ Definition: The median is the middle value when data is arranged in ascending or descending order."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "href": "files/lecture_notes/lecture2/lecture2.html#calculation-steps",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Calculation Steps",
    "text": "Calculation Steps\n\nArrange data in ascending order\nFind the middle position:\n\nIf n is odd: position = \\(\\frac{n + 1}{2}\\)\nIf n is even: average of positions \\(\\frac{n}{2}\\) and \\(\\frac{n}{2} + 1\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#examples",
    "href": "files/lecture_notes/lecture2/lecture2.html#examples",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Examples",
    "text": "Examples\n\nOdd number of values:\n\n\nData: 12, 15, 18, 20, 25\nWhat is the median here ?\nMedian = 18 (middle value)\n\n\n\n\nEven number of values:\n\n\nData: 10, 15, 20, 25, 30, 35\nWhat is the median here ?\nMedian = \\(\\frac{20 + 25}{2} = 22.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Median",
    "text": "Properties of the Median\n\n\nNot affected by outliers - resistant measure\nRepresents the 50th percentile\nMay not be an actual data value (when n is even)\nAppropriate for ordinal, interval, and ratio data\nDivides data into two equal halves"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-median",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Median",
    "text": "When to Use the Median\n‚úÖ Use the median when:\n\nData is skewed (not symmetric)\nOutliers are present\nWorking with ordinal data\nWant a robust measure of central tendency\nData represents income, housing prices, or similar distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "href": "files/lecture_notes/lecture2/lecture2.html#median-vs-mean-with-outliers",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Median vs Mean with Outliers",
    "text": "Median vs Mean with Outliers\nConsider household incomes: $30,000, $32,000, $35,000, $38,000, $2,000,000\n\n\nMean = $427,000 (not representative of typical household)\nMedian = $35,000 (better represents typical household)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#definition-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Definition",
    "text": "Definition\n\nüéØ Definition: The mode is the value that appears most frequently in a dataset.\n\n\n\n\n\n\n%%{init: {'flowchart': {'nodeSpacing': 100, 'rankSpacing': 100}, 'width': 600, 'height': 400}}%%\ngraph TD\n    A[\"Mode Types\"]\n    A --&gt; B[\"Unimodal&lt;br/&gt;One peak\"]\n    A --&gt; C[\"Bimodal&lt;br/&gt;Two peaks\"]\n    A --&gt; D[\"Multimodal&lt;br/&gt;Multiple peaks\"]\n    A --&gt; E[\"No Mode&lt;br/&gt;No repeated values\"]\n    \n    classDef main fill:#e1f5fe,stroke:#01579b,stroke-width:3px,font-size:16px\n    classDef types fill:#f5f5f5,stroke:#424242,stroke-width:2px,font-size:14px\n    \n    class A main\n    class B,C,D,E types"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#types-of-distributions-by-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Types of Distributions by Mode",
    "text": "Types of Distributions by Mode\n\nUnimodal: One mode\nBimodal: Two modes\n\nMultimodal: More than two modes\nNo mode: All values appear with equal frequency"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-1",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 1:",
    "text": "Example 1:\nData: 2, 3, 3, 4, 5, 5, 5, 6, 7\n\nAnalysis:\n\n\nCount each value: 2(1), 3(2), 4(1), 5(3), 6(1), 7(1)\nMost frequent value: 5 appears 3 times\nMode = 5\nType: Unimodal (one mode)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-2",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 2:",
    "text": "Example 2:\nData: 1, 2, 2, 3, 4, 4, 5\n\nAnalysis:\n\n\nCount each value: 1(1), 2(2), 3(1), 4(2), 5(1)\nMost frequent values: 2 and 4 both appear twice\nModes = 2 and 4\nType: Bimodal (two modes)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "href": "files/lecture_notes/lecture2/lecture2.html#example-3",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Example 3:",
    "text": "Example 3:\nData: 1, 2, 3, 4, 5\n\nAnalysis:\n\n\nCount each value: 1(1), 2(1), 3(1), 4(1), 5(1)\nAll values appear exactly once\nNo mode (no value repeats)\nType: No mode"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "href": "files/lecture_notes/lecture2/lecture2.html#mode-for-different-data-types",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mode for Different Data Types",
    "text": "Mode for Different Data Types\nCategorical Data:\nFavorite colors: Red, Blue, Blue, Green, Blue, Red, Blue Mode = Blue\nContinuous Data:\nOften requires grouping into intervals or bins Example: Heights grouped into ranges"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#properties-of-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Properties of the Mode",
    "text": "Properties of the Mode\n\nCan be used with any type of data (nominal, ordinal, interval, ratio)\nNot affected by outliers\nMay not exist or may not be unique\nRepresents the most common value\nEasy to identify in frequency distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "href": "files/lecture_notes/lecture2/lecture2.html#when-to-use-the-mode",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "When to Use the Mode",
    "text": "When to Use the Mode\n‚úÖ Use the mode when:\n\nWorking with categorical (nominal) data\nWant to identify the most popular or common choice\nData has clear peaks in frequency\nQuality control applications (most common defect type)\nBusiness applications (best-selling product, most common customer complaint)"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "href": "files/lecture_notes/lecture2/lecture2.html#comparing-measures-of-central-tendency",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Comparing Measures of Central Tendency",
    "text": "Comparing Measures of Central Tendency\n\n\n\n\n\n\n\n\n\n\nMeasure\nBest for Data Type\nStrengths\nWeaknesses\nAffected by Outliers?\n\n\n\n\nMean\nInterval, Ratio\nUses all data, mathematically tractable\nSensitive to outliers\nYes\n\n\nMedian\nOrdinal, Interval, Ratio\nRobust to outliers, represents middle\nIgnores extreme values\nNo\n\n\nMode\nAll types\nWorks with categorical, identifies most common\nMay not exist/be unique\nNo"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "href": "files/lecture_notes/lecture2/lecture2.html#shape-of-distribution-effects",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Shape of Distribution Effects",
    "text": "Shape of Distribution Effects\n\nSymmetric distribution: Mean ‚âà Median ‚âà Mode\nRight-skewed (positively skewed): Mean &gt; Median &gt; Mode\n\nLeft-skewed (negatively skewed): Mode &gt; Median &gt; Mean"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "href": "files/lecture_notes/lecture2/lecture2.html#central-measures",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Central Measures",
    "text": "Central Measures\n\n\n\nMean CalculationMedian CalculationMode Calculation\n\n\n\n# Import numpy library for numeric operations\nimport numpy as np \n\n# Import pandas library for data structures\nimport pandas as pd\n\n# Define sample data as a list of test scores\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\n\n# Compute the arithmetic mean using NumPy\nmean_np = np.mean(data)\nprint(f\"Mean (NumPy): {mean_np:.2f}\")\n\n# Convert the data list into a pandas DataFrame\ndf = pd.DataFrame({'scores': data})\n\n# Compute the arithmetic mean using Pandas\nmean_pd = df['scores'].mean()\nprint(f\"Mean (Pandas): {mean_pd:.2f}\")\n\n# Manually sum all scores and divide by count\nmanual_mean = sum(data) / len(data)\nprint(f\"Mean (Manual): {manual_mean:.2f}\")\n\nMean (NumPy): 87.10\nMean (Pandas): 87.10\nMean (Manual): 87.10\n\n\n\n\n\n# Compute the median value using NumPy\nmedian_np = np.median(data)\nprint(f\"Median (NumPy): {median_np:.2f}\")\n\n# Compute the median value using Pandas\nmedian_pd = df['scores'].median()\nprint(f\"Median (Pandas): {median_pd:.2f}\")\n\n# Sort the data list in ascending order\nsorted_data = sorted(data)\n\n# Determine the number of elements\nn = len(sorted_data)\n\n# If even count, average the two middle elements; else take middle element\nif n % 2 == 0:\n    manual_median = (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2\nelse:\n    manual_median = sorted_data[n//2]\n\nprint(f\"Median (Manual): {manual_median:.2f}\")\n\nMedian (NumPy): 87.50\nMedian (Pandas): 87.50\nMedian (Manual): 87.50\n\n\n\n\n\n# Import SciPy stats module to compute mode\nfrom scipy import stats\n\n# Use SciPy to find the most common value and its count\nmode_result = stats.mode(data, keepdims=True)\nprint(f\"Mode (SciPy): {mode_result.mode[0]}, Count: {mode_result.count[0]}\")\n\n# Use Pandas to get mode(s) from the DataFrame\nmode_pd = df['scores'].mode()\nprint(f\"Mode (Pandas): {mode_pd.values}\")\n\n# Import Counter for manual frequency counting\nfrom collections import Counter\n\n# Count occurrences of each score\ncounter = Counter(data)\n\n# Find the highest frequency\nmax_count = max(counter.values())\n\n# Identify all values that appear with that frequency\nmodes = [k for k, v in counter.items() if v == max_count]\n\nprint(f\"Mode (Manual): {modes}, Count: {max_count}\")\n\nMode (SciPy): 85, Count: 2\nMode (Pandas): [85]\nMode (Manual): [85], Count: 2"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "href": "files/lecture_notes/lecture2/lecture2.html#mean-mode-and-median-visualization",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Mean, Mode and Median Visualization",
    "text": "Mean, Mode and Median Visualization\n\nCodeVisualization\n\n\n\n# import libraries\nimport numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n# define your data and compute statistics here\ndata = [85, 90, 78, 92, 88, 91, 85, 87, 89, 86]\nmean_np   = np.mean(data)\nmedian_np = np.median(data)\n# for mode, use Counter\ncounter   = Counter(data)\nmax_count = max(counter.values())\nmodes     = [k for k,v in counter.items() if v==max_count]\nmode_val  = modes[0]\n\n\n\n\n\n\n\n\nDistribution of Test Scores with Central Tendency Measures"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#business-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Business Applications",
    "text": "Business Applications\n\nCustomer Satisfaction: Mean rating shows overall satisfaction, median shows typical experience\nSales Data: Mode identifies best-selling products, median shows typical sale amount\n\nEmployee Performance: Mean for overall team performance, median for typical employee"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#educational-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Educational Applications",
    "text": "Educational Applications\n\nTest Scores: Mean for class average, median for typical student performance\nGrade Distribution: Mode shows most common grade\nAttendance: Mean for overall attendance rate"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "href": "files/lecture_notes/lecture2/lecture2.html#healthcare-applications",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Healthcare Applications",
    "text": "Healthcare Applications\n\nPatient Wait Times: Median often preferred due to skewed distributions\nTreatment Outcomes: Mean for overall effectiveness, mode for most common result\nVital Signs: All three measures provide different insights"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "href": "files/lecture_notes/lecture2/lecture2.html#interpretation-guidelines",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Interpretation Guidelines",
    "text": "Interpretation Guidelines\n\nAlways consider the context of your data\nReport multiple measures when appropriate\n\nBe aware of data distribution shape\nConsider the presence of outliers\nChoose the most appropriate measure for your specific question"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "href": "files/lecture_notes/lecture2/lecture2.html#remember-these-points",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Remember These Points",
    "text": "Remember These Points\n\nData type determines which statistics are appropriate\nMean uses all data but is sensitive to outliers\nMedian is robust and represents the middle value\nMode identifies the most common value and works with all data types\nContext matters when choosing and interpreting measures\nPython provides powerful tools for calculating descriptive statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "href": "files/lecture_notes/lecture2/lecture2.html#next-lecture-preview",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Next Lecture Preview",
    "text": "Next Lecture Preview\nDescriptive Statistics Part II will cover:\n\nMeasures of variability (range, variance, standard deviation)\nMeasures of position (percentiles, quartiles, z-scores)\nShape of distributions (skewness and kurtosis)\nAdvanced Python visualization techniques"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "href": "files/lecture_notes/lecture2/lecture2.html#try-these-problems",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Try These Problems",
    "text": "Try These Problems\n\nCalculate mean, median, and mode for: 12, 15, 18, 12, 20, 25, 12, 30\nA dataset has mean = 50 and median = 45. What does this tell you about the distribution?\nWhy might median be preferred over mean for reporting household income?\nCreate a Python function to identify the most appropriate measure of central tendency for a given dataset."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#learning-objectives",
    "href": "files/lecture_notes/lecture3/lecture3.html#learning-objectives",
    "title": "Descriptive Statistics Part II",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture, you will be able to:\n\nCalculate and interpret measures of variability (range, variance, standard deviation)\nUnderstand and compute measures of position (percentiles, quartiles, z-scores)\nAssess distribution shape using skewness and kurtosis\nCreate and interpret histograms with appropriate bin widths\nConstruct and analyze boxplots for data exploration\nIdentify trends, patterns, and outliers in data visualizations\nApply Python for comprehensive descriptive analysis and visualization"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#lecture-outline",
    "href": "files/lecture_notes/lecture3/lecture3.html#lecture-outline",
    "title": "Descriptive Statistics Part II",
    "section": "Lecture Outline",
    "text": "Lecture Outline\n\n\nPart I: Measures of Variability (25 min)\n\nRange, Variance, Standard Deviation\nCoefficient of Variation\nPython Implementation\n\nPart II: Measures of Position (20 min)\n\nPercentiles and Quartiles\nZ-scores and Standardization\n\n\n\nPart III: Distribution Shape (10 min)\n\nSkewness and Kurtosis\n\nPart IV: Data Visualization (20 min)\n\nHistograms and Bin Width Selection\nBoxplots and Interpretation\n\nPart V: Identifying Patterns (5 min)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-is-variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-is-variability",
    "title": "Descriptive Statistics Part II",
    "section": "What is Variability?",
    "text": "What is Variability?\n\nüéØ Definition: Variability (or dispersion) measures how spread out or scattered the data points are around the center.\n\nWhy Variability Matters\n\nTwo datasets can have the same mean but very different spreads\nVariability indicates consistency and predictability\nEssential for risk assessment and quality control\nHelps determine confidence in our central tendency measures"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#range",
    "href": "files/lecture_notes/lecture3/lecture3.html#range",
    "title": "Descriptive Statistics Part II",
    "section": "Range",
    "text": "Range\n\nRange = Maximum value - Minimum value\n\nExample\nData: 12, 15, 18, 22, 25, 30, 35\n\nRange = 35 - 12 = 23"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#when-to-use-range",
    "href": "files/lecture_notes/lecture3/lecture3.html#when-to-use-range",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Range",
    "text": "When to Use Range\n‚úÖ Use range when:\n\nNeed a quick, simple measure of spread\nWorking with small datasets\nCommunicating to non-technical audiences\n\n‚ùå Avoid range when:\n\nOutliers are present\nNeed detailed information about variability\nWorking with large datasets"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#variance-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#variance-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Variance Definition",
    "text": "Variance Definition\n\nüéØ Definition: Variance measures the average squared deviation from the mean."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#recall",
    "href": "files/lecture_notes/lecture3/lecture3.html#recall",
    "title": "Descriptive Statistics Part II",
    "section": "Recall",
    "text": "Recall"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#side-by-side-comparison",
    "href": "files/lecture_notes/lecture3/lecture3.html#side-by-side-comparison",
    "title": "Descriptive Statistics Part II",
    "section": "Side-by-Side Comparison",
    "text": "Side-by-Side Comparison\n\n\n\nPopulation Variance\n\n\n\\[\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\]\n\n\\(\\sigma^2\\) = population variance\n\\(x_i\\) = value of \\(i^{th}\\) element\n\\(\\mu\\) = population mean\n\\(N\\) = population size\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\]\n\n\\(s^2\\) = sample variance\n\\(x_i\\) = value of \\(i^{th}\\) element\n\\(\\bar{x}\\) = sample mean\n\\(n\\) = sample size"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#key-differences",
    "href": "files/lecture_notes/lecture3/lecture3.html#key-differences",
    "title": "Descriptive Statistics Part II",
    "section": "Key Differences",
    "text": "Key Differences\n\nKey Difference: Sample variance uses \\((n-1)\\) instead of \\(N\\) in the denominator\n\nWhy \\((n-1)\\)?\n\nWhen we use sample mean \\(\\bar{x}\\) to estimate population mean \\(\\mu\\)\nWe lose one degree of freedom\nCalled Bessel‚Äôs correction\nMakes sample variance an unbiased estimator"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#when-to-use-each-formula",
    "href": "files/lecture_notes/lecture3/lecture3.html#when-to-use-each-formula",
    "title": "Descriptive Statistics Part II",
    "section": "When to Use Each Formula",
    "text": "When to Use Each Formula\n\nPopulation Variance (\\(\\sigma^2\\))\n\nYou have data for the entire population\nYou know the true population mean \\(\\mu\\)\nExample: Test scores for all students in a small class\n\n\n\nSample Variance (\\(s^2\\))\n\nYou have data from a sample only\nWant to estimate population variance\nExample: Survey responses from 100 people out of 10,000"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#understanding-degrees-of-freedom",
    "href": "files/lecture_notes/lecture3/lecture3.html#understanding-degrees-of-freedom",
    "title": "Descriptive Statistics Part II",
    "section": "Understanding Degrees of Freedom",
    "text": "Understanding Degrees of Freedom\n\n\nüìä Population Case\nAll observations are independent\n\nWe know the true population mean \\(\\mu\\)\nEach of the \\(N\\) observations provides independent information\nNo constraints on the data\n\n\n\\[\\text{Degrees of Freedom} = N\\]\n\n\n\nüìà Sample Case\nConstraint introduced by sample mean\n\nWe must estimate \\(\\mu\\) using \\(\\bar{x}\\)\nOnce we know \\(\\bar{x}\\) and \\((n-1)\\) observations, the last one is determined\nWe ‚Äúlose‚Äù one degree of freedom\n\n\n\\[\\text{Degrees of Freedom} = n-1\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#section",
    "href": "files/lecture_notes/lecture3/lecture3.html#section",
    "title": "Descriptive Statistics Part II",
    "section": "",
    "text": "Sample Mean Constraint\n\\[\\bar{x} = \\frac{x_1 + x_2 + \\cdots + x_n}{n}\\]\nRearranging: \\[x_n = n\\bar{x} - (x_1 + x_2 + \\cdots + x_{n-1})\\]\nOnce we know \\(\\bar{x}\\) and the first \\((n-1)\\) values, \\(x_n\\) is completely determined!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#example-calculation",
    "href": "files/lecture_notes/lecture3/lecture3.html#example-calculation",
    "title": "Descriptive Statistics Part II",
    "section": "Example Calculation",
    "text": "Example Calculation\nData: 3, 7, 2, 8, 5\nIf this is the entire population:\n\n\\(\\mu = \\frac{3+7+2+8+5}{5} = 5\\)\n\\(\\sigma^2 = \\frac{(3-5)^2+(7-5)^2+(2-5)^2+(8-5)^2+(5-5)^2}{5} = \\frac{22}{5} = 4.4\\)\n\nIf this is a sample:\n\n\\(\\bar{x} = 5\\) (same calculation)\n\\(s^2 = \\frac{22}{5-1} = \\frac{22}{4} = 5.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#variance-properties",
    "href": "files/lecture_notes/lecture3/lecture3.html#variance-properties",
    "title": "Descriptive Statistics Part II",
    "section": "Variance Properties",
    "text": "Variance Properties\nVariance measures:\n\nAverage squared deviation from the mean\nAlways non-negative: \\(\\sigma^2 \\geq 0\\), \\(s^2 \\geq 0\\)\nUnits: (original units)¬≤\n\nStandard Deviation:\n\n\\(\\sigma = \\sqrt{\\sigma^2}\\) (population)\n\\(s = \\sqrt{s^2}\\) (sample)\nSame units as original data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#bias-and-unbiasedness",
    "href": "files/lecture_notes/lecture3/lecture3.html#bias-and-unbiasedness",
    "title": "Descriptive Statistics Part II",
    "section": "Bias and Unbiasedness",
    "text": "Bias and Unbiasedness\nPopulation variance:\n\nTrue parameter value\nNo estimation involved\n\nSample variance with \\((n-1)\\):\n\n\\(E[s^2] = \\sigma^2\\) (unbiased)\nOn average, equals population variance\n\nSample variance with \\(n\\):\n\n\\(E\\left[\\frac{\\sum(x_i - \\bar{x})^2}{n}\\right] = \\frac{n-1}{n}\\sigma^2\\) (biased)\nSystematically underestimates population variance"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#implementation",
    "href": "files/lecture_notes/lecture3/lecture3.html#implementation",
    "title": "Descriptive Statistics Part II",
    "section": "Implementation",
    "text": "Implementation\nCalculators:\n\nMost use \\((n-1)\\) by default for sample standard deviation\nCheck your calculator‚Äôs documentation\n\nSoftware:\n\nR: var() uses \\((n-1)\\), sd() uses \\((n-1)\\)\nExcel: VAR.S() uses \\((n-1)\\), VAR.P() uses \\(n\\)\nPython: np.var(ddof=1) uses \\((n-1)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practice-problem",
    "href": "files/lecture_notes/lecture3/lecture3.html#practice-problem",
    "title": "Descriptive Statistics Part II",
    "section": "Practice Problem",
    "text": "Practice Problem\nDataset: Number of hours studied by 6 students: 2, 4, 3, 5, 6, 4\nCalculate both:\n\nPopulation variance (assuming this is the entire population)\nSample variance (assuming this is a sample)\n\n\nSolution:\n\nMean: \\(\\bar{x} = \\frac{24}{6} = 4\\)\nPopulation variance: \\(\\sigma^2 = \\frac{10}{6} = 1.67\\)\nSample variance: \\(s^2 = \\frac{10}{5} = 2.0\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#summary",
    "href": "files/lecture_notes/lecture3/lecture3.html#summary",
    "title": "Descriptive Statistics Part II",
    "section": "Summary",
    "text": "Summary\n\nKey Takeaways\n\nPopulation variance uses \\(N\\) (entire population)\nSample variance uses \\((n-1)\\) (Bessel‚Äôs correction)\nSample variance is unbiased estimator of population variance\nDifference matters more for small samples\nAlways check which formula your software uses!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#example-1",
    "href": "files/lecture_notes/lecture3/lecture3.html#example-1",
    "title": "Descriptive Statistics Part II",
    "section": "Example",
    "text": "Example\n\n\nüìä Complete Population Data (Test Scores)\nWe have test scores from 100 students arranged in a grid:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nM\nN\nO\nP\nQ\nR\nS\nT\n\n\n\n\n1\n24\n96\n30\n69\n85\n60\n55\n18\n30\n66\n64\n99\n92\n95\n84\n55\n72\n38\n86\n32\n\n\n2\n53\n81\n30\n89\n42\n94\n31\n26\n53\n78\n38\n60\n93\n90\n82\n85\n89\n54\n30\n58\n\n\n3\n62\n67\n75\n47\n99\n25\n32\n63\n49\n45\n30\n97\n57\n32\n37\n62\n33\n16\n11\n41\n\n\n4\n95\n74\n28\n73\n82\n97\n65\n88\n56\n95\n85\n44\n70\n65\n34\n85\n58\n15\n64\n84\n\n\n5\n76\n46\n83\n56\n98\n16\n76\n77\n35\n19\n97\n42\n90\n79\n73\n28\n82\n92\n90\n22\n\n\n\n\n\n\nüéØ Random Sample Selection\nWe randomly select 5 scores from different positions in our population:\nOur Sample: 82, 95, 83, 60, 92"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#final-calculations",
    "href": "files/lecture_notes/lecture3/lecture3.html#final-calculations",
    "title": "Descriptive Statistics Part II",
    "section": "Final Calculations",
    "text": "Final Calculations\n\n\n\nSample Variance\n\n\n\\[s^2 = \\frac{\\sum(x_i - \\bar{x})^2}{n-1}\\] \\[s^2 = \\frac{753.2}{5-1} = \\frac{753.2}{4} = 188.3\\]\n\n\n\n\nSample Standard Deviation\n\n\n\\[s = \\sqrt{s^2}\\] \\[s = \\sqrt{188.3} = 13.72\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#properties-of-standard-deviation",
    "href": "files/lecture_notes/lecture3/lecture3.html#properties-of-standard-deviation",
    "title": "Descriptive Statistics Part II",
    "section": "Properties of Standard Deviation",
    "text": "Properties of Standard Deviation\n\nSame units as the original data\nAlways non-negative\nZero only when all values are identical\nLarger values indicate more variability\nApproximately 68% of data within 1 SD of mean (for normal distributions)\nApproximately 95% of data within 2 SD of mean"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#empirical-rule-68-95-99.7-rule",
    "href": "files/lecture_notes/lecture3/lecture3.html#empirical-rule-68-95-99.7-rule",
    "title": "Descriptive Statistics Part II",
    "section": "Empirical Rule (68-95-99.7 Rule)",
    "text": "Empirical Rule (68-95-99.7 Rule)\nFor approximately normal distributions:\n\n68% of data falls within 1 standard deviation of the mean\n95% of data falls within 2 standard deviations of the mean\n99.7% of data falls within 3 standard deviations of the mean\n\nThis rule helps us understand what constitutes ‚Äútypical‚Äù vs ‚Äúunusual‚Äù values."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#definition-and-purpose",
    "href": "files/lecture_notes/lecture3/lecture3.html#definition-and-purpose",
    "title": "Descriptive Statistics Part II",
    "section": "Definition and Purpose",
    "text": "Definition and Purpose\n\nüéØ Definition: Coefficient of Variation (CV) = \\(\\frac{\\text{Standard Deviation}}{\\text{Mean}} \\times 100\\%\\)\n\n\nWhy Use CV?\n\nCompares variability across different units or scales\nRelative measure of variability\nUseful when means differ substantially"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-implementation---variability",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-implementation---variability",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Variability",
    "text": "Python Implementation - Variability\n\nCodeVisualization\n\n\n\nimport numpy as np\nimport pandas as pd\n\n# Sample data\ndata = [10, 12, 14, 16, 18, 22, 25]\n\n# Calculate measures of variability\nrange_val = np.max(data) - np.min(data)\nvariance_sample = np.var(data, ddof=1)  # Sample variance\nstd_sample = np.std(data, ddof=1)       # Sample standard deviation\ncv = (std_sample / np.mean(data)) * 100\n\nprint(f\"Range: {range_val}\")\nprint(f\"Variance: {variance_sample:.2f}\")\nprint(f\"Standard Deviation: {std_sample:.2f}\")\nprint(f\"Coefficient of Variation: {cv:.1f}%\")\n\nRange: 15\nVariance: 28.90\nStandard Deviation: 5.38\nCoefficient of Variation: 32.2%"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-are-measures-of-position",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-are-measures-of-position",
    "title": "Descriptive Statistics Part II",
    "section": "What are Measures of Position?",
    "text": "What are Measures of Position?\n\n\nMeasures of position tell us where a particular value stands relative to the rest of the data.\nThey answer questions like:\n\n‚ÄúWhat percentage of students scored below 85?‚Äù\n‚ÄúIs this value typical or unusual?‚Äù\n‚ÄúHow does this observation compare to others?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#percentiles-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#percentiles-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Percentiles Definition",
    "text": "Percentiles Definition\nThe k-th percentile is the value below which k% of the data falls.\nExamples:\n\n50th percentile = Median (50% of data below this value)\n90th percentile = 90% of data falls below this value\n25th percentile = 25% of data falls below this value"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#quartiles",
    "href": "files/lecture_notes/lecture3/lecture3.html#quartiles",
    "title": "Descriptive Statistics Part II",
    "section": "Quartiles",
    "text": "Quartiles\nQuartiles divide the data into four equal parts:\n\nQ1 (First Quartile) = 25th percentile\nQ2 (Second Quartile) = 50th percentile = Median\nQ3 (Third Quartile) = 75th percentile"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#interquartile-range-iqr",
    "href": "files/lecture_notes/lecture3/lecture3.html#interquartile-range-iqr",
    "title": "Descriptive Statistics Part II",
    "section": "Interquartile Range (IQR)",
    "text": "Interquartile Range (IQR)\nIQR = Q3 - Q1\n\n\n\n\nProperties of IQR:\n\nContains the middle 50% of the data\nResistant to outliers\nUsed in boxplot construction\nUseful for outlier detection"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#z-score-definition",
    "href": "files/lecture_notes/lecture3/lecture3.html#z-score-definition",
    "title": "Descriptive Statistics Part II",
    "section": "Z-score Definition",
    "text": "Z-score Definition\n\n\n\nüéØ Definition\nZ-score tells us how many standard deviations a value is from the mean.\n\n\n\\[z = \\frac{x - \\mu}{\\sigma} \\text{ or } z = \\frac{x - \\bar{x}}{s}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#z-score-example",
    "href": "files/lecture_notes/lecture3/lecture3.html#z-score-example",
    "title": "Descriptive Statistics Part II",
    "section": "Z-score Example",
    "text": "Z-score Example\nStudent‚Äôs test score: 85 Class mean: 78, Class standard deviation: 6\n\n\\[z = \\frac{85 - 78}{6} = \\frac{7}{6} = 1.17\\]\n\nInterpretation: This student scored 1.17 standard deviations above the class average."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#benefits-of-standardization",
    "href": "files/lecture_notes/lecture3/lecture3.html#benefits-of-standardization",
    "title": "Descriptive Statistics Part II",
    "section": "Benefits of Standardization",
    "text": "Benefits of Standardization\n\nCompare across different scales (test scores vs income)\nIdentify outliers systematically\n\nCombine different variables meaningfully\nPrepare data for certain statistical methods"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#skewness",
    "href": "files/lecture_notes/lecture3/lecture3.html#skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Skewness",
    "text": "Skewness\nSkewness measures the asymmetry of a distribution.\nTypes of Skewness:\n\n\n\n\nSymmetric (Skewness ‚âà 0): Mean ‚âà Median ‚âà Mode\nRight-skewed (Positive skewness): Mean &gt; Median, long tail to the right\nLeft-skewed (Negative skewness): Mean &lt; Median, long tail to the left"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#examples-of-skewness",
    "href": "files/lecture_notes/lecture3/lecture3.html#examples-of-skewness",
    "title": "Descriptive Statistics Part II",
    "section": "Examples of Skewness",
    "text": "Examples of Skewness\nRight-skewed (Income data):\n\nMost people earn moderate amounts\nFew people earn very high amounts\nMean &gt; Median\n\nLeft-skewed (Test scores with ceiling effect):\n\nMost students score high\nFew students score very low\nMean &lt; Median"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#kurtosis",
    "href": "files/lecture_notes/lecture3/lecture3.html#kurtosis",
    "title": "Descriptive Statistics Part II",
    "section": "Kurtosis",
    "text": "Kurtosis\nKurtosis measures the ‚Äútailedness‚Äù of a distribution. It measures the degree of peaked Ness or flatness of a distribution compared to the normal distribution.\nTypes:\n\nMesokurtic (Normal-like): Kurtosis ‚âà 3\nLeptokurtic (Heavy tails): Kurtosis &gt; 3, more peaked\nPlatykurtic (Light tails): Kurtosis &lt; 3, flatter\n\nExcess Kurtosis = Kurtosis - 3 (makes normal distributions have excess kurtosis of 0)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-implementation---position-shape",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-implementation---position-shape",
    "title": "Descriptive Statistics Part II",
    "section": "Python Implementation - Position & Shape",
    "text": "Python Implementation - Position & Shape\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\n\ndata = [12, 15, 18, 22, 25, 28, 30, 35, 40, 45]\n\n# Percentiles and quartiles\nq1 = np.percentile(data, 25)\nmedian = np.percentile(data, 50)\nq3 = np.percentile(data, 75)\niqr = q3 - q1\n\n# Z-scores\nz_scores = stats.zscore(data)\n\n# Shape measures\nskewness = stats.skew(data)\nkurt = stats.kurtosis(data)\n\nprint(f\"Q1: {q1}, Median: {median}, Q3: {q3}\")\nprint(f\"IQR: {iqr}\")\nprint(f\"Skewness: {skewness:.3f}\")\nprint(f\"Kurtosis: {kurt:.3f}\")\n\nQ1: 19.0, Median: 26.5, Q3: 33.75\nIQR: 14.75\nSkewness: 0.243\nKurtosis: -1.023"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-is-a-histogram",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-is-a-histogram",
    "title": "Descriptive Statistics Part II",
    "section": "What is a Histogram?",
    "text": "What is a Histogram?\nA histogram displays the distribution of a continuous variable by dividing data into bins and showing the frequency of observations in each bin.\nKey Components:\n\nX-axis: Variable values (continuous)\nY-axis: Frequency or density\nBins: Intervals that group the data\nBars: Height represents frequency in each bin"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#choosing-bin-width-critical-decision",
    "href": "files/lecture_notes/lecture3/lecture3.html#choosing-bin-width-critical-decision",
    "title": "Descriptive Statistics Part II",
    "section": "Choosing Bin Width: Critical Decision",
    "text": "Choosing Bin Width: Critical Decision\nBin width dramatically affects histogram interpretation!\nToo Few Bins (Wide bins):\n\nOversmoothing - lose important details\nMay hide multimodality\nDistribution appears simpler than it is\n\nToo Many Bins (Narrow bins):\n\nUndersmoothing - too much noise\nMay create artificial gaps\nHard to see overall pattern"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#bin-width-guidelines",
    "href": "files/lecture_notes/lecture3/lecture3.html#bin-width-guidelines",
    "title": "Descriptive Statistics Part II",
    "section": "Bin Width Guidelines",
    "text": "Bin Width Guidelines\nRule of Thumb Methods:\n\nSquare Root Rule: Number of bins ‚âà \\(\\sqrt{n}\\)\nSturges‚Äô Rule: Number of bins = \\(1 + \\log_2(n)\\)\nScott‚Äôs Rule: Bin width = \\(\\frac{3.5 \\times \\text{SD}}{n^{1/3}}\\)\nFreedman-Diaconis Rule: Bin width = \\(\\frac{2 \\times \\text{IQR}}{n^{1/3}}\\)\n\nBest practice: Try multiple bin widths and choose based on the story your data tells!"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#python-histogram-examples",
    "href": "files/lecture_notes/lecture3/lecture3.html#python-histogram-examples",
    "title": "Descriptive Statistics Part II",
    "section": "Python Histogram Examples",
    "text": "Python Histogram Examples\n\nCodeVisualization\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate sample data\nnp.random.seed(42)\ndata = np.random.normal(100, 15, 1000)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#interpreting-histograms",
    "href": "files/lecture_notes/lecture3/lecture3.html#interpreting-histograms",
    "title": "Descriptive Statistics Part II",
    "section": "Interpreting Histograms",
    "text": "Interpreting Histograms\nWhat to Look For:\n\nShape: Normal, skewed, uniform, bimodal?\nCenter: Where is the ‚Äútypical‚Äù value?\nSpread: How variable is the data?\nOutliers: Any unusual values?\nGaps: Are there missing values in certain ranges?\nMultiple peaks: Suggests multiple subgroups"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#anatomy-of-a-boxplot",
    "href": "files/lecture_notes/lecture3/lecture3.html#anatomy-of-a-boxplot",
    "title": "Descriptive Statistics Part II",
    "section": "Anatomy of a Boxplot",
    "text": "Anatomy of a Boxplot"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#boxplot-components-explained",
    "href": "files/lecture_notes/lecture3/lecture3.html#boxplot-components-explained",
    "title": "Descriptive Statistics Part II",
    "section": "Boxplot Components Explained",
    "text": "Boxplot Components Explained\nThe Box:\n\nLeft edge: Q1 (25th percentile)\nMiddle line: Median (Q2, 50th percentile)\n\nRight edge: Q3 (75th percentile)\nBox width: IQR (contains middle 50% of data)\n\nThe Whiskers:\n\nExtend to: Most extreme values within 1.5 √ó IQR from box edges\nLower whisker: Minimum value within Q1 - 1.5√óIQR\nUpper whisker: Maximum value within Q3 + 1.5√óIQR"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#what-boxplots-tell-us",
    "href": "files/lecture_notes/lecture3/lecture3.html#what-boxplots-tell-us",
    "title": "Descriptive Statistics Part II",
    "section": "What Boxplots Tell Us",
    "text": "What Boxplots Tell Us\nDistribution Shape:\n\nSymmetric: Median in center of box, whiskers equal length\nRight-skewed: Median closer to Q1, longer upper whisker\nLeft-skewed: Median closer to Q3, longer lower whisker\n\nVariability:\n\nWide box: High variability in middle 50%\nLong whiskers: High overall variability\nMany outliers: Extreme variability"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#comparing-groups-with-boxplots",
    "href": "files/lecture_notes/lecture3/lecture3.html#comparing-groups-with-boxplots",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Groups with Boxplots",
    "text": "Comparing Groups with Boxplots"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#advanced-boxplot-interpretations",
    "href": "files/lecture_notes/lecture3/lecture3.html#advanced-boxplot-interpretations",
    "title": "Descriptive Statistics Part II",
    "section": "Advanced Boxplot Interpretations",
    "text": "Advanced Boxplot Interpretations"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#comparing-boxplots",
    "href": "files/lecture_notes/lecture3/lecture3.html#comparing-boxplots",
    "title": "Descriptive Statistics Part II",
    "section": "Comparing Boxplots:",
    "text": "Comparing Boxplots:\n\nMedian differences: Which group has higher typical values?\nIQR differences: Which group is more consistent?\nOutlier patterns: Which group has more extreme values?\nOverlap: Do the groups have similar ranges?"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#business-applications",
    "href": "files/lecture_notes/lecture3/lecture3.html#business-applications",
    "title": "Descriptive Statistics Part II",
    "section": "Business Applications:",
    "text": "Business Applications:\n\nQuality control: Compare product batches\nPerformance analysis: Compare team/department performance\n\nCustomer segmentation: Compare customer groups"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#common-patterns-in-data",
    "href": "files/lecture_notes/lecture3/lecture3.html#common-patterns-in-data",
    "title": "Descriptive Statistics Part II",
    "section": "Common Patterns in Data",
    "text": "Common Patterns in Data\nDistribution Patterns:\n\nNormal/Bell-shaped: Symmetric, single peak\nUniform: All values equally likely\nBimodal: Two distinct peaks (suggests subgroups)\nMultimodal: Multiple peaks\nU-shaped: High values at extremes, low in middle\n\nOutlier Patterns:\n\nIndividual outliers: Data entry errors, measurement errors\nClustered outliers: Distinct subpopulation\nSystematic outliers: May indicate process changes"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#red-flags-in-data-visualization",
    "href": "files/lecture_notes/lecture3/lecture3.html#red-flags-in-data-visualization",
    "title": "Descriptive Statistics Part II",
    "section": "Red Flags in Data Visualization",
    "text": "Red Flags in Data Visualization\nWarning Signs:\n\nGaps in histograms: Missing data or measurement limitations\nHeaping: Values cluster at round numbers (10, 50, 100)\nTruncation: Data cut off at certain values\nDigit preference: People prefer certain ending digits\nMultiple modes: Hidden subgroups in your data"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#essential-concepts-to-remember",
    "href": "files/lecture_notes/lecture3/lecture3.html#essential-concepts-to-remember",
    "title": "Descriptive Statistics Part II",
    "section": "Essential Concepts to Remember",
    "text": "Essential Concepts to Remember\nVariability:\n\nStandard deviation is preferred over range for most analyses\nCV allows comparison across different scales\nIQR is resistant to outliers\n\nPosition:\n\nPercentiles and quartiles provide relative position\nZ-scores standardize across different distributions\nFive-number summary gives complete overview"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#practical-guidelines",
    "href": "files/lecture_notes/lecture3/lecture3.html#practical-guidelines",
    "title": "Descriptive Statistics Part II",
    "section": "Practical Guidelines",
    "text": "Practical Guidelines\n\nAlways visualize before calculating statistics\nUse multiple measures - no single statistic tells the whole story\nConsider the context - what makes sense for your data?\nCheck for outliers - they can drastically affect your analysis\nCompare distributions using standardized measures when appropriate"
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#try-these-exercises",
    "href": "files/lecture_notes/lecture3/lecture3.html#try-these-exercises",
    "title": "Descriptive Statistics Part II",
    "section": "Try These Exercises",
    "text": "Try These Exercises\n\nCalculate the five-number summary for: 12, 15, 18, 22, 25, 28, 30, 35, 40, 45\nCreate histograms with 5, 15, and 50 bins for the same dataset. What patterns do you observe?\nInterpret this scenario: Dataset A has mean=50, SD=5. Dataset B has mean=100, SD=10. Which is more variable?\nA student scores 85 on a test where the class mean is 78 and SD is 6. Calculate and interpret the z-score.\nDesign a boxplot comparison for three different customer segments in your business."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html#additional-resources",
    "href": "files/lecture_notes/lecture3/lecture3.html#additional-resources",
    "title": "Descriptive Statistics Part II",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nMatplotlib Gallery: Histogram and Boxplot Examples\nExplore examples of histograms, boxplots, and other visualizations using Matplotlib.\nSeaborn Documentation: Statistical Visualizations\nFind examples and documentation for statistical visualizations, including distribution plots, categorical plots, and regression plots.\nNumPy Statistical Functions Reference\nOfficial reference for NumPy‚Äôs statistical functions such as mean, median, variance, and standard deviation.\nSciPy Statistical Functions Reference\nComprehensive documentation for statistical functions in scipy.stats, including probability distributions, hypothesis tests, and descriptive statistics.\nRecommended reading: Continue reading Chapter 2 in course textbook"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#problem-statement",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#problem-statement",
    "title": "Linear Transformation Properties",
    "section": "Problem Statement",
    "text": "Problem Statement\n\nGiven: Let \\(X = \\{x_i\\}_{i=1}^{n}\\) and define \\(Y = \\{y_i\\}_{i=1}^{n}\\) by \\(y_i = a x_i\\) for some fixed constant \\(a \\neq 0\\).\nProve the following relationships:\n\\[\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i, \\quad \\bar{Y} = a \\bar{X}, \\quad S_Y^2 = a^2 S_X^2\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#understanding-the-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#understanding-the-notation",
    "title": "Linear Transformation Properties",
    "section": "Understanding the Notation",
    "text": "Understanding the Notation\nSet Notation\n\n\\(X = \\{x_i\\}_{i=1}^{n}\\) means:\n\n\\(X\\) is a dataset containing \\(n\\) observations\nThe observations are labeled \\(x_1, x_2, x_3, \\ldots, x_n\\)\n\\(i\\) is an index that runs from 1 to \\(n\\)\nThis is read as: ‚ÄúX is the set of \\(x_i\\) for \\(i\\) from 1 to \\(n\\)‚Äù\n\n\nExamples:\n\nIf \\(n = 5\\): \\(X = \\{x_1, x_2, x_3, x_4, x_5\\}\\)\nIf \\(X = \\{2, 4, 6, 8, 10\\}\\), then \\(x_1 = 2, x_2 = 4, x_3 = 6, x_4 = 8, x_5 = 10\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#summation-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#summation-notation",
    "title": "Linear Transformation Properties",
    "section": "Summation Notation",
    "text": "Summation Notation\n\n\\(\\sum_{i=1}^{n} x_i\\) means:\n\nAdd up all the \\(x_i\\) values\nStart with \\(i = 1\\) and go up to \\(i = n\\)\nThis equals: \\(x_1 + x_2 + x_3 + \\cdots + x_n\\)\n\n\nExample:\nIf \\(X = \\{2, 4, 6, 8, 10\\}\\), then: \\[\\sum_{i=1}^{5} x_i = x_1 + x_2 + x_3 + x_4 + x_5 = 2 + 4 + 6 + 8 + 10 = 30\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#linear-transformation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#linear-transformation",
    "title": "Linear Transformation Properties",
    "section": "Linear Transformation",
    "text": "Linear Transformation\n\n\\(Y = \\{y_i\\}_{i=1}^{n}\\) where \\(y_i = a x_i\\) means:\n\nEach element of \\(Y\\) is obtained by multiplying the corresponding element of \\(X\\) by the constant \\(a\\)\nThis is called a linear transformation\n\\(a\\) is called the scaling factor\n\n\nExample:\nIf \\(X = \\{2, 4, 6, 8, 10\\}\\) and \\(a = 3\\), then:\n\n\\(y_1 = 3 \\times 2 = 6\\)\n\\(y_2 = 3 \\times 4 = 12\\)\n\\(y_3 = 3 \\times 6 = 18\\)\n\\(y_4 = 3 \\times 8 = 24\\)\n\\(y_5 = 3 \\times 10 = 30\\)\n\nSo \\(Y = \\{6, 12, 18, 24, 30\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#sample-mean-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#sample-mean-notation",
    "title": "Linear Transformation Properties",
    "section": "Sample Mean Notation",
    "text": "Sample Mean Notation\n\nSample Mean: \\(\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\\)\nThis means:\n\nAdd up all observations: \\(\\sum_{i=1}^{n} x_i\\)\nDivide by the number of observations: \\(n\\)\nThe ‚Äúbar‚Äù over \\(X\\) indicates the mean\n\n\nExample:\nFor \\(X = \\{2, 4, 6, 8, 10\\}\\): \\[\\bar{X} = \\frac{1}{5}(2 + 4 + 6 + 8 + 10) = \\frac{30}{5} = 6\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#sample-variance-notation",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#sample-variance-notation",
    "title": "Linear Transformation Properties",
    "section": "Sample Variance Notation",
    "text": "Sample Variance Notation\n\nSample Variance: \\(S_X^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2\\)\nThis means:\n\nFor each observation, find its deviation from the mean: \\((x_i - \\bar{X})\\)\nSquare each deviation: \\((x_i - \\bar{X})^2\\)\nAdd up all squared deviations: \\(\\sum_{i=1}^{n} (x_i - \\bar{X})^2\\)\nDivide by \\((n-1)\\): This gives the sample variance"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-1",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-1",
    "title": "Linear Transformation Properties",
    "section": "Proof 1: Sum Relationship",
    "text": "Proof 1: Sum Relationship\n\nStep 1: Start with the definition of \\(y_i\\) \\[y_i = a x_i \\text{ for all } i = 1, 2, \\ldots, n\\]\nStep 2: Write out the sum of all \\(y_i\\) \\[\\sum_{i=1}^{n} y_i = y_1 + y_2 + y_3 + \\cdots + y_n\\]\nStep 3: Substitute the definition \\(y_i = a x_i\\) \\[\\sum_{i=1}^{n} y_i = a x_1 + a x_2 + a x_3 + \\cdots + a x_n\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-continued",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-1-sum-relationship-continued",
    "title": "Linear Transformation Properties",
    "section": "Proof 1: Sum Relationship (continued)",
    "text": "Proof 1: Sum Relationship (continued)\n\n\n\nStep 4: Factor out the constant \\(a\\) \\[\\sum_{i=1}^{n} y_i = a(x_1 + x_2 + x_3 + \\cdots + x_n)\\]\nStep 5: Recognize the sum notation \\[\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\]\nTherefore: \\(\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\) ‚úì\n\n\n\nKey Property Used: Constants can be factored out of sums \\[\\sum_{i=1}^{n} (c \\cdot x_i) = c \\sum_{i=1}^{n} x_i\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#example-sum-relationship",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#example-sum-relationship",
    "title": "Linear Transformation Properties",
    "section": "Example: Sum Relationship",
    "text": "Example: Sum Relationship\n\nGiven: \\(X = \\{2, 4, 6\\}\\) and \\(a = 5\\)\nThen: \\(Y = \\{10, 20, 30\\}\\) (since \\(y_i = 5x_i\\))\nCheck our formula:\n\n\\(\\sum_{i=1}^{3} x_i = 2 + 4 + 6 = 12\\)\n\\(\\sum_{i=1}^{3} y_i = 10 + 20 + 30 = 60\\)\n\\(a \\sum_{i=1}^{3} x_i = 5 \\times 12 = 60\\) ‚úì\n\nVerification: \\(60 = 60\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-1",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-1",
    "title": "Linear Transformation Properties",
    "section": "Proof 2: Sample Mean Relationship",
    "text": "Proof 2: Sample Mean Relationship\n\nStep 1: Start with the definition of sample mean \\[\\bar{Y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i\\]\nStep 2: Use our result from Proof 1 We proved that \\(\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\)\nStep 3: Substitute this result \\[\\bar{Y} = \\frac{1}{n} \\cdot a \\sum_{i=1}^{n} x_i\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-continued",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-2-sample-mean-relationship-continued",
    "title": "Linear Transformation Properties",
    "section": "Proof 2: Sample Mean Relationship (continued)",
    "text": "Proof 2: Sample Mean Relationship (continued)\n\n\n\nStep 4: Rearrange the constants \\[\\bar{Y} = a \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]\nStep 5: Recognize the definition of \\(\\bar{X}\\) \\[\\bar{Y} = a \\bar{X}\\]\nTherefore: \\(\\bar{Y} = a \\bar{X}\\) ‚úì\n\n\n\nKey Property Used: Constants can be moved outside of fractions \\[\\frac{1}{n} \\cdot a \\sum_{i=1}^{n} x_i = a \\cdot \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-mean-relationship",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-mean-relationship",
    "title": "Linear Transformation Properties",
    "section": "Example: Sample Mean Relationship",
    "text": "Example: Sample Mean Relationship\n\nGiven: \\(X = \\{2, 4, 6\\}\\) and \\(a = 5\\)\nThen: \\(Y = \\{10, 20, 30\\}\\)\nCheck our formula:\n\n\\(\\bar{X} = \\frac{1}{3}(2 + 4 + 6) = \\frac{12}{3} = 4\\)\n\\(\\bar{Y} = \\frac{1}{3}(10 + 20 + 30) = \\frac{60}{3} = 20\\)\n\\(a \\bar{X} = 5 \\times 4 = 20\\) ‚úì\n\nVerification: \\(20 = 20\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-1",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-1",
    "title": "Linear Transformation Properties",
    "section": "Proof 3: Sample Variance Relationship",
    "text": "Proof 3: Sample Variance Relationship\n\nStep 1: Start with the definition of sample variance \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\bar{Y})^2\\]\nStep 2: Substitute \\(y_i = a x_i\\) and \\(\\bar{Y} = a \\bar{X}\\) \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (a x_i - a \\bar{X})^2\\]\nStep 3: Factor out \\(a\\) from the parentheses \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} [a(x_i - \\bar{X})]^2\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-continued",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#proof-3-sample-variance-relationship-continued",
    "title": "Linear Transformation Properties",
    "section": "Proof 3: Sample Variance Relationship (continued)",
    "text": "Proof 3: Sample Variance Relationship (continued)\n\nStep 4: Use the property \\((ab)^2 = a^2 b^2\\) \\[S_Y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} a^2 (x_i - \\bar{X})^2\\]\nStep 5: Factor out the constant \\(a^2\\) from the sum \\[S_Y^2 = \\frac{a^2}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2\\]\nStep 6: Recognize the definition of \\(S_X^2\\) \\[S_Y^2 = a^2 \\cdot \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{X})^2 = a^2 S_X^2\\]\nTherefore: \\(S_Y^2 = a^2 S_X^2\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#key-properties-used-in-variance-proof",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#key-properties-used-in-variance-proof",
    "title": "Linear Transformation Properties",
    "section": "Key Properties Used in Variance Proof",
    "text": "Key Properties Used in Variance Proof\n\nProperties Used:\n\nFactoring: \\(ax_i - a\\bar{X} = a(x_i - \\bar{X})\\)\nSquaring: \\([a(x_i - \\bar{X})]^2 = a^2(x_i - \\bar{X})^2\\)\nConstants in sums: \\(\\sum_{i=1}^{n} a^2 f(x_i) = a^2 \\sum_{i=1}^{n} f(x_i)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-variance-relationship",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#example-sample-variance-relationship",
    "title": "Linear Transformation Properties",
    "section": "Example: Sample Variance Relationship",
    "text": "Example: Sample Variance Relationship\n\nGiven: \\(X = \\{1, 3, 5\\}\\) and \\(a = 2\\)\nCalculate \\(S_X^2\\):\n\n\\(\\bar{X} = \\frac{1+3+5}{3} = 3\\)\n\\(S_X^2 = \\frac{1}{2}[(1-3)^2 + (3-3)^2 + (5-3)^2] = \\frac{1}{2}[4 + 0 + 4] = 4\\)\n\nFor \\(Y = \\{2, 6, 10\\}\\): - \\(\\bar{Y} = \\frac{2+6+10}{3} = 6 = 2 \\times 3\\) ‚úì\n\n\\(S_Y^2 = \\frac{1}{2}[(2-6)^2 + (6-6)^2 + (10-6)^2] = \\frac{1}{2}[16 + 0 + 16] = 16\\)\n\nCheck: \\(a^2 S_X^2 = 2^2 \\times 4 = 16\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#complete-summary-of-results",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#complete-summary-of-results",
    "title": "Linear Transformation Properties",
    "section": "Complete Summary of Results",
    "text": "Complete Summary of Results\n\nFor the linear transformation \\(Y = \\{y_i\\}_{i=1}^{n}\\) where \\(y_i = a x_i\\):\n\nSum: \\(\\sum_{i=1}^{n} y_i = a \\sum_{i=1}^{n} x_i\\)\nMean: \\(\\bar{Y} = a \\bar{X}\\)\nVariance: \\(S_Y^2 = a^2 S_X^2\\)\n\nNote: The standard deviation relationship is \\(S_Y = |a| S_X\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#practical-implications",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#practical-implications",
    "title": "Linear Transformation Properties",
    "section": "Practical Implications",
    "text": "Practical Implications\n\n\nScaling Up (a &gt; 1):\n\nSums and means increase by factor \\(a\\)\nVariance increases by factor \\(a^2\\)\nData becomes more spread out\n\nExample: Converting inches to feet\n\nIf \\(a = 12\\), variance increases by \\(12^2 = 144\\)\n\n\n\nScaling Down (0 &lt; a &lt; 1):\n\nSums and means decrease by factor \\(a\\)\nVariance decreases by factor \\(a^2\\)\nData becomes less spread out\n\nExample: Converting dollars to cents\n\nIf \\(a = 0.01\\), variance decreases by \\((0.01)^2 = 0.0001\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#real-world-applications",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#real-world-applications",
    "title": "Linear Transformation Properties",
    "section": "Real-World Applications",
    "text": "Real-World Applications\n\nTemperature Conversion:\n\nCelsius to Fahrenheit: \\(F = \\frac{9}{5}C + 32\\) (not linear!)\nCelsius to Kelvin: \\(K = C + 273.15\\) (not linear!)\nBut scaling: \\(C_{doubled} = 2C\\) is linear with \\(a = 2\\)\n\nUnit Conversions: - Meters to centimeters: \\(a = 100\\)\n\nDollars to cents: \\(a = 100\\)\nHours to minutes: \\(a = 60\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#why-these-properties-matter",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#why-these-properties-matter",
    "title": "Linear Transformation Properties",
    "section": "Why These Properties Matter",
    "text": "Why These Properties Matter\n\nStatistical Significance:\n\nStandardization: Converting to z-scores uses linear transformations\nUnit Changes: Results remain proportionally correct\nData Analysis: Understanding how transformations affect summary statistics\nModeling: Linear regression relies on these properties\n\nKey Insight: Linear transformations preserve the shape of the distribution while changing location and scale."
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#practice-problem",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#practice-problem",
    "title": "Linear Transformation Properties",
    "section": "Practice Problem",
    "text": "Practice Problem\n\nTry This: A dataset has mean \\(\\bar{X} = 15\\) and variance \\(S_X^2 = 9\\).\nIf we transform the data using \\(y_i = 3x_i - 2\\), what are the new mean and variance?\n\n\n\n\n\n\nTip\n\n\nHint: This is not a pure linear transformation! You need \\(y_i = 3x_i - 2 = 3(x_i - \\frac{2}{3})\\)\n\n\n\n\nAnswer:\n\nNew mean: \\(\\bar{Y} = 3(15) - 2 = 43\\)\nNew variance: \\(S_Y^2 = 3^2 \\times 9 = 81\\)\n(The constant \\(-2\\) doesn‚Äôt affect variance!)"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#common-mistakes-to-avoid",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#common-mistakes-to-avoid",
    "title": "Linear Transformation Properties",
    "section": "Common Mistakes to Avoid",
    "text": "Common Mistakes to Avoid\n\n‚ùå Wrong: \\(S_Y^2 = a S_X^2\\)\n‚úÖ Correct: \\(S_Y^2 = a^2 S_X^2\\)\nWhy: Variance involves squared deviations, so the scaling factor gets squared too.\n‚ùå Wrong: Adding constants affects variance\n‚úÖ Correct: Only multiplication affects variance; addition only shifts the mean"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#conclusion",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#conclusion",
    "title": "Linear Transformation Properties",
    "section": "Conclusion",
    "text": "Conclusion\n\nWhat We Proved:\nFor the linear transformation \\(y_i = ax_i\\) with constant \\(a \\neq 0\\):\n\nSums scale linearly: Factor of \\(a\\)\nMeans scale linearly: Factor of \\(a\\)\n\nVariances scale quadratically: Factor of \\(a^2\\)\n\nKey Takeaway: Understanding these relationships is fundamental for:\n\nData transformations\nStatistical modeling\nUnit conversions\nStandardization procedures"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#questions",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#questions",
    "title": "Linear Transformation Properties",
    "section": "Questions?",
    "text": "Questions?\nKey Concepts Covered:\n\nSummation notation and indexing\nLinear transformations\nProperties of means and variances\nStep-by-step mathematical proofs\n\nNext Steps:\n\nApply to real datasets\nExplore non-linear transformations\nPractice with different scaling factors"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#additional-practice",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#additional-practice",
    "title": "Linear Transformation Properties",
    "section": "Additional Practice",
    "text": "Additional Practice\n\nExercise 1: If \\(X = \\{10, 20, 30, 40\\}\\) and \\(Y = \\{-5, -10, -15, -20\\}\\), what is the value of \\(a\\)?\nExercise 2: A dataset has \\(\\bar{X} = 50\\) and \\(S_X = 10\\). After transformation \\(y_i = 0.5x_i\\), find \\(\\bar{Y}\\) and \\(S_Y\\).\nExercise 3: Prove that if \\(y_i = ax_i + b\\) (adding a constant), then \\(S_Y^2 = a^2 S_X^2\\) (the constant doesn‚Äôt affect variance)."
  },
  {
    "objectID": "files/worksheets/worksheet2.html",
    "href": "files/worksheets/worksheet2.html",
    "title": "PSTAT 5A Practice Worksheet 2",
    "section": "",
    "text": "Download PDF"
  },
  {
    "objectID": "files/worksheets/worksheet2.html#understanding-variance-population-vs-sample",
    "href": "files/worksheets/worksheet2.html#understanding-variance-population-vs-sample",
    "title": "PSTAT 5A Practice Worksheet 2",
    "section": "4.1 Understanding Variance: Population vs Sample",
    "text": "4.1 Understanding Variance: Population vs Sample\n\nüéØ Key Variance Concepts:\nPopulation Variance (when you have ALL data): \\[\\sigma^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\mu)^2}{N}\\]\nSample Variance (when you have a sample): \\[s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n-1}\\]\nWhy (n-1)? Using the sample mean to estimate deviations ‚Äúuses up‚Äù one degree of freedom.\n\n\nProblem C1: Basic Variance Calculations\nThe following data represents the number of customer complaints per day for a small business over 8 days:\nData: 3, 7, 2, 8, 5, 6, 4, 9\nPart (a) : Calculate the sample mean \\(\\bar{x}\\).\nPart (b) : Calculate the sample variance \\(s^2\\) using the formula with \\((n-1)\\) in the denominator.\nPart (c) : Calculate the sample standard deviation \\(s\\).\nPart (d) : If this were treated as a complete population, what would the population variance \\(\\sigma^2\\) be?\nPart (e) : Explain why we divide by \\((n-1)\\) for sample variance instead of \\(n\\).\nAnswer:\n\n\n\nProblem C2: Comparing Variability\nConsider two data sets:\n\nSet A: 10, 12, 14, 16, 18\nSet B: 5, 10, 14, 18, 23\n\n\nCalculate the mean for each set.\nCalculate the sample variance for each set.\nWhich set has greater variability?\nCalculate the coefficient of variation \\((CV = s/xÃÑ)\\) for each set. Which has greater relative variability?\n\nAnswer:"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#resources",
    "href": "files/lecture_notes/lecture4/lecture4.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms\nProbability Animations"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#intersection-a-cup-b",
    "href": "files/lecture_notes/lecture4/lecture4.html#intersection-a-cup-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Intersection: A \\(\\cup\\) B",
    "text": "Intersection: A \\(\\cup\\) B\n\n\n\nDefinition: Area where two or more sets overlap.\nIn Probability: The event that A AND B occurs.\nProperties:\n\nAlways smaller than or equal to individual sets\nCan be empty (disjoint sets)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-vs.-independent",
    "href": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-vs.-independent",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.¬†Independent",
    "text": "Mutually Exclusive vs.¬†Independent\n\nMutually Exclusive (left): the circles A and B do not overlap, so \\(P(A\\cap B)=0\\).\nIndependent (right): the circles overlap, and we‚Äôve sized the intersection so that \\(P(A\\cap B)=P(A)\\,P(B)\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#example-1",
    "href": "files/lecture_notes/lecture4/lecture4.html#example-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example",
    "text": "Example\n\n\n\nDraw a single card from a 52-card deck:\n\nLet A={‚Äúdraw an Ace‚Äù}, so P(A)=4/52.\nLet B={‚Äúdraw a King‚Äù}, so P(B)=4/52.\n\nWhat is \\(P(A\\cap B)\\) ?\n\n\n\n\n\nSolution. They‚Äôre disjoint (you can‚Äôt draw an Ace and a King), so \\(P(A\\cap B) = 0\\).\nBut \\(P(A)\\,P(B) = \\frac{4}{52}\\times\\frac{4}{52} = \\frac{16}{2704} \\neq 0\\).\nHence, \\(P(A\\cap B)\\neq P(A)P(B)\\), so they‚Äôre not independent."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-vs.-independent-example",
    "href": "files/lecture_notes/lecture4/lecture4.html#mutually-exclusive-vs.-independent-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.¬†Independent Example",
    "text": "Mutually Exclusive vs.¬†Independent Example\n\n\n\nDraw a single card from a 52-card deck:\n\nLet A={‚Äúdraw an Ace‚Äù}, so P(A)=4/52.\nLet B={‚Äúdraw a King‚Äù}, so P(B)=4/52.\n\nQ: What is \\(P(A\\cap B)\\) ?\n\n\n\n\n\nSolution. They‚Äôre disjoint (you can‚Äôt draw an Ace and a King), so \\(P(A\\cap B) = 0\\).\nBut \\(P(A)\\,P(B) = \\frac{4}{52}\\times\\frac{4}{52} = \\frac{16}{2704} \\neq 0\\).\nHence, \\(P(A\\cap B)\\neq P(A)P(B)\\), so they‚Äôre not independent."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#tree-diagram-examples",
    "href": "files/lecture_notes/lecture4/lecture4.html#tree-diagram-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagram Examples",
    "text": "Tree Diagram Examples"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#common-probability-mistakes-1",
    "href": "files/lecture_notes/lecture4/lecture4.html#common-probability-mistakes-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nAssuming independence when events are dependent\nIgnoring base rates (as in the medical test example)\n\n\nBase rate fallacy is when you ignore or underweight the prior probability \\(P(H)\\) of a hypothesis, focusing only on the new evidence \\(E\\).\n\n\nDouble counting in union calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4.html#common-questions",
    "href": "files/lecture_notes/lecture4/lecture4.html#common-questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Questions",
    "text": "Common Questions\n\nQ1.: ‚ÄúWhy isn‚Äôt \\(P(A \\cup B) = P(A) + P(B)\\) always?‚Äù\nA: We‚Äôd double-count outcomes in both events\nQ2.: ‚ÄúHow do I know if events are independent?‚Äù\nA: Check if \\(P(A|B) = P(A)\\) or if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nQ3.: ‚ÄúWhen do I use Bayes‚Äô theorem?‚Äù\nA: When you want to ‚Äúreverse‚Äù a conditional probability\n\n\nQ3 note (Bayes Example)\n\nForward: I know my test picks up disease 95% of the time ‚áí \\(P(+\\mid D)=0.95\\).\nReverse: I want the chance I really have the disease when the test is positive ‚áí \\(P(D\\mid +)\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture3/lecture3.html",
    "href": "files/lecture_notes/lecture3/lecture3.html",
    "title": "Descriptive Statistics Part II",
    "section": "",
    "text": "By the end of this lecture, you will be able to:\n\nCalculate and interpret measures of variability (range, variance, standard deviation)\nUnderstand and compute measures of position (percentiles, quartiles, z-scores)\nAssess distribution shape using skewness and kurtosis\nCreate and interpret histograms with appropriate bin widths\nConstruct and analyze boxplots for data exploration\nIdentify trends, patterns, and outliers in data visualizations\nApply Python for comprehensive descriptive analysis and visualization"
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html",
    "href": "files/lecture_notes/lecture2/lecture2.html",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "",
    "text": "Introduction to Descriptive Statistics (10 minutes)\n\nWhat is descriptive statistics?\n\nWhy it matters before any modeling\n\n\nTypes of Data and Measurement Scales (15 minutes)\nMeasures of Central Tendency (35 minutes)\n\nMean (12 minutes)\nMedian (12 minutes)\nMode (11 minutes)\n\nPython Implementation (15 minutes)\nReal-world Applications and Interpretation (5 minutes)\n\n\nQuick ice-breaker: ask students for one dataset they‚Äôve looked at recently and what first question they asked about it."
  },
  {
    "objectID": "files/lecture_notes/lecture2/lecture2.html#footnotes",
    "href": "files/lecture_notes/lecture2/lecture2.html#footnotes",
    "title": "Lecture 2: Descriptive Statistics I",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(source)‚Ü©Ô∏é"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#sec-objectives",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#sec-prob",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#sec-prob",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is Probability?",
    "text": "What is Probability?\n\nüéØ Definition\nProbability is a measure of the likelihood that an event will occur"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#probability-range",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#probability-range",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Range",
    "text": "Probability Range\n\n\n\nRanges from 0 to 1 (or 0% to 100%)\n0: Event will never occur (impossible)\n1: Event will certainly occur (certain)\n0.5: Event has equal chance of occurring or not"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#three-ways-to-express-probability",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#three-ways-to-express-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Three Ways to Express Probability",
    "text": "Three Ways to Express Probability\n\nFraction: \\(\\frac{1}{2}\\), \\(\\frac{3}{4}\\), \\(\\frac{2}{6}\\)\nDecimal: 0.5, 0.75, 0.33\nPercentage: 50%, 75%, 33%"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#example",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example",
    "text": "Example\nWhen we roll a die, there are six possible outcomes:\n1, 2, 3, 4, 5, 6.\nThe probability of any of them turning up is 1/6 or 16%."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#why-study-probability",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#why-study-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Why Study Probability?",
    "text": "Why Study Probability?\nProbability helps us:\n\nMake decisions under uncertainty\nUnderstand random processes\nAnalyze data and draw conclusions\nModel real-world phenomena\nAssess risk and likelihood\n\n\n\nApplications: Weather forecasting, medical diagnosis, finance, quality control, gaming, insurance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#random-experiments",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#random-experiments",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Random Experiments",
    "text": "Random Experiments\nA random experiment is a process that:\n\nCan be repeated under similar conditions\nHas multiple possible outcomes\nThe outcome cannot be predicted with certainty\n\n\n\nExamples\n\nü™ô Flipping a coin\nüé≤ Rolling a die\nüÉè Drawing a card from a deck\nüí° Measuring the lifetime of a light bulb"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#sample-space",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#sample-space",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space",
    "text": "Sample Space\n\nüéØ Definition The sample space (denoted \\(S\\) or \\(\\Omega\\)) is the set of all possible outcomes of a random experiment"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#sample-space-examples",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#sample-space-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space Examples",
    "text": "Sample Space Examples\n\nCoin flip: \\(S = \\{H, T\\}\\)\nTwo coin flips: \\(S = \\{HH, HT, TH, TT\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#types-of-sample-spaces",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#types-of-sample-spaces",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Types of Sample Spaces",
    "text": "Types of Sample Spaces\n\n\nFinite Sample Space\n\nLimited number of outcomes\n\nExample: Rolling a die\n\n\n\n\n\n\n\n\n\n\n\nInfinite Sample Space\n\nUnlimited outcomes (countable or uncountable)\n\nExample: Measuring exact height of students"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#events",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Events",
    "text": "Events\n\nüéØ Definition An event is a subset of the sample space\n\nSimple event: Contains exactly one outcome (Ex: \\(A = \\{3\\}\\) (rolling a 3))\nCompound event: Contains multiple outcomes (Ex: \\(B = \\{2, 4, 6\\}\\) (rolling an even number))"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#event-notation",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#event-notation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Event Notation",
    "text": "Event Notation\nFor a die roll with \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (rolling an odd number)\n\\(B = \\{4, 5, 6\\}\\) (rolling 4 or higher)\n\\(C = \\{6\\}\\) (rolling a six)\n\n\n\nWe can describe events in words or using set notation"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#set-operations-overview",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#set-operations-overview",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Set Operations Overview",
    "text": "Set Operations Overview\n\n\n\n\nüéØ Definition:\n\nSet: Collection of distinct objects\nUnion: A OR B occurs\n\nIntersection: A AND B occurs\nComplement: A does NOT occur\nSample Space: All possible outcomes"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#what-is-a-set",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#what-is-a-set",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is a Set?",
    "text": "What is a Set?\n\n\n\n\nüéØ Definition: A collection of things that share common characteristics. They can be elements, members, objects or similar terms.\nExamples:\n\nSet of even numbers:\n\n{2, 4, 6, 8, ‚Ä¶}\n\nSet of vowels: {a, e, i, o, u}"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#union-a-b",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#union-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Union: A ‚à™ B",
    "text": "Union: A ‚à™ B\n\n\n\n\nüéØ Definition: Contains all set elements, including intersections.\nIn Probability: The event that A OR B occurs (or both).\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#intersection-a-b",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#intersection-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Intersection: A ‚à© B",
    "text": "Intersection: A ‚à© B\n\n\n\n\nüéØ Definition: Area where two or more sets overlap.\nIn Probability: The event that A AND B occurs.\nProperties:\n\nAlways smaller than or equal to individual sets\nCan be empty (disjoint sets)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#absolute-complement-ac",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#absolute-complement-ac",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Absolute Complement: \\(A^c\\)",
    "text": "Absolute Complement: \\(A^c\\)\n\n\n\nüéØ Definition: All elements that do not belong to the set.\nIn Probability: The event that A does NOT occur.\n\n\\(P(A^c) = 1 - P(A)\\)\n\nKey Property:\n\n\\(A \\cup A^c = S\\) (Sample Space)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#summary-table",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#summary-table",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Summary Table",
    "text": "Summary Table\n\n\n\n\n\n\n\n\n\nOperation\nSymbol\nMeaning\nProbability\n\n\n\n\nUnion\n\\(A \\cup B\\)\nOccurs if \\(A\\) or \\(B\\)\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\nIntersection\n\\(A \\cap B\\)\nOccurs if \\(A\\) and \\(B\\)\n\\(P(A \\cap B)\\)\n\n\nComplement\n\\(A^c\\)\nOccurs if \\(A\\) does not occur\n\\(P(A^c) = 1 - P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#probability-axioms-commutative",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#probability-axioms-commutative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Commutative",
    "text": "Probability Axioms: Commutative\n\nCommutative\n\\(A \\cup B = B \\cup A\\)\n\\(A \\cap B = B \\cap A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#probability-axioms-associative",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#probability-axioms-associative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Associative",
    "text": "Probability Axioms: Associative\n\nAssociative\n\\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\)\n\\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#probability-axioms-distributive",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#probability-axioms-distributive",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Distributive",
    "text": "Probability Axioms: Distributive\n\nDistributive\n\\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\n\\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#probability-axioms-de-morgans-laws",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#probability-axioms-de-morgans-laws",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: De Morgan‚Äôs Laws",
    "text": "Probability Axioms: De Morgan‚Äôs Laws\n\nDe Morgan‚Äôs Laws\n\\((A \\cup B)^c = A^c \\cap B^c\\)\n\\((A \\cap B)^c = A^c \\cup B^c\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#practice-examples",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#practice-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Examples",
    "text": "Practice Examples\n\nExample 1: In a class of students:\n\nSet A = Students who like Math\nSet B = Students who like Science\n\nQ: What does A ‚à™ B represent?\n\n\n\nSolution. Students who like Math OR Science (or both)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#example-set-operations",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#example-set-operations",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example: Set Operations",
    "text": "Example: Set Operations\n\n\nFor die roll \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (odd numbers)\n\\(B = \\{4, 5, 6\\}\\) (4 or higher)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFind:\n\n\\(A \\cup B\\)\n\\(A \\cap B\\)\n\\(A^c\\)\n\n\n\n\n\nSolution. \n\n\\(A \\cup B = \\{1, 3, 4, 5, 6\\}\\)\n\\(A \\cap B = \\{5\\}\\)\n\\(A^c = \\{2, 4, 6\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#mutually-exclusive-events",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#mutually-exclusive-events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive Events",
    "text": "Mutually Exclusive Events\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive (or disjoint) if they cannot occur simultaneously\n\\[A \\cap B = \\emptyset\\]\n\n\n\n\n\n\n\n\n\n\n\n\nWhen rolling a die\n\n\\(A = \\{1, 3, 5\\}\\) (odd)\n\\(B = \\{2, 4, 6\\}\\) (even)\n\n\\(A\\) and \\(B\\) are mutually exclusive"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#the-classical-definition-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#the-classical-definition-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Classical Definition of Probability",
    "text": "The Classical Definition of Probability\n\nüéØ Definition: For equally likely outcomes:\n\\[P(A) = \\frac{\\text{Number of outcomes in } A}{\\text{Total number of outcomes in } S}\\]\n\n\nProbability of rolling an even number on a fair die\n\n\n\\[P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#properties-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#properties-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Properties of Probability",
    "text": "Properties of Probability\n\nNon-negativity: \\(P(A) \\geq 0\\) for any event \\(A\\)\nNormalization: \\(P(S) = 1\\)\nAdditivity: If \\(A\\) and \\(B\\) are mutually exclusive, then\n\n\n\\[P(A \\cup B) = P(A) + P(B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#the-complement-rule",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#the-complement-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Complement Rule",
    "text": "The Complement Rule\n\n\\[P(A) + P(A^c) = 1\\]\n\\[P(A^c) = 1 - P(A)\\]\n\n\n\nIf the probability of rain is 0.3, what‚Äôs the probability of no rain?\n\n\n\n\nSolution. \\[P(\\text{no rain}) = 1 - P(\\text{rain}) = 1 - 0.3 = 0.7\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#questions",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday‚Äôs 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Conditional Probabilities & Independence"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4_part1.html#resources",
    "href": "files/lecture_notes/lecture4/lecture4_part1.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html",
    "href": "files/lecture_notes/lecture9/lecture9.html",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "",
    "text": "Discrete Random Variables\nFrom outcomes to numbers: quantifying randomness"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#welcome-to-lecture-7",
    "href": "files/lecture_notes/lecture9/lecture9.html#welcome-to-lecture-7",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "",
    "text": "Discrete Random Variables\nFrom outcomes to numbers: quantifying randomness"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture9/lecture9.html#todays-learning-objectives",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine random variables and distinguish discrete from continuous\nWork with probability mass functions (PMFs) and cumulative distribution functions (CDFs)\nCalculate expected values and variances for discrete random variables\nApply properties of expectation and variance\nWork with common discrete distributions (Bernoulli, Binomial, Geometric, Poisson)\nSolve real-world problems using discrete random variables\nUse technology to compute probabilities and parameters"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#what-is-a-random-variable",
    "href": "files/lecture_notes/lecture9/lecture9.html#what-is-a-random-variable",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "What is a Random Variable?",
    "text": "What is a Random Variable?\nA random variable is a function that assigns a numerical value to each outcome of a random experiment\nNotation: Usually denoted by capital letters \\(X\\), \\(Y\\), \\(Z\\)\nKey insight: Random variables transform outcomes into numbers, making mathematical analysis possible\n\nExample: Rolling a die - Outcomes: \\(\\{1, 2, 3, 4, 5, 6\\}\\) - Random variable \\(X\\): the number shown - \\(X\\) can take values \\(\\{1, 2, 3, 4, 5, 6\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#why-use-random-variables",
    "href": "files/lecture_notes/lecture9/lecture9.html#why-use-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Why Use Random Variables?",
    "text": "Why Use Random Variables?\nRandom variables allow us to:\n\nQuantify outcomes numerically\nCalculate means, variances, and other statistics\nModel real-world phenomena mathematically\nMake predictions and decisions\nCompare different random processes\n\n\nExamples: Height, test scores, number of defects, wait times, stock prices"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#types-of-random-variables",
    "href": "files/lecture_notes/lecture9/lecture9.html#types-of-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Types of Random Variables",
    "text": "Types of Random Variables\nDiscrete Random Variable: - Takes on a countable number of values - Can list all possible values - Examples: dice rolls, number of emails, quiz scores\nContinuous Random Variable: - Takes on uncountably many values (intervals) - Cannot list all possible values\n- Examples: height, weight, time, temperature\n\nToday we focus on discrete random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#examples-of-discrete-random-variables",
    "href": "files/lecture_notes/lecture9/lecture9.html#examples-of-discrete-random-variables",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Examples of Discrete Random Variables",
    "text": "Examples of Discrete Random Variables\n\\(X\\) = Number of heads in 3 coin flips - Possible values: \\(\\{0, 1, 2, 3\\}\\)\n\\(Y\\) = Number of customers in an hour - Possible values: \\(\\{0, 1, 2, 3, \\ldots\\}\\)\n\\(Z\\) = Score on a 10-question quiz - Possible values: \\(\\{0, 1, 2, \\ldots, 10\\}\\)\n\nNotice: All values are integers with gaps between them"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#probability-mass-function-pmf",
    "href": "files/lecture_notes/lecture9/lecture9.html#probability-mass-function-pmf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Probability Mass Function (PMF)",
    "text": "Probability Mass Function (PMF)\nThe probability mass function of a discrete random variable \\(X\\) is:\n\\[P(X = x) = \\text{probability that } X \\text{ takes the value } x\\]\nProperties of PMF: 1. \\(P(X = x) \\geq 0\\) for all \\(x\\) 2. \\(\\sum_{\\text{all } x} P(X = x) = 1\\)\n\nNotation: Sometimes written as \\(p(x)\\) or \\(f(x)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#pmf-example-fair-die",
    "href": "files/lecture_notes/lecture9/lecture9.html#pmf-example-fair-die",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "PMF Example: Fair Die",
    "text": "PMF Example: Fair Die\nLet \\(X\\) = outcome of rolling a fair six-sided die\n\\[P(X = x) = \\begin{cases}\n\\frac{1}{6} & \\text{if } x \\in \\{1, 2, 3, 4, 5, 6\\} \\\\\n0 & \\text{otherwise}\n\\end{cases}\\]\n\nVerification: - All probabilities ‚â• 0 ‚úì - Sum = \\(6 \\times \\frac{1}{6} = 1\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#pmf-example-two-coin-flips",
    "href": "files/lecture_notes/lecture9/lecture9.html#pmf-example-two-coin-flips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "PMF Example: Two Coin Flips",
    "text": "PMF Example: Two Coin Flips\nLet \\(X\\) = number of heads in two coin flips\nSample space: \\(\\{HH, HT, TH, TT\\}\\)\n\n\n\n\n\\(x\\)\nOutcomes\n\\(P(X = x)\\)\n\n\n\n\n0\nTT\n1/4\n\n\n1\nHT, TH\n2/4 = 1/2\n\n\n2\nHH\n1/4\n\n\n\nVerification: \\(\\frac{1}{4} + \\frac{1}{2} + \\frac{1}{4} = 1\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#practice-problem-1",
    "href": "files/lecture_notes/lecture9/lecture9.html#practice-problem-1",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\nA box contains 3 red balls and 2 blue balls. Two balls are drawn without replacement. Let \\(X\\) = number of red balls drawn.\nFind the PMF of \\(X\\).\n\nSolution: \\(X\\) can be 0, 1, or 2\n\\(P(X = 0) = \\frac{\\binom{3}{0}\\binom{2}{2}}{\\binom{5}{2}} = \\frac{1 \\times 1}{10} = \\frac{1}{10}\\)\n\\(P(X = 1) = \\frac{\\binom{3}{1}\\binom{2}{1}}{\\binom{5}{2}} = \\frac{3 \\times 2}{10} = \\frac{6}{10}\\)\n\\(P(X = 2) = \\frac{\\binom{3}{2}\\binom{2}{0}}{\\binom{5}{2}} = \\frac{3 \\times 1}{10} = \\frac{3}{10}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#cumulative-distribution-function-cdf",
    "href": "files/lecture_notes/lecture9/lecture9.html#cumulative-distribution-function-cdf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Cumulative Distribution Function (CDF)",
    "text": "Cumulative Distribution Function (CDF)\nThe cumulative distribution function of a random variable \\(X\\) is:\n\\[F(x) = P(X \\leq x)\\]\nProperties of CDF: 1. \\(F(x)\\) is non-decreasing 2. \\(\\lim_{x \\to -\\infty} F(x) = 0\\) 3. \\(\\lim_{x \\to \\infty} F(x) = 1\\) 4. \\(F(x)\\) is right-continuous"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#cdf-example-two-coin-flips",
    "href": "files/lecture_notes/lecture9/lecture9.html#cdf-example-two-coin-flips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "CDF Example: Two Coin Flips",
    "text": "CDF Example: Two Coin Flips\nFrom our previous example where \\(X\\) = number of heads:\n\\[F(x) = \\begin{cases}\n0 & \\text{if } x &lt; 0 \\\\\n\\frac{1}{4} & \\text{if } 0 \\leq x &lt; 1 \\\\\n\\frac{3}{4} & \\text{if } 1 \\leq x &lt; 2 \\\\\n1 & \\text{if } x \\geq 2\n\\end{cases}\\]\n\nKey insight: CDF is a step function for discrete random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#relationship-between-pmf-and-cdf",
    "href": "files/lecture_notes/lecture9/lecture9.html#relationship-between-pmf-and-cdf",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Relationship Between PMF and CDF",
    "text": "Relationship Between PMF and CDF\nFrom PMF to CDF: \\(F(x) = \\sum_{k \\leq x} P(X = k)\\)\nFrom CDF to PMF: \\(P(X = k) = F(k) - F(k^-)\\)\nwhere \\(F(k^-)\\) is the limit from the left\n\nUseful CDF Properties: - \\(P(X &gt; x) = 1 - F(x)\\) - \\(P(a &lt; X \\leq b) = F(b) - F(a)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#practice-problem-2",
    "href": "files/lecture_notes/lecture9/lecture9.html#practice-problem-2",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\nUsing the red balls example from Problem 1, find:\n\n\\(F(0.5)\\)\n\\(F(1)\\)\n\n\\(P(X &gt; 1)\\)\n\\(P(0.5 &lt; X \\leq 1.5)\\)\n\n\nSolutions: a) \\(F(0.5) = P(X \\leq 0.5) = P(X = 0) = \\frac{1}{10}\\) b) \\(F(1) = P(X \\leq 1) = P(X = 0) + P(X = 1) = \\frac{1}{10} + \\frac{6}{10} = \\frac{7}{10}\\) c) \\(P(X &gt; 1) = 1 - F(1) = 1 - \\frac{7}{10} = \\frac{3}{10}\\) d) \\(P(0.5 &lt; X \\leq 1.5) = F(1.5) - F(0.5) = \\frac{7}{10} - \\frac{1}{10} = \\frac{6}{10}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#expected-value-mean",
    "href": "files/lecture_notes/lecture9/lecture9.html#expected-value-mean",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value (Mean)",
    "text": "Expected Value (Mean)\nThe expected value of a discrete random variable \\(X\\) is:\n\\[E[X] = \\mu = \\sum_{\\text{all } x} x \\cdot P(X = x)\\]\nInterpretation: The long-run average value if the experiment is repeated many times\n\nAlso called: Mean, expectation, average"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#expected-value-example",
    "href": "files/lecture_notes/lecture9/lecture9.html#expected-value-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value Example",
    "text": "Expected Value Example\nFor two coin flips where \\(X\\) = number of heads:\n\\[E[X] = 0 \\cdot P(X = 0) + 1 \\cdot P(X = 1) + 2 \\cdot P(X = 2)\\]\n\\[= 0 \\cdot \\frac{1}{4} + 1 \\cdot \\frac{1}{2} + 2 \\cdot \\frac{1}{4} = 0 + \\frac{1}{2} + \\frac{1}{2} = 1\\]\n\nMakes sense: On average, we expect 1 head in 2 coin flips"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#practice-problem-3",
    "href": "files/lecture_notes/lecture9/lecture9.html#practice-problem-3",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\nFind the expected value for the red balls example (Problem 1).\n\nSolution: \\[E[X] = 0 \\cdot \\frac{1}{10} + 1 \\cdot \\frac{6}{10} + 2 \\cdot \\frac{3}{10}\\]\n\\[= 0 + \\frac{6}{10} + \\frac{6}{10} = \\frac{12}{10} = 1.2\\]\nOn average, we expect to draw 1.2 red balls"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#properties-of-expected-value",
    "href": "files/lecture_notes/lecture9/lecture9.html#properties-of-expected-value",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Properties of Expected Value",
    "text": "Properties of Expected Value\nLinearity of Expectation: 1. \\(E[c] = c\\) (constant) 2. \\(E[cX] = c \\cdot E[X]\\) (scaling) 3. \\(E[X + Y] = E[X] + E[Y]\\) (additivity) 4. \\(E[aX + bY + c] = aE[X] + bE[Y] + c\\)\n\nImportant: Property 3 holds even if \\(X\\) and \\(Y\\) are dependent!"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#expected-value-of-functions",
    "href": "files/lecture_notes/lecture9/lecture9.html#expected-value-of-functions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Expected Value of Functions",
    "text": "Expected Value of Functions\nFor a function \\(g(X)\\) of a random variable \\(X\\):\n\\[E[g(X)] = \\sum_{\\text{all } x} g(x) \\cdot P(X = x)\\]\n\nCommon example: \\(g(X) = X^2\\)\n\\[E[X^2] = \\sum_{\\text{all } x} x^2 \\cdot P(X = x)\\]\nNote: Generally \\(E[g(X)] \\neq g(E[X])\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#variance",
    "href": "files/lecture_notes/lecture9/lecture9.html#variance",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Variance",
    "text": "Variance\nThe variance of a random variable \\(X\\) measures spread around the mean:\n\\[\\text{Var}(X) = \\sigma^2 = E[(X - \\mu)^2]\\]\nAlternative formula (often easier to compute): \\[\\text{Var}(X) = E[X^2] - (E[X])^2\\]\nStandard deviation: \\(\\sigma = \\sqrt{\\text{Var}(X)}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#variance-example",
    "href": "files/lecture_notes/lecture9/lecture9.html#variance-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Variance Example",
    "text": "Variance Example\nFor two coin flips where \\(X\\) = number of heads, \\(E[X] = 1\\):\nFirst, find \\(E[X^2]\\): \\[E[X^2] = 0^2 \\cdot \\frac{1}{4} + 1^2 \\cdot \\frac{1}{2} + 2^2 \\cdot \\frac{1}{4} = 0 + \\frac{1}{2} + 1 = \\frac{3}{2}\\]\n\nThen: \\(\\text{Var}(X) = E[X^2] - (E[X])^2 = \\frac{3}{2} - 1^2 = \\frac{1}{2}\\)\nStandard deviation: \\(\\sigma = \\sqrt{\\frac{1}{2}} \\approx 0.707\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#properties-of-variance",
    "href": "files/lecture_notes/lecture9/lecture9.html#properties-of-variance",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Properties of Variance",
    "text": "Properties of Variance\n\n\\(\\text{Var}(c) = 0\\) (constants have no variability)\n\\(\\text{Var}(cX) = c^2 \\text{Var}(X)\\) (scaling by \\(c\\) scales variance by \\(c^2\\))\n\\(\\text{Var}(X + c) = \\text{Var}(X)\\) (shifting doesn‚Äôt change spread)\nIf \\(X\\) and \\(Y\\) are independent: \\(\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y)\\)\n\n\nNote: Property 4 requires independence, unlike expectation!"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#practice-problem-4",
    "href": "files/lecture_notes/lecture9/lecture9.html#practice-problem-4",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\nFor the red balls example, find the variance and standard deviation.\nWe found \\(E[X] = 1.2\\). First find \\(E[X^2]\\):\n\n\\[E[X^2] = 0^2 \\cdot \\frac{1}{10} + 1^2 \\cdot \\frac{6}{10} + 2^2 \\cdot \\frac{3}{10}\\] \\[= 0 + \\frac{6}{10} + \\frac{12}{10} = \\frac{18}{10} = 1.8\\]\n\\[\\text{Var}(X) = 1.8 - (1.2)^2 = 1.8 - 1.44 = 0.36\\]\n\\[\\sigma = \\sqrt{0.36} = 0.6\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#bernoulli-distribution",
    "href": "files/lecture_notes/lecture9/lecture9.html#bernoulli-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\nA Bernoulli random variable models a single trial with two outcomes:\n\nSuccess (1) with probability \\(p\\)\nFailure (0) with probability \\(1-p\\)\n\nPMF: \\(P(X = x) = p^x(1-p)^{1-x}\\) for \\(x \\in \\{0, 1\\}\\)\nParameters: \\(p \\in [0, 1]\\)\n\nExamples: Coin flip, single exam question (pass/fail), defective item"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#bernoulli-properties",
    "href": "files/lecture_notes/lecture9/lecture9.html#bernoulli-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bernoulli Properties",
    "text": "Bernoulli Properties\nFor \\(X \\sim \\text{Bernoulli}(p)\\):\nMean: \\(E[X] = p\\)\nVariance: \\(\\text{Var}(X) = p(1-p)\\)\nStandard deviation: \\(\\sigma = \\sqrt{p(1-p)}\\)\n\nIntuition: - Mean \\(p\\) makes sense: probability of success - Variance maximized when \\(p = 0.5\\) (most uncertainty)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#binomial-distribution",
    "href": "files/lecture_notes/lecture9/lecture9.html#binomial-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\nA binomial random variable counts successes in \\(n\\) independent Bernoulli trials, each with success probability \\(p\\)\nPMF: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\) for \\(k = 0, 1, 2, \\ldots, n\\)\nParameters: \\(n\\) (number of trials), \\(p\\) (success probability)\nNotation: \\(X \\sim \\text{Binomial}(n, p)\\) or \\(X \\sim B(n, p)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#binomial-properties",
    "href": "files/lecture_notes/lecture9/lecture9.html#binomial-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Binomial Properties",
    "text": "Binomial Properties\nFor \\(X \\sim \\text{Binomial}(n, p)\\):\nMean: \\(E[X] = np\\)\nVariance: \\(\\text{Var}(X) = np(1-p)\\)\nStandard deviation: \\(\\sigma = \\sqrt{np(1-p)}\\)\n\nDerivation: Sum of \\(n\\) independent Bernoulli\\((p)\\) random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#binomial-example",
    "href": "files/lecture_notes/lecture9/lecture9.html#binomial-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Binomial Example",
    "text": "Binomial Example\nA multiple choice quiz has 10 questions, each with 4 options. A student guesses randomly on each question. Let \\(X\\) = number of correct answers.\n\\(X \\sim \\text{Binomial}(10, 0.25)\\)\nWhat‚Äôs the probability of getting exactly 3 correct?\n\n\\[P(X = 3) = \\binom{10}{3} (0.25)^3 (0.75)^7\\] \\[= 120 \\times 0.015625 \\times 0.1335 \\approx 0.250\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#practice-problem-5",
    "href": "files/lecture_notes/lecture9/lecture9.html#practice-problem-5",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 5",
    "text": "Practice Problem 5\nFor the quiz example:\n\nWhat‚Äôs the expected number of correct answers?\nWhat‚Äôs the standard deviation?\nWhat‚Äôs the probability of getting at least 4 correct?\n\n\nSolutions: a) \\(E[X] = np = 10 \\times 0.25 = 2.5\\) b) \\(\\sigma = \\sqrt{np(1-p)} = \\sqrt{10 \\times 0.25 \\times 0.75} = \\sqrt{1.875} \\approx 1.37\\) c) \\(P(X \\geq 4) = 1 - P(X \\leq 3) = 1 - [P(X=0) + P(X=1) + P(X=2) + P(X=3)]\\) Use binomial table or calculator: \\(P(X \\geq 4) \\approx 0.224\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#geometric-distribution",
    "href": "files/lecture_notes/lecture9/lecture9.html#geometric-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\nA geometric random variable counts the number of trials until the first success\nPMF: \\(P(X = k) = (1-p)^{k-1} p\\) for \\(k = 1, 2, 3, \\ldots\\)\nParameters: \\(p\\) (success probability per trial)\nNotation: \\(X \\sim \\text{Geometric}(p)\\)\n\nExamples: Number of coin flips until heads, number of shots until goal, number of calls until sale"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#geometric-properties",
    "href": "files/lecture_notes/lecture9/lecture9.html#geometric-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Geometric Properties",
    "text": "Geometric Properties\nFor \\(X \\sim \\text{Geometric}(p)\\):\nMean: \\(E[X] = \\frac{1}{p}\\)\nVariance: \\(\\text{Var}(X) = \\frac{1-p}{p^2}\\)\nMemoryless property: \\(P(X &gt; s + t | X &gt; s) = P(X &gt; t)\\)\n\nIntuition: If \\(p = 0.1\\), expect to wait \\(\\frac{1}{0.1} = 10\\) trials on average"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#geometric-example",
    "href": "files/lecture_notes/lecture9/lecture9.html#geometric-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Geometric Example",
    "text": "Geometric Example\nA basketball player has a 60% free throw percentage. What‚Äôs the probability they make their first shot on the 3rd attempt?\n\\(X \\sim \\text{Geometric}(0.6)\\)\n\n\\[P(X = 3) = (1-0.6)^{3-1} \\times 0.6 = (0.4)^2 \\times 0.6 = 0.16 \\times 0.6 = 0.096\\]\nExpected number of attempts: \\(E[X] = \\frac{1}{0.6} \\approx 1.67\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#practice-problem-6",
    "href": "files/lecture_notes/lecture9/lecture9.html#practice-problem-6",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\nA quality control inspector tests items until finding the first defective one. If 5% of items are defective:\n\nWhat‚Äôs the probability the first defective item is the 10th one tested?\nWhat‚Äôs the expected number of items tested?\nWhat‚Äôs the probability of testing more than 20 items?\n\n\nSolutions: a) \\(P(X = 10) = (0.95)^9 \\times 0.05 \\approx 0.0315\\) b) \\(E[X] = \\frac{1}{0.05} = 20\\) items c) \\(P(X &gt; 20) = (0.95)^{20} \\approx 0.358\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#poisson-distribution",
    "href": "files/lecture_notes/lecture9/lecture9.html#poisson-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution\nA Poisson random variable counts events occurring in a fixed interval when events happen at a constant average rate\nPMF: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\) for \\(k = 0, 1, 2, \\ldots\\)\nParameters: \\(\\lambda &gt; 0\\) (average rate)\nNotation: \\(X \\sim \\text{Poisson}(\\lambda)\\)\n\nExamples: Emails per hour, accidents per day, mutations per genome"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#poisson-properties",
    "href": "files/lecture_notes/lecture9/lecture9.html#poisson-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Poisson Properties",
    "text": "Poisson Properties\nFor \\(X \\sim \\text{Poisson}(\\lambda)\\):\nMean: \\(E[X] = \\lambda\\)\nVariance: \\(\\text{Var}(X) = \\lambda\\)\nStandard deviation: \\(\\sigma = \\sqrt{\\lambda}\\)\n\nUnique property: Mean equals variance!\nApproximation: Binomial\\((n, p)\\) ‚âà Poisson\\((np)\\) when \\(n\\) large, \\(p\\) small"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#poisson-example",
    "href": "files/lecture_notes/lecture9/lecture9.html#poisson-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Poisson Example",
    "text": "Poisson Example\nA call center receives an average of 3 calls per minute. What‚Äôs the probability of receiving exactly 5 calls in the next minute?\n\\(X \\sim \\text{Poisson}(3)\\)\n\n\\[P(X = 5) = \\frac{3^5 e^{-3}}{5!} = \\frac{243 \\times e^{-3}}{120} \\approx \\frac{243 \\times 0.0498}{120} \\approx 0.101\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#practice-problem-7",
    "href": "files/lecture_notes/lecture9/lecture9.html#practice-problem-7",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\nFor the call center example:\n\nWhat‚Äôs the probability of no calls in a minute?\nWhat‚Äôs the probability of at most 2 calls?\nIn a 2-minute period, what‚Äôs the expected number of calls?\n\n\nSolutions: a) \\(P(X = 0) = \\frac{3^0 e^{-3}}{0!} = e^{-3} \\approx 0.0498\\) b) \\(P(X \\leq 2) = P(X=0) + P(X=1) + P(X=2) \\approx 0.0498 + 0.1494 + 0.2240 = 0.423\\) c) For 2 minutes: \\(Y \\sim \\text{Poisson}(6)\\), so \\(E[Y] = 6\\) calls"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#hypergeometric-distribution",
    "href": "files/lecture_notes/lecture9/lecture9.html#hypergeometric-distribution",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Hypergeometric Distribution",
    "text": "Hypergeometric Distribution\nA hypergeometric random variable counts successes when sampling without replacement from a finite population\nSetup: Population of \\(N\\) items, \\(K\\) are successes, draw \\(n\\) items\nPMF: \\(P(X = k) = \\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}\\)\nNotation: \\(X \\sim \\text{Hypergeometric}(N, K, n)\\)\n\nExamples: Defective items in a batch, aces in a card hand, tagged fish in a sample"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#hypergeometric-properties",
    "href": "files/lecture_notes/lecture9/lecture9.html#hypergeometric-properties",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Hypergeometric Properties",
    "text": "Hypergeometric Properties\nFor \\(X \\sim \\text{Hypergeometric}(N, K, n)\\):\nMean: \\(E[X] = n \\cdot \\frac{K}{N}\\)\nVariance: \\(\\text{Var}(X) = n \\cdot \\frac{K}{N} \\cdot \\frac{N-K}{N} \\cdot \\frac{N-n}{N-1}\\)\n\nConnection to Binomial: When \\(N\\) is large relative to \\(n\\), hypergeometric ‚âà binomial\\((n, K/N)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#hypergeometric-example",
    "href": "files/lecture_notes/lecture9/lecture9.html#hypergeometric-example",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Hypergeometric Example",
    "text": "Hypergeometric Example\nA batch of 20 light bulbs contains 3 defective ones. If 5 bulbs are randomly selected, what‚Äôs the probability exactly 1 is defective?\n\\(X \\sim \\text{Hypergeometric}(20, 3, 5)\\)\n\n\\[P(X = 1) = \\frac{\\binom{3}{1}\\binom{17}{4}}{\\binom{20}{5}} = \\frac{3 \\times 2380}{15504} = \\frac{7140}{15504} \\approx 0.461\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#practice-problem-8",
    "href": "files/lecture_notes/lecture9/lecture9.html#practice-problem-8",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 8",
    "text": "Practice Problem 8\nFor the light bulb example:\n\nWhat‚Äôs the expected number of defective bulbs in the sample?\nWhat‚Äôs the probability of no defective bulbs?\nWhat‚Äôs the probability of at least 2 defective bulbs?\n\n\nSolutions: a) \\(E[X] = 5 \\times \\frac{3}{20} = 0.75\\) bulbs b) \\(P(X = 0) = \\frac{\\binom{3}{0}\\binom{17}{5}}{\\binom{20}{5}} = \\frac{6188}{15504} \\approx 0.399\\) c) \\(P(X \\geq 2) = 1 - P(X = 0) - P(X = 1) \\approx 1 - 0.399 - 0.461 = 0.140\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#comparing-distributions",
    "href": "files/lecture_notes/lecture9/lecture9.html#comparing-distributions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Comparing Distributions",
    "text": "Comparing Distributions\n\n\n\n\n\n\n\n\n\n\nDistribution\nParameters\nMean\nVariance\nUse Case\n\n\n\n\nBernoulli\n\\(p\\)\n\\(p\\)\n\\(p(1-p)\\)\nSingle trial\n\n\nBinomial\n\\(n, p\\)\n\\(np\\)\n\\(np(1-p)\\)\nFixed trials\n\n\nGeometric\n\\(p\\)\n\\(1/p\\)\n\\((1-p)/p^2\\)\nWait for success\n\n\nPoisson\n\\(\\lambda\\)\n\\(\\lambda\\)\n\\(\\lambda\\)\nCount events\n\n\nHypergeometric\n\\(N, K, n\\)\n\\(n(K/N)\\)\nComplex\nSample w/o replacement"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#technology-and-software",
    "href": "files/lecture_notes/lecture9/lecture9.html#technology-and-software",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Technology and Software",
    "text": "Technology and Software\nCalculators: - Binomial: binompdf(), binomcdf() - Poisson: poissonpdf(), poissoncdf()\nR: - dbinom(), pbinom(), rbinom() - dpois(), ppois(), rpois() - dgeom(), pgeom(), rgeom()\nPython: - scipy.stats.binom, scipy.stats.poisson - numpy.random for simulation"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture9/lecture9.html#problem-solving-strategy",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\nIdentify the scenario: What type of process?\nCheck assumptions: Independence, constant probability, etc.\nChoose distribution: Match scenario to distribution\nIdentify parameters: \\(n\\), \\(p\\), \\(\\lambda\\), etc.\nCalculate probabilities: Use PMF, CDF, or technology\nInterpret results: Does the answer make sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#real-world-applications",
    "href": "files/lecture_notes/lecture9/lecture9.html#real-world-applications",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nQuality Control: - Binomial for defect rates - Hypergeometric for batch sampling\nReliability Engineering: - Geometric for time to failure - Poisson for system failures\nEpidemiology: - Binomial for disease spread - Poisson for rare events\nFinance: - Poisson for market events - Binomial for option pricing"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#practice-problem-9",
    "href": "files/lecture_notes/lecture9/lecture9.html#practice-problem-9",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 9",
    "text": "Practice Problem 9\nA website receives an average of 2 orders per minute. Assuming orders follow a Poisson process:\n\nWhat‚Äôs the probability of exactly 3 orders in a minute?\nWhat‚Äôs the probability of no orders in 30 seconds?\nWhat‚Äôs the probability of more than 5 orders in 2 minutes?\n\n\nSolutions: a) \\(X \\sim \\text{Poisson}(2)\\): \\(P(X = 3) = \\frac{2^3 e^{-2}}{3!} \\approx 0.180\\) b) \\(Y \\sim \\text{Poisson}(1)\\): \\(P(Y = 0) = e^{-1} \\approx 0.368\\) c) \\(Z \\sim \\text{Poisson}(4)\\): \\(P(Z &gt; 5) = 1 - P(Z \\leq 5) \\approx 0.215\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#central-limit-theorem-preview",
    "href": "files/lecture_notes/lecture9/lecture9.html#central-limit-theorem-preview",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Central Limit Theorem Preview",
    "text": "Central Limit Theorem Preview\nFor large \\(n\\), many discrete distributions approach normal:\nBinomial: \\(X \\sim \\text{Binomial}(n, p)\\) ‚Üí \\(N(np, np(1-p))\\) when \\(np &gt; 5\\) and \\(n(1-p) &gt; 5\\)\nPoisson: \\(X \\sim \\text{Poisson}(\\lambda)\\) ‚Üí \\(N(\\lambda, \\lambda)\\) when \\(\\lambda &gt; 10\\)\n\nThis connection will be crucial for hypothesis testing and confidence intervals"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#common-mistakes",
    "href": "files/lecture_notes/lecture9/lecture9.html#common-mistakes",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Common Mistakes",
    "text": "Common Mistakes\n\nWrong distribution choice: Check assumptions carefully\nParameter confusion: Is it \\(n\\), \\(p\\), or \\(\\lambda\\)?\nInclusion errors: ‚ÄúAt least 3‚Äù vs ‚ÄúMore than 3‚Äù\nIndependence assumption: Sampling with/without replacement\nTechnology errors: pdf vs cdf functions"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#practice-problem-10",
    "href": "files/lecture_notes/lecture9/lecture9.html#practice-problem-10",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Practice Problem 10",
    "text": "Practice Problem 10\nA multiple choice test has 20 questions with 5 options each. A student knows the answers to 12 questions and guesses on the rest.\n\nWhat‚Äôs the expected score?\nWhat‚Äôs the probability of scoring at least 15?\nWhat‚Äôs the standard deviation of the score?\n\n\nSolution: Let \\(X\\) = known correct, \\(Y\\) = guessed correct - \\(X = 12\\) (deterministic) - \\(Y \\sim \\text{Binomial}(8, 0.2)\\) - Total score \\(S = X + Y = 12 + Y\\)\n\n\\(E[S] = 12 + E[Y] = 12 + 8(0.2) = 13.6\\)\n\\(P(S \\geq 15) = P(Y \\geq 3) \\approx 0.203\\)\n\n\\(\\sigma_S = \\sigma_Y = \\sqrt{8(0.2)(0.8)} = \\sqrt{1.28} \\approx 1.13\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#extensions-and-advanced-topics",
    "href": "files/lecture_notes/lecture9/lecture9.html#extensions-and-advanced-topics",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Extensions and Advanced Topics",
    "text": "Extensions and Advanced Topics\nNegative Binomial: Number of trials to get \\(r\\) successes\nMultinomial: Extension of binomial to more than 2 categories\nCompound Distributions: Sums of random variables\nGenerating Functions: Advanced technique for deriving properties\n\nThese topics appear in advanced probability courses"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#historical-context",
    "href": "files/lecture_notes/lecture9/lecture9.html#historical-context",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Historical Context",
    "text": "Historical Context\nJacob Bernoulli (1654-1705): Bernoulli trials and law of large numbers\nSim√©on Denis Poisson (1781-1840): Poisson distribution and approximation\nAbraham de Moivre (1667-1754): Normal approximation to binomial\nModern Applications: Computer science, machine learning, bioinformatics"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#common-student-questions",
    "href": "files/lecture_notes/lecture9/lecture9.html#common-student-questions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: ‚ÄúHow do I choose between binomial and hypergeometric?‚Äù A: Use binomial for sampling with replacement, hypergeometric without\nQ: ‚ÄúWhen can I use Poisson approximation?‚Äù A: When \\(n\\) is large, \\(p\\) is small, and \\(np\\) is moderate\nQ: ‚ÄúWhy does Poisson have mean = variance?‚Äù A: Mathematical property arising from its derivation as a limit\nQ: ‚ÄúHow do I know if trials are independent?‚Äù A: Check if outcome of one trial affects others"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture9/lecture9.html#key-formulas-summary",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\nExpected Value: \\(E[X] = \\sum x \\cdot P(X = x)\\)\nVariance: \\(\\text{Var}(X) = E[X^2] - (E[X])^2\\)\nBinomial: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\)\nGeometric: \\(P(X = k) = (1-p)^{k-1} p\\)\nPoisson: \\(P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#looking-ahead",
    "href": "files/lecture_notes/lecture9/lecture9.html#looking-ahead",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture: Continuous Random Variables - Probability density functions (PDFs) - Normal distribution - Exponential distribution\n- Central Limit Theorem applications\nConnection: Discrete distributions often approximate continuous ones, and vice versa"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#study-tips",
    "href": "files/lecture_notes/lecture9/lecture9.html#study-tips",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Study Tips",
    "text": "Study Tips\n\nMaster the basics: PMF, CDF, expectation, variance\nLearn distribution characteristics: When to use each one\nPractice with technology: Get comfortable with calculators/software\nWork real problems: Apply distributions to actual scenarios\nCheck your intuition: Do answers make practical sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#final-thoughts",
    "href": "files/lecture_notes/lecture9/lecture9.html#final-thoughts",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nDiscrete random variables are fundamental to: - Modeling real-world phenomena - Making statistical inferences - Understanding probability theory - Building more complex models\n\nKey insight: Random variables transform unpredictable outcomes into predictable patterns"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#questions",
    "href": "files/lecture_notes/lecture9/lecture9.html#questions",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: [Your office hours] Email: [Your email]\nNext Class: Continuous Random Variables\nRemember: Homework due [date]"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#bonus-law-of-large-numbers",
    "href": "files/lecture_notes/lecture9/lecture9.html#bonus-law-of-large-numbers",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bonus: Law of Large Numbers",
    "text": "Bonus: Law of Large Numbers\nAs \\(n\\) increases, the sample mean approaches the expected value:\n\\[\\bar{X}_n = \\frac{X_1 + X_2 + \\cdots + X_n}{n} \\to E[X]\\]\nExample: Flip a coin 1000 times - proportion of heads will be close to 0.5\nThis justifies our interpretation of expected value as ‚Äúlong-run average‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture9/lecture9.html#bonus-simulation",
    "href": "files/lecture_notes/lecture9/lecture9.html#bonus-simulation",
    "title": "PSTAT 5A: Discrete Random Variables",
    "section": "Bonus: Simulation",
    "text": "Bonus: Simulation\nMonte Carlo Method: Use computer simulation to estimate probabilities\n# Simulate 10,000 binomial random variables\nX &lt;- rbinom(10000, size=10, prob=0.3)\nmean(X)  # Should be close to 10*0.3 = 3\nvar(X)   # Should be close to 10*0.3*0.7 = 2.1\nSimulation helps verify theoretical results and solve complex problems"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "",
    "text": "Introduction to Probability\nUnderstanding uncertainty through statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#welcome-to-lecture-4",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#welcome-to-lecture-4",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "",
    "text": "Introduction to Probability\nUnderstanding uncertainty through statistics"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-objectives",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities\nDetermine when events are independent\nUse Bayes‚Äô theorem in simple applications"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-prob",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sec-prob",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is Probability?",
    "text": "What is Probability?\n\nüéØ Definition\nProbability is a measure of the likelihood that an event will occur"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-range",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-range",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Range",
    "text": "Probability Range\n\n\n\nRanges from 0 to 1 (or 0% to 100%)\n0: Event will never occur (impossible)\n1: Event will certainly occur (certain)\n0.5: Event has equal chance of occurring or not"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#three-ways-to-express-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#three-ways-to-express-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Three Ways to Express Probability",
    "text": "Three Ways to Express Probability\n\nFraction: \\(\\frac{1}{2}\\), \\(\\frac{3}{4}\\), \\(\\frac{2}{6}\\)\nDecimal: 0.5, 0.75, 0.33\nPercentage: 50%, 75%, 33%"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example",
    "text": "Example\nWhen we roll a die, there are six possible outcomes:\n1, 2, 3, 4, 5, 6.\nThe probability of any of them turning up is 1/6 or 16%."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#why-study-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#why-study-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Why Study Probability?",
    "text": "Why Study Probability?\nProbability helps us:\n\nMake decisions under uncertainty\nUnderstand random processes\nAnalyze data and draw conclusions\nModel real-world phenomena\nAssess risk and likelihood\n\n\n\nApplications: Weather forecasting, medical diagnosis, finance, quality control, gaming, insurance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#random-experiments",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#random-experiments",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Random Experiments",
    "text": "Random Experiments\nA random experiment is a process that:\n\nCan be repeated under similar conditions\nHas multiple possible outcomes\nThe outcome cannot be predicted with certainty\n\n\n\nExamples\n\nü™ô Flipping a coin\nüé≤ Rolling a die\nüÉè Drawing a card from a deck\nüí° Measuring the lifetime of a light bulb"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space",
    "text": "Sample Space\n\nüéØ Definition The sample space (denoted \\(S\\) or \\(\\Omega\\)) is the set of all possible outcomes of a random experiment\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# Create a blank canvas with a rectangle representing the sample space\nfig, ax = plt.subplots(figsize=(6, 4))\nrect = patches.Rectangle(\n    (0.1, 0.1), 0.8, 0.8,\n    linewidth=3, edgecolor='black', facecolor='none'\n)\nax.add_patch(rect)\n\n# Label the sample space inside the rectangle\nax.text(0.5, 0.88, r'$\\Omega$', fontsize=24, fontweight='bold', ha='center', va='top')\nax.text(0.5, 0.5, 'All possible outcomes', fontsize=14, ha='center')\n\n# Clean up axes\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nax.axis('off')\n\nplt.title('Sample Space (Œ©)', fontsize=16, pad=20)\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space-examples",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#sample-space-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Sample Space Examples",
    "text": "Sample Space Examples\n\nCoin flip: \\(S = \\{H, T\\}\\)\nTwo coin flips: \\(S = \\{HH, HT, TH, TT\\}\\)\n\n\n\n\n\n\n\n\nüé≤ Die roll: \\(S = \\{1, 2, 3, 4, 5, 6\\}\\)\nTwo die rolls \n\n\n\n\\(S = \\{A\\heartsuit,\\ 2\\heartsuit,\\ \\dots,\\ K\\heartsuit,\\\\\n\\phantom{S = \\{}A\\diamondsuit,\\ 2\\diamondsuit,\\ \\dots,\\ K\\diamondsuit,\\\\\n\\phantom{S = \\{}A\\clubsuit,\\ 2\\clubsuit,\\ \\dots,\\ K\\clubsuit,\\\\\n\\phantom{S = \\{}A\\spadesuit,\\ 2\\spadesuit,\\ \\dots,\\ K\\spadesuit\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#types-of-sample-spaces",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#types-of-sample-spaces",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Types of Sample Spaces",
    "text": "Types of Sample Spaces\n\n\nFinite Sample Space\n\nLimited number of outcomes\n\nExample: Rolling a die\n\n\n\n\n\n\n\n\n\n\n\n\nInfinite Sample Space\n\nUnlimited outcomes (countable or uncountable)\n\nExample: Measuring exact height of students"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#events",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Events",
    "text": "Events\n\nüéØ Definition An event is a subset of the sample space\n\nSimple event: Contains exactly one outcome (Ex: \\(A = \\{3\\}\\) (rolling a 3))\nCompound event: Contains multiple outcomes (Ex: \\(B = \\{2, 4, 6\\}\\) (rolling an even number))\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport matplotlib.lines as mlines\n\n# Coordinates and styling\noutcomes = list(range(1, 7))\ny = 0.5\nradius = 0.3\ndot_y = y\nfig, ax = plt.subplots(figsize=(8, 4))\nax.axis('off')\n\n# Rectangle bounds to fit all circles\nmin_x = min(outcomes) - radius\nmax_x = max(outcomes) + radius\nmin_y = dot_y - radius\nmax_y = dot_y + radius\nrect = patches.Rectangle((min_x, min_y), max_x-min_x, max_y-min_y,\n                         linewidth=2, edgecolor='black', facecolor='none')\nax.add_patch(rect)\n\n# Label the sample space inside\nax.text((min_x+max_x)/2, max_y + 0.05, r'$\\Omega$', fontsize=20, fontweight='bold', ha='center')\n\n# Plot all outcomes marked by gray crosses\nax.scatter(outcomes, [dot_y]*6, s=200, color='gray', marker='x', linewidths=3, zorder=2)\n\n# Highlight simple event {3} in red\ncircle_simple = patches.Circle((3, dot_y), radius, facecolor='red', alpha=0.3,\n                               edgecolor='black', linewidth=2, zorder=1)\nax.add_patch(circle_simple)\n\n# Highlight compound event {2,4,6} in blue\nfor x in [2, 4, 6]:\n    circle = patches.Circle((x, dot_y), radius, facecolor='blue', alpha=0.3,\n                            edgecolor='black', linewidth=2, zorder=1)\n    ax.add_patch(circle)\n\n# Legend for events\nlegend_handles = [\n    mlines.Line2D([], [], color='red', marker='o', linestyle='None',\n                  markersize=15, label='Simple event {3}', alpha=0.3),\n    mlines.Line2D([], [], color='blue', marker='o', linestyle='None',\n                  markersize=15, label='Compound event {2,4,6}', alpha=0.3)\n]\nax.legend(handles=legend_handles, loc='lower center', ncol=2, frameon=False, bbox_to_anchor=(0.5, -0.3))\n\n# Adjust limits\nax.set_xlim(min_x - 0.5, max_x + 0.5)\nax.set_ylim(min_y - 0.2, max_y + 0.2)\n\nplt.title('Sample Space and Events', fontsize=16, pad=20)\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#event-notation",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#event-notation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Event Notation",
    "text": "Event Notation\nFor a die roll with \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (rolling an odd number)\n\\(B = \\{4, 5, 6\\}\\) (rolling 4 or higher)\n\\(C = \\{6\\}\\) (rolling a six)\n\n\n\n\n\n\n\nWe can describe events in words or using set notation"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#set-operations-overview",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#set-operations-overview",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Set Operations Overview",
    "text": "Set Operations Overview\n\n\n\n\nüéØ Definition:\n\nSet: Collection of distinct objects\nUnion: A OR B occurs\n\nIntersection: A AND B occurs\nComplement: A does NOT occur\nSample Space: All possible outcomes\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# 1) Draw the Venn, but format subset labels to be blank\nv = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    ax=ax,\n    subset_label_formatter=lambda x: \"\"     # removes the \"1\" labels\n)\n\n# 2) Color each region (optional)\nv.get_patch_by_id('10').set_color('lightblue')\nv.get_patch_by_id('01').set_color('lightcoral')\nv.get_patch_by_id('11').set_color('lightgreen')\n\n# 3) Add a dashed universe rectangle around S, with high z‚Äêorder\nrect = patches.Rectangle(\n    (-1, -1),    # lower‚Äêleft corner\n    2, 2,        # width, height\n    linewidth=2,\n    edgecolor='black',\n    facecolor='none',\n    linestyle='--',\n    zorder=10     # put on top of the circles\n)\nax.add_patch(rect)\n\n# 4) Label the universe \"S\"\nax.text(-.95,  0.95, 'S', fontsize=14, fontweight='bold',\n        va='top', ha='left', zorder=11)\n\n# 5) Tidy up\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.set_axis_off()\n\nplt.title('Sample Space $S$ with Events $A$ and $B$')\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#what-is-a-set",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#what-is-a-set",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "What is a Set?",
    "text": "What is a Set?\n\n\n\n\nüéØ Definition: A collection of things that share common characteristics. They can be elements, members, objects or similar terms.\nExamples:\n\nSet of even numbers:\n\n{2, 4, 6, 8, ‚Ä¶}\n\nSet of vowels: {a, e, i, o, u}\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\n# Create the figure and axes\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# Draw the Venn with no default set labels and blank subset labels\nv = venn2(\n    subsets=(1, 0, 0),\n    set_labels=('', ''),                       # no set labels\n    subset_label_formatter=lambda x: \"\",       # hide subset‚Äêsize labels\n    ax=ax\n)\n\n# Color and shade the A region\npatch = v.get_patch_by_id('10')\npatch.set_color('lightblue')\npatch.set_alpha(0.7)\n\n# Add the dashed universe rectangle for S\nrect = patches.Rectangle(\n    (-1, -1),   # lower‚Äêleft corner\n    2,          # width\n    2,          # height\n    linewidth=2,\n    edgecolor='black',\n    facecolor='none',\n    linestyle='--',\n    zorder=2     # above the circles\n)\nax.add_patch(rect)\n\n# Label the universe \"S\"\nax.text(\n    -0.95, 0.95, 'S',\n    fontsize=14, fontweight='bold',\n    va='top', ha='left',\n    zorder=3\n)\n\n# Label set A inside the circle\nax.text(\n    0, 0, 'SET A',\n    fontsize=14, fontweight='bold',\n    ha='center',\n    zorder=3\n)\n\n# Adjust limits and styling\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\n\nplt.title('A Single Set $A$ within Sample Space $S$')\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#union-a-b",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#union-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Union: A ‚à™ B",
    "text": "Union: A ‚à™ B\n\n\n\n\nüéØ Definition: Contains all set elements, including intersections.\nIn Probability: The event that A OR B occurs (or both).\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\n# Create figure and axes\nfig, ax = plt.subplots(figsize=(6, 6))\n\n# Draw Venn without default numeric labels\nv = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    subset_label_formatter=lambda x: \"\",\n    ax=ax\n)\n\n# Fill entire circles for A and B with semi-transparent colors\nfor region in ('10', '11'):  # parts of A\n    patch = v.get_patch_by_id(region)\n    patch.set_facecolor('skyblue')\n    patch.set_alpha(0.5)\n    patch.set_edgecolor('black')\n    patch.set_linewidth(2)\nfor region in ('01', '11'):  # parts of B\n    patch = v.get_patch_by_id(region)\n    patch.set_facecolor('lightcoral')\n    patch.set_alpha(0.5)\n    patch.set_edgecolor('black')\n    patch.set_linewidth(2)\n\n# Union label at center\nax.text(\n    0, 0, r'$\\mathbf{A \\cup B}$',\n    fontsize=18, fontweight='bold', ha='center', va='center'\n)\n\n# Add the universe rectangle (sample space)\nrect = patches.Rectangle(\n    (-1.1, -1.1), 2.2, 2.2,\n    linewidth=2, edgecolor='black', facecolor='none', linestyle='--'\n)\nax.add_patch(rect)\n\n# Label the universe \"Œ©\"\nax.text(\n    -1.05, 1.05, 'Œ©',\n    fontsize=16, fontweight='bold', va='top', ha='left'\n)\n\n# Increase set label font size\nv.get_label_by_id('A').set_fontsize(14)\nv.get_label_by_id('B').set_fontsize(14)\n\n# Title and styling\nax.set_title('Union of Events: $A \\\\cup B$', fontsize=16, pad=20)\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\n\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#intersection-a-b",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#intersection-a-b",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Intersection: A ‚à© B",
    "text": "Intersection: A ‚à© B\n\n\n\n\nüéØ Definition: Area where two or more sets overlap.\nIn Probability: The event that A AND B occurs.\nProperties:\n\nAlways smaller than or equal to individual sets\nCan be empty (disjoint sets)\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\n# Create figure and axes\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# Draw Venn without subset‚Äêsize labels\nv = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    subset_label_formatter=lambda x: \"\",  # hide the \"1\" labels\n    ax=ax\n)\n\n# Shade the non‚Äêintersection regions light gray\nfor region in ('10', '01'):\n    patch = v.get_patch_by_id(region)\n    patch.set_color('lightgray')\n    patch.set_alpha(0.8)\n\n# Shade the intersection region red\npatch = v.get_patch_by_id('11')\npatch.set_color('red')\npatch.set_alpha(0.8)\n\n# Add the universe rectangle\nrect = patches.Rectangle(\n    (-1, -1),    # lower‚Äêleft corner\n    2,           # width\n    2,           # height\n    linewidth=2,\n    edgecolor='black',\n    facecolor='none',\n    linestyle='--',\n    zorder=2      # above circles\n)\nax.add_patch(rect)\n\n# Label the universe \"S\"\nax.text(\n    -0.95, 0.95, 'S',\n    fontsize=14, fontweight='bold',\n    va='top', ha='left',\n    zorder=3\n)\n\n# Label the intersection inside\nax.text(\n    0, 0, 'A ‚à© B',\n    fontsize=14, fontweight='bold',\n    ha='center', va='center',\n    zorder=3\n)\n\n# Tidy up\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\n\nplt.title('Intersection: $A \\\\cap B$ (A AND B)')\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#absolute-complement-ac",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#absolute-complement-ac",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Absolute Complement: \\(A^c\\)",
    "text": "Absolute Complement: \\(A^c\\)\n\n\n\nüéØ Definition: All elements that do not belong to the set.\nIn Probability: The event that A does NOT occur.\n\n\\(P(A^c) = 1 - P(A)\\)\n\nKey Property:\n\n\\(A \\cup A^c = S\\) (Sample Space)\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2, venn2_circles\n\n# 1) Create figure and axes\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# 2) Draw the universe rectangle (purple background)\nrect = patches.Rectangle(\n    (-1, -1),  # lower-left corner\n    2, 2,      # width, height\n    linewidth=2,\n    edgecolor='black',\n    facecolor='purple',\n    alpha=0.3,\n    zorder=1\n)\nax.add_patch(rect)\n\n# 3) Draw Venn diagram with blank subset labels\nv = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    subset_label_formatter=lambda x: \"\",\n    ax=ax\n)\n\n# 4) Mask out A (both A‚Äêonly and intersection) with white\nfor region in ('10', '11'):\n    p = v.get_patch_by_id(region)\n    p.set_facecolor('white')\n    p.set_edgecolor('none')\n    p.set_alpha(1)\n\n# 5) Hide the B‚Äêonly region so purple shows through\np_b = v.get_patch_by_id('01')\np_b.set_facecolor('none')\np_b.set_edgecolor('none')\np_b.set_alpha(1)\n\n# 6) Draw crisp circle outlines on top\nvenn2_circles((1, 1, 1), ax=ax, linestyle='solid', linewidth=2, color='black')\n\n# 7) Label universe and complement\nax.text(-0.95, 0.95, 'S', fontsize=14, fontweight='bold', va='top', ha='left', zorder=3)\nax.text(-.6, 0.75, r'$A^c$', fontsize=14, fontweight='bold', ha='center', va='center', zorder=3)\n\n# 8) Final styling\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\nplt.title('Complement: $A^c$ (NOT A)')\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#summary-table",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#summary-table",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Summary Table",
    "text": "Summary Table\n\n\n\n\n\n\n\n\n\nOperation\nSymbol\nMeaning\nProbability\n\n\n\n\nUnion\n\\(A \\cup B\\)\nOccurs if \\(A\\) or \\(B\\)\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\nIntersection\n\\(A \\cap B\\)\nOccurs if \\(A\\) and \\(B\\)\n\\(P(A \\cap B)\\)\n\n\nComplement\n\\(A^c\\)\nOccurs if \\(A\\) does not occur\n\\(P(A^c) = 1 - P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-commutative",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-commutative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Commutative",
    "text": "Probability Axioms: Commutative\n\nCommutative\n\\(A \\cup B = B \\cup A\\)\n\\(A \\cap B = B \\cap A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-associative",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-associative",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Associative",
    "text": "Probability Axioms: Associative\n\nAssociative\n\\((A \\cup B) \\cup C = A \\cup (B \\cup C)\\)\n\\((A \\cap B) \\cap C = A \\cap (B \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-distributive",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-distributive",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: Distributive",
    "text": "Probability Axioms: Distributive\n\nDistributive\n\\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\n\\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-de-morgans-laws",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-axioms-de-morgans-laws",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability Axioms: De Morgan‚Äôs Laws",
    "text": "Probability Axioms: De Morgan‚Äôs Laws\n\nDe Morgan‚Äôs Laws\n\\((A \\cup B)^c = A^c \\cap B^c\\)\n\\((A \\cap B)^c = A^c \\cup B^c\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-examples",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Examples",
    "text": "Practice Examples\n\nExample 1: In a class of students:\n\nSet A = Students who like Math\nSet B = Students who like Science\n\nQ: What does A ‚à™ B represent?\n\n\n\nSolution. Students who like Math OR Science (or both)\n\n\n\n\nExample 2: What does A ‚à© B represent?\n\n\n\nSolution. Students who like BOTH Math AND Science\n\n\n\n\nExample 3: What does \\(A^c\\) represent?\n\n\n\nSolution. Students who do NOT like Math"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#example-set-operations",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#example-set-operations",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Example: Set Operations",
    "text": "Example: Set Operations\n\n\nFor die roll \\(S = \\{1, 2, 3, 4, 5, 6\\}\\):\n\n\\(A = \\{1, 3, 5\\}\\) (odd numbers)\n\\(B = \\{4, 5, 6\\}\\) (4 or higher)\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\n# Create the figure and axes\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# Correct subset sizes: A only = 2, B only = 2, A ‚à© B = 1\nv = venn2(\n    subsets=(2, 2, 1),\n    set_labels=('A', 'B'),\n    subset_label_formatter=lambda x: \"\",  # hide the count labels\n    ax=ax\n)\n\n# Label each region\nv.get_label_by_id('10').set_text('A ‚àñ B\\n{1, 3}')\nv.get_label_by_id('01').set_text('B ‚àñ A\\n{4, 6}')\nv.get_label_by_id('11').set_text('A ‚à© B\\n{5}')\n\n# Draw the universe rectangle for S\nrect = patches.Rectangle(\n    (-1, -1),   # lower-left corner\n    2, 2,       # width, height\n    linewidth=2,\n    edgecolor='black',\n    facecolor='none',\n    linestyle='--',\n    zorder=1\n)\nax.add_patch(rect)\n\n# Label the universe\nax.text(\n    -0.95, 0.95, 'S = {1,2,3,4,5,6}',\n    fontsize=12, fontweight='bold',\n    va='top', ha='left',\n    zorder=2\n)\n\n# Final styling\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\n\nplt.title('Odd Numbers vs. 4 or Higher')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nFind:\n\n\\(A \\cup B\\)\n\\(A \\cap B\\)\n\\(A^c\\)\n\n\n\n\n\nSolution. \n\n\\(A \\cup B = \\{1, 3, 4, 5, 6\\}\\)\n\\(A \\cap B = \\{5\\}\\)\n\\(A^c = \\{2, 4, 6\\}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-events",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-events",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive Events",
    "text": "Mutually Exclusive Events\n\n\nEvents \\(A\\) and \\(B\\) are mutually exclusive (or disjoint) if they cannot occur simultaneously\n\\[A \\cap B = \\emptyset\\]\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib_venn import venn2\n\n# Create figure and axes\nfig, ax = plt.subplots(figsize=(6, 4))\n\n# Draw Venn diagram with blank subset labels\nv = venn2(\n    subsets=(3, 3, 0),\n    set_labels=('A', 'B'),\n    subset_label_formatter=lambda x: \"\",\n    ax=ax\n)\n\n# Color and shade regions\nv.get_patch_by_id('10').set_color('lightblue')\nv.get_patch_by_id('01').set_color('lightcoral')\nv.get_patch_by_id('10').set_alpha(0.7)\nv.get_patch_by_id('01').set_alpha(0.7)\n\n# Label each region explicitly\nv.get_label_by_id('10').set_text('A: {1,3,5}')\nv.get_label_by_id('01').set_text('B: {2,4,6}')\n\n# Add universe rectangle for S\nrect = patches.Rectangle(\n    (-1, -1), 2, 2,\n    linewidth=2,\n    edgecolor='black',\n    facecolor='none',\n    linestyle='--',\n    zorder=1\n)\nax.add_patch(rect)\n\n# Label the universe\nax.text(\n    -0.95, 0.95, 'S = {1, 2, 3, 4, 5, 6}',\n    fontsize=12, fontweight='bold',\n    va='top', ha='left',\n    zorder=2\n)\n\n# Final styling\nax.set_xlim(-1.2, 1.2)\nax.set_ylim(-1.2, 1.2)\nax.set_aspect('equal')\nax.axis('off')\n\nplt.title('Mutually Exclusive: Odd vs. Even')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nWhen rolling a die\n\n\\(A = \\{1, 3, 5\\}\\) (odd)\n\\(B = \\{2, 4, 6\\}\\) (even)\n\n\\(A\\) and \\(B\\) are mutually exclusive"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#the-classical-definition-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#the-classical-definition-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Classical Definition of Probability",
    "text": "The Classical Definition of Probability\n\nüéØ Definition: For equally likely outcomes:\n\\[P(A) = \\frac{\\text{Number of outcomes in } A}{\\text{Total number of outcomes in } S}\\]\n\n\nProbability of rolling an even number on a fair die\n\n\n\\[P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#properties-of-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#properties-of-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Properties of Probability",
    "text": "Properties of Probability\n\nNon-negativity: \\(P(A) \\geq 0\\) for any event \\(A\\)\nNormalization: \\(P(S) = 1\\)\nAdditivity: If \\(A\\) and \\(B\\) are mutually exclusive, then\n\n\n\\[P(A \\cup B) = P(A) + P(B)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#the-complement-rule",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#the-complement-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Complement Rule",
    "text": "The Complement Rule\n\n\\[P(A) + P(A^c) = 1\\]\n\\[P(A^c) = 1 - P(A)\\]\n\n\n\nIf the probability of rain is 0.3, what‚Äôs the probability of no rain?\n\n\n\n\nSolution. \\[P(\\text{no rain}) = 1 - P(\\text{rain}) = 1 - 0.3 = 0.7\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-1",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\n\n\n\n\nA standard deck has 52 cards. What is the probability of drawing:\n\nA heart \\(\\heartsuit\\)?\nA face card (Jack, Queen, King)?\nThe ace of spades \\(\\spadesuit\\)?\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{heart}) = \\frac{13}{52} = \\frac{1}{4}\\)\n\\(P(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\\)\n\\(P(\\text{ace of spades}) = \\frac{1}{52}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#the-addition-rule",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#the-addition-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Addition Rule",
    "text": "The Addition Rule\nFor any two events \\(A\\) and \\(B\\):\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\n\nWhy subtract \\(P(A \\cap B)\\)?\n\n\n\nSolution. We don‚Äôt want to double-count outcomes that are in both events"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#addition-rule-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#addition-rule-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Addition Rule Example",
    "text": "Addition Rule Example\n\n\n\n\nDrawing from a standard deck:\n\n\\(A\\): Drawing a heart \\(\\heartsuit\\) (\\(P(A) = \\frac{13}{52}\\))\n\\(B\\): Drawing a face card (\\(P(B) = \\frac{12}{52}\\))\nWhat‚Äôs \\(P(A \\cup B)\\) (heart OR face card)?\n\n\n\n\n\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\nplt.figure(figsize=(6,4))\nv = venn2(subsets=(10, 9, 3))\nv.get_label_by_id('10').set_text('A: Hearts')\nv.get_label_by_id('01').set_text('B: Face Cards')\nv.get_label_by_id('11').set_text('A ‚à© B')\nplt.title('Hearts vs. Face Cards')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\n\n# Compute region sizes\nonly_hearts = 13 - 3\nonly_face = 12 - 3\nintersection = 3\n\nplt.figure(figsize=(6,4))\nvenn2(subsets=(only_hearts, only_face, intersection), set_labels=('Hearts', 'Face Cards'))\nplt.title('Hearts vs. Face Cards')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSolution. \\(P(A \\cap B) = \\frac{3}{52}\\) (face cards that are hearts)\n\\(P(A \\cup B) = \\frac{13}{52} + \\frac{12}{52} - \\frac{3}{52} = \\frac{22}{52} = \\frac{11}{26}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\n\n\n\nüéØConditional probability is the probability of event \\(A\\) given that event \\(B\\) has occurred\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nprovided \\(P(B) &gt; 0\\)\n\n\n\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\n\n# Define colors and edge style\ncolor_intersection = '#1f77b4'  # blue\ncolor_B = '#ff7f0e'             # orange\nedge_color = 'black'\nlinewidth = 2\ntext_fontsize = 20\nlabel_fontsize = 20\ntitle_fontsize = 20\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# --- First plot: Intersection Only ---\nv1 = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    ax=axes[0],\n    subset_label_formatter=lambda x: ''\n)\n# Style regions\nfor region in ('10', '01'):\n    patch = v1.get_patch_by_id(region)\n    patch.set_facecolor('none')\n    patch.set_edgecolor(edge_color)\n    patch.set_linewidth(linewidth)\npatch_int1 = v1.get_patch_by_id('11')\npatch_int1.set_facecolor(color_intersection)\npatch_int1.set_alpha(0.5)\npatch_int1.set_edgecolor(edge_color)\npatch_int1.set_linewidth(linewidth)\n# Increase label font sizes\nv1.get_label_by_id('A').set_fontsize(label_fontsize)\nv1.get_label_by_id('B').set_fontsize(label_fontsize)\n# Add bolded P(A‚à©B) text\nx_int, y_int = v1.get_label_by_id('11').get_position()\naxes[0].text(x_int, y_int, r'$\\mathbf{P(A\\cap B)}$', \n             ha='center', va='center', fontsize=text_fontsize)\naxes[0].set_title('Intersection Only', fontsize=title_fontsize)\n\n# --- Second plot: B Only (including intersection) ---\nv2 = venn2(\n    subsets=(1, 1, 1),\n    set_labels=('A', 'B'),\n    ax=axes[1],\n    subset_label_formatter=lambda x: ''\n)\n# Style regions\npatch_A2 = v2.get_patch_by_id('10')\npatch_A2.set_facecolor('none')\npatch_A2.set_edgecolor(edge_color)\npatch_A2.set_linewidth(linewidth)\nfor region in ('01', '11'):\n    patch = v2.get_patch_by_id(region)\n    patch.set_facecolor(color_B)\n    patch.set_alpha(0.5)\n    patch.set_edgecolor(edge_color)\n    patch.set_linewidth(linewidth)\n# Increase label font sizes\nv2.get_label_by_id('A').set_fontsize(label_fontsize)\nv2.get_label_by_id('B').set_fontsize(label_fontsize)\n# Add bolded B text inside B circle\nx_B, y_B = v2.get_label_by_id('01').get_position()\naxes[1].text(x_B, y_B, r'$\\mathbf{B}$', \n             ha='center', va='center', fontsize=text_fontsize)\naxes[1].set_title('B Only', fontsize=title_fontsize)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-interpretation",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-interpretation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Interpretation",
    "text": "Conditional Probability Interpretation\n\\(P(A|B)\\) means:\n\nWe know event  \\(B\\) has occurred \nWhat‚Äôs the probability that \\(A\\) also occurred?\nWe ‚Äúrestrict‚Äù our sample space to only outcomes in \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#conditional-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Example",
    "text": "Conditional Probability Example\n\n\n\nDrawing a card from a standard deck:\n\n\\(A\\): Card is a heart \\(\\heartsuit\\)\n\\(B\\): Card is red\nQ: Find \\(P(A|B)\\)\n\n\n\n\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\nplt.figure(figsize=(6,4))\nv = venn2(subsets=(13, 13, 0))\nv.get_label_by_id('10').set_text('A: Hearts')\nv.get_label_by_id('01').set_text('B: Red Cards')\nplt.title('Hearts vs. Red Cards')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSolution. \\(P(A \\cap B) = P(\\text{heart}) = \\frac{13}{52}\\)\n\\(P(B) = P(\\text{red}) = \\frac{26}{52}\\)\n\\(P(A|B) = \\frac{13/52}{26/52} = \\frac{13}{26} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#independence",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#independence",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\nüéØ Definition Events \\(A\\) and \\(B\\) are independent if:\n\\[P(A|B) = P(A)\\]\nor equivalently:\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\n\n\nKnowing that \\(B\\) occurred doesn‚Äôt change the probability of \\(A\\)\n\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n\n# Define probabilities for independent events\nP_A = 0.4\nP_B = 0.5\nP_AB = P_A * P_B  # 0.2\n\n# Subset sizes: only A, only B, intersection\nsubsets = (P_A - P_AB, P_B - P_AB, P_AB)\n\nfig, ax = plt.subplots(figsize=(6, 6))\nv = venn2(subsets=subsets, set_labels=('A', 'B'), ax=ax)\n\n# Style regions\nv.get_patch_by_id('10').set_color('skyblue')    # A only\nv.get_patch_by_id('10').set_alpha(0.5)\nv.get_patch_by_id('01').set_color('lightgreen') # B only\nv.get_patch_by_id('01').set_alpha(0.5)\nv.get_patch_by_id('11').set_color('orange')     # Intersection\nv.get_patch_by_id('11').set_alpha(0.7)\n\n# Annotate margins and intersection inside\nv.get_label_by_id('10').set_text(f'{subsets[0]:.1f}')\nv.get_label_by_id('01').set_text(f'{subsets[1]:.1f}')\nv.get_label_by_id('11').set_text(f'{subsets[2]:.1f}')\n\n# Print P(A) and P(B) to the sides\nax.text(-0.8, 0.6, f'$P(A)={P_A}$', fontsize=14, fontweight='bold')\nax.text(0.8, 0.6, f'$P(B)={P_B}$', fontsize=14, fontweight='bold')\n\nplt.title('Independent Events\\n$P(A\\\\cap B)=P(A)P(B)$', fontsize=16)\nax.axis('equal')\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#independence-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#independence-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence Example",
    "text": "Independence Example\n\nTwo coin flips:\n\n\\(A\\): First flip is heads\n\\(B\\): Second flip is heads\n\nQ: Are \\(A\\) and \\(B\\) independent?\n\n\n\nSolution. \\(P(A) = \\frac{1}{2}\\), \\(P(B) = \\frac{1}{2}\\)\n\\(P(A \\cap B) = P(\\text{HH}) = \\frac{1}{4}\\)\n\\(P(A) \\times P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\)\nYes, they are independent!"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.¬†Independent",
    "text": "Mutually Exclusive vs.¬†Independent\n\nMutually Exclusive (left): the circles A and B do not overlap, so \\(P(A\\cap B)=0\\).\nIndependent (right): the circles overlap, and we‚Äôve sized the intersection so that \\(P(A\\cap B)=P(A)\\,P(B)\\).\n\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\n\n# Create side-by-side Venn diagrams\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# 1) Mutually Exclusive: no overlap\nvenn2(\n    subsets=(1, 1, 0),\n    set_labels=('A', 'B'),\n    ax=axes[0],\n    subset_label_formatter=lambda x: ''\n)\naxes[0].set_title('Mutually Exclusive\\nP(A‚à©B) = 0')\n\n# 2) Independent: overlap equals product of areas (e.g., 0.5 * 0.5 = 0.25)\n# Scale counts arbitrarily (25, 25, 25) to represent proportions\nvenn2(\n    subsets=(25, 25, 25),\n    set_labels=('A', 'B'),\n    ax=axes[1],\n    subset_label_formatter=lambda x: ''\n)\naxes[1].set_title('Independent\\nP(A‚à©B) = P(A)P(B)')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#mutually-exclusive-vs.-independent-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Mutually Exclusive vs.¬†Independent Example",
    "text": "Mutually Exclusive vs.¬†Independent Example\n\n\n\nDraw a single card from a 52-card deck:\n\nLet A={‚Äúdraw an Ace‚Äù}, so P(A)=4/52.\nLet B={‚Äúdraw a King‚Äù}, so P(B)=4/52.\n\nQ: What is \\(P(A\\cap B)\\) ?\n\n\n\n\n\nSolution. They‚Äôre disjoint (you can‚Äôt draw an Ace and a King), so \\(P(A\\cap B) = 0\\).\nBut \\(P(A)\\,P(B) = \\frac{4}{52}\\times\\frac{4}{52} = \\frac{16}{2704} \\neq 0\\).\nHence, \\(P(A\\cap B)\\neq P(A)P(B)\\), so they‚Äôre not independent."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#multiplication-rule",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#multiplication-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Multiplication Rule",
    "text": "Multiplication Rule\nGeneral case: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nIndependent events: \\(P(A \\cap B) = P(A) \\times P(B)\\)\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\n\n# Define scaled subset sizes for illustration\n# General case: P(A)=40 (10+30), P(B|A)=0.75 so intersection=30, B-only=20 (if P(B)=50)\n# Independent case: P(A)=40, P(B)=50, intersection=P(A)*P(B)=20\ngeneral_subsets = (10, 20, 30)   # (A-only, B-only, intersection)\nindep_subsets = (20, 30, 20)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# --- General Multiplication Rule ---\nvenn2(subsets=general_subsets, set_labels=('A', 'B'), ax=axes[0])\naxes[0].set_title('General: P(A‚à©B) = P(A)¬∑P(B|A)', fontsize=14)\n\n# --- Independent Events ---\nvenn2(subsets=indep_subsets, set_labels=('A', 'B'), ax=axes[1])\naxes[1].set_title('Independent: P(A‚à©B) = P(A)¬∑P(B)', fontsize=14)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagrams",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagrams",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\n\nüéØ Definition Tree diagrams help visualize sequential events and calculate probabilities.\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle, FancyArrowPatch\n\n# Coordinates for nodes\ncoords = {\n    'root': (0.1, 0.5),\n    'A': (0.4, 0.7),\n    'B': (0.4, 0.3),\n    'A_Red': (0.7, 0.8),\n    'A_Blue': (0.7, 0.6),\n    'B_Red': (0.7, 0.4),\n    'B_Blue': (0.7, 0.2),\n}\n\n# Probabilities\np_A = 0.7\np_B = 0.3\np_R_A = 0.6\np_B_A = 0.4\np_R_B = 0.3\np_B_B = 0.7\n\n# Create figure\nfig, ax = plt.subplots(figsize=(8, 6))\nax.set_xlim(0, 1)\nax.set_ylim(0, 1)\nax.axis('off')\n\n# Draw nodes\nfor node, (x, y) in coords.items():\n    circle = Circle((x, y), 0.05, edgecolor='black', facecolor='white', linewidth=2)\n    ax.add_patch(circle)\n    label = node.replace('_', '\\n')\n    if node == 'root':\n        label = 'Start'\n    ax.text(x, y, label, ha='center', va='center', fontsize=12, fontweight='bold')\n\n# Draw arrows and annotate probabilities\ndef draw_branch(start, end, text):\n    x1, y1 = coords[start]\n    x2, y2 = coords[end]\n    arrow = FancyArrowPatch((x1+0.05, y1), (x2-0.05, y2), arrowstyle='-&gt;', mutation_scale=20)\n    ax.add_patch(arrow)\n    ax.text((x1+x2)/2, (y1+y2)/2, text, fontsize=12, backgroundcolor='white', ha='center')\n\ndraw_branch('root', 'A', f'{p_A}')\ndraw_branch('root', 'B', f'{p_B}')\ndraw_branch('A', 'A_Red', f'{p_R_A}')\ndraw_branch('A', 'A_Blue', f'{p_B_A}')\ndraw_branch('B', 'B_Red', f'{p_R_B}')\ndraw_branch('B', 'B_Blue', f'{p_B_B}')\n\n# Title\nax.set_title('Tree Diagram: Drawing from Urn A (70%) or B (30%)', fontsize=14, pad=20)\n\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagram-examples",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#tree-diagram-examples",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Tree Diagram Examples",
    "text": "Tree Diagram Examples\n\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle, FancyArrowPatch\n\n# Coordinates for nodes in the full tree\ncoords = {\n    'root':       (0.1, 0.5),\n    'A':          (0.35, 0.75),\n    'NotA':       (0.35, 0.25),\n    'A_B':        (0.7, 0.8),\n    'A_notB':     (0.7, 0.65),\n    'NotA_B':     (0.7, 0.35),\n    'NotA_notB':  (0.7, 0.2)\n}\n\n# Probabilities (example values)\npA     = 0.4\npNotA  = 0.6\npB_A   = 0.75\npNotB_A= 0.25\npB_notA= 0.333\npNotB_notA=0.667\n\n# Colors\ncolor_intersection = '#1f77b4'  # blue\ncolor_B            = '#ff7f0e'  # orange\ngray               = 'lightgray'\n\ndef draw_tree(highlight_branches, branch_color, node_to_color):\n    fig, ax = plt.subplots(figsize=(6, 4))\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.axis('off')\n\n    # Draw nodes\n    node_patches = {}\n    for node, (x, y) in coords.items():\n        circ = Circle((x, y), 0.035, edgecolor='black', facecolor='white', lw=2)\n        ax.add_patch(circ)\n        node_patches[node] = circ\n        label = {\n            'root': 'Start',\n            'A': 'A',\n            'NotA': '¬¨A',\n            'A_B': 'B',\n            'A_notB': '¬¨B',\n            'NotA_B': 'B',\n            'NotA_notB': '¬¨B'\n        }[node]\n        ax.text(x, y, label, ha='center', va='center', fontsize=12)\n\n    # Function to draw a branch\n    def draw_branch(start, end, text, color, lw=1.5):\n        x1, y1 = coords[start]\n        x2, y2 = coords[end]\n        arr = FancyArrowPatch((x1+0.035, y1), (x2-0.035, y2),\n                              arrowstyle='-|&gt;', mutation_scale=15,\n                              lw=lw, color=color)\n        ax.add_patch(arr)\n        ax.text((x1+x2)/2, (y1+y2)/2, text, ha='center', va='center',\n                backgroundcolor='white', fontsize=10)\n\n    # Draw all branches in gray\n    branches = [\n        ('root','A', f'{pA}'),\n        ('root','NotA', f'{pNotA}'),\n        ('A','A_B', f'{pB_A}'),\n        ('A','A_notB', f'{pNotB_A}'),\n        ('NotA','NotA_B', f'{pB_notA:.3f}'),\n        ('NotA','NotA_notB', f'{pNotB_notA:.3f}')\n    ]\n    for b in branches:\n        draw_branch(*b, color=gray)\n\n    # Highlight requested branches\n    for b in highlight_branches:\n        # find text label for branch\n        prob = {\n            ('root','A'): f'{pA}',\n            ('root','NotA'): f'{pNotA}',\n            ('A','A_B'): f'{pB_A}',\n            ('A','A_notB'): f'{pNotB_A}',\n            ('NotA','NotA_B'): f'{pB_notA:.3f}',\n            ('NotA','NotA_notB'): f'{pNotB_notA:.3f}'\n        }[b]\n        draw_branch(b[0], b[1], prob, color=branch_color, lw=3)\n    \n    # Color the end-node if desired\n    for node in node_to_color:\n        node_patches[node].set_facecolor(branch_color)\n\n    return fig, ax\n\n# Tree 1: highlight only the intersection branch root-&gt;A-&gt;A_B in blue\nfig1, ax1 = draw_tree(highlight_branches=[('root','A'),('A','A_B')],\n                      branch_color=color_intersection,\n                      node_to_color=['A_B'])\nax1.set_title('Intersection Only (P(A‚à©B))', fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n# Tree 2: highlight both B branches (A-&gt;B and ¬¨A-&gt;B) in orange\nfig2, ax2 = draw_tree(highlight_branches=[('root','A'),('A','A_B'),\n                                          ('root','NotA'),('NotA','NotA_B')],\n                      branch_color=color_B,\n                      node_to_color=['A_B','NotA_B'])\nax2.set_title('Event B Only (P(B))', fontsize=14)\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-2",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-2",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\n\n\n\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement.\n\nWhat‚Äôs the probability both balls are red?\nWhat‚Äôs the probability the first is red and second is blue?\n\n\n\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle\nfrom matplotlib.lines import Line2D\n\n# Set up figure\nfig, ax = plt.subplots(figsize=(10, 6))\nax.axis('off')\n\n# Node positions\npositions = {\n    'root': (0.1, 0.5),\n    'R': (0.35, 0.7),\n    'B': (0.35, 0.3),\n    'RR': (0.7, 0.8),\n    'RB': (0.7, 0.6),\n    'BR': (0.7, 0.4),\n    'BB': (0.7, 0.2),\n}\n\n# Define colors\ncolor_root = '#ecf0f1'\ncolor_R = '#e74c3c'       # red for R or RR\ncolor_B = '#3498db'       # blue for B or BB\ncolor_mixed = '#ff7f0e'   # orange for mixed (RB, BR)\nedge_color = 'black'\nlinewidth = 2\ntext_fs = 12\n\n# Draw nodes with colored backgrounds and bold labels\nnode_colors = {\n    'root': color_root,\n    'R': color_R,\n    'B': color_B,\n    'RR': color_R,\n    'RB': color_mixed,\n    'BR': color_mixed,\n    'BB': color_B\n}\n\nfor name, (x, y) in positions.items():\n    circ = Circle((x, y), 0.05, facecolor=node_colors[name],\n                  edgecolor=edge_color, linewidth=linewidth, zorder=2)\n    ax.add_patch(circ)\n    ax.text(x, y, name, ha='center', va='center', fontsize=text_fs, fontweight='bold', zorder=3)\n\n# Function to draw an arrow and label\ndef draw_arrow(src, dst, label):\n    x1, y1 = positions[src]\n    x2, y2 = positions[dst]\n    ax.annotate('', xy=(x2-0.05, y2), xytext=(x1+0.05, y1),\n                arrowprops=dict(arrowstyle='-&gt;', color=node_colors[dst], lw=linewidth), zorder=1)\n    ax.text((x1+x2)/2, (y1+y2)/2, label, ha='center', va='center',\n            backgroundcolor='white', fontsize=text_fs, fontweight='bold', zorder=3)\n\n# Draw branches with probabilities\ndraw_arrow('root', 'R', '5/8')\ndraw_arrow('root', 'B', '3/8')\ndraw_arrow('R', 'RR', '4/7')\ndraw_arrow('R', 'RB', '3/7')\ndraw_arrow('B', 'BR', '5/7')\ndraw_arrow('B', 'BB', '2/7')\n\n# Label leaves with final probabilities in bold\nleaf_probs = {\n    'RR': '20/56',\n    'RB': '15/56',\n    'BR': '15/56',\n    'BB': '6/56'\n}\nfor leaf, prob in leaf_probs.items():\n    x, y = positions[leaf]\n    ax.text(x+0.12, y, prob, ha='left', va='center', fontsize=text_fs, fontweight='bold')\n\n# Legend\nlegend_elements = [\n    Line2D([0], [0], marker='o', color='w', label='RR / R',\n           markerfacecolor=color_R, markersize=12, markeredgecolor=edge_color),\n    Line2D([0], [0], marker='o', color='w', label='BB / B',\n           markerfacecolor=color_B, markersize=12, markeredgecolor=edge_color),\n    Line2D([0], [0], marker='o', color='w', label='RB / BR',\n           markerfacecolor=color_mixed, markersize=12, markeredgecolor=edge_color),\n]\nax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(0.02, 0.95))\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nSolution. \n\n\\(P(\\text{both red}) = \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)\n\\(P(\\text{red then blue}) = \\frac{5}{8} \\times \\frac{3}{7} = \\frac{15}{56}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nüéØ Definition\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space, then:\n\\[P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \\cdots + P(A|B_n)P(B_n)\\]\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Circle, Ellipse, Rectangle\n\n# Example probabilities\nP_B = [0.3, 0.5, 0.2]\nP_A_given_B = [0.2, 0.6, 0.5]\nP_A_and_B = [P_B[i] * P_A_given_B[i] for i in range(3)]\n\n# Create figure\nfig, ax = plt.subplots(figsize=(9, 5))\nax.set_aspect('equal')\nax.axis('off')\n\n# Draw sample space rectangle\nrect = Rectangle((-1, -2), width=8, height=4, edgecolor='black', facecolor='none', linewidth=2)\nax.add_patch(rect)\nax.text(-0.9, 1.7, r'$\\Omega$', fontsize=14, fontweight='bold', va='top', ha='left')\n\n# Draw B partitions as circles\npositions_B = [(1, 0), (3, 0), (5, 0)]\ncolors_B = ['#ffcc00', '#ff6600', '#ff0066']\n\nfor i, (x, y) in enumerate(positions_B):\n    circle = Circle((x, y), radius=1, facecolor=colors_B[i], edgecolor='black', alpha=0.3)\n    ax.add_patch(circle)\n    ax.text(x, y-1.3, f'$P(B_{i+1})={P_B[i]:.2f}$', ha='center', va='center', fontsize=12, fontweight='bold')\n\n# Draw A as a large ellipse overlapping all B's\nellipse = Ellipse((3, 0), width=8, height=3, angle=0, facecolor='#1f77b4', edgecolor='black', alpha=0.2)\nax.add_patch(ellipse)\nax.text(3, 1.2, '$A$', ha='center', va='center', fontsize=14, fontweight='bold')\n\n# Annotate intersections P(A ‚à© Bi)\nfor i, (x, y) in enumerate(positions_B):\n    ax.text(x, 0, f'$P(A\\\\cap B_{i+1})={P_A_and_B[i]:.2f}$', ha='center', va='center', fontsize=12, color='black', fontweight='bold')\n\nax.set_xlim(-1, 7)\nax.set_ylim(-2, 2)\nplt.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\n\nA factory has two machines:\n\nMachine 1: Produces 60% of items, 5% defective\nMachine 2: Produces 40% of items, 3% defective\n\nQ: What‚Äôs the overall probability an item is defective?\n\n\n\nSolution. \\(P(\\text{defective}) = P(D|M_1)P(M_1) + P(D|M_2)P(M_2)\\)\n\\(= 0.05 \\times 0.6 + 0.03 \\times 0.4 = 0.03 + 0.012 = 0.042\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem",
    "text": "Bayes‚Äô Theorem\n\nüéØ Definition \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\nThis allows us to ‚Äúreverse‚Äù conditional probabilities\nNamed after Thomas Bayes (1701-1761)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-components",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-components",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Components",
    "text": "Bayes‚Äô Theorem Components\n\n\\(A,B\\): Events\n\\(P(A|B)\\): Posterior probability - what we want to find\n\\(P(B|A)\\): Likelihood - given \\(A\\), probability of observing \\(B\\)\n\\(P(A)\\): Prior probability - initial probability of \\(A\\)\n\\(P(B)\\): Marginal probability - total probability of \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Example",
    "text": "Bayes‚Äô Theorem Example\n\n\n\nMedical test for a disease: 1\n\nDisease affects 1% of population\nTest is 95% accurate for sick people\nTest is 90% accurate for healthy people\n\nQ:If someone tests positive, what‚Äôs the probability they have the disease?\n\n\n\nimport plotly.express as px\nimport pandas as pd\n\n# Given probabilities\nP_D = 0.01\nP_notD = 0.99\nP_pos_given_D = 0.95\nP_pos_given_notD = 0.10\n\n# Joint probabilities\nP_D_and_pos = P_D * P_pos_given_D       # True positives\nP_notD_and_pos = P_notD * P_pos_given_notD  # False positives\nP_D_and_neg = P_D * (1 - P_pos_given_D)     # False negatives\nP_notD_and_neg = P_notD * (1 - P_pos_given_notD)  # True negatives\n\n# Prepare DataFrame for treemap (mosaic)\ndf = pd.DataFrame({\n    'Test Result': ['Positive', 'Positive', 'Negative', 'Negative'],\n    'Condition':   ['Disease',   'No Disease', 'Disease',   'No Disease'],\n    'Probability': [P_D_and_pos, P_notD_and_pos, P_D_and_neg, P_notD_and_neg]\n})\n\n# Create treemap mosaic plot\nfig = px.treemap(\n    df,\n    path=['Test Result', 'Condition'],\n    values='Probability',\n    color='Condition',\n    color_discrete_map={'Disease':'tomato', 'No Disease':'skyblue'}\n)\nfig.update_traces(textinfo='label+percent entry')\nfig.update_layout(\n    title='Bayes‚Äô Theorem: Distribution by Test Result and Condition',\n    margin=dict(t=50, l=25, r=25, b=25)\n)\nfig.show()"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Solution",
    "text": "Bayes‚Äô Theorem Solution\nLet:\n\n\\(D\\): Person has disease\n\\(T^+\\): Test is positive\n\nGiven:\n\n\\(P(D) = 0.01\\)\n\\(P(T^+|D) = 0.95\\)\n\\(P(T^-|D^c) = 0.90\\), so \\(P(T^+|D^c) = 0.10\\)\n\n\n\nSolution. \\(P(T^+) = P(T^+|D)P(D) + P(T^+|D^c)P(D^c)\\)\n\\(= 0.95 \\times 0.01 + 0.10 \\times 0.99 = 0.1085\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution-cont.",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#bayes-theorem-solution-cont.",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Bayes‚Äô Theorem Solution (cont.)",
    "text": "Bayes‚Äô Theorem Solution (cont.)\n\\[P(D|T^+) = \\frac{P(T^+|D) \\times P(D)}{P(T^+)} = \\frac{0.95 \\times 0.01}{0.1085} \\approx 0.088\\]\n\nimport matplotlib.pyplot as plt\n\n# Posterior probabilities given a positive test\nP_D_and_pos = 0.0095\nP_notD_and_pos = 0.099\nP_positive = P_D_and_pos + P_notD_and_pos\n\nP_D_given_pos = P_D_and_pos / P_positive\nP_notD_given_pos = P_notD_and_pos / P_positive\n\n# Pie chart\nlabels = ['Disease (P‚âà8.8%)', 'No Disease (P‚âà91.2%)']\nsizes = [P_D_given_pos, P_notD_given_pos]\ncolors = ['tomato', 'skyblue']\n\nfig, ax = plt.subplots(figsize=(6, 6))\nax.pie(\n    sizes, labels=labels, colors=colors, autopct='%.1f%%',\n    startangle=90, textprops={'fontsize': 14, 'fontweight': 'bold'}\n)\nax.set_title('Posterior Probability Given Positive Test', fontsize=16, fontweight='bold')\nax.axis('equal')  # Equal aspect ensures pie is circular.\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSurprising result: Even with a positive test, there‚Äôs only an 8.8% chance of having the disease!\nThis is due to the low base rate of the disease"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nConfusing \\(P(A|B)\\) with \\(P(B|A)\\)\n\n\nProsecutor‚Äôs fallacy is a specific error in interpreting conditional probabilities. Confusing\n\\(P(\\text{Evidence}\\mid\\text{Innocent})\n\\quad\\text{with}\\quad\nP(\\text{Innocent}\\mid\\text{Evidence})\\).\nEx: OJ Simpson Case 2"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes-1",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#common-probability-mistakes-1",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Probability Mistakes",
    "text": "Common Probability Mistakes\n\nAssuming independence when events are dependent\nIgnoring base rates (as in the medical test example)\n\n\nBase rate fallacy is when you ignore or underweight the prior probability \\(P(H)\\) of a hypothesis, focusing only on the new evidence \\(E\\).\n\n\nDouble counting in union calculations"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-3",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-3",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\n\nTwo fair dice are rolled. Find:\n\n\\(P(\\text{sum} = 7)\\)\n\\(P(\\text{sum} = 7 | \\text{first die shows 3})\\)\nAre these events independent?\n\n\n\n\nSolution. \n\n6 ways out of 36: \\(P(\\text{sum} = 7) = \\frac{6}{36} = \\frac{1}{6}\\)\nGiven first die is 3, need second die to be 4: \\(P(\\text{sum} = 7 | \\text{first} = 3) = \\frac{1}{6}\\)\nYes, they‚Äôre independent since \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-and-probability",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-and-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Counting and Probability",
    "text": "Counting and Probability\n\nSometimes we need to count outcomes:\n\nMultiplication Principle: If task 1 can be done in \\(m\\) ways and task 2 in \\(n\\) ways, both can be done in \\(m \\times n\\) ways\n\n\nPermutations: Arrangements where order matters \\[P(n,r) = \\frac{n!}{(n-r)!}\\]\n\n\nCombinations: Selections where order doesn‚Äôt matter \\[C(n,r) = \\binom{n}{r} = \\frac{n!}{r!(n-r)!}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-example",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#counting-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Counting Example",
    "text": "Counting Example\n\nQ: How many ways can you arrange 5 people in a row?\n\n\n\nSolution. This is a permutation: \\(P(5,5) = 5! = 120\\) ways\n\n\n\n\n\nQ:How many ways can you choose 3 people from 5 for a committee?\n\n\n\n\nSolution. This is a combination: \\(C(5,3) = \\binom{5}{3} = \\frac{5!}{3!2!} = 10\\) ways"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-with-counting",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#probability-with-counting",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Probability with Counting",
    "text": "Probability with Counting\n\nExample: A committee of 3 people is chosen from 8 people (5 women, 3 men). What‚Äôs the probability all 3 are women?\n\n\n\nSolution. Total ways to choose 3 from 8: \\(\\binom{8}{3} = 56\\)\nWays to choose 3 women from 5: \\(\\binom{5}{3} = 10\\)\nProbability: \\(\\frac{10}{56} = \\frac{5}{28}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#real-world-applications",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#real-world-applications",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Diagnosis: Using Bayes‚Äô theorem for test interpretation\nQuality Control: Probability of defective items\nFinance: Risk assessment and portfolio theory\nSports: Probability of wins, fantasy sports\nInsurance: Calculating premiums based on risk"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#key-formulas-summary",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\n\nBasic probability: \\(P(A) = \\frac{\\text{favorable outcomes}}{\\text{total outcomes}}\\)\nComplement: \\(P(A^c) = 1 - P(A)\\)\nAddition: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nConditional: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nIndependence: \\(P(A \\cap B) = P(A) \\times P(B)\\)\nBayes‚Äô: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#problem-solving-strategy",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\n\nIdentify the sample space and events\nDetermine if events are independent or mutually exclusive\nChoose the appropriate rule or formula\nCalculate step by step\nCheck if your answer makes sense"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\n\nA bag contains 4 red, 3 blue, and 2 green marbles. Three marbles are drawn without replacement.\nFind the probability that: a) All three are red b) No two are the same color c) At least one is blue"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4-solutions",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#practice-problem-4-solutions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Practice Problem 4 Solutions",
    "text": "Practice Problem 4 Solutions\n\nSolution. \n\nAll red: \\(\\frac{4}{9} \\times \\frac{3}{8} \\times \\frac{2}{7} = \\frac{24}{504} = \\frac{1}{21}\\)\nDifferent colors: \\(\\frac{4 \\times 3 \\times 2}{9 \\times 8 \\times 7} \\times 3! = \\frac{24 \\times 6}{504} = \\frac{144}{504} = \\frac{2}{7}\\)\nAt least one blue: \\(1 - P(\\text{no blue}) = 1 - \\frac{6 \\times 5 \\times 4}{9 \\times 8 \\times 7} = 1 - \\frac{120}{504} = \\frac{384}{504} = \\frac{16}{21}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#common-questions",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#common-questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Common Questions",
    "text": "Common Questions\n\nQ1.: ‚ÄúWhy isn‚Äôt \\(P(A \\cup B) = P(A) + P(B)\\) always?‚Äù\nA: We‚Äôd double-count outcomes in both events\nQ2.: ‚ÄúHow do I know if events are independent?‚Äù\nA: Check if \\(P(A|B) = P(A)\\) or if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nQ3.: ‚ÄúWhen do I use Bayes‚Äô theorem?‚Äù\nA: When you want to ‚Äúreverse‚Äù a conditional probability\n\n\nQ3 note (Bayes Example)\n\nForward: I know my test picks up disease 95% of the time ‚áí \\(P(+\\mid D)=0.95\\).\nReverse: I want the chance I really have the disease when the test is positive ‚áí \\(P(D\\mid +)\\)."
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#looking-ahead",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#looking-ahead",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture:\n\nRandom Variables and Probability Distributions\nDiscrete vs.¬†continuous random variables\nExpected value and variance"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#final-thoughts",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#final-thoughts",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Final Thoughts",
    "text": "Final Thoughts\n\nProbability is the foundation of statistics:\n\nHelps us quantify uncertainty\nProvides tools for making decisions with incomplete information\nEssential for understanding statistical inference\n\n\n\nPractice: The key to mastering probability is working through many problems!"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#questions",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#questions",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: Thursday‚Äôs 11 AM On Zoom (Link on Canvas)\nEmail: nmathlouthi@ucsb.edu\nNext Class: Random Variables and Distributions"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#resources",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms"
  },
  {
    "objectID": "files/lecture_notes/lecture4/lecture4-5-6.html#footnotes",
    "href": "files/lecture_notes/lecture4/lecture4-5-6.html#footnotes",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n\\(P(\\neg D \\,\\wedge\\, \\text{Negative})\n\\;=\\;P(\\neg D)\\times P(\\text{Negative}\\mid \\neg D)\n\\;=\\;0.99\\times0.90\n\\;=\\;0.891\\;(89.1\\%)\\)‚Ü©Ô∏é\nthe DNA evidence in the O. J. Simpson trial are a classic example of the prosecutor‚Äôs fallacy. Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was ‚Äúone in 170 million,‚Äù then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent.‚Ü©Ô∏é"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html",
    "href": "files/lecture_notes/lecture8/lecture8.html",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "",
    "text": "Conditional Probabilities\nUnderstanding probability when information changes the game"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#welcome-to-lecture-6",
    "href": "files/lecture_notes/lecture8/lecture8.html#welcome-to-lecture-6",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "",
    "text": "Conditional Probabilities\nUnderstanding probability when information changes the game"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#todays-learning-objectives",
    "href": "files/lecture_notes/lecture8/lecture8.html#todays-learning-objectives",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine and calculate conditional probabilities\nApply the multiplication rule for dependent events\nUse tree diagrams to solve multi-stage problems\nApply the law of total probability\nUse Bayes‚Äô theorem to solve real-world problems\nDistinguish between independence and conditional independence\nRecognize and avoid common conditional probability fallacies"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#motivation-why-conditional-probability",
    "href": "files/lecture_notes/lecture8/lecture8.html#motivation-why-conditional-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Motivation: Why Conditional Probability?",
    "text": "Motivation: Why Conditional Probability?\nIn real life, we rarely make decisions with no information\nExamples: - Medical diagnosis with test results - Weather forecast with current conditions\n- Investment decisions with market data - Sports betting with team statistics - Insurance premiums based on risk factors\n\nConditional probability helps us update our beliefs when we gain new information"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#what-is-conditional-probability",
    "href": "files/lecture_notes/lecture8/lecture8.html#what-is-conditional-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "What is Conditional Probability?",
    "text": "What is Conditional Probability?\nConditional Probability is the probability of an event occurring, given that another event has already occurred\nNotation: \\(P(A|B)\\) read as ‚Äúprobability of A given B‚Äù\n\nKey insight: When we know B has occurred, our sample space effectively ‚Äúshrinks‚Äù to only outcomes where B is true"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#intuitive-example",
    "href": "files/lecture_notes/lecture8/lecture8.html#intuitive-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Intuitive Example",
    "text": "Intuitive Example\nYou roll a fair six-sided die, but before revealing the result, someone tells you ‚Äúthe number is even‚Äù\nWhat‚Äôs the probability it‚Äôs a 4?\n\nWithout information: \\(P(\\text{rolling 4}) = \\frac{1}{6}\\)\nWith information: \\(P(\\text{4 | even}) = ?\\)\nGiven it‚Äôs even, possible outcomes: \\(\\{2, 4, 6\\}\\) So \\(P(\\text{4 | even}) = \\frac{1}{3}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#formal-definition",
    "href": "files/lecture_notes/lecture8/lecture8.html#formal-definition",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Formal Definition",
    "text": "Formal Definition\nFor events A and B where \\(P(B) &gt; 0\\):\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\n\nInterpretation: - Numerator: Outcomes where both A and B occur - Denominator: All outcomes where B occurs\n- Ratio: Fraction of B-outcomes where A also occurs"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#understanding-the-formula",
    "href": "files/lecture_notes/lecture8/lecture8.html#understanding-the-formula",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Understanding the Formula",
    "text": "Understanding the Formula\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nWhy this formula makes sense: - We restrict our attention to outcomes where B occurs - Among those outcomes, what fraction also have A? - This is exactly \\(\\frac{P(A \\cap B)}{P(B)}\\)\n\nRearranging: \\(P(A \\cap B) = P(A|B) \\times P(B)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-1",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-1",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 1",
    "text": "Practice Problem 1\nA card is drawn from a standard 52-card deck. Find:\n\n\\(P(\\text{King | Face card})\\)\n\\(P(\\text{Heart | Red card})\\)\n\n\\(P(\\text{Ace | Black card})\\)\n\n\nSolutions: a) \\(P(\\text{King | Face}) = \\frac{4}{12} = \\frac{1}{3}\\) (4 kings among 12 face cards) b) \\(P(\\text{Heart | Red}) = \\frac{13}{26} = \\frac{1}{2}\\) (13 hearts among 26 red cards) c) \\(P(\\text{Ace | Black}) = \\frac{2}{26} = \\frac{1}{13}\\) (2 black aces among 26 black cards)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#two-way-tables",
    "href": "files/lecture_notes/lecture8/lecture8.html#two-way-tables",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Two-Way Tables",
    "text": "Two-Way Tables\nTwo-way tables are excellent for conditional probability problems\nExample: Survey of 1000 people about coffee preference\n\n\n\n\nCoffee\nNo Coffee\nTotal\n\n\n\n\nMorning\n350\n150\n500\n\n\nEvening\n200\n300\n500\n\n\nTotal\n550\n450\n1000"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#using-two-way-tables",
    "href": "files/lecture_notes/lecture8/lecture8.html#using-two-way-tables",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Using Two-Way Tables",
    "text": "Using Two-Way Tables\nFind: \\(P(\\text{Coffee | Morning person})\\)\nFrom the table: - Morning people: 500 - Morning people who drink coffee: 350\n\n\\(P(\\text{Coffee | Morning}) = \\frac{350}{500} = 0.7\\)\nCompare to: \\(P(\\text{Coffee}) = \\frac{550}{1000} = 0.55\\)\nBeing a morning person increases coffee probability!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-2",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-2",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 2",
    "text": "Practice Problem 2\nUsing the coffee table, find:\n\n\\(P(\\text{Morning | Coffee drinker})\\)\n\\(P(\\text{No Coffee | Evening person})\\)\n\\(P(\\text{Evening | No Coffee})\\)\n\n\nSolutions: a) \\(P(\\text{Morning | Coffee}) = \\frac{350}{550} = \\frac{7}{11} \\approx 0.636\\) b) \\(P(\\text{No Coffee | Evening}) = \\frac{300}{500} = 0.6\\)\nc) \\(P(\\text{Evening | No Coffee}) = \\frac{300}{450} = \\frac{2}{3} \\approx 0.667\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#independence-revisited",
    "href": "files/lecture_notes/lecture8/lecture8.html#independence-revisited",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Independence Revisited",
    "text": "Independence Revisited\nEvents A and B are independent if knowing that B occurred doesn‚Äôt change the probability of A\n\\[P(A|B) = P(A)\\]\nEquivalently: \\[P(A \\cap B) = P(A) \\times P(B)\\]\n\nExample: Two coin flips are independent because \\(P(\\text{H}_2 | \\text{H}_1) = P(\\text{H}_2) = 0.5\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#testing-for-independence",
    "href": "files/lecture_notes/lecture8/lecture8.html#testing-for-independence",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Testing for Independence",
    "text": "Testing for Independence\nMethod 1: Check if \\(P(A|B) = P(A)\\) Method 2: Check if \\(P(A \\cap B) = P(A) \\times P(B)\\)\nMethod 3: Check if \\(P(B|A) = P(B)\\)\n\nCoffee Example: Are coffee preference and time preference independent?\n\\(P(\\text{Coffee}) = 0.55\\) \\(P(\\text{Coffee | Morning}) = 0.7\\)\nSince \\(0.7 \\neq 0.55\\), they are not independent"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#the-multiplication-rule",
    "href": "files/lecture_notes/lecture8/lecture8.html#the-multiplication-rule",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "The Multiplication Rule",
    "text": "The Multiplication Rule\nGeneral Multiplication Rule: \\[P(A \\cap B) = P(A) \\times P(B|A) = P(B) \\times P(A|B)\\]\nFor Independent Events: \\[P(A \\cap B) = P(A) \\times P(B)\\]\n\nExtension to Multiple Events: \\[P(A_1 \\cap A_2 \\cap A_3) = P(A_1) \\times P(A_2|A_1) \\times P(A_3|A_1 \\cap A_2)\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#multiplication-rule-example",
    "href": "files/lecture_notes/lecture8/lecture8.html#multiplication-rule-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Multiplication Rule Example",
    "text": "Multiplication Rule Example\nA jar contains 5 red balls and 3 blue balls. Two balls are drawn without replacement. What‚Äôs the probability both are red?\n\nLet \\(R_1\\) = first ball is red, \\(R_2\\) = second ball is red\n\\(P(R_1 \\cap R_2) = P(R_1) \\times P(R_2|R_1)\\)\n\\(= \\frac{5}{8} \\times \\frac{4}{7} = \\frac{20}{56} = \\frac{5}{14}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-3",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-3",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 3",
    "text": "Practice Problem 3\nA box contains 4 defective and 6 working items. Three items are selected without replacement. Find the probability that:\n\nAll three work\nThe first two work and the third is defective\nExactly two work\n\n\nSolutions: a) \\(P(\\text{WWW}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}\\)\n\n\\(P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{120}{720} = \\frac{1}{6}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-3-continued",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-3-continued",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 3 (continued)",
    "text": "Practice Problem 3 (continued)\n\nExactly two work (three scenarios: WWD, WDW, DWW)\n\n\\(P(\\text{WWD}) = \\frac{6}{10} \\times \\frac{5}{9} \\times \\frac{4}{8} = \\frac{1}{6}\\)\n\\(P(\\text{WDW}) = \\frac{6}{10} \\times \\frac{4}{9} \\times \\frac{5}{8} = \\frac{1}{6}\\)\n\\(P(\\text{DWW}) = \\frac{4}{10} \\times \\frac{6}{9} \\times \\frac{5}{8} = \\frac{1}{6}\\)\n\nTotal: \\(\\frac{1}{6} + \\frac{1}{6} + \\frac{1}{6} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#tree-diagrams",
    "href": "files/lecture_notes/lecture8/lecture8.html#tree-diagrams",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagrams",
    "text": "Tree Diagrams\nTree diagrams help visualize sequential events and conditional probabilities\n                    0.5   Red\n            0.6 ‚îÄ‚îÄ‚îê\n                    0.5   Blue\nBall 1      \n                    0.4   Red  \n            0.4 ‚îÄ‚îÄ‚îê\n                    0.6   Blue\nEach branch shows conditional probabilities"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#tree-diagram-example",
    "href": "files/lecture_notes/lecture8/lecture8.html#tree-diagram-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagram Example",
    "text": "Tree Diagram Example\nMedical test scenario: - 2% of population has disease - Test is 95% accurate for sick people\n- Test is 90% accurate for healthy people\nWhat‚Äôs the probability of testing positive?"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#tree-diagram-solution",
    "href": "files/lecture_notes/lecture8/lecture8.html#tree-diagram-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Tree Diagram Solution",
    "text": "Tree Diagram Solution\n                    0.95   Test +\n            0.02 ‚îÄ‚îÄ‚îê\n                    0.05   Test -\nDisease?    \n                    0.10   Test +\n            0.98 ‚îÄ‚îÄ‚îê\n                    0.90   Test -\n\n\\(P(\\text{Test+}) = P(\\text{Test+|Disease}) \\times P(\\text{Disease}) + P(\\text{Test+|Healthy}) \\times P(\\text{Healthy})\\)\n\\(= 0.95 \\times 0.02 + 0.10 \\times 0.98 = 0.019 + 0.098 = 0.117\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#law-of-total-probability",
    "href": "files/lecture_notes/lecture8/lecture8.html#law-of-total-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\nIf events \\(B_1, B_2, \\ldots, B_n\\) form a partition of the sample space (mutually exclusive and exhaustive), then:\n\\[P(A) = \\sum_{i=1}^{n} P(A|B_i) \\times P(B_i)\\]\n\nPartition means: - \\(B_i \\cap B_j = \\emptyset\\) for \\(i \\neq j\\) (mutually exclusive) - \\(\\bigcup_{i=1}^{n} B_i = S\\) (exhaustive)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#law-of-total-probability-example",
    "href": "files/lecture_notes/lecture8/lecture8.html#law-of-total-probability-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Law of Total Probability Example",
    "text": "Law of Total Probability Example\nA factory has three machines: - Machine A: 50% of production, 1% defective - Machine B: 30% of production, 2% defective\n- Machine C: 20% of production, 3% defective\nWhat‚Äôs the overall defect rate?\n\n\\(P(\\text{Defective}) = P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)\\)\n\\(= 0.01 \\times 0.5 + 0.02 \\times 0.3 + 0.03 \\times 0.2\\)\n\\(= 0.005 + 0.006 + 0.006 = 0.017 = 1.7\\%\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-4",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-4",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 4",
    "text": "Practice Problem 4\nA student studies for an exam with three possible outcomes based on study time: - Studies hard (40%): 90% chance of passing - Studies moderately (35%): 70% chance of passing\n- Doesn‚Äôt study (25%): 30% chance of passing\nWhat‚Äôs the overall probability of passing?\n\n\\(P(\\text{Pass}) = 0.9 \\times 0.4 + 0.7 \\times 0.35 + 0.3 \\times 0.25\\)\n\\(= 0.36 + 0.245 + 0.075 = 0.68\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#bayes-theorem",
    "href": "files/lecture_notes/lecture8/lecture8.html#bayes-theorem",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem",
    "text": "Bayes‚Äô Theorem\nThe Foundation: We often want to ‚Äúreverse‚Äù conditional probabilities\nGiven: \\(P(B|A)\\), \\(P(A)\\), \\(P(B)\\) Want: \\(P(A|B)\\)\nBayes‚Äô Theorem: \\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#bayes-theorem-components",
    "href": "files/lecture_notes/lecture8/lecture8.html#bayes-theorem-components",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem Components",
    "text": "Bayes‚Äô Theorem Components\n\\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\]\n\n\\(P(A|B)\\): Posterior probability (what we want)\n\\(P(B|A)\\): Likelihood (what we observe)\n\n\\(P(A)\\): Prior probability (initial belief)\n\\(P(B)\\): Evidence (marginal probability)\n\n\n‚ÄúIn light of evidence B, how should we update our belief in A?‚Äù"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#bayes-theorem-with-total-probability",
    "href": "files/lecture_notes/lecture8/lecture8.html#bayes-theorem-with-total-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bayes‚Äô Theorem with Total Probability",
    "text": "Bayes‚Äô Theorem with Total Probability\nWhen we need to find \\(P(B)\\):\n\\[P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B|A) \\times P(A) + P(B|A^c) \\times P(A^c)}\\]\nThis is the most common form for applications"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#medical-diagnosis-example",
    "href": "files/lecture_notes/lecture8/lecture8.html#medical-diagnosis-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Medical Diagnosis Example",
    "text": "Medical Diagnosis Example\nRevisiting our medical test: - 2% of population has disease (prior) - Test positive (evidence)\n- Test is 95% accurate for sick, 90% accurate for healthy\nGiven a positive test, what‚Äôs the probability of having the disease?"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#medical-diagnosis-solution",
    "href": "files/lecture_notes/lecture8/lecture8.html#medical-diagnosis-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Medical Diagnosis Solution",
    "text": "Medical Diagnosis Solution\nLet D = disease, T+ = positive test\n\\[P(D|T+) = \\frac{P(T+|D) \\times P(D)}{P(T+|D) \\times P(D) + P(T+|D^c) \\times P(D^c)}\\]\n\\[= \\frac{0.95 \\times 0.02}{0.95 \\times 0.02 + 0.10 \\times 0.98}\\]\n\\[= \\frac{0.019}{0.019 + 0.098} = \\frac{0.019}{0.117} \\approx 0.162\\]\n\nSurprising: Only 16.2% chance of disease despite positive test!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#why-the-low-probability",
    "href": "files/lecture_notes/lecture8/lecture8.html#why-the-low-probability",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Why the Low Probability?",
    "text": "Why the Low Probability?\nBase Rate Fallacy: When disease is rare (2%), most positive tests are false positives\nIntuition: Out of 10,000 people: - 200 have disease ‚Üí 190 test positive\n- 9,800 healthy ‚Üí 980 test positive - Total positive tests: 1,170 - True positives: 190\n\\(P(\\text{Disease | Positive}) = \\frac{190}{1,170} \\approx 0.162\\) ‚úì"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-5",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-5",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 5",
    "text": "Practice Problem 5\nEmail spam filter: - 60% of emails are spam - Filter catches 95% of spam - Filter incorrectly flags 8% of legitimate emails\nIf an email is flagged as spam, what‚Äôs the probability it‚Äôs actually spam?\n\n\\(P(\\text{Spam | Flagged}) = \\frac{0.95 \\times 0.6}{0.95 \\times 0.6 + 0.08 \\times 0.4}\\)\n\\(= \\frac{0.57}{0.57 + 0.032} = \\frac{0.57}{0.602} \\approx 0.947\\)\nThe filter is quite reliable!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#multiple-events-and-bayes",
    "href": "files/lecture_notes/lecture8/lecture8.html#multiple-events-and-bayes",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Multiple Events and Bayes‚Äô",
    "text": "Multiple Events and Bayes‚Äô\nExtended Bayes‚Äô Theorem: If \\(A_1, A_2, \\ldots, A_n\\) partition the sample space:\n\\[P(A_i|B) = \\frac{P(B|A_i) \\times P(A_i)}{\\sum_{j=1}^{n} P(B|A_j) \\times P(A_j)}\\]\nThis allows us to update probabilities for multiple hypotheses"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#three-machine-example-revisited",
    "href": "files/lecture_notes/lecture8/lecture8.html#three-machine-example-revisited",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Three Machine Example Revisited",
    "text": "Three Machine Example Revisited\nA defective item is found. Which machine most likely produced it?\nFrom before: - Machine A: 50% production, 1% defective\n- Machine B: 30% production, 2% defective - Machine C: 20% production, 3% defective - Overall defect rate: 1.7%"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#three-machine-solution",
    "href": "files/lecture_notes/lecture8/lecture8.html#three-machine-solution",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Three Machine Solution",
    "text": "Three Machine Solution\n\\[P(A|\\text{Defective}) = \\frac{0.01 \\times 0.5}{0.017} = \\frac{0.005}{0.017} \\approx 0.294\\]\n\\[P(B|\\text{Defective}) = \\frac{0.02 \\times 0.3}{0.017} = \\frac{0.006}{0.017} \\approx 0.353\\]\n\\[P(C|\\text{Defective}) = \\frac{0.03 \\times 0.2}{0.017} = \\frac{0.006}{0.017} \\approx 0.353\\]\n\nMachine B or C are most likely sources of the defective item"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-6",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-6",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 6",
    "text": "Practice Problem 6\nThree boxes contain colored balls: - Box 1: 3 red, 2 blue (chosen 40% of time) - Box 2: 2 red, 3 blue (chosen 35% of time)\n- Box 3: 1 red, 4 blue (chosen 25% of time)\nA red ball is drawn. Which box was it most likely from?\n\n\\(P(\\text{Red}) = \\frac{3}{5} \\times 0.4 + \\frac{2}{5} \\times 0.35 + \\frac{1}{5} \\times 0.25 = 0.24 + 0.14 + 0.05 = 0.43\\)\n\\(P(\\text{Box 1 | Red}) = \\frac{0.6 \\times 0.4}{0.43} \\approx 0.558\\) \\(P(\\text{Box 2 | Red}) = \\frac{0.4 \\times 0.35}{0.43} \\approx 0.326\\)\n\\(P(\\text{Box 3 | Red}) = \\frac{0.2 \\times 0.25}{0.43} \\approx 0.116\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#conditional-independence",
    "href": "files/lecture_notes/lecture8/lecture8.html#conditional-independence",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Conditional Independence",
    "text": "Conditional Independence\nEvents A and B are conditionally independent given C if:\n\\[P(A \\cap B | C) = P(A|C) \\times P(B|C)\\]\nImportant: Conditional independence doesn‚Äôt imply independence!\n\nExample: Weather in two cities may be independent normally, but conditionally dependent given a major weather system"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#simpsons-paradox",
    "href": "files/lecture_notes/lecture8/lecture8.html#simpsons-paradox",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Simpson‚Äôs Paradox",
    "text": "Simpson‚Äôs Paradox\nSimpson‚Äôs Paradox: A trend in subgroups can reverse when groups are combined\nClassic Example: University admissions by gender\n\n\n\n\nMen\nWomen\n\n\n\n\nDept A\n62% (825/1327)\n82% (108/131)\n\n\nDept B\n63% (560/893)\n68% (25/37)\n\n\nOverall\n44% (1385/2220)\n30% (133/168)\n\n\n\nWomen have higher rates in each department but lower overall!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#common-fallacies",
    "href": "files/lecture_notes/lecture8/lecture8.html#common-fallacies",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Common Fallacies",
    "text": "Common Fallacies\n1. Confusion of the Inverse - Confusing \\(P(A|B)\\) with \\(P(B|A)\\) - ‚ÄúIf it rains, the ground is wet‚Äù ‚â† ‚ÄúIf the ground is wet, it rained‚Äù\n2. Base Rate Neglect\n- Ignoring prior probabilities - Medical test example\n3. Prosecutor‚Äôs Fallacy - \\(P(\\text{Evidence | Innocent}) \\neq P(\\text{Innocent | Evidence})\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#prosecutors-fallacy-example",
    "href": "files/lecture_notes/lecture8/lecture8.html#prosecutors-fallacy-example",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Prosecutor‚Äôs Fallacy Example",
    "text": "Prosecutor‚Äôs Fallacy Example\nDNA evidence matches defendant with probability 1 in a million for random person\nWrong reasoning: ‚ÄúProbability of innocence is 1 in a million‚Äù\nCorrect reasoning: Need to consider: - How many people could have committed the crime? - What‚Äôs the prior probability of guilt? - Possibility of lab error, planted evidence, etc."
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-7",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-7",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 7",
    "text": "Practice Problem 7\nQuality control: 5% of items are defective. A test detects 96% of defective items but has a 4% false positive rate.\n\nWhat‚Äôs the probability an item testing positive is actually defective?\nWhat‚Äôs the probability an item testing negative is actually good?\n\n\n\n\\(P(\\text{Defective | Positive}) = \\frac{0.96 \\times 0.05}{0.96 \\times 0.05 + 0.04 \\times 0.95} = \\frac{0.048}{0.086} \\approx 0.558\\)\n\\(P(\\text{Good | Negative}) = \\frac{0.96 \\times 0.95}{0.96 \\times 0.95 + 0.04 \\times 0.05} = \\frac{0.912}{0.914} \\approx 0.998\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#real-world-applications",
    "href": "files/lecture_notes/lecture8/lecture8.html#real-world-applications",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Real-World Applications",
    "text": "Real-World Applications\nMedical Screening: - Mammograms, COVID tests - Balancing sensitivity vs specificity\nMachine Learning: - Naive Bayes classifiers - Spam detection, recommendation systems\nFinance: - Credit scoring - Fraud detection\nLegal System: - DNA evidence interpretation - Probability of guilt/innocence"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#technology-and-tools",
    "href": "files/lecture_notes/lecture8/lecture8.html#technology-and-tools",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Technology and Tools",
    "text": "Technology and Tools\nCalculators: - Basic probability calculations - Watch for rounding errors\nSoftware: - R: conditional probability tables - Python: pandas for two-way tables - Excel: pivot tables for conditional analysis\nVisualization: - Tree diagrams\n- Contingency tables - Bayes networks"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#diagnostic-thinking",
    "href": "files/lecture_notes/lecture8/lecture8.html#diagnostic-thinking",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Diagnostic Thinking",
    "text": "Diagnostic Thinking\nQuestions to ask: 1. What information am I conditioning on? 2. How does this information change the probability? 3. What‚Äôs the base rate or prior probability? 4. Am I confusing \\(P(A|B)\\) with \\(P(B|A)\\)? 5. Are the events independent?"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#problem-solving-strategy",
    "href": "files/lecture_notes/lecture8/lecture8.html#problem-solving-strategy",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Problem-Solving Strategy",
    "text": "Problem-Solving Strategy\n\nIdentify the type: Direct conditional, Bayes‚Äô, or law of total probability?\nDefine events clearly: Use precise notation\nOrganize information: Two-way tables or tree diagrams\nCheck for independence: Does additional info matter?\nApply appropriate formula: Don‚Äôt forget denominators!\nVerify answer: Does it make intuitive sense?"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-8",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-8",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 8",
    "text": "Practice Problem 8\nA survey shows: - 70% of people like pizza - 60% of people like movies\n- 40% like both pizza and movies\n\nAre liking pizza and movies independent?\nWhat‚Äôs \\(P(\\text{Pizza | Movies})\\)?\nWhat‚Äôs \\(P(\\text{Movies | Pizza})\\)?"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#practice-problem-8-solutions",
    "href": "files/lecture_notes/lecture8/lecture8.html#practice-problem-8-solutions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Practice Problem 8 Solutions",
    "text": "Practice Problem 8 Solutions\n\nCheck independence: \\(P(\\text{Pizza}) \\times P(\\text{Movies}) = 0.7 \\times 0.6 = 0.42 \\neq 0.4\\) Not independent!\n\\(P(\\text{Pizza | Movies}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Movies})} = \\frac{0.4}{0.6} = \\frac{2}{3}\\)\n\\(P(\\text{Movies | Pizza}) = \\frac{P(\\text{Pizza} \\cap \\text{Movies})}{P(\\text{Pizza})} = \\frac{0.4}{0.7} = \\frac{4}{7}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#advanced-topics-preview",
    "href": "files/lecture_notes/lecture8/lecture8.html#advanced-topics-preview",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Advanced Topics Preview",
    "text": "Advanced Topics Preview\nMarkov Chains: - Sequences where future depends only on present - \\(P(X_{n+1} | X_n, X_{n-1}, \\ldots, X_1) = P(X_{n+1} | X_n)\\)\nBayesian Statistics: - Using Bayes‚Äô theorem for statistical inference - Updating beliefs with data\nInformation Theory: - Conditional entropy - Mutual information"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#historical-context",
    "href": "files/lecture_notes/lecture8/lecture8.html#historical-context",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Historical Context",
    "text": "Historical Context\nThomas Bayes (1701-1761): - Presbyterian minister and mathematician - Bayes‚Äô theorem published posthumously\nPierre-Simon Laplace (1749-1827): - Developed and popularized Bayesian methods - ‚ÄúProbability is nothing but common sense reduced to calculation‚Äù\nModern Applications: AI, machine learning, medical diagnosis, finance"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#common-student-questions",
    "href": "files/lecture_notes/lecture8/lecture8.html#common-student-questions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Common Student Questions",
    "text": "Common Student Questions\nQ: ‚ÄúHow do I know when to use Bayes‚Äô theorem?‚Äù A: When you want to ‚Äúreverse‚Äù a conditional probability\nQ: ‚ÄúWhy are medical test problems so counterintuitive?‚Äù\nA: Base rates matter more than we intuitively expect\nQ: ‚ÄúWhat‚Äôs the difference between independence and conditional independence?‚Äù A: Independence means no relationship; conditional independence means no relationship given specific information"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#key-formulas-summary",
    "href": "files/lecture_notes/lecture8/lecture8.html#key-formulas-summary",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Key Formulas Summary",
    "text": "Key Formulas Summary\n\nConditional Probability: \\(P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\)\nMultiplication Rule: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\nLaw of Total Probability: \\(P(A) = \\sum P(A|B_i) \\times P(B_i)\\)\nBayes‚Äô Theorem: \\(P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}\\)\nIndependence: \\(P(A|B) = P(A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#looking-ahead",
    "href": "files/lecture_notes/lecture8/lecture8.html#looking-ahead",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nNext lecture: Discrete Random Variables - Random variables as functions - Probability mass functions - Expected value and variance - Common discrete distributions (binomial, geometric, Poisson)\nConnection: Conditional probability is essential for understanding dependence in random variables"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#study-tips",
    "href": "files/lecture_notes/lecture8/lecture8.html#study-tips",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Study Tips",
    "text": "Study Tips\n\nPractice with real scenarios: Medical tests, quality control\nDraw diagrams: Tree diagrams and two-way tables\nCheck your intuition: Do answers make sense?\nMaster the basics: Conditional probability formula\nWatch for fallacies: Don‚Äôt confuse \\(P(A|B)\\) and \\(P(B|A)\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#final-thoughts",
    "href": "files/lecture_notes/lecture8/lecture8.html#final-thoughts",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nConditional probability is everywhere: - Updates beliefs with new information - Foundation of Bayesian thinking - Critical for proper statistical reasoning - Essential for machine learning and AI\n\nKey insight: Information changes probability - embrace this uncertainty!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#questions",
    "href": "files/lecture_notes/lecture8/lecture8.html#questions",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Questions?",
    "text": "Questions?\nOffice Hours: [Your office hours] Email: [Your email]\nNext Class: Discrete Random Variables\nRemember: Homework due [date]"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#bonus-monty-hall-problem",
    "href": "files/lecture_notes/lecture8/lecture8.html#bonus-monty-hall-problem",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bonus: Monty Hall Problem",
    "text": "Bonus: Monty Hall Problem\nThree doors: one has a car, two have goats 1. You choose a door 2. Host opens a door with a goat 3. Do you switch?\n\nAnswer: Yes! Switch! - \\(P(\\text{Car behind your door}) = \\frac{1}{3}\\) - \\(P(\\text{Car behind other remaining door}) = \\frac{2}{3}\\)\nConditional probability in action!"
  },
  {
    "objectID": "files/lecture_notes/lecture8/lecture8.html#bonus-birthday-paradox-connection",
    "href": "files/lecture_notes/lecture8/lecture8.html#bonus-birthday-paradox-connection",
    "title": "PSTAT 5A: Conditional Probabilities",
    "section": "Bonus: Birthday Paradox Connection",
    "text": "Bonus: Birthday Paradox Connection\nIn a room of 23 people, probability of shared birthday ‚âà 50%\nConditional approach: What‚Äôs \\(P(\\text{no match | first $k$ people have different birthdays})\\)?\nThis helps build intuition for why the probability grows so quickly!\nSurprising results often involve conditional probability!"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#sec-objectives",
    "href": "files/lecture_notes/lecture5/lecture5.html#sec-objectives",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Today‚Äôs Learning Objectives",
    "text": "Today‚Äôs Learning Objectives\nBy the end of this lecture, you will be able to:\n\nDefine probability and understand its basic properties\nIdentify sample spaces and events\nApply fundamental probability rules\nCalculate conditional probabilities"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#the-addition-rule",
    "href": "files/lecture_notes/lecture5/lecture5.html#the-addition-rule",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "The Addition Rule",
    "text": "The Addition Rule\nFor any two events \\(A\\) and \\(B\\):\n\n\\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\n\nWhy subtract \\(P(A \\cap B)\\)?\n\n\n\nSolution. We don‚Äôt want to double-count outcomes that are in both events"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#addition-rule-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#addition-rule-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Addition Rule Example",
    "text": "Addition Rule Example\n\n\n\n\nDrawing from a standard deck:\n\n\\(A\\): Drawing a heart \\(\\heartsuit\\) (\\(P(A) = \\frac{13}{52}\\))\n\\(B\\): Drawing a face card (\\(P(B) = \\frac{12}{52}\\))\nWhat‚Äôs \\(P(A \\cup B)\\) (heart OR face card)?"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\n\n\n\nüéØConditional probability is the probability of event \\(A\\) given that event \\(B\\) has occurred\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\nprovided \\(P(B) &gt; 0\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-interpretation",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-interpretation",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Interpretation",
    "text": "Conditional Probability Interpretation\n\\(P(A|B)\\) means:\n\nWe know event  \\(B\\) has occurred \nWhat‚Äôs the probability that \\(A\\) also occurred?\nWe ‚Äúrestrict‚Äù our sample space to only outcomes in \\(B\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#conditional-probability-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Conditional Probability Example",
    "text": "Conditional Probability Example\n\n\n\nDrawing a card from a standard deck:\n\n\\(A\\): Card is a heart \\(\\heartsuit\\)\n\\(B\\): Card is red\nQ: Find \\(P(A|B)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution. \\(P(A \\cap B) = P(\\text{heart}) = \\frac{13}{52}\\)\n\\(P(B) = P(\\text{red}) = \\frac{26}{52}\\)\n\\(P(A|B) = \\frac{13/52}{26/52} = \\frac{13}{26} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#independence",
    "href": "files/lecture_notes/lecture5/lecture5.html#independence",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\nüéØ Definition Events \\(A\\) and \\(B\\) are independent if:\n\\[P(A|B) = P(A)\\]\nor equivalently:\n\\[P(A \\cap B) = P(A) \\times P(B)\\]\n\n\nKnowing that \\(B\\) occurred doesn‚Äôt change the probability of \\(A\\)"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#independence-example",
    "href": "files/lecture_notes/lecture5/lecture5.html#independence-example",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Independence Example",
    "text": "Independence Example\n\nTwo coin flips:\n\n\\(A\\): First flip is heads\n\\(B\\): Second flip is heads\n\nQ: Are \\(A\\) and \\(B\\) independent?\n\n\n\nSolution. \\(P(A) = \\frac{1}{2}\\), \\(P(B) = \\frac{1}{2}\\)\n\\(P(A \\cap B) = P(\\text{HH}) = \\frac{1}{4}\\)\n\\(P(A) \\times P(B) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\)\nYes, they are independent!"
  },
  {
    "objectID": "files/lecture_notes/lecture5/lecture5.html#resources",
    "href": "files/lecture_notes/lecture5/lecture5.html#resources",
    "title": "PSTAT 5A: Introduction to Probability",
    "section": "Resources",
    "text": "Resources\n\nRead Chapter 3 in course textbook\nElements of Set Theory for Probability\nProbability Models and Axioms\nInteractive Set Theory & Conditional Probability"
  },
  {
    "objectID": "files/lecture_notes/lecture3/q3_worksheet.html#questions-.center",
    "href": "files/lecture_notes/lecture3/q3_worksheet.html#questions-.center",
    "title": "Linear Transformation Properties",
    "section": "Questions? {.center}",
    "text": "Questions? {.center}\nKey Concepts Covered:\n\nSummation notation and indexing\nLinear transformations\nProperties of means and variances\nStep-by-step mathematical proofs\n\nNext Steps:\n\nApply to real datasets\nExplore non-linear transformations\nPractice with different scaling factors"
  },
  {
    "objectID": "resources.html#week-2-introduction-to-probability",
    "href": "resources.html#week-2-introduction-to-probability",
    "title": "Course Resources",
    "section": "Week 2: Introduction to Probability",
    "text": "Week 2: Introduction to Probability"
  },
  {
    "objectID": "resources.html#understanding-uncertainty-through-statistics",
    "href": "resources.html#understanding-uncertainty-through-statistics",
    "title": "Course Resources",
    "section": "Understanding Uncertainty Through Statistics",
    "text": "Understanding Uncertainty Through Statistics\nThis week introduces fundamental concepts in probability theory, including sample spaces, events, conditional probability, independence, and Bayes‚Äô theorem. You‚Äôll learn to quantify uncertainty and make informed decisions with incomplete information."
  },
  {
    "objectID": "resources.html#week-3-data-visualization",
    "href": "resources.html#week-3-data-visualization",
    "title": "Course Resources",
    "section": "Week 3: Data Visualization",
    "text": "Week 3: Data Visualization\n\n\nüöß\n\n\nWeek 3: Statistical Analysis\n\n\nüìä\n\n\nStatistical Inference & Confidence Intervals (CI‚Äôs)\nWeek 3 will cover statistical inference,and confidence intervals. Materials will be posted by week 3."
  },
  {
    "objectID": "resources.html#week-4-statistical-analysis",
    "href": "resources.html#week-4-statistical-analysis",
    "title": "Course Resources",
    "section": "Week 4: Statistical Analysis",
    "text": "Week 4: Statistical Analysis\n\n\nüìä\n\n\nStatistical Inference & Confidence Intervals (CI‚Äôs)\nWeek 4 will cover statistical inference, and confidence intervals. Materials will be posted by week 4."
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html",
    "href": "files/resources/prob_cheat_sheet.html",
    "title": "Probability Rules Cheat Sheet",
    "section": "",
    "text": "Download PDF"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#basic-probability-concepts",
    "href": "files/resources/prob_cheat_sheet.html#basic-probability-concepts",
    "title": "Probability Rules Cheat Sheet",
    "section": "Basic Probability Concepts",
    "text": "Basic Probability Concepts\n\nProbability Definition: \\[P(A) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total number of outcomes}}\\]\nProperties: - \\(0 \\leq P(A) \\leq 1\\) - \\(P(\\emptyset) = 0\\) (impossible event) - \\(P(S) = 1\\) (certain event, where \\(S\\) is sample space)\n\n\nExample: Rolling a fair die, probability of getting an even number:\n\\[P(\\text{even}) = \\frac{3}{6} = \\frac{1}{2} = 0.5\\]\n\n\nPractice: What is the probability of drawing a face card from a standard deck?\nAnswer: \\(P(\\text{face card}) = \\frac{12}{52} = \\frac{3}{13}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#complement-rule",
    "href": "files/resources/prob_cheat_sheet.html#complement-rule",
    "title": "Probability Rules Cheat Sheet",
    "section": "Complement Rule",
    "text": "Complement Rule\n\nFormula: \\[P(A^c) = 1 - P(A)\\] Alternative notation: \\(P(A') = 1 - P(A)\\)\n\nExplanation: The probability that event \\(A\\) does not occur.\n\nIf the probability that Anya will graduate is 0.9, then the probability she will not graduate is:\n\\[P(\\text{not graduate}) = 1 - 0.9 = 0.1\\]\n\n\nIf \\(P(\\text{rain}) = 0.3\\), what is \\(P(\\text{no rain})\\)?\nAnswer: \\(P(\\text{no rain}) = 1 - 0.3 = 0.7\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#addition-rules",
    "href": "files/resources/prob_cheat_sheet.html#addition-rules",
    "title": "Probability Rules Cheat Sheet",
    "section": "Addition Rules",
    "text": "Addition Rules\n\nGeneral Addition Rule (For Any Two Events)\n\nFormula: \\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\]\n\nExplanation: We subtract \\(P(A \\cap B)\\) to avoid double-counting the overlap.\n\nIn a class of 24 students, 10 are girls, 11 are A students, and 6 are girls who are A students.\nProbability of selecting a girl or an A student:\n\\[P(\\text{girl or A}) = \\frac{10}{24} + \\frac{11}{24} - \\frac{6}{24} = \\frac{15}{24} = 0.625\\]\n\n\n\nAddition Rule for Mutually Exclusive Events\n\nFormula: \\[P(A \\cup B) = P(A) + P(B)\\] Condition: \\(P(A \\cap B) = 0\\) (events cannot occur simultaneously)\n\n\nProbability of rolling a 2 or 6 on a die:\n\\[P(2 \\text{ or } 6) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6} = 0.333\\]\n\n\nA bag contains 4 red, 3 blue, and 2 green marbles. What‚Äôs the probability of drawing a red or green marble?\nAnswer: \\(P(\\text{red or green}) = \\frac{4}{9} + \\frac{2}{9} = \\frac{6}{9} = \\frac{2}{3}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#multiplication-rules",
    "href": "files/resources/prob_cheat_sheet.html#multiplication-rules",
    "title": "Probability Rules Cheat Sheet",
    "section": "Multiplication Rules",
    "text": "Multiplication Rules\n\nMultiplication Rule for Dependent Events\n\nFormula: \\[P(A \\cap B) = P(A) \\times P(B|A)\\] Alternative: \\(P(A \\cap B) = P(B) \\times P(A|B)\\)\n\n\nDrawing two red cards without replacement from a standard deck:\n\\[P(\\text{red and red}) = \\frac{26}{52} \\times \\frac{25}{51} = 0.245\\]\n\n\n\nMultiplication Rule for Independent Events\n\nFormula: \\[P(A \\cap B) = P(A) \\times P(B)\\] Condition: Events are independent if \\(P(A|B) = P(A)\\)\n\n\nDrawing two red cards with replacement:\n\\[P(\\text{red and red}) = \\frac{26}{52} \\times \\frac{26}{52} = 0.25\\]\n\n\nTwo fair coins are flipped. What‚Äôs the probability of getting two heads?\nAnswer: \\(P(HH) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#conditional-probability",
    "href": "files/resources/prob_cheat_sheet.html#conditional-probability",
    "title": "Probability Rules Cheat Sheet",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nFormula: \\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\] Condition: \\(P(B) &gt; 0\\)\n\nExplanation: The probability of event \\(A\\) occurring given that event \\(B\\) has occurred.\n\nIn a group of 100 people, 60 are employed and 40 are unemployed. Of the employed, 45 are satisfied with their job.\nWhat‚Äôs the probability someone is satisfied given they are employed?\n\\[P(\\text{satisfied} | \\text{employed}) = \\frac{45}{60} = 0.75\\]\n\n\nA card is drawn from a deck. Given that it‚Äôs red, what‚Äôs the probability it‚Äôs a heart?\nAnswer: \\(P(\\text{heart} | \\text{red}) = \\frac{13}{26} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "files/resources/prob_cheat_sheet.html#set-operations-and-probability",
    "href": "files/resources/prob_cheat_sheet.html#set-operations-and-probability",
    "title": "Probability Rules Cheat Sheet",
    "section": "Set Operations and Probability",
    "text": "Set Operations and Probability\n\nUnion (OR): - Symbol: \\(A \\cup B\\) - Meaning: Event \\(A\\) OR event \\(B\\) (or both) occurs - Formula: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\n\nIntersection (AND): - Symbol: \\(A \\cap B\\) - Meaning: Both events \\(A\\) AND \\(B\\) occur - Formula: \\(P(A \\cap B) = P(A) \\times P(B|A)\\)\n\n\nComplement (NOT): - Symbol: \\(A^c\\) or \\(A'\\) - Meaning: Event \\(A\\) does NOT occur - Formula: \\(P(A^c) = 1 - P(A)\\)"
  }
]