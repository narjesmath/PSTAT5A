---
title: "PSTAT 5A: Conditional Probability Continued & Bayes’ Theorem"
subtitle: "Lecture 6"
author: "Narjes Mathlouthi"
date: today
format: 
  revealjs:
    logo: /img/logo.png
    theme: default
    css: /files/lecture_notes/theme/lecture-styles.css
    slide-number: true
    chalkboard: true
    preview-links: auto
    footer: "Understanding Data - Conditional Probability © 2025 Narjes Mathlouthi"
    transition: slide
    background-transition: fade
jupyter: pstat5a
---


## Today's Learning Objectives {#sec-objectives .smaller}


By the end of this lecture, you will be able to:

- [Define probability and understand its basic properties](#sec-prob)
- [Identify sample spaces and events](#sample-space)
- [Apply fundamental probability rules](#set-operations-overview)
- [Calculate conditional probabilities](#conditional-probability)
- [Determine when events are independent](#independence)
- [Use Bayes' theorem in simple applications](#bayes-theorem)

---

## Mutually Exclusive vs. Independent {.smaller}

- **Mutually Exclusive (left):** the circles A and B do not overlap, so $P(A\cap B)=0$.

- **Independent (right):** the circles overlap, and we’ve sized the intersection so that $P(A\cap B)=P(A)\,P(B)$.


```{python}

from matplotlib import pyplot as plt
from matplotlib_venn import venn2

# Create side-by-side Venn diagrams
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# 1) Mutually Exclusive: no overlap
venn2(
    subsets=(1, 1, 0),
    set_labels=('A', 'B'),
    ax=axes[0],
    subset_label_formatter=lambda x: ''
)
axes[0].set_title('Mutually Exclusive\nP(A∩B) = 0')

# 2) Independent: overlap equals product of areas (e.g., 0.5 * 0.5 = 0.25)
# Scale counts arbitrarily (25, 25, 25) to represent proportions
venn2(
    subsets=(25, 25, 25),
    set_labels=('A', 'B'),
    ax=axes[1],
    subset_label_formatter=lambda x: ''
)
axes[1].set_title('Independent\nP(A∩B) = P(A)P(B)')

plt.tight_layout()
plt.show()

```

---

## Mutually Exclusive vs. Independent Example {.smaller}

:::{.columns}
:::{.column}
:::{.example}
Draw a single card from a 52-card deck:

- Let A={“draw an Ace”}, so P(A)=4/52.

- Let B={“draw a King”}, so P(B)=4/52.

**Q: What is $P(A\cap B)$ ?**

![](/files/lecture_notes/lecture4/img/cards.png)
:::
:::

:::{.column}


:::{.fragment}
:::{.solution}
They’re disjoint (you can’t draw an Ace and a King), so
$P(A\cap B) = 0$.

But
$P(A)\,P(B) = \frac{4}{52}\times\frac{4}{52} = \frac{16}{2704} \neq 0$.

Hence, $P(A\cap B)\neq P(A)P(B)$, so they’re not independent.
:::
:::


:::
:::
___

## Multiplication Rule

**General case**: $P(A \cap B) = P(A) \times P(B|A)$

**Independent events**: $P(A \cap B) = P(A) \times P(B)$

```{python}
from matplotlib import pyplot as plt
from matplotlib_venn import venn2

# Define scaled subset sizes for illustration
# General case: P(A)=40 (10+30), P(B|A)=0.75 so intersection=30, B-only=20 (if P(B)=50)
# Independent case: P(A)=40, P(B)=50, intersection=P(A)*P(B)=20
general_subsets = (10, 20, 30)   # (A-only, B-only, intersection)
indep_subsets = (20, 30, 20)

fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# --- General Multiplication Rule ---
venn2(subsets=general_subsets, set_labels=('A', 'B'), ax=axes[0])
axes[0].set_title('General: P(A∩B) = P(A)·P(B|A)', fontsize=14)

# --- Independent Events ---
venn2(subsets=indep_subsets, set_labels=('A', 'B'), ax=axes[1])
axes[1].set_title('Independent: P(A∩B) = P(A)·P(B)', fontsize=14)

plt.tight_layout()
plt.show()


```

---

## Tree Diagrams{.smaller}

::: {.definition}
**🎯 Definition**
Tree diagrams help visualize sequential events and calculate probabilities.
:::

```{python}
import matplotlib.pyplot as plt
from matplotlib.patches import Circle, FancyArrowPatch

# Coordinates for nodes
coords = {
    'root': (0.1, 0.5),
    'A': (0.4, 0.7),
    'B': (0.4, 0.3),
    'A_Red': (0.7, 0.8),
    'A_Blue': (0.7, 0.6),
    'B_Red': (0.7, 0.4),
    'B_Blue': (0.7, 0.2),
}

# Probabilities
p_A = 0.7
p_B = 0.3
p_R_A = 0.6
p_B_A = 0.4
p_R_B = 0.3
p_B_B = 0.7

# Create figure
fig, ax = plt.subplots(figsize=(8, 6))
ax.set_xlim(0, 1)
ax.set_ylim(0, 1)
ax.axis('off')

# Draw nodes
for node, (x, y) in coords.items():
    circle = Circle((x, y), 0.05, edgecolor='black', facecolor='white', linewidth=2)
    ax.add_patch(circle)
    label = node.replace('_', '\n')
    if node == 'root':
        label = 'Start'
    ax.text(x, y, label, ha='center', va='center', fontsize=12, fontweight='bold')

# Draw arrows and annotate probabilities
def draw_branch(start, end, text):
    x1, y1 = coords[start]
    x2, y2 = coords[end]
    arrow = FancyArrowPatch((x1+0.05, y1), (x2-0.05, y2), arrowstyle='->', mutation_scale=20)
    ax.add_patch(arrow)
    ax.text((x1+x2)/2, (y1+y2)/2, text, fontsize=12, backgroundcolor='white', ha='center')

draw_branch('root', 'A', f'{p_A}')
draw_branch('root', 'B', f'{p_B}')
draw_branch('A', 'A_Red', f'{p_R_A}')
draw_branch('A', 'A_Blue', f'{p_B_A}')
draw_branch('B', 'B_Red', f'{p_R_B}')
draw_branch('B', 'B_Blue', f'{p_B_B}')

# Title
ax.set_title('Tree Diagram: Drawing from Urn A (70%) or B (30%)', fontsize=14, pad=20)

plt.show()
```



---

## Tree Diagram Examples {.smaller}
:::{.columns}
:::{.column}

```{python}

import matplotlib.pyplot as plt
from matplotlib.patches import Circle, FancyArrowPatch

# Coordinates for nodes in the full tree
coords = {
    'root':       (0.1, 0.5),
    'A':          (0.35, 0.75),
    'NotA':       (0.35, 0.25),
    'A_B':        (0.7, 0.8),
    'A_notB':     (0.7, 0.65),
    'NotA_B':     (0.7, 0.35),
    'NotA_notB':  (0.7, 0.2)
}

# Probabilities (example values)
pA     = 0.4
pNotA  = 0.6
pB_A   = 0.75
pNotB_A= 0.25
pB_notA= 0.333
pNotB_notA=0.667

# Colors
color_intersection = '#1f77b4'  # blue
color_B            = '#ff7f0e'  # orange
gray               = 'lightgray'

def draw_tree(highlight_branches, branch_color, node_to_color):
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')

    # Draw nodes
    node_patches = {}
    for node, (x, y) in coords.items():
        circ = Circle((x, y), 0.035, edgecolor='black', facecolor='white', lw=2)
        ax.add_patch(circ)
        node_patches[node] = circ
        label = {
            'root': 'Start',
            'A': 'A',
            'NotA': '¬A',
            'A_B': 'B',
            'A_notB': '¬B',
            'NotA_B': 'B',
            'NotA_notB': '¬B'
        }[node]
        ax.text(x, y, label, ha='center', va='center', fontsize=12)

    # Function to draw a branch
    def draw_branch(start, end, text, color, lw=1.5):
        x1, y1 = coords[start]
        x2, y2 = coords[end]
        arr = FancyArrowPatch((x1+0.035, y1), (x2-0.035, y2),
                              arrowstyle='-|>', mutation_scale=15,
                              lw=lw, color=color)
        ax.add_patch(arr)
        ax.text((x1+x2)/2, (y1+y2)/2, text, ha='center', va='center',
                backgroundcolor='white', fontsize=10)

    # Draw all branches in gray
    branches = [
        ('root','A', f'{pA}'),
        ('root','NotA', f'{pNotA}'),
        ('A','A_B', f'{pB_A}'),
        ('A','A_notB', f'{pNotB_A}'),
        ('NotA','NotA_B', f'{pB_notA:.3f}'),
        ('NotA','NotA_notB', f'{pNotB_notA:.3f}')
    ]
    for b in branches:
        draw_branch(*b, color=gray)

    # Highlight requested branches
    for b in highlight_branches:
        # find text label for branch
        prob = {
            ('root','A'): f'{pA}',
            ('root','NotA'): f'{pNotA}',
            ('A','A_B'): f'{pB_A}',
            ('A','A_notB'): f'{pNotB_A}',
            ('NotA','NotA_B'): f'{pB_notA:.3f}',
            ('NotA','NotA_notB'): f'{pNotB_notA:.3f}'
        }[b]
        draw_branch(b[0], b[1], prob, color=branch_color, lw=3)
    
    # Color the end-node if desired
    for node in node_to_color:
        node_patches[node].set_facecolor(branch_color)

    return fig, ax

# Tree 1: highlight only the intersection branch root->A->A_B in blue
fig1, ax1 = draw_tree(highlight_branches=[('root','A'),('A','A_B')],
                      branch_color=color_intersection,
                      node_to_color=['A_B'])
ax1.set_title('Intersection Only (P(A∩B))', fontsize=14)
plt.show()



```
:::

:::{.column }
```{python}

# Tree 2: highlight both B branches (A->B and ¬A->B) in orange
fig2, ax2 = draw_tree(highlight_branches=[('root','A'),('A','A_B'),
                                          ('root','NotA'),('NotA','NotA_B')],
                      branch_color=color_B,
                      node_to_color=['A_B','NotA_B'])
ax2.set_title('Event B Only (P(B))', fontsize=14)
plt.show()

```
:::
:::




## Practice Problem 2{.smaller}

:::{.columns}
:::{.column}
:::{.example}
A jar contains 5 red balls and 3 blue balls. Two balls are drawn **without replacement**.

a) What's the probability both balls are red?

b) What's the probability the first is red and second is blue?
:::
:::

:::{.column}
:::{.fragment}

```{python}
import matplotlib.pyplot as plt
from matplotlib.patches import Circle
from matplotlib.lines import Line2D

# Set up figure
fig, ax = plt.subplots(figsize=(10, 6))
ax.axis('off')

# Node positions
positions = {
    'root': (0.1, 0.5),
    'R': (0.35, 0.7),
    'B': (0.35, 0.3),
    'RR': (0.7, 0.8),
    'RB': (0.7, 0.6),
    'BR': (0.7, 0.4),
    'BB': (0.7, 0.2),
}

# Define colors
color_root = '#ecf0f1'
color_R = '#e74c3c'       # red for R or RR
color_B = '#3498db'       # blue for B or BB
color_mixed = '#ff7f0e'   # orange for mixed (RB, BR)
edge_color = 'black'
linewidth = 2
text_fs = 12

# Draw nodes with colored backgrounds and bold labels
node_colors = {
    'root': color_root,
    'R': color_R,
    'B': color_B,
    'RR': color_R,
    'RB': color_mixed,
    'BR': color_mixed,
    'BB': color_B
}

for name, (x, y) in positions.items():
    circ = Circle((x, y), 0.05, facecolor=node_colors[name],
                  edgecolor=edge_color, linewidth=linewidth, zorder=2)
    ax.add_patch(circ)
    ax.text(x, y, name, ha='center', va='center', fontsize=text_fs, fontweight='bold', zorder=3)

# Function to draw an arrow and label
def draw_arrow(src, dst, label):
    x1, y1 = positions[src]
    x2, y2 = positions[dst]
    ax.annotate('', xy=(x2-0.05, y2), xytext=(x1+0.05, y1),
                arrowprops=dict(arrowstyle='->', color=node_colors[dst], lw=linewidth), zorder=1)
    ax.text((x1+x2)/2, (y1+y2)/2, label, ha='center', va='center',
            backgroundcolor='white', fontsize=text_fs, fontweight='bold', zorder=3)

# Draw branches with probabilities
draw_arrow('root', 'R', '5/8')
draw_arrow('root', 'B', '3/8')
draw_arrow('R', 'RR', '4/7')
draw_arrow('R', 'RB', '3/7')
draw_arrow('B', 'BR', '5/7')
draw_arrow('B', 'BB', '2/7')

# Label leaves with final probabilities in bold
leaf_probs = {
    'RR': '20/56',
    'RB': '15/56',
    'BR': '15/56',
    'BB': '6/56'
}
for leaf, prob in leaf_probs.items():
    x, y = positions[leaf]
    ax.text(x+0.12, y, prob, ha='left', va='center', fontsize=text_fs, fontweight='bold')

# Legend
legend_elements = [
    Line2D([0], [0], marker='o', color='w', label='RR / R',
           markerfacecolor=color_R, markersize=12, markeredgecolor=edge_color),
    Line2D([0], [0], marker='o', color='w', label='BB / B',
           markerfacecolor=color_B, markersize=12, markeredgecolor=edge_color),
    Line2D([0], [0], marker='o', color='w', label='RB / BR',
           markerfacecolor=color_mixed, markersize=12, markeredgecolor=edge_color),
]
ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(0.02, 0.95))

plt.tight_layout()
plt.show()

```

:::{.solution}
a) $P(\text{both red}) = \frac{5}{8} \times \frac{4}{7} = \frac{20}{56} = \frac{5}{14}$

b) $P(\text{red then blue}) = \frac{5}{8} \times \frac{3}{7} = \frac{15}{56}$
:::
:::
:::

:::
---

## Law of Total Probability {.smaller}

:::{.definition}
**🎯 Definition**

If events $B_1, B_2, \ldots, B_n$ form a partition of the sample space, then:

$$P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \cdots + P(A|B_n)P(B_n)$$
:::

```{python}

import matplotlib.pyplot as plt
from matplotlib.patches import Circle, Ellipse, Rectangle

# Example probabilities
P_B = [0.3, 0.5, 0.2]
P_A_given_B = [0.2, 0.6, 0.5]
P_A_and_B = [P_B[i] * P_A_given_B[i] for i in range(3)]

# Create figure
fig, ax = plt.subplots(figsize=(9, 5))
ax.set_aspect('equal')
ax.axis('off')

# Draw sample space rectangle
rect = Rectangle((-1, -2), width=8, height=4, edgecolor='black', facecolor='none', linewidth=2)
ax.add_patch(rect)
ax.text(-0.9, 1.7, r'$\Omega$', fontsize=14, fontweight='bold', va='top', ha='left')

# Draw B partitions as circles
positions_B = [(1, 0), (3, 0), (5, 0)]
colors_B = ['#ffcc00', '#ff6600', '#ff0066']

for i, (x, y) in enumerate(positions_B):
    circle = Circle((x, y), radius=1, facecolor=colors_B[i], edgecolor='black', alpha=0.3)
    ax.add_patch(circle)
    ax.text(x, y-1.3, f'$P(B_{i+1})={P_B[i]:.2f}$', ha='center', va='center', fontsize=12, fontweight='bold')

# Draw A as a large ellipse overlapping all B's
ellipse = Ellipse((3, 0), width=8, height=3, angle=0, facecolor='#1f77b4', edgecolor='black', alpha=0.2)
ax.add_patch(ellipse)
ax.text(3, 1.2, '$A$', ha='center', va='center', fontsize=14, fontweight='bold')

# Annotate intersections P(A ∩ Bi)
for i, (x, y) in enumerate(positions_B):
    ax.text(x, 0, f'$P(A\\cap B_{i+1})={P_A_and_B[i]:.2f}$', ha='center', va='center', fontsize=12, color='black', fontweight='bold')

ax.set_xlim(-1, 7)
ax.set_ylim(-2, 2)
plt.show()

```

---

## Law of Total Probability Example{.smaller}

:::{.example}

A factory has two machines:

- Machine 1: Produces 60% of items, 5% defective
  
- Machine 2: Produces 40% of items, 3% defective

**Q: What's the overall probability an item is defective?**
:::


:::{.fragment}
:::{.solution}

$P(\text{defective}) = P(D|M_1)P(M_1) + P(D|M_2)P(M_2)$ 

$= 0.05 \times 0.6 + 0.03 \times 0.4 = 0.03 + 0.012 = 0.042$
:::
:::

---

## Bayes' Theorem

::: {.definition}
**🎯 Definition**
$$P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}$$

This allows us to "reverse" conditional probabilities

*Named after Thomas Bayes (1701-1761)*

![](/files/lecture_notes/lecture4/img/bayes.gif){width="200" fig-align="right"}
:::




---

## Bayes' Theorem Components

- $A,B$: **Events**
- $P(A|B)$: **Posterior probability** - what we want to find
- $P(B|A)$: **Likelihood** - given $A$, probability of observing $B$
- $P(A)$: **Prior probability** - initial probability of $A$
- $P(B)$: **Marginal probability** - total probability of $B$

---

## Bayes' Theorem Example {.smaller}

:::{.columns}
:::{.column width ="40%"}
:::{.example}
**Medical test for a disease:** ^[$P(\neg D \,\wedge\, \text{Negative})
\;=\;P(\neg D)\times P(\text{Negative}\mid \neg D)
\;=\;0.99\times0.90
\;=\;0.891\;(89.1\%)$]

- Disease affects 1% of population
  
- Test is 95% accurate for sick people
  
- Test is 90% accurate for healthy people



**Q:If someone tests positive, what's the probability they have the disease?**

:::
:::

:::{.column width="60%"}

```{python}
import plotly.express as px
import pandas as pd

# Given probabilities
P_D = 0.01
P_notD = 0.99
P_pos_given_D = 0.95
P_pos_given_notD = 0.10

# Joint probabilities
P_D_and_pos = P_D * P_pos_given_D       # True positives
P_notD_and_pos = P_notD * P_pos_given_notD  # False positives
P_D_and_neg = P_D * (1 - P_pos_given_D)     # False negatives
P_notD_and_neg = P_notD * (1 - P_pos_given_notD)  # True negatives

# Prepare DataFrame for treemap (mosaic)
df = pd.DataFrame({
    'Test Result': ['Positive', 'Positive', 'Negative', 'Negative'],
    'Condition':   ['Disease',   'No Disease', 'Disease',   'No Disease'],
    'Probability': [P_D_and_pos, P_notD_and_pos, P_D_and_neg, P_notD_and_neg]
})

# Create treemap mosaic plot
fig = px.treemap(
    df,
    path=['Test Result', 'Condition'],
    values='Probability',
    color='Condition',
    color_discrete_map={'Disease':'tomato', 'No Disease':'skyblue'}
)
fig.update_traces(textinfo='label+percent entry')
fig.update_layout(
    title='Bayes’ Theorem: Distribution by Test Result and Condition',
    margin=dict(t=50, l=25, r=25, b=25)
)
fig.show()
```


:::
:::
---

## Bayes' Theorem Solution {.smaller}

Let:

- $D$: Person has disease
  
- $T^+$: Test is positive

Given:

- $P(D) = 0.01$
  
- $P(T^+|D) = 0.95$
  
- $P(T^-|D^c) = 0.90$, so $P(T^+|D^c) = 0.10$

:::{.fragment}
:::{.solution}
$P(T^+) = P(T^+|D)P(D) + P(T^+|D^c)P(D^c)$

$= 0.95 \times 0.01 + 0.10 \times 0.99 = 0.1085$
:::
:::

---

## Bayes' Theorem Solution (cont.) {.smaller}

$$P(D|T^+) = \frac{P(T^+|D) \times P(D)}{P(T^+)} = \frac{0.95 \times 0.01}{0.1085} \approx 0.088$$

```{python}
import matplotlib.pyplot as plt

# Posterior probabilities given a positive test
P_D_and_pos = 0.0095
P_notD_and_pos = 0.099
P_positive = P_D_and_pos + P_notD_and_pos

P_D_given_pos = P_D_and_pos / P_positive
P_notD_given_pos = P_notD_and_pos / P_positive

# Pie chart
labels = ['Disease (P≈8.8%)', 'No Disease (P≈91.2%)']
sizes = [P_D_given_pos, P_notD_given_pos]
colors = ['tomato', 'skyblue']

fig, ax = plt.subplots(figsize=(6, 6))
ax.pie(
    sizes, labels=labels, colors=colors, autopct='%.1f%%',
    startangle=90, textprops={'fontsize': 14, 'fontweight': 'bold'}
)
ax.set_title('Posterior Probability Given Positive Test', fontsize=16, fontweight='bold')
ax.axis('equal')  # Equal aspect ensures pie is circular.
plt.show()

```

:::{.fragment}
:::{.note}
**Surprising result**: Even with a positive test, there's only an 8.8% chance of having the disease!

*This is due to the low base rate of the disease*
:::
:::

---

## Common Probability Mistakes {.smaller}

- **Confusing $P(A|B)$ with $P(B|A)$**
   
:::{.note}
[Prosecutor's fallacy](https://en.wikipedia.org/wiki/Base_rate_fallacy) is a specific error in interpreting conditional probabilities.
Confusing 

$P(\text{Evidence}\mid\text{Innocent})
\quad\text{with}\quad
P(\text{Innocent}\mid\text{Evidence})$. 

Ex: OJ Simpson Case ^[the DNA evidence in the O. J. Simpson trial are a classic example of the prosecutor’s fallacy.  Prosecutors highlighted that the chance of a random person matching the crime-scene DNA was “one in 170 million,” then implied (or let the jury infer) that Simpson therefore had a 1 in 170 million chance of being innocent.]
:::


---

## Common Probability Mistakes {.smaller}

-  **Assuming independence when events are dependent**

-  **Ignoring base rates** (as in the medical test example)

:::{.note}
[Base rate fallacy](https://en.wikipedia.org/wiki/Base_rate_fallacy) is when you ignore or underweight the prior probability $P(H)$ of a hypothesis, focusing only on the new evidence $E$.
:::

-  **Double counting in union calculations**


---

## Practice Problem 3 {.smaller}
:::{.example}
Two fair dice are rolled. Find:

a) $P(\text{sum} = 7)$
b) $P(\text{sum} = 7 | \text{first die shows 3})$
c) Are these events independent?
:::

:::{.fragment}
:::{.solution}
a) 6 ways out of 36: $P(\text{sum} = 7) = \frac{6}{36} = \frac{1}{6}$

b) Given first die is 3, need second die to be 4: $P(\text{sum} = 7 | \text{first} = 3) = \frac{1}{6}$

c) Yes, they're independent since $P(A|B) = P(A)$
:::
:::


---

## Counting and Probability{.smaller}

:::{.definition}
Sometimes we need to count outcomes:

:::{.formula-box}
**Multiplication Principle**: If task 1 can be done in $m$ ways and task 2 in $n$ ways, both can be done in $m \times n$ ways
:::

:::{.formula-box}
**Permutations**: Arrangements where order matters
$$P(n,r) = \frac{n!}{(n-r)!}$$
:::

:::{.formula-box}
**Combinations**: Selections where order doesn't matter
$$C(n,r) = \binom{n}{r} = \frac{n!}{r!(n-r)!}$$
:::
:::
---

## Counting Example

:::{.example}
**Q: How many ways can you arrange 5 people in a row?**
:::

:::{.fragment}
:::{.solution}
This is a permutation: $P(5,5) = 5! = 120$ ways
:::
:::

---

:::{.fragment}
:::{.example}
**Q:How many ways can you choose 3 people from 5 for a committee?**
:::
:::

:::{.fragment}
:::{.solution}
This is a combination: $C(5,3) = \binom{5}{3} = \frac{5!}{3!2!} = 10$ ways
:::
:::

---

## Probability with Counting

:::{.example}
**Example**: A committee of 3 people is chosen from 8 people (5 women, 3 men). What's the probability all 3 are women?
:::

:::{.fragment}
:::{.solution}
Total ways to choose 3 from 8: $\binom{8}{3} = 56$

Ways to choose 3 women from 5: $\binom{5}{3} = 10$

Probability: $\frac{10}{56} = \frac{5}{28}$
:::
:::

---


## Real-World Applications

**Medical Diagnosis**: Using Bayes' theorem for test interpretation

**Quality Control**: Probability of defective items

**Finance**: Risk assessment and portfolio theory

**Sports**: Probability of wins, fantasy sports

**Insurance**: Calculating premiums based on risk

---

## Key Formulas Summary

:::{.formula-box}
- **Basic probability**: $P(A) = \frac{\text{favorable outcomes}}{\text{total outcomes}}$
- **Complement**: $P(A^c) = 1 - P(A)$
- **Addition**: $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
- **Conditional**: $P(A|B) = \frac{P(A \cap B)}{P(B)}$
- **Independence**: $P(A \cap B) = P(A) \times P(B)$
- **Bayes'**: $P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}$
:::

---

## Problem-Solving Strategy

:::{.note}
1. **Identify** the sample space and events
2. **Determine** if events are independent or mutually exclusive
3. **Choose** the appropriate rule or formula
4. **Calculate** step by step
5. **Check** if your answer makes sense
:::
---

## Practice Problem 4

:::{.example}
A bag contains 4 red, 3 blue, and 2 green marbles. Three marbles are drawn without replacement.

Find the probability that:
a) All three are red
b) No two are the same color
c) At least one is blue

:::
---

## Practice Problem 4 Solutions

:::{.solution}
a) All red: $\frac{4}{9} \times \frac{3}{8} \times \frac{2}{7} = \frac{24}{504} = \frac{1}{21}$

b) Different colors: $\frac{4 \times 3 \times 2}{9 \times 8 \times 7} \times 3! = \frac{24 \times 6}{504} = \frac{144}{504} = \frac{2}{7}$

c) At least one blue: $1 - P(\text{no blue}) = 1 - \frac{6 \times 5 \times 4}{9 \times 8 \times 7} = 1 - \frac{120}{504} = \frac{384}{504} = \frac{16}{21}$
:::
---

## Common Questions {.smaller}

:::{.example}
**Q1.**: **"Why isn't $P(A \cup B) = P(A) + P(B)$ always?"**

**A**: We'd double-count outcomes in both events

**Q2.**: **"How do I know if events are independent?"**

**A**: Check if $P(A|B) = P(A)$ or if $P(A \cap B) = P(A) \times P(B)$

**Q3.**: **"When do I use Bayes' theorem?"**

**A**: When you want to "reverse" a conditional probability

:::

:::{.note}
*Q3 note (Bayes Example)*

- Forward: I know my test picks up disease 95% of the time ⇒ $P(+\mid D)=0.95$.

- Reverse: I want the chance I really have the disease when the test is positive ⇒ $P(D\mid +)$.
:::
---

## Looking Ahead

**Next lecture**: 

- Random Variables and Probability Distributions
  
- Discrete vs. continuous random variables
  
- Expected value and variance
  



---

## Final Thoughts

:::{.note}
Probability is the foundation of statistics:

- Helps us quantify uncertainty
  
- Provides tools for making decisions with incomplete information
  
- Essential for understanding statistical inference
:::

:::{.fragment}
**Practice**: The key to mastering probability is working through many problems!
:::

## Questions? {.center}

**Office Hours**: Thursday's 11 AM On Zoom (Link on Canvas)

**Email**: nmathlouthi@ucsb.edu

**Next Class**: Random Variables and Distributions



---

## Resources

- [Read Chapter 3 in course textbook]((/files/Book/os4_for_screen_reader.pdf))
  
- [Elements of Set Theory for Probability](https://bookdown.org/daniel_flores_agreda/Prob1-GSEM-UNIGE/settheory.html#the-venn-diagram)

- [Probability Models and Axioms](https://ocw.mit.edu/courses/res-6-012-introduction-to-probability-spring-2018/resources/mitres_6_012s18_l01as/)